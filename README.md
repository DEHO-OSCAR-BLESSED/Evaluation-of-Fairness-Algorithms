# Evaluation-of-Fairness-Algorithms

Machine Learning (ML) systems have become widespread due to their powerful problem solving capabilities. However, it has been found that ML systems may be biased against certain demographic groups. Fair ML has thus gained a lot of attention in the last decade. The many fairness metrics and bias mitigation algorithms in the fair ML community is an evidence of how important fairness is. Unlike other domains such as criminal justice, it is only recently that attention has been paid to fairness in learning analytics. We still haven't seen the many available fairness algorithms being used in relevant real world situations. The context-dependency of fairness and the many evidence of incompatibilities between the various fairness metrics has been a challenge. In this work, we analyzed SOTA fairness algorithms on SOTA fairness-aware datasets and comparatively evaluated them using commonly used fairness and and performance metrics. 
