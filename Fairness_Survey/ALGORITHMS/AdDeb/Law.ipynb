{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Law.ipynb","provenance":[{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"authorship_tag":"ABX9TyMtag1KDyrd5W4enccyou3N"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5qYRG8zufHw","executionInfo":{"status":"ok","timestamp":1629957942209,"user_tz":-570,"elapsed":14113,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"8b477c07-3678-42e1-ecf8-a682cd4ff4ef"},"source":["!pip install aif360\n","!pip install fairlearn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting aif360\n","  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 5.0 MB/s \n","\u001b[?25hCollecting tempeh\n","  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n","Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.3.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n","Collecting memory-profiler\n","  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 45.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.10.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (21.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.8.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.62.0)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.34.0)\n","Building wheels for collected packages: memory-profiler, shap\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=53b03263be588efab9e593d0c9f333c34f0714b3c86dd89bf02f8a64f6e8577c\n","  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491651 sha256=35e5bc49b33435417fcc11be8fbf29e0fbd636c9ba07fe922740ce1eb5c3fc74\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built memory-profiler shap\n","Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n","Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n","Collecting fairlearn\n","  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n","Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\n","Installing collected packages: fairlearn\n","Successfully installed fairlearn-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TltW3iPkux0Q","executionInfo":{"status":"ok","timestamp":1629957943150,"user_tz":-570,"elapsed":977,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"0797d935-f0ce-48fa-e411-2c056a5df2fb"},"source":["!apt-get install -jre\n","!java -version"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Command line option 'j' [from -jre] is not understood in combination with the other options.\n","openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KssrNl8GvDYU","executionInfo":{"status":"ok","timestamp":1629957973665,"user_tz":-570,"elapsed":30521,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"dc9dbb2c-2d6c-4b5f-b037-7b0b08240e0f"},"source":["!pip install h2o"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting h2o\n","  Downloading h2o-3.32.1.6.tar.gz (168.4 MB)\n","\u001b[K     |████████████████████████████████| 168.4 MB 54 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n","Collecting colorama>=0.3.8\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2021.5.30)\n","Building wheels for collected packages: h2o\n","  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for h2o: filename=h2o-3.32.1.6-py2.py3-none-any.whl size=168439194 sha256=34e5eb1f6ed33ef4db37f13cc3c3d89ed80f3492417d535271e73f73ddc19af5\n","  Stored in directory: /root/.cache/pip/wheels/ee/0f/51/849ba221c4c1b11a04efb4a3427dc9cb1c4dcde218c6c98b13\n","Successfully built h2o\n","Installing collected packages: colorama, h2o\n","Successfully installed colorama-0.4.4 h2o-3.32.1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NQn2JJ0uw6u","executionInfo":{"status":"ok","timestamp":1629957977009,"user_tz":-570,"elapsed":3350,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"145bd992-4cd4-4970-93a5-df61da60478a"},"source":["!pip install xlsxwriter"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n","\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 148 kB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0YklbHpAxd8","executionInfo":{"status":"ok","timestamp":1629957982413,"user_tz":-570,"elapsed":5420,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"e86f438c-6bbc-427a-ce6c-dd5287887407"},"source":["!pip install BlackBoxAuditing"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting BlackBoxAuditing\n","  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->BlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n","Building wheels for collected packages: BlackBoxAuditing\n","  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394771 sha256=f88e157e3f18414873bcdd5f948f5e6a0bf8d8fb833c04cd4a70af58a25678c8\n","  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n","Successfully built BlackBoxAuditing\n","Installing collected packages: BlackBoxAuditing\n","Successfully installed BlackBoxAuditing-0.1.54\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","metadata":{"id":"rf1aISz6vGfR","executionInfo":{"status":"ok","timestamp":1629958443448,"user_tz":-570,"elapsed":478,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover, MetaFairClassifier, AdversarialDebiasing\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","import h2o\n","from h2o.automl import H2OAutoML\n","from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"RcxQeeX7vUXz","executionInfo":{"status":"ok","timestamp":1629958444171,"user_tz":-570,"elapsed":441,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"3fdc4bfa-5784-40fd-cd01-8ee7229e22b9"},"source":["h2o.init()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n","<td>7 mins 27 secs</td></tr>\n","<tr><td>H2O_cluster_timezone:</td>\n","<td>Etc/UTC</td></tr>\n","<tr><td>H2O_data_parsing_timezone:</td>\n","<td>UTC</td></tr>\n","<tr><td>H2O_cluster_version:</td>\n","<td>3.32.1.6</td></tr>\n","<tr><td>H2O_cluster_version_age:</td>\n","<td>6 days </td></tr>\n","<tr><td>H2O_cluster_name:</td>\n","<td>H2O_from_python_unknownUser_mb6hzv</td></tr>\n","<tr><td>H2O_cluster_total_nodes:</td>\n","<td>1</td></tr>\n","<tr><td>H2O_cluster_free_memory:</td>\n","<td>3.172 Gb</td></tr>\n","<tr><td>H2O_cluster_total_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_allowed_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_status:</td>\n","<td>locked, healthy</td></tr>\n","<tr><td>H2O_connection_url:</td>\n","<td>http://localhost:54321</td></tr>\n","<tr><td>H2O_connection_proxy:</td>\n","<td>{\"http\": null, \"https\": null}</td></tr>\n","<tr><td>H2O_internal_security:</td>\n","<td>False</td></tr>\n","<tr><td>H2O_API_Extensions:</td>\n","<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n","<tr><td>Python_version:</td>\n","<td>3.7.11 final</td></tr></table></div>"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O_cluster_uptime:         7 mins 27 secs\n","H2O_cluster_timezone:       Etc/UTC\n","H2O_data_parsing_timezone:  UTC\n","H2O_cluster_version:        3.32.1.6\n","H2O_cluster_version_age:    6 days\n","H2O_cluster_name:           H2O_from_python_unknownUser_mb6hzv\n","H2O_cluster_total_nodes:    1\n","H2O_cluster_free_memory:    3.172 Gb\n","H2O_cluster_total_cores:    2\n","H2O_cluster_allowed_cores:  2\n","H2O_cluster_status:         locked, healthy\n","H2O_connection_url:         http://localhost:54321\n","H2O_connection_proxy:       {\"http\": null, \"https\": null}\n","H2O_internal_security:      False\n","H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python_version:             3.7.11 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEGPULDrvk3g","executionInfo":{"status":"ok","timestamp":1629958478448,"user_tz":-570,"elapsed":34299,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"5adba066-bf46-4c69-800b-7016eccc1360"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# AdDeb\n"]},{"cell_type":"code","metadata":{"id":"ZavqYLLkE9VW","executionInfo":{"status":"ok","timestamp":1629958478449,"user_tz":-570,"elapsed":12,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["#initialize Tf\n","sess = tf.Session() #initialize Tf"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uN9VfZBAvxCj","executionInfo":{"status":"ok","timestamp":1629959531817,"user_tz":-570,"elapsed":1053379,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"4c44d33c-6053-4686-a00d-10690e0f9a19"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  Fitter= MM.fit(train)\n","  transformed_train=Fitter.transform(train)\n","  train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  #test normalization\n","  transformed_test=Fitter.transform(test)\n","  test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  #******************************** AdDeb Classifier regularizer*****************************\n","  \n","  sess.close() # This closse would close the previous iteration  and start a new session for the current iteration\n","  tf.reset_default_graph()\n","  sess = tf.Session()\n","  Classifier = AdversarialDebiasing(privileged_groups = advantagedGroup,\n","                          unprivileged_groups = disadvantagedGroup,\n","                          scope_name='debiased_classifier',\n","                          debias=True,\n","                          sess=sess)\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/AdDeb/AdDeb.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/AdDeb/AdDeb.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","epoch 0; iter: 0; batch classifier loss: 0.737988; batch adversarial loss: 0.887182\n","epoch 1; iter: 0; batch classifier loss: 0.316294; batch adversarial loss: 0.933988\n","epoch 2; iter: 0; batch classifier loss: 0.267255; batch adversarial loss: 0.782634\n","epoch 3; iter: 0; batch classifier loss: 0.235440; batch adversarial loss: 0.667969\n","epoch 4; iter: 0; batch classifier loss: 0.207436; batch adversarial loss: 0.601424\n","epoch 5; iter: 0; batch classifier loss: 0.299569; batch adversarial loss: 0.537233\n","epoch 6; iter: 0; batch classifier loss: 0.251476; batch adversarial loss: 0.482104\n","epoch 7; iter: 0; batch classifier loss: 0.285681; batch adversarial loss: 0.500987\n","epoch 8; iter: 0; batch classifier loss: 0.266400; batch adversarial loss: 0.525082\n","epoch 9; iter: 0; batch classifier loss: 0.247237; batch adversarial loss: 0.442851\n","epoch 10; iter: 0; batch classifier loss: 0.259198; batch adversarial loss: 0.380879\n","epoch 11; iter: 0; batch classifier loss: 0.260108; batch adversarial loss: 0.420837\n","epoch 12; iter: 0; batch classifier loss: 0.266614; batch adversarial loss: 0.407704\n","epoch 13; iter: 0; batch classifier loss: 0.324435; batch adversarial loss: 0.472253\n","epoch 14; iter: 0; batch classifier loss: 0.440002; batch adversarial loss: 0.500592\n","epoch 15; iter: 0; batch classifier loss: 0.179298; batch adversarial loss: 0.403929\n","epoch 16; iter: 0; batch classifier loss: 0.233017; batch adversarial loss: 0.402263\n","epoch 17; iter: 0; batch classifier loss: 0.194787; batch adversarial loss: 0.368372\n","epoch 18; iter: 0; batch classifier loss: 0.231195; batch adversarial loss: 0.383767\n","epoch 19; iter: 0; batch classifier loss: 0.208906; batch adversarial loss: 0.472924\n","epoch 20; iter: 0; batch classifier loss: 0.287946; batch adversarial loss: 0.516624\n","epoch 21; iter: 0; batch classifier loss: 0.244176; batch adversarial loss: 0.481549\n","epoch 22; iter: 0; batch classifier loss: 0.224146; batch adversarial loss: 0.406132\n","epoch 23; iter: 0; batch classifier loss: 0.383172; batch adversarial loss: 0.444517\n","epoch 24; iter: 0; batch classifier loss: 0.364161; batch adversarial loss: 0.474325\n","epoch 25; iter: 0; batch classifier loss: 0.223976; batch adversarial loss: 0.393892\n","epoch 26; iter: 0; batch classifier loss: 0.238863; batch adversarial loss: 0.347347\n","epoch 27; iter: 0; batch classifier loss: 0.234589; batch adversarial loss: 0.308996\n","epoch 28; iter: 0; batch classifier loss: 0.215778; batch adversarial loss: 0.343053\n","epoch 29; iter: 0; batch classifier loss: 0.255656; batch adversarial loss: 0.351384\n","epoch 30; iter: 0; batch classifier loss: 0.255506; batch adversarial loss: 0.358402\n","epoch 31; iter: 0; batch classifier loss: 0.203067; batch adversarial loss: 0.407274\n","epoch 32; iter: 0; batch classifier loss: 0.347796; batch adversarial loss: 0.329568\n","epoch 33; iter: 0; batch classifier loss: 0.211303; batch adversarial loss: 0.356569\n","epoch 34; iter: 0; batch classifier loss: 0.244240; batch adversarial loss: 0.475370\n","epoch 35; iter: 0; batch classifier loss: 0.279835; batch adversarial loss: 0.337172\n","epoch 36; iter: 0; batch classifier loss: 0.278115; batch adversarial loss: 0.433398\n","epoch 37; iter: 0; batch classifier loss: 0.308462; batch adversarial loss: 0.458084\n","epoch 38; iter: 0; batch classifier loss: 0.297019; batch adversarial loss: 0.368449\n","epoch 39; iter: 0; batch classifier loss: 0.333138; batch adversarial loss: 0.418861\n","epoch 40; iter: 0; batch classifier loss: 0.275304; batch adversarial loss: 0.365944\n","epoch 41; iter: 0; batch classifier loss: 0.327076; batch adversarial loss: 0.429358\n","epoch 42; iter: 0; batch classifier loss: 0.245939; batch adversarial loss: 0.385775\n","epoch 43; iter: 0; batch classifier loss: 0.244516; batch adversarial loss: 0.416464\n","epoch 44; iter: 0; batch classifier loss: 0.273187; batch adversarial loss: 0.434380\n","epoch 45; iter: 0; batch classifier loss: 0.312034; batch adversarial loss: 0.375644\n","epoch 46; iter: 0; batch classifier loss: 0.214937; batch adversarial loss: 0.400219\n","epoch 47; iter: 0; batch classifier loss: 0.248809; batch adversarial loss: 0.400887\n","epoch 48; iter: 0; batch classifier loss: 0.258340; batch adversarial loss: 0.455032\n","epoch 49; iter: 0; batch classifier loss: 0.251070; batch adversarial loss: 0.514227\n","Accuracy 0.899518238128011\n","epoch 0; iter: 0; batch classifier loss: 0.664188; batch adversarial loss: 1.056819\n","epoch 1; iter: 0; batch classifier loss: 0.349401; batch adversarial loss: 1.106238\n","epoch 2; iter: 0; batch classifier loss: 0.274883; batch adversarial loss: 0.936397\n","epoch 3; iter: 0; batch classifier loss: 0.341542; batch adversarial loss: 0.801739\n","epoch 4; iter: 0; batch classifier loss: 0.272845; batch adversarial loss: 0.675964\n","epoch 5; iter: 0; batch classifier loss: 0.319597; batch adversarial loss: 0.582018\n","epoch 6; iter: 0; batch classifier loss: 0.249840; batch adversarial loss: 0.530908\n","epoch 7; iter: 0; batch classifier loss: 0.180168; batch adversarial loss: 0.490955\n","epoch 8; iter: 0; batch classifier loss: 0.239288; batch adversarial loss: 0.474541\n","epoch 9; iter: 0; batch classifier loss: 0.251419; batch adversarial loss: 0.438827\n","epoch 10; iter: 0; batch classifier loss: 0.225668; batch adversarial loss: 0.432163\n","epoch 11; iter: 0; batch classifier loss: 0.215163; batch adversarial loss: 0.431551\n","epoch 12; iter: 0; batch classifier loss: 0.270744; batch adversarial loss: 0.379977\n","epoch 13; iter: 0; batch classifier loss: 0.303002; batch adversarial loss: 0.417692\n","epoch 14; iter: 0; batch classifier loss: 0.246074; batch adversarial loss: 0.427318\n","epoch 15; iter: 0; batch classifier loss: 0.251061; batch adversarial loss: 0.382024\n","epoch 16; iter: 0; batch classifier loss: 0.336192; batch adversarial loss: 0.438013\n","epoch 17; iter: 0; batch classifier loss: 0.328968; batch adversarial loss: 0.447370\n","epoch 18; iter: 0; batch classifier loss: 0.228029; batch adversarial loss: 0.320229\n","epoch 19; iter: 0; batch classifier loss: 0.270698; batch adversarial loss: 0.487213\n","epoch 20; iter: 0; batch classifier loss: 0.270439; batch adversarial loss: 0.367168\n","epoch 21; iter: 0; batch classifier loss: 0.274622; batch adversarial loss: 0.389798\n","epoch 22; iter: 0; batch classifier loss: 0.198005; batch adversarial loss: 0.406797\n","epoch 23; iter: 0; batch classifier loss: 0.315541; batch adversarial loss: 0.502896\n","epoch 24; iter: 0; batch classifier loss: 0.170497; batch adversarial loss: 0.404034\n","epoch 25; iter: 0; batch classifier loss: 0.308046; batch adversarial loss: 0.432277\n","epoch 26; iter: 0; batch classifier loss: 0.240017; batch adversarial loss: 0.419310\n","epoch 27; iter: 0; batch classifier loss: 0.172034; batch adversarial loss: 0.359121\n","epoch 28; iter: 0; batch classifier loss: 0.147200; batch adversarial loss: 0.422450\n","epoch 29; iter: 0; batch classifier loss: 0.316972; batch adversarial loss: 0.564185\n","epoch 30; iter: 0; batch classifier loss: 0.248529; batch adversarial loss: 0.311751\n","epoch 31; iter: 0; batch classifier loss: 0.196977; batch adversarial loss: 0.338226\n","epoch 32; iter: 0; batch classifier loss: 0.302141; batch adversarial loss: 0.409048\n","epoch 33; iter: 0; batch classifier loss: 0.257423; batch adversarial loss: 0.512241\n","epoch 34; iter: 0; batch classifier loss: 0.294521; batch adversarial loss: 0.392852\n","epoch 35; iter: 0; batch classifier loss: 0.284527; batch adversarial loss: 0.501854\n","epoch 36; iter: 0; batch classifier loss: 0.249545; batch adversarial loss: 0.412630\n","epoch 37; iter: 0; batch classifier loss: 0.266715; batch adversarial loss: 0.433046\n","epoch 38; iter: 0; batch classifier loss: 0.273378; batch adversarial loss: 0.448114\n","epoch 39; iter: 0; batch classifier loss: 0.258613; batch adversarial loss: 0.400885\n","epoch 40; iter: 0; batch classifier loss: 0.289436; batch adversarial loss: 0.357121\n","epoch 41; iter: 0; batch classifier loss: 0.232172; batch adversarial loss: 0.406747\n","epoch 42; iter: 0; batch classifier loss: 0.268845; batch adversarial loss: 0.408353\n","epoch 43; iter: 0; batch classifier loss: 0.194500; batch adversarial loss: 0.377257\n","epoch 44; iter: 0; batch classifier loss: 0.240213; batch adversarial loss: 0.453637\n","epoch 45; iter: 0; batch classifier loss: 0.172236; batch adversarial loss: 0.417742\n","epoch 46; iter: 0; batch classifier loss: 0.219148; batch adversarial loss: 0.450552\n","epoch 47; iter: 0; batch classifier loss: 0.235403; batch adversarial loss: 0.379216\n","epoch 48; iter: 0; batch classifier loss: 0.322220; batch adversarial loss: 0.359458\n","epoch 49; iter: 0; batch classifier loss: 0.264101; batch adversarial loss: 0.491823\n","Accuracy 0.8937586048646168\n","epoch 0; iter: 0; batch classifier loss: 0.673654; batch adversarial loss: 0.994397\n","epoch 1; iter: 0; batch classifier loss: 0.330850; batch adversarial loss: 1.214436\n","epoch 2; iter: 0; batch classifier loss: 0.217674; batch adversarial loss: 0.968189\n","epoch 3; iter: 0; batch classifier loss: 0.301369; batch adversarial loss: 0.819257\n","epoch 4; iter: 0; batch classifier loss: 0.247142; batch adversarial loss: 0.708753\n","epoch 5; iter: 0; batch classifier loss: 0.237465; batch adversarial loss: 0.618571\n","epoch 6; iter: 0; batch classifier loss: 0.181219; batch adversarial loss: 0.552076\n","epoch 7; iter: 0; batch classifier loss: 0.241258; batch adversarial loss: 0.500856\n","epoch 8; iter: 0; batch classifier loss: 0.361096; batch adversarial loss: 0.449802\n","epoch 9; iter: 0; batch classifier loss: 0.264495; batch adversarial loss: 0.433399\n","epoch 10; iter: 0; batch classifier loss: 0.242849; batch adversarial loss: 0.471668\n","epoch 11; iter: 0; batch classifier loss: 0.207995; batch adversarial loss: 0.420017\n","epoch 12; iter: 0; batch classifier loss: 0.290891; batch adversarial loss: 0.488071\n","epoch 13; iter: 0; batch classifier loss: 0.303562; batch adversarial loss: 0.462503\n","epoch 14; iter: 0; batch classifier loss: 0.314098; batch adversarial loss: 0.415119\n","epoch 15; iter: 0; batch classifier loss: 0.311672; batch adversarial loss: 0.410153\n","epoch 16; iter: 0; batch classifier loss: 0.215884; batch adversarial loss: 0.433565\n","epoch 17; iter: 0; batch classifier loss: 0.328200; batch adversarial loss: 0.365800\n","epoch 18; iter: 0; batch classifier loss: 0.286404; batch adversarial loss: 0.442982\n","epoch 19; iter: 0; batch classifier loss: 0.254720; batch adversarial loss: 0.426176\n","epoch 20; iter: 0; batch classifier loss: 0.315709; batch adversarial loss: 0.417208\n","epoch 21; iter: 0; batch classifier loss: 0.274418; batch adversarial loss: 0.446808\n","epoch 22; iter: 0; batch classifier loss: 0.251663; batch adversarial loss: 0.404791\n","epoch 23; iter: 0; batch classifier loss: 0.268891; batch adversarial loss: 0.430906\n","epoch 24; iter: 0; batch classifier loss: 0.363979; batch adversarial loss: 0.430892\n","epoch 25; iter: 0; batch classifier loss: 0.310556; batch adversarial loss: 0.375087\n","epoch 26; iter: 0; batch classifier loss: 0.269943; batch adversarial loss: 0.347168\n","epoch 27; iter: 0; batch classifier loss: 0.214445; batch adversarial loss: 0.487543\n","epoch 28; iter: 0; batch classifier loss: 0.294248; batch adversarial loss: 0.414194\n","epoch 29; iter: 0; batch classifier loss: 0.227401; batch adversarial loss: 0.414155\n","epoch 30; iter: 0; batch classifier loss: 0.316088; batch adversarial loss: 0.436494\n","epoch 31; iter: 0; batch classifier loss: 0.186856; batch adversarial loss: 0.409402\n","epoch 32; iter: 0; batch classifier loss: 0.273123; batch adversarial loss: 0.370536\n","epoch 33; iter: 0; batch classifier loss: 0.295039; batch adversarial loss: 0.381030\n","epoch 34; iter: 0; batch classifier loss: 0.285195; batch adversarial loss: 0.399460\n","epoch 35; iter: 0; batch classifier loss: 0.237501; batch adversarial loss: 0.342621\n","epoch 36; iter: 0; batch classifier loss: 0.257676; batch adversarial loss: 0.334350\n","epoch 37; iter: 0; batch classifier loss: 0.249043; batch adversarial loss: 0.370008\n","epoch 38; iter: 0; batch classifier loss: 0.188810; batch adversarial loss: 0.383711\n","epoch 39; iter: 0; batch classifier loss: 0.266012; batch adversarial loss: 0.437797\n","epoch 40; iter: 0; batch classifier loss: 0.287379; batch adversarial loss: 0.429784\n","epoch 41; iter: 0; batch classifier loss: 0.360763; batch adversarial loss: 0.433365\n","epoch 42; iter: 0; batch classifier loss: 0.317130; batch adversarial loss: 0.374408\n","epoch 43; iter: 0; batch classifier loss: 0.363271; batch adversarial loss: 0.437443\n","epoch 44; iter: 0; batch classifier loss: 0.408192; batch adversarial loss: 0.373611\n","epoch 45; iter: 0; batch classifier loss: 0.271810; batch adversarial loss: 0.368026\n","epoch 46; iter: 0; batch classifier loss: 0.209989; batch adversarial loss: 0.418946\n","epoch 47; iter: 0; batch classifier loss: 0.305713; batch adversarial loss: 0.333024\n","epoch 48; iter: 0; batch classifier loss: 0.331252; batch adversarial loss: 0.427157\n","epoch 49; iter: 0; batch classifier loss: 0.284818; batch adversarial loss: 0.491396\n","Accuracy 0.90110142267095\n","epoch 0; iter: 0; batch classifier loss: 0.726917; batch adversarial loss: 0.699841\n","epoch 1; iter: 0; batch classifier loss: 0.437049; batch adversarial loss: 0.617081\n","epoch 2; iter: 0; batch classifier loss: 0.319599; batch adversarial loss: 0.502948\n","epoch 3; iter: 0; batch classifier loss: 0.358466; batch adversarial loss: 0.506546\n","epoch 4; iter: 0; batch classifier loss: 0.291169; batch adversarial loss: 0.448990\n","epoch 5; iter: 0; batch classifier loss: 0.273637; batch adversarial loss: 0.422460\n","epoch 6; iter: 0; batch classifier loss: 0.322327; batch adversarial loss: 0.510825\n","epoch 7; iter: 0; batch classifier loss: 1.610865; batch adversarial loss: 0.666200\n","epoch 8; iter: 0; batch classifier loss: 2.102545; batch adversarial loss: 0.550262\n","epoch 9; iter: 0; batch classifier loss: 1.987851; batch adversarial loss: 0.550326\n","epoch 10; iter: 0; batch classifier loss: 2.325779; batch adversarial loss: 0.521689\n","epoch 11; iter: 0; batch classifier loss: 1.909586; batch adversarial loss: 0.534484\n","epoch 12; iter: 0; batch classifier loss: 0.433868; batch adversarial loss: 0.508266\n","epoch 13; iter: 0; batch classifier loss: 0.378376; batch adversarial loss: 0.454502\n","epoch 14; iter: 0; batch classifier loss: 0.259455; batch adversarial loss: 0.415192\n","epoch 15; iter: 0; batch classifier loss: 0.337712; batch adversarial loss: 0.362004\n","epoch 16; iter: 0; batch classifier loss: 0.441044; batch adversarial loss: 0.412378\n","epoch 17; iter: 0; batch classifier loss: 0.321072; batch adversarial loss: 0.426058\n","epoch 18; iter: 0; batch classifier loss: 0.300939; batch adversarial loss: 0.447242\n","epoch 19; iter: 0; batch classifier loss: 0.328021; batch adversarial loss: 0.446271\n","epoch 20; iter: 0; batch classifier loss: 0.192555; batch adversarial loss: 0.433284\n","epoch 21; iter: 0; batch classifier loss: 0.270539; batch adversarial loss: 0.378992\n","epoch 22; iter: 0; batch classifier loss: 0.347828; batch adversarial loss: 0.466172\n","epoch 23; iter: 0; batch classifier loss: 0.301943; batch adversarial loss: 0.434283\n","epoch 24; iter: 0; batch classifier loss: 0.186957; batch adversarial loss: 0.355669\n","epoch 25; iter: 0; batch classifier loss: 0.217998; batch adversarial loss: 0.497499\n","epoch 26; iter: 0; batch classifier loss: 0.248672; batch adversarial loss: 0.490370\n","epoch 27; iter: 0; batch classifier loss: 0.289687; batch adversarial loss: 0.389086\n","epoch 28; iter: 0; batch classifier loss: 0.302786; batch adversarial loss: 0.396841\n","epoch 29; iter: 0; batch classifier loss: 0.425473; batch adversarial loss: 0.484693\n","epoch 30; iter: 0; batch classifier loss: 0.322456; batch adversarial loss: 0.337662\n","epoch 31; iter: 0; batch classifier loss: 0.235089; batch adversarial loss: 0.465774\n","epoch 32; iter: 0; batch classifier loss: 0.258772; batch adversarial loss: 0.444688\n","epoch 33; iter: 0; batch classifier loss: 0.279892; batch adversarial loss: 0.379978\n","epoch 34; iter: 0; batch classifier loss: 0.322970; batch adversarial loss: 0.522111\n","epoch 35; iter: 0; batch classifier loss: 0.235815; batch adversarial loss: 0.348476\n","epoch 36; iter: 0; batch classifier loss: 0.182623; batch adversarial loss: 0.428486\n","epoch 37; iter: 0; batch classifier loss: 0.271432; batch adversarial loss: 0.397272\n","epoch 38; iter: 0; batch classifier loss: 0.345954; batch adversarial loss: 0.414110\n","epoch 39; iter: 0; batch classifier loss: 0.279513; batch adversarial loss: 0.327814\n","epoch 40; iter: 0; batch classifier loss: 0.213849; batch adversarial loss: 0.331071\n","epoch 41; iter: 0; batch classifier loss: 0.280545; batch adversarial loss: 0.452135\n","epoch 42; iter: 0; batch classifier loss: 0.185181; batch adversarial loss: 0.378354\n","epoch 43; iter: 0; batch classifier loss: 0.269087; batch adversarial loss: 0.447433\n","epoch 44; iter: 0; batch classifier loss: 0.327220; batch adversarial loss: 0.457670\n","epoch 45; iter: 0; batch classifier loss: 0.291290; batch adversarial loss: 0.411113\n","epoch 46; iter: 0; batch classifier loss: 0.370579; batch adversarial loss: 0.401008\n","epoch 47; iter: 0; batch classifier loss: 0.397327; batch adversarial loss: 0.478102\n","epoch 48; iter: 0; batch classifier loss: 0.227598; batch adversarial loss: 0.388559\n","epoch 49; iter: 0; batch classifier loss: 0.376567; batch adversarial loss: 0.385800\n","Accuracy 0.8864157870582836\n","epoch 0; iter: 0; batch classifier loss: 0.639518; batch adversarial loss: 0.760548\n","epoch 1; iter: 0; batch classifier loss: 0.312339; batch adversarial loss: 0.677838\n","epoch 2; iter: 0; batch classifier loss: 0.311244; batch adversarial loss: 0.570568\n","epoch 3; iter: 0; batch classifier loss: 0.339022; batch adversarial loss: 0.535747\n","epoch 4; iter: 0; batch classifier loss: 0.392472; batch adversarial loss: 0.474999\n","epoch 5; iter: 0; batch classifier loss: 0.625988; batch adversarial loss: 0.512240\n","epoch 6; iter: 0; batch classifier loss: 1.333524; batch adversarial loss: 0.578526\n","epoch 7; iter: 0; batch classifier loss: 1.397705; batch adversarial loss: 0.507245\n","epoch 8; iter: 0; batch classifier loss: 0.981164; batch adversarial loss: 0.532817\n","epoch 9; iter: 0; batch classifier loss: 0.407028; batch adversarial loss: 0.481926\n","epoch 10; iter: 0; batch classifier loss: 0.390853; batch adversarial loss: 0.437263\n","epoch 11; iter: 0; batch classifier loss: 0.262849; batch adversarial loss: 0.420255\n","epoch 12; iter: 0; batch classifier loss: 0.302940; batch adversarial loss: 0.367716\n","epoch 13; iter: 0; batch classifier loss: 0.259371; batch adversarial loss: 0.456000\n","epoch 14; iter: 0; batch classifier loss: 0.180761; batch adversarial loss: 0.358423\n","epoch 15; iter: 0; batch classifier loss: 0.239213; batch adversarial loss: 0.398060\n","epoch 16; iter: 0; batch classifier loss: 0.380238; batch adversarial loss: 0.482457\n","epoch 17; iter: 0; batch classifier loss: 0.340709; batch adversarial loss: 0.419453\n","epoch 18; iter: 0; batch classifier loss: 0.246096; batch adversarial loss: 0.344828\n","epoch 19; iter: 0; batch classifier loss: 0.190756; batch adversarial loss: 0.423123\n","epoch 20; iter: 0; batch classifier loss: 0.196719; batch adversarial loss: 0.370444\n","epoch 21; iter: 0; batch classifier loss: 0.211329; batch adversarial loss: 0.458731\n","epoch 22; iter: 0; batch classifier loss: 0.270059; batch adversarial loss: 0.399317\n","epoch 23; iter: 0; batch classifier loss: 0.241807; batch adversarial loss: 0.397923\n","epoch 24; iter: 0; batch classifier loss: 0.243279; batch adversarial loss: 0.394133\n","epoch 25; iter: 0; batch classifier loss: 0.309596; batch adversarial loss: 0.517742\n","epoch 26; iter: 0; batch classifier loss: 0.212951; batch adversarial loss: 0.460375\n","epoch 27; iter: 0; batch classifier loss: 0.309961; batch adversarial loss: 0.433057\n","epoch 28; iter: 0; batch classifier loss: 0.306765; batch adversarial loss: 0.417846\n","epoch 29; iter: 0; batch classifier loss: 0.221801; batch adversarial loss: 0.393000\n","epoch 30; iter: 0; batch classifier loss: 0.314122; batch adversarial loss: 0.322536\n","epoch 31; iter: 0; batch classifier loss: 0.312416; batch adversarial loss: 0.516326\n","epoch 32; iter: 0; batch classifier loss: 0.236648; batch adversarial loss: 0.550144\n","epoch 33; iter: 0; batch classifier loss: 0.273425; batch adversarial loss: 0.451236\n","epoch 34; iter: 0; batch classifier loss: 0.234115; batch adversarial loss: 0.418367\n","epoch 35; iter: 0; batch classifier loss: 0.174965; batch adversarial loss: 0.406791\n","epoch 36; iter: 0; batch classifier loss: 0.249919; batch adversarial loss: 0.442521\n","epoch 37; iter: 0; batch classifier loss: 0.236168; batch adversarial loss: 0.408943\n","epoch 38; iter: 0; batch classifier loss: 0.243673; batch adversarial loss: 0.315821\n","epoch 39; iter: 0; batch classifier loss: 0.218791; batch adversarial loss: 0.435617\n","epoch 40; iter: 0; batch classifier loss: 0.279576; batch adversarial loss: 0.423509\n","epoch 41; iter: 0; batch classifier loss: 0.203061; batch adversarial loss: 0.444127\n","epoch 42; iter: 0; batch classifier loss: 0.231485; batch adversarial loss: 0.420929\n","epoch 43; iter: 0; batch classifier loss: 0.309436; batch adversarial loss: 0.383012\n","epoch 44; iter: 0; batch classifier loss: 0.211727; batch adversarial loss: 0.335044\n","epoch 45; iter: 0; batch classifier loss: 0.281464; batch adversarial loss: 0.415327\n","epoch 46; iter: 0; batch classifier loss: 0.324904; batch adversarial loss: 0.446038\n","epoch 47; iter: 0; batch classifier loss: 0.264053; batch adversarial loss: 0.414708\n","epoch 48; iter: 0; batch classifier loss: 0.321090; batch adversarial loss: 0.456558\n","epoch 49; iter: 0; batch classifier loss: 0.262299; batch adversarial loss: 0.517078\n","Accuracy 0.8914639743001377\n","epoch 0; iter: 0; batch classifier loss: 0.683725; batch adversarial loss: 0.518789\n","epoch 1; iter: 0; batch classifier loss: 1.395846; batch adversarial loss: 0.676250\n","epoch 2; iter: 0; batch classifier loss: 1.599526; batch adversarial loss: 0.673527\n","epoch 3; iter: 0; batch classifier loss: 1.654161; batch adversarial loss: 0.551672\n","epoch 4; iter: 0; batch classifier loss: 1.068378; batch adversarial loss: 0.549675\n","epoch 5; iter: 0; batch classifier loss: 0.600947; batch adversarial loss: 0.493377\n","epoch 6; iter: 0; batch classifier loss: 0.576374; batch adversarial loss: 0.491397\n","epoch 7; iter: 0; batch classifier loss: 0.752482; batch adversarial loss: 0.483563\n","epoch 8; iter: 0; batch classifier loss: 0.674443; batch adversarial loss: 0.475780\n","epoch 9; iter: 0; batch classifier loss: 0.426111; batch adversarial loss: 0.395649\n","epoch 10; iter: 0; batch classifier loss: 0.261219; batch adversarial loss: 0.373174\n","epoch 11; iter: 0; batch classifier loss: 0.231624; batch adversarial loss: 0.462015\n","epoch 12; iter: 0; batch classifier loss: 0.353133; batch adversarial loss: 0.456332\n","epoch 13; iter: 0; batch classifier loss: 0.311161; batch adversarial loss: 0.396609\n","epoch 14; iter: 0; batch classifier loss: 0.255122; batch adversarial loss: 0.406505\n","epoch 15; iter: 0; batch classifier loss: 0.164772; batch adversarial loss: 0.325081\n","epoch 16; iter: 0; batch classifier loss: 0.308551; batch adversarial loss: 0.380952\n","epoch 17; iter: 0; batch classifier loss: 0.336212; batch adversarial loss: 0.488821\n","epoch 18; iter: 0; batch classifier loss: 0.240162; batch adversarial loss: 0.413467\n","epoch 19; iter: 0; batch classifier loss: 0.194408; batch adversarial loss: 0.406304\n","epoch 20; iter: 0; batch classifier loss: 0.301103; batch adversarial loss: 0.490695\n","epoch 21; iter: 0; batch classifier loss: 0.268336; batch adversarial loss: 0.380663\n","epoch 22; iter: 0; batch classifier loss: 0.221094; batch adversarial loss: 0.425682\n","epoch 23; iter: 0; batch classifier loss: 0.300924; batch adversarial loss: 0.322519\n","epoch 24; iter: 0; batch classifier loss: 0.258939; batch adversarial loss: 0.385780\n","epoch 25; iter: 0; batch classifier loss: 0.267879; batch adversarial loss: 0.405100\n","epoch 26; iter: 0; batch classifier loss: 0.281495; batch adversarial loss: 0.349371\n","epoch 27; iter: 0; batch classifier loss: 0.302417; batch adversarial loss: 0.430853\n","epoch 28; iter: 0; batch classifier loss: 0.264427; batch adversarial loss: 0.369094\n","epoch 29; iter: 0; batch classifier loss: 0.265245; batch adversarial loss: 0.431536\n","epoch 30; iter: 0; batch classifier loss: 0.246219; batch adversarial loss: 0.376505\n","epoch 31; iter: 0; batch classifier loss: 0.203280; batch adversarial loss: 0.360518\n","epoch 32; iter: 0; batch classifier loss: 0.238677; batch adversarial loss: 0.429554\n","epoch 33; iter: 0; batch classifier loss: 0.199966; batch adversarial loss: 0.393599\n","epoch 34; iter: 0; batch classifier loss: 0.168838; batch adversarial loss: 0.313989\n","epoch 35; iter: 0; batch classifier loss: 0.303971; batch adversarial loss: 0.368378\n","epoch 36; iter: 0; batch classifier loss: 0.223285; batch adversarial loss: 0.401684\n","epoch 37; iter: 0; batch classifier loss: 0.289556; batch adversarial loss: 0.432576\n","epoch 38; iter: 0; batch classifier loss: 0.260769; batch adversarial loss: 0.444342\n","epoch 39; iter: 0; batch classifier loss: 0.288449; batch adversarial loss: 0.420302\n","epoch 40; iter: 0; batch classifier loss: 0.277130; batch adversarial loss: 0.258809\n","epoch 41; iter: 0; batch classifier loss: 0.290862; batch adversarial loss: 0.391408\n","epoch 42; iter: 0; batch classifier loss: 0.246638; batch adversarial loss: 0.426130\n","epoch 43; iter: 0; batch classifier loss: 0.312315; batch adversarial loss: 0.471037\n","epoch 44; iter: 0; batch classifier loss: 0.170398; batch adversarial loss: 0.420212\n","epoch 45; iter: 0; batch classifier loss: 0.304214; batch adversarial loss: 0.335438\n","epoch 46; iter: 0; batch classifier loss: 0.296861; batch adversarial loss: 0.389698\n","epoch 47; iter: 0; batch classifier loss: 0.263620; batch adversarial loss: 0.392020\n","epoch 48; iter: 0; batch classifier loss: 0.321567; batch adversarial loss: 0.387419\n","epoch 49; iter: 0; batch classifier loss: 0.201884; batch adversarial loss: 0.356360\n","Accuracy 0.8908006423491627\n","epoch 0; iter: 0; batch classifier loss: 0.614085; batch adversarial loss: 0.426042\n","epoch 1; iter: 0; batch classifier loss: 1.387154; batch adversarial loss: 0.755962\n","epoch 2; iter: 0; batch classifier loss: 1.598919; batch adversarial loss: 0.756957\n","epoch 3; iter: 0; batch classifier loss: 1.734801; batch adversarial loss: 0.615763\n","epoch 4; iter: 0; batch classifier loss: 1.605009; batch adversarial loss: 0.558990\n","epoch 5; iter: 0; batch classifier loss: 0.987046; batch adversarial loss: 0.547285\n","epoch 6; iter: 0; batch classifier loss: 0.459137; batch adversarial loss: 0.487327\n","epoch 7; iter: 0; batch classifier loss: 0.305803; batch adversarial loss: 0.386792\n","epoch 8; iter: 0; batch classifier loss: 0.254333; batch adversarial loss: 0.380220\n","epoch 9; iter: 0; batch classifier loss: 0.265694; batch adversarial loss: 0.466401\n","epoch 10; iter: 0; batch classifier loss: 0.270198; batch adversarial loss: 0.531820\n","epoch 11; iter: 0; batch classifier loss: 0.290300; batch adversarial loss: 0.386658\n","epoch 12; iter: 0; batch classifier loss: 0.218650; batch adversarial loss: 0.416700\n","epoch 13; iter: 0; batch classifier loss: 0.194376; batch adversarial loss: 0.318197\n","epoch 14; iter: 0; batch classifier loss: 0.284801; batch adversarial loss: 0.490511\n","epoch 15; iter: 0; batch classifier loss: 0.421407; batch adversarial loss: 0.482311\n","epoch 16; iter: 0; batch classifier loss: 0.279621; batch adversarial loss: 0.370708\n","epoch 17; iter: 0; batch classifier loss: 0.200559; batch adversarial loss: 0.376584\n","epoch 18; iter: 0; batch classifier loss: 0.230627; batch adversarial loss: 0.425765\n","epoch 19; iter: 0; batch classifier loss: 0.258380; batch adversarial loss: 0.380915\n","epoch 20; iter: 0; batch classifier loss: 0.268199; batch adversarial loss: 0.438726\n","epoch 21; iter: 0; batch classifier loss: 0.280378; batch adversarial loss: 0.338383\n","epoch 22; iter: 0; batch classifier loss: 0.276661; batch adversarial loss: 0.348959\n","epoch 23; iter: 0; batch classifier loss: 0.254415; batch adversarial loss: 0.467154\n","epoch 24; iter: 0; batch classifier loss: 0.380758; batch adversarial loss: 0.478169\n","epoch 25; iter: 0; batch classifier loss: 0.205901; batch adversarial loss: 0.371256\n","epoch 26; iter: 0; batch classifier loss: 0.329141; batch adversarial loss: 0.309641\n","epoch 27; iter: 0; batch classifier loss: 0.239531; batch adversarial loss: 0.429008\n","epoch 28; iter: 0; batch classifier loss: 0.308929; batch adversarial loss: 0.421915\n","epoch 29; iter: 0; batch classifier loss: 0.275562; batch adversarial loss: 0.376331\n","epoch 30; iter: 0; batch classifier loss: 0.288072; batch adversarial loss: 0.313985\n","epoch 31; iter: 0; batch classifier loss: 0.216333; batch adversarial loss: 0.378047\n","epoch 32; iter: 0; batch classifier loss: 0.334796; batch adversarial loss: 0.358762\n","epoch 33; iter: 0; batch classifier loss: 0.220280; batch adversarial loss: 0.318050\n","epoch 34; iter: 0; batch classifier loss: 0.164557; batch adversarial loss: 0.351702\n","epoch 35; iter: 0; batch classifier loss: 0.187165; batch adversarial loss: 0.418740\n","epoch 36; iter: 0; batch classifier loss: 0.182030; batch adversarial loss: 0.457656\n","epoch 37; iter: 0; batch classifier loss: 0.303394; batch adversarial loss: 0.382438\n","epoch 38; iter: 0; batch classifier loss: 0.227505; batch adversarial loss: 0.517209\n","epoch 39; iter: 0; batch classifier loss: 0.321849; batch adversarial loss: 0.467838\n","epoch 40; iter: 0; batch classifier loss: 0.294377; batch adversarial loss: 0.410398\n","epoch 41; iter: 0; batch classifier loss: 0.267607; batch adversarial loss: 0.432349\n","epoch 42; iter: 0; batch classifier loss: 0.249148; batch adversarial loss: 0.451823\n","epoch 43; iter: 0; batch classifier loss: 0.252370; batch adversarial loss: 0.350041\n","epoch 44; iter: 0; batch classifier loss: 0.245860; batch adversarial loss: 0.327833\n","epoch 45; iter: 0; batch classifier loss: 0.272611; batch adversarial loss: 0.401241\n","epoch 46; iter: 0; batch classifier loss: 0.271183; batch adversarial loss: 0.464795\n","epoch 47; iter: 0; batch classifier loss: 0.367438; batch adversarial loss: 0.459141\n","epoch 48; iter: 0; batch classifier loss: 1.640344; batch adversarial loss: 0.665418\n","epoch 49; iter: 0; batch classifier loss: 2.307777; batch adversarial loss: 0.571126\n"],"name":"stdout"},{"output_type":"stream","text":["divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.18425883432767323\n","epoch 0; iter: 0; batch classifier loss: 0.693908; batch adversarial loss: 0.896065\n","epoch 1; iter: 0; batch classifier loss: 0.268644; batch adversarial loss: 0.951575\n","epoch 2; iter: 0; batch classifier loss: 0.321491; batch adversarial loss: 0.781964\n","epoch 3; iter: 0; batch classifier loss: 0.405092; batch adversarial loss: 0.679628\n","epoch 4; iter: 0; batch classifier loss: 0.257560; batch adversarial loss: 0.595550\n","epoch 5; iter: 0; batch classifier loss: 0.229154; batch adversarial loss: 0.538004\n","epoch 6; iter: 0; batch classifier loss: 0.217051; batch adversarial loss: 0.439900\n","epoch 7; iter: 0; batch classifier loss: 0.233138; batch adversarial loss: 0.494779\n","epoch 8; iter: 0; batch classifier loss: 0.220921; batch adversarial loss: 0.457333\n","epoch 9; iter: 0; batch classifier loss: 0.230285; batch adversarial loss: 0.374037\n","epoch 10; iter: 0; batch classifier loss: 0.291540; batch adversarial loss: 0.499640\n","epoch 11; iter: 0; batch classifier loss: 0.247295; batch adversarial loss: 0.427553\n","epoch 12; iter: 0; batch classifier loss: 0.284088; batch adversarial loss: 0.404010\n","epoch 13; iter: 0; batch classifier loss: 0.379404; batch adversarial loss: 0.464796\n","epoch 14; iter: 0; batch classifier loss: 0.231657; batch adversarial loss: 0.436306\n","epoch 15; iter: 0; batch classifier loss: 0.219232; batch adversarial loss: 0.386948\n","epoch 16; iter: 0; batch classifier loss: 0.292087; batch adversarial loss: 0.429020\n","epoch 17; iter: 0; batch classifier loss: 0.301751; batch adversarial loss: 0.506072\n","epoch 18; iter: 0; batch classifier loss: 0.347255; batch adversarial loss: 0.436547\n","epoch 19; iter: 0; batch classifier loss: 0.238318; batch adversarial loss: 0.362854\n","epoch 20; iter: 0; batch classifier loss: 0.243482; batch adversarial loss: 0.449186\n","epoch 21; iter: 0; batch classifier loss: 0.239746; batch adversarial loss: 0.481467\n","epoch 22; iter: 0; batch classifier loss: 0.252092; batch adversarial loss: 0.383787\n","epoch 23; iter: 0; batch classifier loss: 0.279121; batch adversarial loss: 0.402776\n","epoch 24; iter: 0; batch classifier loss: 0.162199; batch adversarial loss: 0.421856\n","epoch 25; iter: 0; batch classifier loss: 0.270186; batch adversarial loss: 0.449084\n","epoch 26; iter: 0; batch classifier loss: 0.312188; batch adversarial loss: 0.453263\n","epoch 27; iter: 0; batch classifier loss: 0.234252; batch adversarial loss: 0.401095\n","epoch 28; iter: 0; batch classifier loss: 0.314290; batch adversarial loss: 0.376280\n","epoch 29; iter: 0; batch classifier loss: 0.320604; batch adversarial loss: 0.387368\n","epoch 30; iter: 0; batch classifier loss: 0.232680; batch adversarial loss: 0.411730\n","epoch 31; iter: 0; batch classifier loss: 0.293841; batch adversarial loss: 0.440299\n","epoch 32; iter: 0; batch classifier loss: 0.295228; batch adversarial loss: 0.324867\n","epoch 33; iter: 0; batch classifier loss: 0.313611; batch adversarial loss: 0.383720\n","epoch 34; iter: 0; batch classifier loss: 0.223345; batch adversarial loss: 0.473716\n","epoch 35; iter: 0; batch classifier loss: 0.203409; batch adversarial loss: 0.353500\n","epoch 36; iter: 0; batch classifier loss: 0.259760; batch adversarial loss: 0.445532\n","epoch 37; iter: 0; batch classifier loss: 0.257464; batch adversarial loss: 0.398106\n","epoch 38; iter: 0; batch classifier loss: 0.288755; batch adversarial loss: 0.447266\n","epoch 39; iter: 0; batch classifier loss: 0.230664; batch adversarial loss: 0.374984\n","epoch 40; iter: 0; batch classifier loss: 0.167898; batch adversarial loss: 0.498389\n","epoch 41; iter: 0; batch classifier loss: 0.282017; batch adversarial loss: 0.335068\n","epoch 42; iter: 0; batch classifier loss: 0.250105; batch adversarial loss: 0.389185\n","epoch 43; iter: 0; batch classifier loss: 0.286959; batch adversarial loss: 0.367651\n","epoch 44; iter: 0; batch classifier loss: 0.282816; batch adversarial loss: 0.476558\n","epoch 45; iter: 0; batch classifier loss: 0.354523; batch adversarial loss: 0.376229\n","epoch 46; iter: 0; batch classifier loss: 0.248512; batch adversarial loss: 0.305592\n","epoch 47; iter: 0; batch classifier loss: 0.181586; batch adversarial loss: 0.353881\n","epoch 48; iter: 0; batch classifier loss: 0.314650; batch adversarial loss: 0.348635\n","epoch 49; iter: 0; batch classifier loss: 0.360275; batch adversarial loss: 0.401328\n","Accuracy 0.8942175309775127\n","epoch 0; iter: 0; batch classifier loss: 0.645639; batch adversarial loss: 0.703095\n","epoch 1; iter: 0; batch classifier loss: 0.343985; batch adversarial loss: 0.579133\n","epoch 2; iter: 0; batch classifier loss: 0.355955; batch adversarial loss: 0.505631\n","epoch 3; iter: 0; batch classifier loss: 0.335145; batch adversarial loss: 0.502584\n","epoch 4; iter: 0; batch classifier loss: 0.236665; batch adversarial loss: 0.436812\n","epoch 5; iter: 0; batch classifier loss: 0.341729; batch adversarial loss: 0.404859\n","epoch 6; iter: 0; batch classifier loss: 0.256790; batch adversarial loss: 0.405998\n","epoch 7; iter: 0; batch classifier loss: 0.449341; batch adversarial loss: 0.451670\n","epoch 8; iter: 0; batch classifier loss: 0.244273; batch adversarial loss: 0.351326\n","epoch 9; iter: 0; batch classifier loss: 0.329382; batch adversarial loss: 0.422757\n","epoch 10; iter: 0; batch classifier loss: 0.324368; batch adversarial loss: 0.324126\n","epoch 11; iter: 0; batch classifier loss: 0.408888; batch adversarial loss: 0.534388\n","epoch 12; iter: 0; batch classifier loss: 0.330914; batch adversarial loss: 0.423720\n","epoch 13; iter: 0; batch classifier loss: 0.209062; batch adversarial loss: 0.378852\n","epoch 14; iter: 0; batch classifier loss: 0.264490; batch adversarial loss: 0.412092\n","epoch 15; iter: 0; batch classifier loss: 0.231968; batch adversarial loss: 0.349541\n","epoch 16; iter: 0; batch classifier loss: 0.268917; batch adversarial loss: 0.331688\n","epoch 17; iter: 0; batch classifier loss: 0.194306; batch adversarial loss: 0.359960\n","epoch 18; iter: 0; batch classifier loss: 0.238029; batch adversarial loss: 0.391254\n","epoch 19; iter: 0; batch classifier loss: 0.318212; batch adversarial loss: 0.396812\n","epoch 20; iter: 0; batch classifier loss: 0.293680; batch adversarial loss: 0.415470\n","epoch 21; iter: 0; batch classifier loss: 0.247467; batch adversarial loss: 0.394102\n","epoch 22; iter: 0; batch classifier loss: 0.255006; batch adversarial loss: 0.431479\n","epoch 23; iter: 0; batch classifier loss: 0.252642; batch adversarial loss: 0.412041\n","epoch 24; iter: 0; batch classifier loss: 0.239352; batch adversarial loss: 0.415826\n","epoch 25; iter: 0; batch classifier loss: 0.198903; batch adversarial loss: 0.318752\n","epoch 26; iter: 0; batch classifier loss: 0.215429; batch adversarial loss: 0.401578\n","epoch 27; iter: 0; batch classifier loss: 0.233155; batch adversarial loss: 0.461940\n","epoch 28; iter: 0; batch classifier loss: 0.263570; batch adversarial loss: 0.402578\n","epoch 29; iter: 0; batch classifier loss: 0.207373; batch adversarial loss: 0.395649\n","epoch 30; iter: 0; batch classifier loss: 0.263989; batch adversarial loss: 0.446386\n","epoch 31; iter: 0; batch classifier loss: 0.261683; batch adversarial loss: 0.492180\n","epoch 32; iter: 0; batch classifier loss: 0.226661; batch adversarial loss: 0.432360\n","epoch 33; iter: 0; batch classifier loss: 0.269703; batch adversarial loss: 0.493426\n","epoch 34; iter: 0; batch classifier loss: 0.291868; batch adversarial loss: 0.381557\n","epoch 35; iter: 0; batch classifier loss: 0.282093; batch adversarial loss: 0.326306\n","epoch 36; iter: 0; batch classifier loss: 0.259361; batch adversarial loss: 0.390740\n","epoch 37; iter: 0; batch classifier loss: 0.168326; batch adversarial loss: 0.474605\n","epoch 38; iter: 0; batch classifier loss: 0.291864; batch adversarial loss: 0.369054\n","epoch 39; iter: 0; batch classifier loss: 0.282718; batch adversarial loss: 0.458958\n","epoch 40; iter: 0; batch classifier loss: 0.268572; batch adversarial loss: 0.463429\n","epoch 41; iter: 0; batch classifier loss: 0.284937; batch adversarial loss: 0.422111\n","epoch 42; iter: 0; batch classifier loss: 0.311183; batch adversarial loss: 0.420201\n","epoch 43; iter: 0; batch classifier loss: 0.250643; batch adversarial loss: 0.419194\n","epoch 44; iter: 0; batch classifier loss: 0.226449; batch adversarial loss: 0.318213\n","epoch 45; iter: 0; batch classifier loss: 0.247376; batch adversarial loss: 0.409547\n","epoch 46; iter: 0; batch classifier loss: 0.280886; batch adversarial loss: 0.488040\n","epoch 47; iter: 0; batch classifier loss: 0.296330; batch adversarial loss: 0.332093\n","epoch 48; iter: 0; batch classifier loss: 0.338674; batch adversarial loss: 0.450568\n","epoch 49; iter: 0; batch classifier loss: 1.309434; batch adversarial loss: 0.692901\n"],"name":"stdout"},{"output_type":"stream","text":["divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.17508031206975677\n","epoch 0; iter: 0; batch classifier loss: 0.755621; batch adversarial loss: 0.579880\n","epoch 1; iter: 0; batch classifier loss: 1.447632; batch adversarial loss: 0.683001\n","epoch 2; iter: 0; batch classifier loss: 1.541902; batch adversarial loss: 0.643713\n","epoch 3; iter: 0; batch classifier loss: 1.448373; batch adversarial loss: 0.598315\n","epoch 4; iter: 0; batch classifier loss: 0.596387; batch adversarial loss: 0.546101\n","epoch 5; iter: 0; batch classifier loss: 0.677262; batch adversarial loss: 0.522993\n","epoch 6; iter: 0; batch classifier loss: 0.874881; batch adversarial loss: 0.533885\n","epoch 7; iter: 0; batch classifier loss: 0.661368; batch adversarial loss: 0.545799\n","epoch 8; iter: 0; batch classifier loss: 0.356712; batch adversarial loss: 0.467981\n","epoch 9; iter: 0; batch classifier loss: 0.291282; batch adversarial loss: 0.506751\n","epoch 10; iter: 0; batch classifier loss: 0.297090; batch adversarial loss: 0.320969\n","epoch 11; iter: 0; batch classifier loss: 0.300602; batch adversarial loss: 0.390477\n","epoch 12; iter: 0; batch classifier loss: 0.306227; batch adversarial loss: 0.540786\n","epoch 13; iter: 0; batch classifier loss: 0.176541; batch adversarial loss: 0.401675\n","epoch 14; iter: 0; batch classifier loss: 0.270252; batch adversarial loss: 0.387616\n","epoch 15; iter: 0; batch classifier loss: 0.145803; batch adversarial loss: 0.383914\n","epoch 16; iter: 0; batch classifier loss: 0.305332; batch adversarial loss: 0.470031\n","epoch 17; iter: 0; batch classifier loss: 0.226492; batch adversarial loss: 0.466638\n","epoch 18; iter: 0; batch classifier loss: 0.219624; batch adversarial loss: 0.551105\n","epoch 19; iter: 0; batch classifier loss: 0.342387; batch adversarial loss: 0.356826\n","epoch 20; iter: 0; batch classifier loss: 0.221398; batch adversarial loss: 0.314986\n","epoch 21; iter: 0; batch classifier loss: 0.233391; batch adversarial loss: 0.418932\n","epoch 22; iter: 0; batch classifier loss: 0.236927; batch adversarial loss: 0.398310\n","epoch 23; iter: 0; batch classifier loss: 0.355055; batch adversarial loss: 0.417304\n","epoch 24; iter: 0; batch classifier loss: 0.224756; batch adversarial loss: 0.451402\n","epoch 25; iter: 0; batch classifier loss: 0.233406; batch adversarial loss: 0.467931\n","epoch 26; iter: 0; batch classifier loss: 0.316636; batch adversarial loss: 0.474515\n","epoch 27; iter: 0; batch classifier loss: 0.271136; batch adversarial loss: 0.396059\n","epoch 28; iter: 0; batch classifier loss: 0.332935; batch adversarial loss: 0.386920\n","epoch 29; iter: 0; batch classifier loss: 0.268573; batch adversarial loss: 0.420576\n","epoch 30; iter: 0; batch classifier loss: 0.231441; batch adversarial loss: 0.487075\n","epoch 31; iter: 0; batch classifier loss: 0.199532; batch adversarial loss: 0.348357\n","epoch 32; iter: 0; batch classifier loss: 0.284917; batch adversarial loss: 0.386938\n","epoch 33; iter: 0; batch classifier loss: 0.271751; batch adversarial loss: 0.285152\n","epoch 34; iter: 0; batch classifier loss: 0.252809; batch adversarial loss: 0.439322\n","epoch 35; iter: 0; batch classifier loss: 0.329045; batch adversarial loss: 0.341828\n","epoch 36; iter: 0; batch classifier loss: 0.263449; batch adversarial loss: 0.415736\n","epoch 37; iter: 0; batch classifier loss: 0.257309; batch adversarial loss: 0.420915\n","epoch 38; iter: 0; batch classifier loss: 0.198544; batch adversarial loss: 0.404140\n","epoch 39; iter: 0; batch classifier loss: 0.198299; batch adversarial loss: 0.335877\n","epoch 40; iter: 0; batch classifier loss: 0.359226; batch adversarial loss: 0.401618\n","epoch 41; iter: 0; batch classifier loss: 0.270800; batch adversarial loss: 0.420713\n","epoch 42; iter: 0; batch classifier loss: 0.278813; batch adversarial loss: 0.442855\n","epoch 43; iter: 0; batch classifier loss: 0.330109; batch adversarial loss: 0.584069\n","epoch 44; iter: 0; batch classifier loss: 0.299762; batch adversarial loss: 0.326050\n","epoch 45; iter: 0; batch classifier loss: 0.254465; batch adversarial loss: 0.394515\n","epoch 46; iter: 0; batch classifier loss: 0.244845; batch adversarial loss: 0.287444\n","epoch 47; iter: 0; batch classifier loss: 0.207151; batch adversarial loss: 0.419214\n","epoch 48; iter: 0; batch classifier loss: 0.350076; batch adversarial loss: 0.430342\n","epoch 49; iter: 0; batch classifier loss: 0.278520; batch adversarial loss: 0.408838\n","Accuracy 0.8951353832033042\n","epoch 0; iter: 0; batch classifier loss: 0.558496; batch adversarial loss: 0.999241\n","epoch 1; iter: 0; batch classifier loss: 0.280519; batch adversarial loss: 0.932281\n","epoch 2; iter: 0; batch classifier loss: 0.254906; batch adversarial loss: 0.777795\n","epoch 3; iter: 0; batch classifier loss: 0.349814; batch adversarial loss: 0.651551\n","epoch 4; iter: 0; batch classifier loss: 0.306236; batch adversarial loss: 0.562423\n","epoch 5; iter: 0; batch classifier loss: 0.292580; batch adversarial loss: 0.540727\n","epoch 6; iter: 0; batch classifier loss: 0.266623; batch adversarial loss: 0.520353\n","epoch 7; iter: 0; batch classifier loss: 0.301478; batch adversarial loss: 0.517192\n","epoch 8; iter: 0; batch classifier loss: 0.201021; batch adversarial loss: 0.431852\n","epoch 9; iter: 0; batch classifier loss: 0.267934; batch adversarial loss: 0.471718\n","epoch 10; iter: 0; batch classifier loss: 0.288198; batch adversarial loss: 0.460168\n","epoch 11; iter: 0; batch classifier loss: 0.303469; batch adversarial loss: 0.416735\n","epoch 12; iter: 0; batch classifier loss: 0.259533; batch adversarial loss: 0.499099\n","epoch 13; iter: 0; batch classifier loss: 0.309942; batch adversarial loss: 0.431103\n","epoch 14; iter: 0; batch classifier loss: 0.222001; batch adversarial loss: 0.410475\n","epoch 15; iter: 0; batch classifier loss: 0.256051; batch adversarial loss: 0.452257\n","epoch 16; iter: 0; batch classifier loss: 0.308131; batch adversarial loss: 0.417665\n","epoch 17; iter: 0; batch classifier loss: 0.304987; batch adversarial loss: 0.439299\n","epoch 18; iter: 0; batch classifier loss: 0.315276; batch adversarial loss: 0.465879\n","epoch 19; iter: 0; batch classifier loss: 0.277819; batch adversarial loss: 0.381309\n","epoch 20; iter: 0; batch classifier loss: 0.291861; batch adversarial loss: 0.421877\n","epoch 21; iter: 0; batch classifier loss: 0.307251; batch adversarial loss: 0.363049\n","epoch 22; iter: 0; batch classifier loss: 0.278305; batch adversarial loss: 0.402305\n","epoch 23; iter: 0; batch classifier loss: 0.415276; batch adversarial loss: 0.490600\n","epoch 24; iter: 0; batch classifier loss: 0.267247; batch adversarial loss: 0.323207\n","epoch 25; iter: 0; batch classifier loss: 0.189609; batch adversarial loss: 0.498328\n","epoch 26; iter: 0; batch classifier loss: 0.247688; batch adversarial loss: 0.404842\n","epoch 27; iter: 0; batch classifier loss: 0.305264; batch adversarial loss: 0.494076\n","epoch 28; iter: 0; batch classifier loss: 0.288729; batch adversarial loss: 0.411493\n","epoch 29; iter: 0; batch classifier loss: 0.331709; batch adversarial loss: 0.533431\n","epoch 30; iter: 0; batch classifier loss: 0.275941; batch adversarial loss: 0.428544\n","epoch 31; iter: 0; batch classifier loss: 0.298394; batch adversarial loss: 0.483578\n","epoch 32; iter: 0; batch classifier loss: 0.226276; batch adversarial loss: 0.465806\n","epoch 33; iter: 0; batch classifier loss: 0.330040; batch adversarial loss: 0.390372\n","epoch 34; iter: 0; batch classifier loss: 0.344562; batch adversarial loss: 0.488586\n","epoch 35; iter: 0; batch classifier loss: 0.216339; batch adversarial loss: 0.393432\n","epoch 36; iter: 0; batch classifier loss: 0.267091; batch adversarial loss: 0.413737\n","epoch 37; iter: 0; batch classifier loss: 0.270521; batch adversarial loss: 0.336945\n","epoch 38; iter: 0; batch classifier loss: 0.200873; batch adversarial loss: 0.392544\n","epoch 39; iter: 0; batch classifier loss: 0.241963; batch adversarial loss: 0.355108\n","epoch 40; iter: 0; batch classifier loss: 0.224695; batch adversarial loss: 0.356387\n","epoch 41; iter: 0; batch classifier loss: 0.272851; batch adversarial loss: 0.345641\n","epoch 42; iter: 0; batch classifier loss: 0.279619; batch adversarial loss: 0.386638\n","epoch 43; iter: 0; batch classifier loss: 0.273528; batch adversarial loss: 0.311468\n","epoch 44; iter: 0; batch classifier loss: 0.275142; batch adversarial loss: 0.396078\n","epoch 45; iter: 0; batch classifier loss: 0.278746; batch adversarial loss: 0.395261\n","epoch 46; iter: 0; batch classifier loss: 0.308206; batch adversarial loss: 0.390472\n","epoch 47; iter: 0; batch classifier loss: 0.247644; batch adversarial loss: 0.408020\n","epoch 48; iter: 0; batch classifier loss: 0.266372; batch adversarial loss: 0.346058\n","epoch 49; iter: 0; batch classifier loss: 0.268209; batch adversarial loss: 0.482829\n","Accuracy 0.9025005735260381\n","epoch 0; iter: 0; batch classifier loss: 0.771719; batch adversarial loss: 0.971107\n","epoch 1; iter: 0; batch classifier loss: 0.322811; batch adversarial loss: 1.175404\n","epoch 2; iter: 0; batch classifier loss: 0.253173; batch adversarial loss: 1.016328\n","epoch 3; iter: 0; batch classifier loss: 0.276691; batch adversarial loss: 0.844334\n","epoch 4; iter: 0; batch classifier loss: 0.302611; batch adversarial loss: 0.711540\n","epoch 5; iter: 0; batch classifier loss: 0.289892; batch adversarial loss: 0.654717\n","epoch 6; iter: 0; batch classifier loss: 0.369767; batch adversarial loss: 0.579456\n","epoch 7; iter: 0; batch classifier loss: 0.211026; batch adversarial loss: 0.515026\n","epoch 8; iter: 0; batch classifier loss: 0.323537; batch adversarial loss: 0.470208\n","epoch 9; iter: 0; batch classifier loss: 0.422883; batch adversarial loss: 0.451541\n","epoch 10; iter: 0; batch classifier loss: 0.219582; batch adversarial loss: 0.443515\n","epoch 11; iter: 0; batch classifier loss: 0.242713; batch adversarial loss: 0.476710\n","epoch 12; iter: 0; batch classifier loss: 0.280481; batch adversarial loss: 0.473952\n","epoch 13; iter: 0; batch classifier loss: 0.348097; batch adversarial loss: 0.438823\n","epoch 14; iter: 0; batch classifier loss: 0.215039; batch adversarial loss: 0.413745\n","epoch 15; iter: 0; batch classifier loss: 0.318051; batch adversarial loss: 0.481850\n","epoch 16; iter: 0; batch classifier loss: 0.251508; batch adversarial loss: 0.435581\n","epoch 17; iter: 0; batch classifier loss: 0.318579; batch adversarial loss: 0.411571\n","epoch 18; iter: 0; batch classifier loss: 0.317209; batch adversarial loss: 0.389642\n","epoch 19; iter: 0; batch classifier loss: 0.405441; batch adversarial loss: 0.397371\n","epoch 20; iter: 0; batch classifier loss: 0.377719; batch adversarial loss: 0.351907\n","epoch 21; iter: 0; batch classifier loss: 0.266239; batch adversarial loss: 0.335961\n","epoch 22; iter: 0; batch classifier loss: 0.259799; batch adversarial loss: 0.433043\n","epoch 23; iter: 0; batch classifier loss: 0.173891; batch adversarial loss: 0.434205\n","epoch 24; iter: 0; batch classifier loss: 0.291257; batch adversarial loss: 0.429691\n","epoch 25; iter: 0; batch classifier loss: 0.250254; batch adversarial loss: 0.406920\n","epoch 26; iter: 0; batch classifier loss: 0.352590; batch adversarial loss: 0.474197\n","epoch 27; iter: 0; batch classifier loss: 0.218826; batch adversarial loss: 0.331865\n","epoch 28; iter: 0; batch classifier loss: 0.206707; batch adversarial loss: 0.467507\n","epoch 29; iter: 0; batch classifier loss: 0.254513; batch adversarial loss: 0.524699\n","epoch 30; iter: 0; batch classifier loss: 0.225116; batch adversarial loss: 0.401425\n","epoch 31; iter: 0; batch classifier loss: 0.267479; batch adversarial loss: 0.301593\n","epoch 32; iter: 0; batch classifier loss: 0.230152; batch adversarial loss: 0.362822\n","epoch 33; iter: 0; batch classifier loss: 0.241013; batch adversarial loss: 0.436533\n","epoch 34; iter: 0; batch classifier loss: 0.218921; batch adversarial loss: 0.407045\n","epoch 35; iter: 0; batch classifier loss: 0.298223; batch adversarial loss: 0.421568\n","epoch 36; iter: 0; batch classifier loss: 0.233148; batch adversarial loss: 0.320470\n","epoch 37; iter: 0; batch classifier loss: 0.224795; batch adversarial loss: 0.405193\n","epoch 38; iter: 0; batch classifier loss: 0.295221; batch adversarial loss: 0.388558\n","epoch 39; iter: 0; batch classifier loss: 0.285147; batch adversarial loss: 0.454765\n","epoch 40; iter: 0; batch classifier loss: 0.252922; batch adversarial loss: 0.332941\n","epoch 41; iter: 0; batch classifier loss: 0.311824; batch adversarial loss: 0.470253\n","epoch 42; iter: 0; batch classifier loss: 0.323672; batch adversarial loss: 0.426908\n","epoch 43; iter: 0; batch classifier loss: 0.255680; batch adversarial loss: 0.349568\n","epoch 44; iter: 0; batch classifier loss: 0.285972; batch adversarial loss: 0.387551\n","epoch 45; iter: 0; batch classifier loss: 0.205629; batch adversarial loss: 0.405898\n","epoch 46; iter: 0; batch classifier loss: 0.464433; batch adversarial loss: 0.441798\n","epoch 47; iter: 0; batch classifier loss: 0.258274; batch adversarial loss: 0.436937\n","epoch 48; iter: 0; batch classifier loss: 0.219680; batch adversarial loss: 0.457155\n","epoch 49; iter: 0; batch classifier loss: 0.279077; batch adversarial loss: 0.448531\n","Accuracy 0.8871041762276274\n","epoch 0; iter: 0; batch classifier loss: 0.720865; batch adversarial loss: 0.682630\n","epoch 1; iter: 0; batch classifier loss: 0.853967; batch adversarial loss: 0.664907\n","epoch 2; iter: 0; batch classifier loss: 1.245131; batch adversarial loss: 0.636378\n","epoch 3; iter: 0; batch classifier loss: 1.215046; batch adversarial loss: 0.585917\n","epoch 4; iter: 0; batch classifier loss: 0.470880; batch adversarial loss: 0.501852\n","epoch 5; iter: 0; batch classifier loss: 0.891107; batch adversarial loss: 0.551819\n","epoch 6; iter: 0; batch classifier loss: 0.941736; batch adversarial loss: 0.495531\n","epoch 7; iter: 0; batch classifier loss: 0.600857; batch adversarial loss: 0.507778\n","epoch 8; iter: 0; batch classifier loss: 0.524095; batch adversarial loss: 0.371299\n","epoch 9; iter: 0; batch classifier loss: 0.678156; batch adversarial loss: 0.482924\n","epoch 10; iter: 0; batch classifier loss: 0.786354; batch adversarial loss: 0.459261\n","epoch 11; iter: 0; batch classifier loss: 0.556525; batch adversarial loss: 0.434204\n","epoch 12; iter: 0; batch classifier loss: 0.332953; batch adversarial loss: 0.469753\n","epoch 13; iter: 0; batch classifier loss: 0.262894; batch adversarial loss: 0.399788\n","epoch 14; iter: 0; batch classifier loss: 0.260718; batch adversarial loss: 0.385370\n","epoch 15; iter: 0; batch classifier loss: 0.289339; batch adversarial loss: 0.423559\n","epoch 16; iter: 0; batch classifier loss: 0.293490; batch adversarial loss: 0.363922\n","epoch 17; iter: 0; batch classifier loss: 0.397952; batch adversarial loss: 0.496287\n","epoch 18; iter: 0; batch classifier loss: 0.225099; batch adversarial loss: 0.524356\n","epoch 19; iter: 0; batch classifier loss: 0.423985; batch adversarial loss: 0.364490\n","epoch 20; iter: 0; batch classifier loss: 0.305506; batch adversarial loss: 0.389158\n","epoch 21; iter: 0; batch classifier loss: 0.339031; batch adversarial loss: 0.460006\n","epoch 22; iter: 0; batch classifier loss: 0.302477; batch adversarial loss: 0.323868\n","epoch 23; iter: 0; batch classifier loss: 0.271457; batch adversarial loss: 0.443255\n","epoch 24; iter: 0; batch classifier loss: 0.311474; batch adversarial loss: 0.289276\n","epoch 25; iter: 0; batch classifier loss: 0.201937; batch adversarial loss: 0.412744\n","epoch 26; iter: 0; batch classifier loss: 0.289832; batch adversarial loss: 0.467781\n","epoch 27; iter: 0; batch classifier loss: 0.359019; batch adversarial loss: 0.371566\n","epoch 28; iter: 0; batch classifier loss: 0.248794; batch adversarial loss: 0.345050\n","epoch 29; iter: 0; batch classifier loss: 0.369083; batch adversarial loss: 0.372640\n","epoch 30; iter: 0; batch classifier loss: 0.302166; batch adversarial loss: 0.496364\n","epoch 31; iter: 0; batch classifier loss: 0.361799; batch adversarial loss: 0.404529\n","epoch 32; iter: 0; batch classifier loss: 0.256298; batch adversarial loss: 0.476743\n","epoch 33; iter: 0; batch classifier loss: 0.282065; batch adversarial loss: 0.374747\n","epoch 34; iter: 0; batch classifier loss: 0.227314; batch adversarial loss: 0.357455\n","epoch 35; iter: 0; batch classifier loss: 0.320749; batch adversarial loss: 0.382836\n","epoch 36; iter: 0; batch classifier loss: 0.291175; batch adversarial loss: 0.395587\n","epoch 37; iter: 0; batch classifier loss: 0.190111; batch adversarial loss: 0.402588\n","epoch 38; iter: 0; batch classifier loss: 0.241547; batch adversarial loss: 0.290048\n","epoch 39; iter: 0; batch classifier loss: 0.299097; batch adversarial loss: 0.341175\n","epoch 40; iter: 0; batch classifier loss: 0.212337; batch adversarial loss: 0.355498\n","epoch 41; iter: 0; batch classifier loss: 0.218569; batch adversarial loss: 0.408228\n","epoch 42; iter: 0; batch classifier loss: 0.269580; batch adversarial loss: 0.439090\n","epoch 43; iter: 0; batch classifier loss: 0.322628; batch adversarial loss: 0.425543\n","epoch 44; iter: 0; batch classifier loss: 0.260409; batch adversarial loss: 0.386942\n","epoch 45; iter: 0; batch classifier loss: 0.266225; batch adversarial loss: 0.458807\n","epoch 46; iter: 0; batch classifier loss: 0.302687; batch adversarial loss: 0.407717\n","epoch 47; iter: 0; batch classifier loss: 0.320315; batch adversarial loss: 0.412634\n","epoch 48; iter: 0; batch classifier loss: 0.198198; batch adversarial loss: 0.410886\n","epoch 49; iter: 0; batch classifier loss: 0.236602; batch adversarial loss: 0.374794\n","Accuracy 0.8999541073887104\n","epoch 0; iter: 0; batch classifier loss: 0.647937; batch adversarial loss: 0.802044\n","epoch 1; iter: 0; batch classifier loss: 0.297394; batch adversarial loss: 0.719673\n","epoch 2; iter: 0; batch classifier loss: 0.284686; batch adversarial loss: 0.612423\n","epoch 3; iter: 0; batch classifier loss: 0.359803; batch adversarial loss: 0.571162\n","epoch 4; iter: 0; batch classifier loss: 0.289235; batch adversarial loss: 0.475040\n","epoch 5; iter: 0; batch classifier loss: 0.411613; batch adversarial loss: 0.530077\n","epoch 6; iter: 0; batch classifier loss: 1.283661; batch adversarial loss: 0.557649\n","epoch 7; iter: 0; batch classifier loss: 1.433858; batch adversarial loss: 0.566383\n","epoch 8; iter: 0; batch classifier loss: 1.170418; batch adversarial loss: 0.543414\n","epoch 9; iter: 0; batch classifier loss: 0.471139; batch adversarial loss: 0.467165\n","epoch 10; iter: 0; batch classifier loss: 0.307074; batch adversarial loss: 0.476042\n","epoch 11; iter: 0; batch classifier loss: 0.238031; batch adversarial loss: 0.373622\n","epoch 12; iter: 0; batch classifier loss: 0.174773; batch adversarial loss: 0.354543\n","epoch 13; iter: 0; batch classifier loss: 0.376682; batch adversarial loss: 0.454552\n","epoch 14; iter: 0; batch classifier loss: 0.263869; batch adversarial loss: 0.357964\n","epoch 15; iter: 0; batch classifier loss: 0.373088; batch adversarial loss: 0.506420\n","epoch 16; iter: 0; batch classifier loss: 0.285385; batch adversarial loss: 0.364980\n","epoch 17; iter: 0; batch classifier loss: 0.285870; batch adversarial loss: 0.473729\n","epoch 18; iter: 0; batch classifier loss: 0.253118; batch adversarial loss: 0.433833\n","epoch 19; iter: 0; batch classifier loss: 0.169183; batch adversarial loss: 0.419839\n","epoch 20; iter: 0; batch classifier loss: 0.241718; batch adversarial loss: 0.410959\n","epoch 21; iter: 0; batch classifier loss: 0.237701; batch adversarial loss: 0.406372\n","epoch 22; iter: 0; batch classifier loss: 0.267170; batch adversarial loss: 0.453570\n","epoch 23; iter: 0; batch classifier loss: 0.255671; batch adversarial loss: 0.368108\n","epoch 24; iter: 0; batch classifier loss: 0.273642; batch adversarial loss: 0.483207\n","epoch 25; iter: 0; batch classifier loss: 0.287358; batch adversarial loss: 0.396046\n","epoch 26; iter: 0; batch classifier loss: 0.284881; batch adversarial loss: 0.368081\n","epoch 27; iter: 0; batch classifier loss: 0.264513; batch adversarial loss: 0.322605\n","epoch 28; iter: 0; batch classifier loss: 0.311361; batch adversarial loss: 0.484094\n","epoch 29; iter: 0; batch classifier loss: 0.250105; batch adversarial loss: 0.340570\n","epoch 30; iter: 0; batch classifier loss: 0.364721; batch adversarial loss: 0.353658\n","epoch 31; iter: 0; batch classifier loss: 0.335909; batch adversarial loss: 0.451047\n","epoch 32; iter: 0; batch classifier loss: 0.203949; batch adversarial loss: 0.406263\n","epoch 33; iter: 0; batch classifier loss: 0.297036; batch adversarial loss: 0.405971\n","epoch 34; iter: 0; batch classifier loss: 0.280138; batch adversarial loss: 0.464071\n","epoch 35; iter: 0; batch classifier loss: 0.225439; batch adversarial loss: 0.310723\n","epoch 36; iter: 0; batch classifier loss: 0.240951; batch adversarial loss: 0.539559\n","epoch 37; iter: 0; batch classifier loss: 0.232712; batch adversarial loss: 0.434380\n","epoch 38; iter: 0; batch classifier loss: 0.227549; batch adversarial loss: 0.429486\n","epoch 39; iter: 0; batch classifier loss: 0.205269; batch adversarial loss: 0.445834\n","epoch 40; iter: 0; batch classifier loss: 0.317495; batch adversarial loss: 0.419390\n","epoch 41; iter: 0; batch classifier loss: 0.229547; batch adversarial loss: 0.490010\n","epoch 42; iter: 0; batch classifier loss: 0.263804; batch adversarial loss: 0.404719\n","epoch 43; iter: 0; batch classifier loss: 0.228737; batch adversarial loss: 0.347099\n","epoch 44; iter: 0; batch classifier loss: 0.288317; batch adversarial loss: 0.408543\n","epoch 45; iter: 0; batch classifier loss: 0.203417; batch adversarial loss: 0.397050\n","epoch 46; iter: 0; batch classifier loss: 0.253268; batch adversarial loss: 0.412906\n","epoch 47; iter: 0; batch classifier loss: 0.303400; batch adversarial loss: 0.406763\n","epoch 48; iter: 0; batch classifier loss: 0.243070; batch adversarial loss: 0.427836\n","epoch 49; iter: 0; batch classifier loss: 0.423619; batch adversarial loss: 0.433231\n","Accuracy 0.8944469940339606\n","epoch 0; iter: 0; batch classifier loss: 0.682775; batch adversarial loss: 0.634484\n","epoch 1; iter: 0; batch classifier loss: 1.074986; batch adversarial loss: 0.699754\n","epoch 2; iter: 0; batch classifier loss: 1.391487; batch adversarial loss: 0.646762\n","epoch 3; iter: 0; batch classifier loss: 1.537831; batch adversarial loss: 0.584566\n","epoch 4; iter: 0; batch classifier loss: 0.904669; batch adversarial loss: 0.531701\n","epoch 5; iter: 0; batch classifier loss: 0.366120; batch adversarial loss: 0.494734\n","epoch 6; iter: 0; batch classifier loss: 0.280836; batch adversarial loss: 0.436758\n","epoch 7; iter: 0; batch classifier loss: 0.381878; batch adversarial loss: 0.398409\n","epoch 8; iter: 0; batch classifier loss: 0.317113; batch adversarial loss: 0.467892\n","epoch 9; iter: 0; batch classifier loss: 0.360764; batch adversarial loss: 0.447270\n","epoch 10; iter: 0; batch classifier loss: 0.213589; batch adversarial loss: 0.331584\n","epoch 11; iter: 0; batch classifier loss: 0.243681; batch adversarial loss: 0.323392\n","epoch 12; iter: 0; batch classifier loss: 0.318811; batch adversarial loss: 0.485070\n","epoch 13; iter: 0; batch classifier loss: 0.334927; batch adversarial loss: 0.424677\n","epoch 14; iter: 0; batch classifier loss: 0.240536; batch adversarial loss: 0.510126\n","epoch 15; iter: 0; batch classifier loss: 0.278761; batch adversarial loss: 0.380226\n","epoch 16; iter: 0; batch classifier loss: 0.192313; batch adversarial loss: 0.360315\n","epoch 17; iter: 0; batch classifier loss: 0.306448; batch adversarial loss: 0.444103\n","epoch 18; iter: 0; batch classifier loss: 0.404958; batch adversarial loss: 0.367206\n","epoch 19; iter: 0; batch classifier loss: 0.295442; batch adversarial loss: 0.343653\n","epoch 20; iter: 0; batch classifier loss: 0.223715; batch adversarial loss: 0.418650\n","epoch 21; iter: 0; batch classifier loss: 0.283465; batch adversarial loss: 0.441593\n","epoch 22; iter: 0; batch classifier loss: 0.188270; batch adversarial loss: 0.385878\n","epoch 23; iter: 0; batch classifier loss: 0.316978; batch adversarial loss: 0.365056\n","epoch 24; iter: 0; batch classifier loss: 0.321606; batch adversarial loss: 0.412495\n","epoch 25; iter: 0; batch classifier loss: 0.332253; batch adversarial loss: 0.418574\n","epoch 26; iter: 0; batch classifier loss: 0.213597; batch adversarial loss: 0.410194\n","epoch 27; iter: 0; batch classifier loss: 0.206553; batch adversarial loss: 0.496603\n","epoch 28; iter: 0; batch classifier loss: 0.272056; batch adversarial loss: 0.489140\n","epoch 29; iter: 0; batch classifier loss: 0.260566; batch adversarial loss: 0.505981\n","epoch 30; iter: 0; batch classifier loss: 0.262823; batch adversarial loss: 0.380878\n","epoch 31; iter: 0; batch classifier loss: 0.187837; batch adversarial loss: 0.434398\n","epoch 32; iter: 0; batch classifier loss: 0.272235; batch adversarial loss: 0.365728\n","epoch 33; iter: 0; batch classifier loss: 0.293679; batch adversarial loss: 0.398853\n","epoch 34; iter: 0; batch classifier loss: 0.233803; batch adversarial loss: 0.309080\n","epoch 35; iter: 0; batch classifier loss: 0.159680; batch adversarial loss: 0.305517\n","epoch 36; iter: 0; batch classifier loss: 0.257484; batch adversarial loss: 0.425824\n","epoch 37; iter: 0; batch classifier loss: 0.222109; batch adversarial loss: 0.402154\n","epoch 38; iter: 0; batch classifier loss: 0.292336; batch adversarial loss: 0.404343\n","epoch 39; iter: 0; batch classifier loss: 0.303758; batch adversarial loss: 0.387129\n","epoch 40; iter: 0; batch classifier loss: 0.348011; batch adversarial loss: 0.310970\n","epoch 41; iter: 0; batch classifier loss: 0.264028; batch adversarial loss: 0.472381\n","epoch 42; iter: 0; batch classifier loss: 0.345428; batch adversarial loss: 0.504708\n","epoch 43; iter: 0; batch classifier loss: 0.246854; batch adversarial loss: 0.472521\n","epoch 44; iter: 0; batch classifier loss: 0.221654; batch adversarial loss: 0.412842\n","epoch 45; iter: 0; batch classifier loss: 0.272758; batch adversarial loss: 0.480939\n","epoch 46; iter: 0; batch classifier loss: 0.339704; batch adversarial loss: 0.404704\n","epoch 47; iter: 0; batch classifier loss: 0.245717; batch adversarial loss: 0.359696\n","epoch 48; iter: 0; batch classifier loss: 0.260664; batch adversarial loss: 0.476850\n","epoch 49; iter: 0; batch classifier loss: 0.227612; batch adversarial loss: 0.442457\n","Accuracy 0.8887104176227627\n","epoch 0; iter: 0; batch classifier loss: 0.659957; batch adversarial loss: 0.728444\n","epoch 1; iter: 0; batch classifier loss: 0.291561; batch adversarial loss: 0.617252\n","epoch 2; iter: 0; batch classifier loss: 0.239379; batch adversarial loss: 0.516933\n","epoch 3; iter: 0; batch classifier loss: 0.241609; batch adversarial loss: 0.451509\n","epoch 4; iter: 0; batch classifier loss: 0.311003; batch adversarial loss: 0.441925\n","epoch 5; iter: 0; batch classifier loss: 0.346738; batch adversarial loss: 0.443596\n","epoch 6; iter: 0; batch classifier loss: 0.185630; batch adversarial loss: 0.386822\n","epoch 7; iter: 0; batch classifier loss: 0.210362; batch adversarial loss: 0.424630\n","epoch 8; iter: 0; batch classifier loss: 0.232171; batch adversarial loss: 0.378982\n","epoch 9; iter: 0; batch classifier loss: 0.232599; batch adversarial loss: 0.378995\n","epoch 10; iter: 0; batch classifier loss: 0.325084; batch adversarial loss: 0.477617\n","epoch 11; iter: 0; batch classifier loss: 0.216700; batch adversarial loss: 0.401426\n","epoch 12; iter: 0; batch classifier loss: 0.187215; batch adversarial loss: 0.422019\n","epoch 13; iter: 0; batch classifier loss: 0.241561; batch adversarial loss: 0.429150\n","epoch 14; iter: 0; batch classifier loss: 0.283363; batch adversarial loss: 0.297355\n","epoch 15; iter: 0; batch classifier loss: 0.233089; batch adversarial loss: 0.354285\n","epoch 16; iter: 0; batch classifier loss: 0.287808; batch adversarial loss: 0.422073\n","epoch 17; iter: 0; batch classifier loss: 0.249757; batch adversarial loss: 0.403129\n","epoch 18; iter: 0; batch classifier loss: 0.266647; batch adversarial loss: 0.441023\n","epoch 19; iter: 0; batch classifier loss: 0.339332; batch adversarial loss: 0.379101\n","epoch 20; iter: 0; batch classifier loss: 0.226240; batch adversarial loss: 0.385724\n","epoch 21; iter: 0; batch classifier loss: 0.305183; batch adversarial loss: 0.419430\n","epoch 22; iter: 0; batch classifier loss: 0.256643; batch adversarial loss: 0.440650\n","epoch 23; iter: 0; batch classifier loss: 0.211809; batch adversarial loss: 0.307262\n","epoch 24; iter: 0; batch classifier loss: 0.308415; batch adversarial loss: 0.284230\n","epoch 25; iter: 0; batch classifier loss: 0.254041; batch adversarial loss: 0.388841\n","epoch 26; iter: 0; batch classifier loss: 0.291973; batch adversarial loss: 0.572623\n","epoch 27; iter: 0; batch classifier loss: 0.227814; batch adversarial loss: 0.499801\n","epoch 28; iter: 0; batch classifier loss: 0.240754; batch adversarial loss: 0.291475\n","epoch 29; iter: 0; batch classifier loss: 0.269564; batch adversarial loss: 0.412907\n","epoch 30; iter: 0; batch classifier loss: 0.258170; batch adversarial loss: 0.314491\n","epoch 31; iter: 0; batch classifier loss: 0.261598; batch adversarial loss: 0.408025\n","epoch 32; iter: 0; batch classifier loss: 0.245224; batch adversarial loss: 0.503156\n","epoch 33; iter: 0; batch classifier loss: 0.275270; batch adversarial loss: 0.427312\n","epoch 34; iter: 0; batch classifier loss: 0.277865; batch adversarial loss: 0.464190\n","epoch 35; iter: 0; batch classifier loss: 0.291558; batch adversarial loss: 0.401113\n","epoch 36; iter: 0; batch classifier loss: 0.291437; batch adversarial loss: 0.403861\n","epoch 37; iter: 0; batch classifier loss: 0.311482; batch adversarial loss: 0.393578\n","epoch 38; iter: 0; batch classifier loss: 0.315546; batch adversarial loss: 0.371971\n","epoch 39; iter: 0; batch classifier loss: 0.206486; batch adversarial loss: 0.407129\n","epoch 40; iter: 0; batch classifier loss: 0.264744; batch adversarial loss: 0.464420\n","epoch 41; iter: 0; batch classifier loss: 0.268007; batch adversarial loss: 0.492637\n","epoch 42; iter: 0; batch classifier loss: 0.306156; batch adversarial loss: 0.363246\n","epoch 43; iter: 0; batch classifier loss: 0.342934; batch adversarial loss: 0.394763\n","epoch 44; iter: 0; batch classifier loss: 0.318382; batch adversarial loss: 0.398691\n","epoch 45; iter: 0; batch classifier loss: 0.251752; batch adversarial loss: 0.327923\n","epoch 46; iter: 0; batch classifier loss: 0.252081; batch adversarial loss: 0.332889\n","epoch 47; iter: 0; batch classifier loss: 0.232823; batch adversarial loss: 0.396729\n","epoch 48; iter: 0; batch classifier loss: 0.300731; batch adversarial loss: 0.406834\n","epoch 49; iter: 0; batch classifier loss: 0.260020; batch adversarial loss: 0.481082\n","Accuracy 0.8905712319339298\n","epoch 0; iter: 0; batch classifier loss: 0.653672; batch adversarial loss: 0.989718\n","epoch 1; iter: 0; batch classifier loss: 0.168768; batch adversarial loss: 1.164427\n","epoch 2; iter: 0; batch classifier loss: 0.316577; batch adversarial loss: 0.949206\n","epoch 3; iter: 0; batch classifier loss: 0.273368; batch adversarial loss: 0.771270\n","epoch 4; iter: 0; batch classifier loss: 0.245431; batch adversarial loss: 0.668116\n","epoch 5; iter: 0; batch classifier loss: 0.284863; batch adversarial loss: 0.618535\n","epoch 6; iter: 0; batch classifier loss: 0.241553; batch adversarial loss: 0.539624\n","epoch 7; iter: 0; batch classifier loss: 0.274135; batch adversarial loss: 0.490472\n","epoch 8; iter: 0; batch classifier loss: 0.316680; batch adversarial loss: 0.512871\n","epoch 9; iter: 0; batch classifier loss: 0.303795; batch adversarial loss: 0.488193\n","epoch 10; iter: 0; batch classifier loss: 0.241647; batch adversarial loss: 0.451801\n","epoch 11; iter: 0; batch classifier loss: 0.245257; batch adversarial loss: 0.478906\n","epoch 12; iter: 0; batch classifier loss: 0.280580; batch adversarial loss: 0.390244\n","epoch 13; iter: 0; batch classifier loss: 0.258075; batch adversarial loss: 0.382046\n","epoch 14; iter: 0; batch classifier loss: 0.247010; batch adversarial loss: 0.412101\n","epoch 15; iter: 0; batch classifier loss: 0.165345; batch adversarial loss: 0.358425\n","epoch 16; iter: 0; batch classifier loss: 0.290586; batch adversarial loss: 0.444945\n","epoch 17; iter: 0; batch classifier loss: 0.173090; batch adversarial loss: 0.326106\n","epoch 18; iter: 0; batch classifier loss: 0.376465; batch adversarial loss: 0.435911\n","epoch 19; iter: 0; batch classifier loss: 0.179124; batch adversarial loss: 0.490152\n","epoch 20; iter: 0; batch classifier loss: 0.281991; batch adversarial loss: 0.380900\n","epoch 21; iter: 0; batch classifier loss: 0.315406; batch adversarial loss: 0.458836\n","epoch 22; iter: 0; batch classifier loss: 0.186660; batch adversarial loss: 0.354933\n","epoch 23; iter: 0; batch classifier loss: 0.267096; batch adversarial loss: 0.480319\n","epoch 24; iter: 0; batch classifier loss: 0.221923; batch adversarial loss: 0.394763\n","epoch 25; iter: 0; batch classifier loss: 0.392435; batch adversarial loss: 0.441897\n","epoch 26; iter: 0; batch classifier loss: 0.267350; batch adversarial loss: 0.356174\n","epoch 27; iter: 0; batch classifier loss: 0.348500; batch adversarial loss: 0.395386\n","epoch 28; iter: 0; batch classifier loss: 0.310824; batch adversarial loss: 0.389960\n","epoch 29; iter: 0; batch classifier loss: 0.359138; batch adversarial loss: 0.417463\n","epoch 30; iter: 0; batch classifier loss: 0.273587; batch adversarial loss: 0.426716\n","epoch 31; iter: 0; batch classifier loss: 0.297314; batch adversarial loss: 0.414032\n","epoch 32; iter: 0; batch classifier loss: 0.299810; batch adversarial loss: 0.395613\n","epoch 33; iter: 0; batch classifier loss: 0.283976; batch adversarial loss: 0.471501\n","epoch 34; iter: 0; batch classifier loss: 0.260990; batch adversarial loss: 0.408651\n","epoch 35; iter: 0; batch classifier loss: 0.291873; batch adversarial loss: 0.449524\n","epoch 36; iter: 0; batch classifier loss: 0.290325; batch adversarial loss: 0.504444\n","epoch 37; iter: 0; batch classifier loss: 0.241337; batch adversarial loss: 0.438099\n","epoch 38; iter: 0; batch classifier loss: 0.233522; batch adversarial loss: 0.375716\n","epoch 39; iter: 0; batch classifier loss: 0.237641; batch adversarial loss: 0.430432\n","epoch 40; iter: 0; batch classifier loss: 0.263035; batch adversarial loss: 0.465081\n","epoch 41; iter: 0; batch classifier loss: 0.230126; batch adversarial loss: 0.393113\n","epoch 42; iter: 0; batch classifier loss: 0.276854; batch adversarial loss: 0.396538\n","epoch 43; iter: 0; batch classifier loss: 0.260600; batch adversarial loss: 0.438973\n","epoch 44; iter: 0; batch classifier loss: 0.266214; batch adversarial loss: 0.392705\n","epoch 45; iter: 0; batch classifier loss: 0.295999; batch adversarial loss: 0.509898\n","epoch 46; iter: 0; batch classifier loss: 0.257815; batch adversarial loss: 0.420165\n","epoch 47; iter: 0; batch classifier loss: 0.343498; batch adversarial loss: 0.417107\n","epoch 48; iter: 0; batch classifier loss: 0.313319; batch adversarial loss: 0.466291\n","epoch 49; iter: 0; batch classifier loss: 0.207748; batch adversarial loss: 0.428937\n","Accuracy 0.893299678751721\n","epoch 0; iter: 0; batch classifier loss: 0.779503; batch adversarial loss: 0.859200\n","epoch 1; iter: 0; batch classifier loss: 0.277198; batch adversarial loss: 0.957546\n","epoch 2; iter: 0; batch classifier loss: 0.236740; batch adversarial loss: 0.784167\n","epoch 3; iter: 0; batch classifier loss: 0.353528; batch adversarial loss: 0.672934\n","epoch 4; iter: 0; batch classifier loss: 0.247177; batch adversarial loss: 0.596478\n","epoch 5; iter: 0; batch classifier loss: 0.285080; batch adversarial loss: 0.554275\n","epoch 6; iter: 0; batch classifier loss: 0.233895; batch adversarial loss: 0.460220\n","epoch 7; iter: 0; batch classifier loss: 0.309888; batch adversarial loss: 0.458606\n","epoch 8; iter: 0; batch classifier loss: 0.327956; batch adversarial loss: 0.459103\n","epoch 9; iter: 0; batch classifier loss: 0.313508; batch adversarial loss: 0.438842\n","epoch 10; iter: 0; batch classifier loss: 0.261864; batch adversarial loss: 0.416549\n","epoch 11; iter: 0; batch classifier loss: 0.339307; batch adversarial loss: 0.439934\n","epoch 12; iter: 0; batch classifier loss: 0.296320; batch adversarial loss: 0.384349\n","epoch 13; iter: 0; batch classifier loss: 0.188640; batch adversarial loss: 0.417633\n","epoch 14; iter: 0; batch classifier loss: 0.170426; batch adversarial loss: 0.505242\n","epoch 15; iter: 0; batch classifier loss: 0.278678; batch adversarial loss: 0.377211\n","epoch 16; iter: 0; batch classifier loss: 0.160021; batch adversarial loss: 0.426973\n","epoch 17; iter: 0; batch classifier loss: 0.153042; batch adversarial loss: 0.296411\n","epoch 18; iter: 0; batch classifier loss: 0.245582; batch adversarial loss: 0.368460\n","epoch 19; iter: 0; batch classifier loss: 0.237880; batch adversarial loss: 0.338480\n","epoch 20; iter: 0; batch classifier loss: 0.277731; batch adversarial loss: 0.395461\n","epoch 21; iter: 0; batch classifier loss: 0.219495; batch adversarial loss: 0.398683\n","epoch 22; iter: 0; batch classifier loss: 0.303594; batch adversarial loss: 0.399520\n","epoch 23; iter: 0; batch classifier loss: 0.210951; batch adversarial loss: 0.465633\n","epoch 24; iter: 0; batch classifier loss: 0.246270; batch adversarial loss: 0.271272\n","epoch 25; iter: 0; batch classifier loss: 0.282265; batch adversarial loss: 0.407305\n","epoch 26; iter: 0; batch classifier loss: 0.214163; batch adversarial loss: 0.435868\n","epoch 27; iter: 0; batch classifier loss: 0.165164; batch adversarial loss: 0.357504\n","epoch 28; iter: 0; batch classifier loss: 0.284159; batch adversarial loss: 0.504714\n","epoch 29; iter: 0; batch classifier loss: 0.275870; batch adversarial loss: 0.410311\n","epoch 30; iter: 0; batch classifier loss: 0.278212; batch adversarial loss: 0.389374\n","epoch 31; iter: 0; batch classifier loss: 0.386713; batch adversarial loss: 0.384125\n","epoch 32; iter: 0; batch classifier loss: 0.331120; batch adversarial loss: 0.410675\n","epoch 33; iter: 0; batch classifier loss: 0.260374; batch adversarial loss: 0.342119\n","epoch 34; iter: 0; batch classifier loss: 0.196766; batch adversarial loss: 0.471877\n","epoch 35; iter: 0; batch classifier loss: 0.317448; batch adversarial loss: 0.403056\n","epoch 36; iter: 0; batch classifier loss: 0.331666; batch adversarial loss: 0.430032\n","epoch 37; iter: 0; batch classifier loss: 0.361763; batch adversarial loss: 0.334565\n","epoch 38; iter: 0; batch classifier loss: 0.313386; batch adversarial loss: 0.414095\n","epoch 39; iter: 0; batch classifier loss: 0.238143; batch adversarial loss: 0.465062\n","epoch 40; iter: 0; batch classifier loss: 0.293732; batch adversarial loss: 0.496531\n","epoch 41; iter: 0; batch classifier loss: 0.389785; batch adversarial loss: 0.408564\n","epoch 42; iter: 0; batch classifier loss: 0.342204; batch adversarial loss: 0.357798\n","epoch 43; iter: 0; batch classifier loss: 0.266138; batch adversarial loss: 0.457172\n","epoch 44; iter: 0; batch classifier loss: 0.301673; batch adversarial loss: 0.408833\n","epoch 45; iter: 0; batch classifier loss: 0.402675; batch adversarial loss: 0.439687\n","epoch 46; iter: 0; batch classifier loss: 0.233555; batch adversarial loss: 0.403924\n","epoch 47; iter: 0; batch classifier loss: 0.344652; batch adversarial loss: 0.404764\n","epoch 48; iter: 0; batch classifier loss: 0.303971; batch adversarial loss: 0.398812\n","epoch 49; iter: 0; batch classifier loss: 0.213621; batch adversarial loss: 0.334435\n","Accuracy 0.8944469940339606\n","epoch 0; iter: 0; batch classifier loss: 0.785749; batch adversarial loss: 0.564268\n","epoch 1; iter: 0; batch classifier loss: 1.431614; batch adversarial loss: 0.629324\n","epoch 2; iter: 0; batch classifier loss: 1.569926; batch adversarial loss: 0.641982\n","epoch 3; iter: 0; batch classifier loss: 1.433232; batch adversarial loss: 0.589848\n","epoch 4; iter: 0; batch classifier loss: 0.677532; batch adversarial loss: 0.526108\n","epoch 5; iter: 0; batch classifier loss: 0.715867; batch adversarial loss: 0.536979\n","epoch 6; iter: 0; batch classifier loss: 0.708280; batch adversarial loss: 0.512793\n","epoch 7; iter: 0; batch classifier loss: 0.611832; batch adversarial loss: 0.494504\n","epoch 8; iter: 0; batch classifier loss: 0.653126; batch adversarial loss: 0.456406\n","epoch 9; iter: 0; batch classifier loss: 0.386749; batch adversarial loss: 0.393095\n","epoch 10; iter: 0; batch classifier loss: 0.318310; batch adversarial loss: 0.477409\n","epoch 11; iter: 0; batch classifier loss: 0.253345; batch adversarial loss: 0.412642\n","epoch 12; iter: 0; batch classifier loss: 0.347627; batch adversarial loss: 0.423041\n","epoch 13; iter: 0; batch classifier loss: 0.294910; batch adversarial loss: 0.447625\n","epoch 14; iter: 0; batch classifier loss: 0.251181; batch adversarial loss: 0.390264\n","epoch 15; iter: 0; batch classifier loss: 0.185060; batch adversarial loss: 0.361512\n","epoch 16; iter: 0; batch classifier loss: 0.220774; batch adversarial loss: 0.505625\n","epoch 17; iter: 0; batch classifier loss: 0.277151; batch adversarial loss: 0.337556\n","epoch 18; iter: 0; batch classifier loss: 0.310081; batch adversarial loss: 0.412907\n","epoch 19; iter: 0; batch classifier loss: 0.250357; batch adversarial loss: 0.394480\n","epoch 20; iter: 0; batch classifier loss: 0.379139; batch adversarial loss: 0.466847\n","epoch 21; iter: 0; batch classifier loss: 0.271122; batch adversarial loss: 0.418053\n","epoch 22; iter: 0; batch classifier loss: 0.210831; batch adversarial loss: 0.356014\n","epoch 23; iter: 0; batch classifier loss: 0.249805; batch adversarial loss: 0.408158\n","epoch 24; iter: 0; batch classifier loss: 0.204631; batch adversarial loss: 0.389949\n","epoch 25; iter: 0; batch classifier loss: 0.199794; batch adversarial loss: 0.340580\n","epoch 26; iter: 0; batch classifier loss: 0.295924; batch adversarial loss: 0.409170\n","epoch 27; iter: 0; batch classifier loss: 0.255427; batch adversarial loss: 0.381377\n","epoch 28; iter: 0; batch classifier loss: 0.276035; batch adversarial loss: 0.402469\n","epoch 29; iter: 0; batch classifier loss: 0.323655; batch adversarial loss: 0.381029\n","epoch 30; iter: 0; batch classifier loss: 0.305580; batch adversarial loss: 0.436304\n","epoch 31; iter: 0; batch classifier loss: 0.240891; batch adversarial loss: 0.447855\n","epoch 32; iter: 0; batch classifier loss: 0.265301; batch adversarial loss: 0.411632\n","epoch 33; iter: 0; batch classifier loss: 0.251692; batch adversarial loss: 0.370485\n","epoch 34; iter: 0; batch classifier loss: 0.359456; batch adversarial loss: 0.429949\n","epoch 35; iter: 0; batch classifier loss: 0.273919; batch adversarial loss: 0.527479\n","epoch 36; iter: 0; batch classifier loss: 0.281251; batch adversarial loss: 0.426797\n","epoch 37; iter: 0; batch classifier loss: 0.206996; batch adversarial loss: 0.384462\n","epoch 38; iter: 0; batch classifier loss: 0.287507; batch adversarial loss: 0.407862\n","epoch 39; iter: 0; batch classifier loss: 0.217262; batch adversarial loss: 0.363936\n","epoch 40; iter: 0; batch classifier loss: 0.292451; batch adversarial loss: 0.362211\n","epoch 41; iter: 0; batch classifier loss: 0.207445; batch adversarial loss: 0.359213\n","epoch 42; iter: 0; batch classifier loss: 0.285484; batch adversarial loss: 0.430732\n","epoch 43; iter: 0; batch classifier loss: 0.316232; batch adversarial loss: 0.405440\n","epoch 44; iter: 0; batch classifier loss: 0.161470; batch adversarial loss: 0.391188\n","epoch 45; iter: 0; batch classifier loss: 0.249211; batch adversarial loss: 0.428064\n","epoch 46; iter: 0; batch classifier loss: 0.220925; batch adversarial loss: 0.295445\n","epoch 47; iter: 0; batch classifier loss: 0.271635; batch adversarial loss: 0.433746\n","epoch 48; iter: 0; batch classifier loss: 0.335059; batch adversarial loss: 0.408300\n","epoch 49; iter: 0; batch classifier loss: 0.137982; batch adversarial loss: 0.309552\n","Accuracy 0.8976594768242313\n","epoch 0; iter: 0; batch classifier loss: 0.614058; batch adversarial loss: 0.862110\n","epoch 1; iter: 0; batch classifier loss: 0.255291; batch adversarial loss: 0.822467\n","epoch 2; iter: 0; batch classifier loss: 0.181941; batch adversarial loss: 0.689613\n","epoch 3; iter: 0; batch classifier loss: 0.269990; batch adversarial loss: 0.600844\n","epoch 4; iter: 0; batch classifier loss: 0.256579; batch adversarial loss: 0.517758\n","epoch 5; iter: 0; batch classifier loss: 0.262067; batch adversarial loss: 0.496809\n","epoch 6; iter: 0; batch classifier loss: 0.325414; batch adversarial loss: 0.441582\n","epoch 7; iter: 0; batch classifier loss: 0.271954; batch adversarial loss: 0.482764\n","epoch 8; iter: 0; batch classifier loss: 0.255400; batch adversarial loss: 0.473930\n","epoch 9; iter: 0; batch classifier loss: 0.201063; batch adversarial loss: 0.413031\n","epoch 10; iter: 0; batch classifier loss: 0.262461; batch adversarial loss: 0.436237\n","epoch 11; iter: 0; batch classifier loss: 0.590852; batch adversarial loss: 0.415087\n","epoch 12; iter: 0; batch classifier loss: 1.509563; batch adversarial loss: 0.491355\n","epoch 13; iter: 0; batch classifier loss: 1.200308; batch adversarial loss: 0.528596\n","epoch 14; iter: 0; batch classifier loss: 0.599295; batch adversarial loss: 0.475739\n","epoch 15; iter: 0; batch classifier loss: 0.319214; batch adversarial loss: 0.427869\n","epoch 16; iter: 0; batch classifier loss: 0.229952; batch adversarial loss: 0.454179\n","epoch 17; iter: 0; batch classifier loss: 0.256567; batch adversarial loss: 0.410983\n","epoch 18; iter: 0; batch classifier loss: 0.247824; batch adversarial loss: 0.474789\n","epoch 19; iter: 0; batch classifier loss: 0.270138; batch adversarial loss: 0.338201\n","epoch 20; iter: 0; batch classifier loss: 0.451359; batch adversarial loss: 0.439956\n","epoch 21; iter: 0; batch classifier loss: 0.275630; batch adversarial loss: 0.358776\n","epoch 22; iter: 0; batch classifier loss: 0.265773; batch adversarial loss: 0.360406\n","epoch 23; iter: 0; batch classifier loss: 0.298173; batch adversarial loss: 0.356783\n","epoch 24; iter: 0; batch classifier loss: 0.294800; batch adversarial loss: 0.472037\n","epoch 25; iter: 0; batch classifier loss: 0.218732; batch adversarial loss: 0.419578\n","epoch 26; iter: 0; batch classifier loss: 0.278138; batch adversarial loss: 0.403655\n","epoch 27; iter: 0; batch classifier loss: 0.217673; batch adversarial loss: 0.414610\n","epoch 28; iter: 0; batch classifier loss: 0.254010; batch adversarial loss: 0.334132\n","epoch 29; iter: 0; batch classifier loss: 0.197003; batch adversarial loss: 0.267282\n","epoch 30; iter: 0; batch classifier loss: 0.297565; batch adversarial loss: 0.367393\n","epoch 31; iter: 0; batch classifier loss: 0.151215; batch adversarial loss: 0.395100\n","epoch 32; iter: 0; batch classifier loss: 0.275838; batch adversarial loss: 0.386921\n","epoch 33; iter: 0; batch classifier loss: 0.243529; batch adversarial loss: 0.510384\n","epoch 34; iter: 0; batch classifier loss: 0.272156; batch adversarial loss: 0.324425\n","epoch 35; iter: 0; batch classifier loss: 0.221943; batch adversarial loss: 0.359566\n","epoch 36; iter: 0; batch classifier loss: 0.295029; batch adversarial loss: 0.423524\n","epoch 37; iter: 0; batch classifier loss: 0.340403; batch adversarial loss: 0.270525\n","epoch 38; iter: 0; batch classifier loss: 0.336723; batch adversarial loss: 0.460324\n","epoch 39; iter: 0; batch classifier loss: 0.203906; batch adversarial loss: 0.447944\n","epoch 40; iter: 0; batch classifier loss: 0.261668; batch adversarial loss: 0.411700\n","epoch 41; iter: 0; batch classifier loss: 0.226903; batch adversarial loss: 0.365962\n","epoch 42; iter: 0; batch classifier loss: 0.267201; batch adversarial loss: 0.339795\n","epoch 43; iter: 0; batch classifier loss: 0.220374; batch adversarial loss: 0.394203\n","epoch 44; iter: 0; batch classifier loss: 0.247790; batch adversarial loss: 0.358965\n","epoch 45; iter: 0; batch classifier loss: 0.273086; batch adversarial loss: 0.438945\n","epoch 46; iter: 0; batch classifier loss: 0.216293; batch adversarial loss: 0.363123\n","epoch 47; iter: 0; batch classifier loss: 0.248653; batch adversarial loss: 0.376840\n","epoch 48; iter: 0; batch classifier loss: 0.387019; batch adversarial loss: 0.330616\n","epoch 49; iter: 0; batch classifier loss: 0.216346; batch adversarial loss: 0.345250\n","Accuracy 0.8999541073887104\n","epoch 0; iter: 0; batch classifier loss: 0.709411; batch adversarial loss: 1.006805\n","epoch 1; iter: 0; batch classifier loss: 0.221696; batch adversarial loss: 1.445762\n","epoch 2; iter: 0; batch classifier loss: 0.311159; batch adversarial loss: 1.105063\n","epoch 3; iter: 0; batch classifier loss: 0.216887; batch adversarial loss: 0.954421\n","epoch 4; iter: 0; batch classifier loss: 0.228688; batch adversarial loss: 0.817341\n","epoch 5; iter: 0; batch classifier loss: 0.355607; batch adversarial loss: 0.699529\n","epoch 6; iter: 0; batch classifier loss: 0.200734; batch adversarial loss: 0.619227\n","epoch 7; iter: 0; batch classifier loss: 0.244988; batch adversarial loss: 0.583556\n","epoch 8; iter: 0; batch classifier loss: 0.306092; batch adversarial loss: 0.550265\n","epoch 9; iter: 0; batch classifier loss: 0.255997; batch adversarial loss: 0.442928\n","epoch 10; iter: 0; batch classifier loss: 0.278359; batch adversarial loss: 0.474409\n","epoch 11; iter: 0; batch classifier loss: 0.243272; batch adversarial loss: 0.489454\n","epoch 12; iter: 0; batch classifier loss: 0.331061; batch adversarial loss: 0.421519\n","epoch 13; iter: 0; batch classifier loss: 0.171030; batch adversarial loss: 0.465939\n","epoch 14; iter: 0; batch classifier loss: 0.159062; batch adversarial loss: 0.442209\n","epoch 15; iter: 0; batch classifier loss: 0.325196; batch adversarial loss: 0.389423\n","epoch 16; iter: 0; batch classifier loss: 0.250682; batch adversarial loss: 0.367982\n","epoch 17; iter: 0; batch classifier loss: 0.325175; batch adversarial loss: 0.540670\n","epoch 18; iter: 0; batch classifier loss: 0.321635; batch adversarial loss: 0.394572\n","epoch 19; iter: 0; batch classifier loss: 0.305654; batch adversarial loss: 0.406374\n","epoch 20; iter: 0; batch classifier loss: 0.189101; batch adversarial loss: 0.400855\n","epoch 21; iter: 0; batch classifier loss: 0.202267; batch adversarial loss: 0.383633\n","epoch 22; iter: 0; batch classifier loss: 0.177167; batch adversarial loss: 0.418752\n","epoch 23; iter: 0; batch classifier loss: 0.270677; batch adversarial loss: 0.357437\n","epoch 24; iter: 0; batch classifier loss: 0.269324; batch adversarial loss: 0.498354\n","epoch 25; iter: 0; batch classifier loss: 0.275758; batch adversarial loss: 0.347046\n","epoch 26; iter: 0; batch classifier loss: 0.218021; batch adversarial loss: 0.451039\n","epoch 27; iter: 0; batch classifier loss: 0.223405; batch adversarial loss: 0.375106\n","epoch 28; iter: 0; batch classifier loss: 0.281178; batch adversarial loss: 0.431714\n","epoch 29; iter: 0; batch classifier loss: 0.282867; batch adversarial loss: 0.413971\n","epoch 30; iter: 0; batch classifier loss: 0.273130; batch adversarial loss: 0.412101\n","epoch 31; iter: 0; batch classifier loss: 0.267189; batch adversarial loss: 0.410806\n","epoch 32; iter: 0; batch classifier loss: 0.249259; batch adversarial loss: 0.369678\n","epoch 33; iter: 0; batch classifier loss: 0.320500; batch adversarial loss: 0.452991\n","epoch 34; iter: 0; batch classifier loss: 0.235462; batch adversarial loss: 0.384734\n","epoch 35; iter: 0; batch classifier loss: 0.184115; batch adversarial loss: 0.295678\n","epoch 36; iter: 0; batch classifier loss: 0.289302; batch adversarial loss: 0.429197\n","epoch 37; iter: 0; batch classifier loss: 0.331463; batch adversarial loss: 0.373786\n","epoch 38; iter: 0; batch classifier loss: 0.240688; batch adversarial loss: 0.483839\n","epoch 39; iter: 0; batch classifier loss: 0.293555; batch adversarial loss: 0.423994\n","epoch 40; iter: 0; batch classifier loss: 0.193939; batch adversarial loss: 0.369260\n","epoch 41; iter: 0; batch classifier loss: 0.244665; batch adversarial loss: 0.416889\n","epoch 42; iter: 0; batch classifier loss: 0.324824; batch adversarial loss: 0.512509\n","epoch 43; iter: 0; batch classifier loss: 0.276860; batch adversarial loss: 0.339725\n","epoch 44; iter: 0; batch classifier loss: 0.271426; batch adversarial loss: 0.398689\n","epoch 45; iter: 0; batch classifier loss: 0.268777; batch adversarial loss: 0.423376\n","epoch 46; iter: 0; batch classifier loss: 0.289506; batch adversarial loss: 0.349113\n","epoch 47; iter: 0; batch classifier loss: 0.295096; batch adversarial loss: 0.427302\n","epoch 48; iter: 0; batch classifier loss: 0.201014; batch adversarial loss: 0.440564\n","epoch 49; iter: 0; batch classifier loss: 0.311103; batch adversarial loss: 0.433959\n","Accuracy 0.9043358568479009\n","epoch 0; iter: 0; batch classifier loss: 0.689670; batch adversarial loss: 0.531886\n","epoch 1; iter: 0; batch classifier loss: 1.308617; batch adversarial loss: 0.770809\n","epoch 2; iter: 0; batch classifier loss: 1.775336; batch adversarial loss: 0.680825\n","epoch 3; iter: 0; batch classifier loss: 2.011513; batch adversarial loss: 0.636652\n","epoch 4; iter: 0; batch classifier loss: 1.767133; batch adversarial loss: 0.645445\n","epoch 5; iter: 0; batch classifier loss: 1.721990; batch adversarial loss: 0.505117\n","epoch 6; iter: 0; batch classifier loss: 0.394376; batch adversarial loss: 0.460103\n","epoch 7; iter: 0; batch classifier loss: 0.331853; batch adversarial loss: 0.432568\n","epoch 8; iter: 0; batch classifier loss: 0.238359; batch adversarial loss: 0.387808\n","epoch 9; iter: 0; batch classifier loss: 0.343392; batch adversarial loss: 0.463387\n","epoch 10; iter: 0; batch classifier loss: 0.216650; batch adversarial loss: 0.376154\n","epoch 11; iter: 0; batch classifier loss: 0.314924; batch adversarial loss: 0.421414\n","epoch 12; iter: 0; batch classifier loss: 0.377373; batch adversarial loss: 0.445274\n","epoch 13; iter: 0; batch classifier loss: 0.334945; batch adversarial loss: 0.434765\n","epoch 14; iter: 0; batch classifier loss: 0.389571; batch adversarial loss: 0.467816\n","epoch 15; iter: 0; batch classifier loss: 0.258221; batch adversarial loss: 0.324089\n","epoch 16; iter: 0; batch classifier loss: 0.285869; batch adversarial loss: 0.392941\n","epoch 17; iter: 0; batch classifier loss: 0.240306; batch adversarial loss: 0.411864\n","epoch 18; iter: 0; batch classifier loss: 0.409503; batch adversarial loss: 0.462425\n","epoch 19; iter: 0; batch classifier loss: 0.227133; batch adversarial loss: 0.388569\n","epoch 20; iter: 0; batch classifier loss: 0.212530; batch adversarial loss: 0.419983\n","epoch 21; iter: 0; batch classifier loss: 0.192241; batch adversarial loss: 0.382189\n","epoch 22; iter: 0; batch classifier loss: 0.275310; batch adversarial loss: 0.427942\n","epoch 23; iter: 0; batch classifier loss: 0.255446; batch adversarial loss: 0.452094\n","epoch 24; iter: 0; batch classifier loss: 0.441053; batch adversarial loss: 0.403719\n","epoch 25; iter: 0; batch classifier loss: 0.238048; batch adversarial loss: 0.342612\n","epoch 26; iter: 0; batch classifier loss: 0.268930; batch adversarial loss: 0.334689\n","epoch 27; iter: 0; batch classifier loss: 0.251641; batch adversarial loss: 0.516226\n","epoch 28; iter: 0; batch classifier loss: 0.269755; batch adversarial loss: 0.429605\n","epoch 29; iter: 0; batch classifier loss: 0.255937; batch adversarial loss: 0.477979\n","epoch 30; iter: 0; batch classifier loss: 0.262258; batch adversarial loss: 0.473038\n","epoch 31; iter: 0; batch classifier loss: 0.299063; batch adversarial loss: 0.475009\n","epoch 32; iter: 0; batch classifier loss: 0.222762; batch adversarial loss: 0.392407\n","epoch 33; iter: 0; batch classifier loss: 0.221244; batch adversarial loss: 0.308492\n","epoch 34; iter: 0; batch classifier loss: 0.261130; batch adversarial loss: 0.424298\n","epoch 35; iter: 0; batch classifier loss: 0.298749; batch adversarial loss: 0.445666\n","epoch 36; iter: 0; batch classifier loss: 0.339186; batch adversarial loss: 0.445145\n","epoch 37; iter: 0; batch classifier loss: 0.202624; batch adversarial loss: 0.334411\n","epoch 38; iter: 0; batch classifier loss: 0.298971; batch adversarial loss: 0.518799\n","epoch 39; iter: 0; batch classifier loss: 0.296912; batch adversarial loss: 0.443633\n","epoch 40; iter: 0; batch classifier loss: 0.292657; batch adversarial loss: 0.545653\n","epoch 41; iter: 0; batch classifier loss: 0.178579; batch adversarial loss: 0.389561\n","epoch 42; iter: 0; batch classifier loss: 0.347019; batch adversarial loss: 0.406361\n","epoch 43; iter: 0; batch classifier loss: 0.227736; batch adversarial loss: 0.287619\n","epoch 44; iter: 0; batch classifier loss: 0.324710; batch adversarial loss: 0.418766\n","epoch 45; iter: 0; batch classifier loss: 0.316117; batch adversarial loss: 0.378483\n","epoch 46; iter: 0; batch classifier loss: 0.268594; batch adversarial loss: 0.441812\n","epoch 47; iter: 0; batch classifier loss: 0.212710; batch adversarial loss: 0.317867\n","epoch 48; iter: 0; batch classifier loss: 0.330427; batch adversarial loss: 0.499032\n","epoch 49; iter: 0; batch classifier loss: 0.360361; batch adversarial loss: 0.554141\n","Accuracy 0.8781551170261588\n","epoch 0; iter: 0; batch classifier loss: 0.815553; batch adversarial loss: 0.583677\n","epoch 1; iter: 0; batch classifier loss: 1.446451; batch adversarial loss: 0.685049\n","epoch 2; iter: 0; batch classifier loss: 1.909260; batch adversarial loss: 0.647344\n","epoch 3; iter: 0; batch classifier loss: 1.899960; batch adversarial loss: 0.667602\n","epoch 4; iter: 0; batch classifier loss: 2.030011; batch adversarial loss: 0.576794\n","epoch 5; iter: 0; batch classifier loss: 1.968497; batch adversarial loss: 0.534295\n","epoch 6; iter: 0; batch classifier loss: 0.538960; batch adversarial loss: 0.480125\n","epoch 7; iter: 0; batch classifier loss: 0.466452; batch adversarial loss: 0.476397\n","epoch 8; iter: 0; batch classifier loss: 0.503177; batch adversarial loss: 0.491071\n","epoch 9; iter: 0; batch classifier loss: 0.662643; batch adversarial loss: 0.414255\n","epoch 10; iter: 0; batch classifier loss: 0.689131; batch adversarial loss: 0.506244\n","epoch 11; iter: 0; batch classifier loss: 0.635308; batch adversarial loss: 0.421199\n","epoch 12; iter: 0; batch classifier loss: 0.356576; batch adversarial loss: 0.354267\n","epoch 13; iter: 0; batch classifier loss: 0.315325; batch adversarial loss: 0.341451\n","epoch 14; iter: 0; batch classifier loss: 0.280635; batch adversarial loss: 0.416972\n","epoch 15; iter: 0; batch classifier loss: 0.293129; batch adversarial loss: 0.381854\n","epoch 16; iter: 0; batch classifier loss: 0.352395; batch adversarial loss: 0.456869\n","epoch 17; iter: 0; batch classifier loss: 0.274005; batch adversarial loss: 0.418561\n","epoch 18; iter: 0; batch classifier loss: 0.343686; batch adversarial loss: 0.422080\n","epoch 19; iter: 0; batch classifier loss: 0.409902; batch adversarial loss: 0.467522\n","epoch 20; iter: 0; batch classifier loss: 0.329720; batch adversarial loss: 0.437209\n","epoch 21; iter: 0; batch classifier loss: 0.217428; batch adversarial loss: 0.354450\n","epoch 22; iter: 0; batch classifier loss: 0.306587; batch adversarial loss: 0.363130\n","epoch 23; iter: 0; batch classifier loss: 0.269714; batch adversarial loss: 0.358476\n","epoch 24; iter: 0; batch classifier loss: 0.228630; batch adversarial loss: 0.412888\n","epoch 25; iter: 0; batch classifier loss: 0.287582; batch adversarial loss: 0.351000\n","epoch 26; iter: 0; batch classifier loss: 0.361363; batch adversarial loss: 0.389527\n","epoch 27; iter: 0; batch classifier loss: 0.231815; batch adversarial loss: 0.364182\n","epoch 28; iter: 0; batch classifier loss: 0.240541; batch adversarial loss: 0.339867\n","epoch 29; iter: 0; batch classifier loss: 0.236300; batch adversarial loss: 0.316804\n","epoch 30; iter: 0; batch classifier loss: 0.263616; batch adversarial loss: 0.341025\n","epoch 31; iter: 0; batch classifier loss: 0.338015; batch adversarial loss: 0.425664\n","epoch 32; iter: 0; batch classifier loss: 0.335212; batch adversarial loss: 0.347599\n","epoch 33; iter: 0; batch classifier loss: 0.232626; batch adversarial loss: 0.338807\n","epoch 34; iter: 0; batch classifier loss: 0.475158; batch adversarial loss: 0.364879\n","epoch 35; iter: 0; batch classifier loss: 0.219010; batch adversarial loss: 0.321159\n","epoch 36; iter: 0; batch classifier loss: 0.264926; batch adversarial loss: 0.283964\n","epoch 37; iter: 0; batch classifier loss: 0.207119; batch adversarial loss: 0.351263\n","epoch 38; iter: 0; batch classifier loss: 0.219584; batch adversarial loss: 0.311099\n","epoch 39; iter: 0; batch classifier loss: 0.270502; batch adversarial loss: 0.402045\n","epoch 40; iter: 0; batch classifier loss: 0.282024; batch adversarial loss: 0.368433\n","epoch 41; iter: 0; batch classifier loss: 0.332905; batch adversarial loss: 0.400825\n","epoch 42; iter: 0; batch classifier loss: 0.232676; batch adversarial loss: 0.492451\n","epoch 43; iter: 0; batch classifier loss: 0.286398; batch adversarial loss: 0.411263\n","epoch 44; iter: 0; batch classifier loss: 0.236217; batch adversarial loss: 0.410156\n","epoch 45; iter: 0; batch classifier loss: 0.290399; batch adversarial loss: 0.346495\n","epoch 46; iter: 0; batch classifier loss: 0.158111; batch adversarial loss: 0.305812\n","epoch 47; iter: 0; batch classifier loss: 0.261192; batch adversarial loss: 0.321219\n","epoch 48; iter: 0; batch classifier loss: 0.293288; batch adversarial loss: 0.501619\n","epoch 49; iter: 0; batch classifier loss: 0.270927; batch adversarial loss: 0.491814\n","Accuracy 0.8962826984855439\n","epoch 0; iter: 0; batch classifier loss: 0.720570; batch adversarial loss: 0.665018\n","epoch 1; iter: 0; batch classifier loss: 0.939689; batch adversarial loss: 0.690273\n","epoch 2; iter: 0; batch classifier loss: 1.223281; batch adversarial loss: 0.652583\n","epoch 3; iter: 0; batch classifier loss: 1.232820; batch adversarial loss: 0.603250\n","epoch 4; iter: 0; batch classifier loss: 1.105828; batch adversarial loss: 0.550431\n","epoch 5; iter: 0; batch classifier loss: 0.668083; batch adversarial loss: 0.488487\n","epoch 6; iter: 0; batch classifier loss: 0.919620; batch adversarial loss: 0.485896\n","epoch 7; iter: 0; batch classifier loss: 0.865209; batch adversarial loss: 0.519279\n","epoch 8; iter: 0; batch classifier loss: 0.542425; batch adversarial loss: 0.480195\n","epoch 9; iter: 0; batch classifier loss: 0.500651; batch adversarial loss: 0.512559\n","epoch 10; iter: 0; batch classifier loss: 0.670762; batch adversarial loss: 0.464976\n","epoch 11; iter: 0; batch classifier loss: 0.645158; batch adversarial loss: 0.450089\n","epoch 12; iter: 0; batch classifier loss: 0.397505; batch adversarial loss: 0.491009\n","epoch 13; iter: 0; batch classifier loss: 0.310394; batch adversarial loss: 0.490813\n","epoch 14; iter: 0; batch classifier loss: 0.258403; batch adversarial loss: 0.299444\n","epoch 15; iter: 0; batch classifier loss: 0.240022; batch adversarial loss: 0.356935\n","epoch 16; iter: 0; batch classifier loss: 0.259544; batch adversarial loss: 0.431493\n","epoch 17; iter: 0; batch classifier loss: 0.247038; batch adversarial loss: 0.460053\n","epoch 18; iter: 0; batch classifier loss: 0.323734; batch adversarial loss: 0.422395\n","epoch 19; iter: 0; batch classifier loss: 0.216139; batch adversarial loss: 0.358213\n","epoch 20; iter: 0; batch classifier loss: 0.267745; batch adversarial loss: 0.425824\n","epoch 21; iter: 0; batch classifier loss: 0.241806; batch adversarial loss: 0.485426\n","epoch 22; iter: 0; batch classifier loss: 0.200091; batch adversarial loss: 0.416040\n","epoch 23; iter: 0; batch classifier loss: 0.377598; batch adversarial loss: 0.466199\n","epoch 24; iter: 0; batch classifier loss: 0.200270; batch adversarial loss: 0.376451\n","epoch 25; iter: 0; batch classifier loss: 0.278647; batch adversarial loss: 0.471754\n","epoch 26; iter: 0; batch classifier loss: 0.336676; batch adversarial loss: 0.361202\n","epoch 27; iter: 0; batch classifier loss: 0.254268; batch adversarial loss: 0.297420\n","epoch 28; iter: 0; batch classifier loss: 0.222372; batch adversarial loss: 0.409168\n","epoch 29; iter: 0; batch classifier loss: 0.196015; batch adversarial loss: 0.358501\n","epoch 30; iter: 0; batch classifier loss: 0.375419; batch adversarial loss: 0.475781\n","epoch 31; iter: 0; batch classifier loss: 0.305725; batch adversarial loss: 0.375929\n","epoch 32; iter: 0; batch classifier loss: 0.230463; batch adversarial loss: 0.442767\n","epoch 33; iter: 0; batch classifier loss: 0.265459; batch adversarial loss: 0.394551\n","epoch 34; iter: 0; batch classifier loss: 0.238208; batch adversarial loss: 0.373808\n","epoch 35; iter: 0; batch classifier loss: 0.222488; batch adversarial loss: 0.317453\n","epoch 36; iter: 0; batch classifier loss: 0.189395; batch adversarial loss: 0.355399\n","epoch 37; iter: 0; batch classifier loss: 0.210297; batch adversarial loss: 0.299582\n","epoch 38; iter: 0; batch classifier loss: 0.319283; batch adversarial loss: 0.433036\n","epoch 39; iter: 0; batch classifier loss: 0.204529; batch adversarial loss: 0.483257\n","epoch 40; iter: 0; batch classifier loss: 0.272288; batch adversarial loss: 0.329746\n","epoch 41; iter: 0; batch classifier loss: 0.289473; batch adversarial loss: 0.433468\n","epoch 42; iter: 0; batch classifier loss: 0.279915; batch adversarial loss: 0.410958\n","epoch 43; iter: 0; batch classifier loss: 0.293462; batch adversarial loss: 0.432227\n","epoch 44; iter: 0; batch classifier loss: 0.236376; batch adversarial loss: 0.397294\n","epoch 45; iter: 0; batch classifier loss: 0.278986; batch adversarial loss: 0.312831\n","epoch 46; iter: 0; batch classifier loss: 0.233869; batch adversarial loss: 0.347893\n","epoch 47; iter: 0; batch classifier loss: 0.277209; batch adversarial loss: 0.429353\n","epoch 48; iter: 0; batch classifier loss: 0.254201; batch adversarial loss: 0.539370\n","epoch 49; iter: 0; batch classifier loss: 0.145170; batch adversarial loss: 0.365774\n","Accuracy 0.8884809545663148\n","epoch 0; iter: 0; batch classifier loss: 0.648370; batch adversarial loss: 0.707974\n","epoch 1; iter: 0; batch classifier loss: 0.196829; batch adversarial loss: 0.604463\n","epoch 2; iter: 0; batch classifier loss: 0.311089; batch adversarial loss: 0.494371\n","epoch 3; iter: 0; batch classifier loss: 0.330678; batch adversarial loss: 0.500880\n","epoch 4; iter: 0; batch classifier loss: 0.349268; batch adversarial loss: 0.465205\n","epoch 5; iter: 0; batch classifier loss: 0.343513; batch adversarial loss: 0.450203\n","epoch 6; iter: 0; batch classifier loss: 0.368081; batch adversarial loss: 0.438316\n","epoch 7; iter: 0; batch classifier loss: 0.218654; batch adversarial loss: 0.426631\n","epoch 8; iter: 0; batch classifier loss: 0.319253; batch adversarial loss: 0.402571\n","epoch 9; iter: 0; batch classifier loss: 0.269062; batch adversarial loss: 0.357245\n","epoch 10; iter: 0; batch classifier loss: 0.319589; batch adversarial loss: 0.379880\n","epoch 11; iter: 0; batch classifier loss: 0.353925; batch adversarial loss: 0.496786\n","epoch 12; iter: 0; batch classifier loss: 0.233801; batch adversarial loss: 0.481121\n","epoch 13; iter: 0; batch classifier loss: 0.251884; batch adversarial loss: 0.382511\n","epoch 14; iter: 0; batch classifier loss: 0.283545; batch adversarial loss: 0.377554\n","epoch 15; iter: 0; batch classifier loss: 0.247361; batch adversarial loss: 0.522417\n","epoch 16; iter: 0; batch classifier loss: 0.247479; batch adversarial loss: 0.393689\n","epoch 17; iter: 0; batch classifier loss: 0.406894; batch adversarial loss: 0.565848\n","epoch 18; iter: 0; batch classifier loss: 0.314267; batch adversarial loss: 0.456582\n","epoch 19; iter: 0; batch classifier loss: 0.197003; batch adversarial loss: 0.346122\n","epoch 20; iter: 0; batch classifier loss: 0.211219; batch adversarial loss: 0.374111\n","epoch 21; iter: 0; batch classifier loss: 0.278093; batch adversarial loss: 0.464644\n","epoch 22; iter: 0; batch classifier loss: 0.257872; batch adversarial loss: 0.385582\n","epoch 23; iter: 0; batch classifier loss: 0.231736; batch adversarial loss: 0.348690\n","epoch 24; iter: 0; batch classifier loss: 0.233037; batch adversarial loss: 0.381442\n","epoch 25; iter: 0; batch classifier loss: 0.207527; batch adversarial loss: 0.485434\n","epoch 26; iter: 0; batch classifier loss: 0.257721; batch adversarial loss: 0.434993\n","epoch 27; iter: 0; batch classifier loss: 0.225544; batch adversarial loss: 0.332972\n","epoch 28; iter: 0; batch classifier loss: 0.211684; batch adversarial loss: 0.350747\n","epoch 29; iter: 0; batch classifier loss: 0.322333; batch adversarial loss: 0.420166\n","epoch 30; iter: 0; batch classifier loss: 0.238382; batch adversarial loss: 0.352428\n","epoch 31; iter: 0; batch classifier loss: 0.301182; batch adversarial loss: 0.459287\n","epoch 32; iter: 0; batch classifier loss: 0.267795; batch adversarial loss: 0.522337\n","epoch 33; iter: 0; batch classifier loss: 0.304331; batch adversarial loss: 0.345298\n","epoch 34; iter: 0; batch classifier loss: 0.225903; batch adversarial loss: 0.352581\n","epoch 35; iter: 0; batch classifier loss: 0.220404; batch adversarial loss: 0.346572\n","epoch 36; iter: 0; batch classifier loss: 0.291743; batch adversarial loss: 0.399322\n","epoch 37; iter: 0; batch classifier loss: 0.237939; batch adversarial loss: 0.363563\n","epoch 38; iter: 0; batch classifier loss: 0.217247; batch adversarial loss: 0.428677\n","epoch 39; iter: 0; batch classifier loss: 0.260668; batch adversarial loss: 0.441447\n","epoch 40; iter: 0; batch classifier loss: 0.272952; batch adversarial loss: 0.395578\n","epoch 41; iter: 0; batch classifier loss: 0.316984; batch adversarial loss: 0.506443\n","epoch 42; iter: 0; batch classifier loss: 0.297839; batch adversarial loss: 0.518059\n","epoch 43; iter: 0; batch classifier loss: 0.337612; batch adversarial loss: 0.399650\n","epoch 44; iter: 0; batch classifier loss: 0.336217; batch adversarial loss: 0.418738\n","epoch 45; iter: 0; batch classifier loss: 0.240628; batch adversarial loss: 0.386262\n","epoch 46; iter: 0; batch classifier loss: 0.235932; batch adversarial loss: 0.416451\n","epoch 47; iter: 0; batch classifier loss: 0.233772; batch adversarial loss: 0.478227\n","epoch 48; iter: 0; batch classifier loss: 0.317543; batch adversarial loss: 0.469886\n","epoch 49; iter: 0; batch classifier loss: 0.341517; batch adversarial loss: 0.448308\n","Accuracy 0.8981184029371271\n","epoch 0; iter: 0; batch classifier loss: 0.802242; batch adversarial loss: 0.702367\n","epoch 1; iter: 0; batch classifier loss: 0.248017; batch adversarial loss: 0.595538\n","epoch 2; iter: 0; batch classifier loss: 0.324124; batch adversarial loss: 0.518443\n","epoch 3; iter: 0; batch classifier loss: 0.367772; batch adversarial loss: 0.504447\n","epoch 4; iter: 0; batch classifier loss: 0.380447; batch adversarial loss: 0.454405\n","epoch 5; iter: 0; batch classifier loss: 0.378368; batch adversarial loss: 0.444290\n","epoch 6; iter: 0; batch classifier loss: 0.249799; batch adversarial loss: 0.383199\n","epoch 7; iter: 0; batch classifier loss: 0.367214; batch adversarial loss: 0.404689\n","epoch 8; iter: 0; batch classifier loss: 0.322839; batch adversarial loss: 0.430206\n","epoch 9; iter: 0; batch classifier loss: 0.261312; batch adversarial loss: 0.456277\n","epoch 10; iter: 0; batch classifier loss: 0.219591; batch adversarial loss: 0.445195\n","epoch 11; iter: 0; batch classifier loss: 0.274063; batch adversarial loss: 0.399262\n","epoch 12; iter: 0; batch classifier loss: 0.286763; batch adversarial loss: 0.455667\n","epoch 13; iter: 0; batch classifier loss: 0.290738; batch adversarial loss: 0.453795\n","epoch 14; iter: 0; batch classifier loss: 0.197959; batch adversarial loss: 0.275139\n","epoch 15; iter: 0; batch classifier loss: 0.330852; batch adversarial loss: 0.465548\n","epoch 16; iter: 0; batch classifier loss: 0.286069; batch adversarial loss: 0.439441\n","epoch 17; iter: 0; batch classifier loss: 0.295682; batch adversarial loss: 0.455423\n","epoch 18; iter: 0; batch classifier loss: 0.292485; batch adversarial loss: 0.301159\n","epoch 19; iter: 0; batch classifier loss: 0.356555; batch adversarial loss: 0.400274\n","epoch 20; iter: 0; batch classifier loss: 0.221562; batch adversarial loss: 0.406015\n","epoch 21; iter: 0; batch classifier loss: 0.214730; batch adversarial loss: 0.338053\n","epoch 22; iter: 0; batch classifier loss: 0.167782; batch adversarial loss: 0.368755\n","epoch 23; iter: 0; batch classifier loss: 0.292295; batch adversarial loss: 0.458166\n","epoch 24; iter: 0; batch classifier loss: 0.204031; batch adversarial loss: 0.423003\n","epoch 25; iter: 0; batch classifier loss: 0.175356; batch adversarial loss: 0.368642\n","epoch 26; iter: 0; batch classifier loss: 0.261683; batch adversarial loss: 0.309708\n","epoch 27; iter: 0; batch classifier loss: 0.204720; batch adversarial loss: 0.409711\n","epoch 28; iter: 0; batch classifier loss: 0.369706; batch adversarial loss: 0.354043\n","epoch 29; iter: 0; batch classifier loss: 0.239192; batch adversarial loss: 0.407690\n","epoch 30; iter: 0; batch classifier loss: 0.234042; batch adversarial loss: 0.356510\n","epoch 31; iter: 0; batch classifier loss: 0.391638; batch adversarial loss: 0.466893\n","epoch 32; iter: 0; batch classifier loss: 0.200328; batch adversarial loss: 0.398850\n","epoch 33; iter: 0; batch classifier loss: 0.206308; batch adversarial loss: 0.348232\n","epoch 34; iter: 0; batch classifier loss: 0.259690; batch adversarial loss: 0.437454\n","epoch 35; iter: 0; batch classifier loss: 0.296188; batch adversarial loss: 0.362366\n","epoch 36; iter: 0; batch classifier loss: 0.397568; batch adversarial loss: 0.442292\n","epoch 37; iter: 0; batch classifier loss: 0.248042; batch adversarial loss: 0.442520\n","epoch 38; iter: 0; batch classifier loss: 0.225323; batch adversarial loss: 0.474968\n","epoch 39; iter: 0; batch classifier loss: 0.281874; batch adversarial loss: 0.430380\n","epoch 40; iter: 0; batch classifier loss: 0.240752; batch adversarial loss: 0.313619\n","epoch 41; iter: 0; batch classifier loss: 0.266952; batch adversarial loss: 0.431028\n","epoch 42; iter: 0; batch classifier loss: 0.306980; batch adversarial loss: 0.452294\n","epoch 43; iter: 0; batch classifier loss: 0.168157; batch adversarial loss: 0.393582\n","epoch 44; iter: 0; batch classifier loss: 0.188841; batch adversarial loss: 0.327295\n","epoch 45; iter: 0; batch classifier loss: 0.232955; batch adversarial loss: 0.392440\n","epoch 46; iter: 0; batch classifier loss: 0.180501; batch adversarial loss: 0.349074\n","epoch 47; iter: 0; batch classifier loss: 0.242110; batch adversarial loss: 0.443430\n","epoch 48; iter: 0; batch classifier loss: 0.400242; batch adversarial loss: 0.496562\n","epoch 49; iter: 0; batch classifier loss: 0.306533; batch adversarial loss: 0.400606\n","Accuracy 0.8862124340445057\n","epoch 0; iter: 0; batch classifier loss: 0.801788; batch adversarial loss: 0.497021\n","epoch 1; iter: 0; batch classifier loss: 1.338911; batch adversarial loss: 0.857188\n","epoch 2; iter: 0; batch classifier loss: 1.803100; batch adversarial loss: 0.728244\n","epoch 3; iter: 0; batch classifier loss: 1.852293; batch adversarial loss: 0.654628\n","epoch 4; iter: 0; batch classifier loss: 1.752547; batch adversarial loss: 0.636761\n","epoch 5; iter: 0; batch classifier loss: 1.215810; batch adversarial loss: 0.539227\n","epoch 6; iter: 0; batch classifier loss: 0.571281; batch adversarial loss: 0.464609\n","epoch 7; iter: 0; batch classifier loss: 0.311669; batch adversarial loss: 0.421331\n","epoch 8; iter: 0; batch classifier loss: 0.224477; batch adversarial loss: 0.396934\n","epoch 9; iter: 0; batch classifier loss: 0.240039; batch adversarial loss: 0.398102\n","epoch 10; iter: 0; batch classifier loss: 0.339062; batch adversarial loss: 0.409454\n","epoch 11; iter: 0; batch classifier loss: 0.238673; batch adversarial loss: 0.423569\n","epoch 12; iter: 0; batch classifier loss: 0.234537; batch adversarial loss: 0.411570\n","epoch 13; iter: 0; batch classifier loss: 0.244435; batch adversarial loss: 0.449076\n","epoch 14; iter: 0; batch classifier loss: 0.322058; batch adversarial loss: 0.349031\n","epoch 15; iter: 0; batch classifier loss: 0.240283; batch adversarial loss: 0.306897\n","epoch 16; iter: 0; batch classifier loss: 0.230851; batch adversarial loss: 0.466298\n","epoch 17; iter: 0; batch classifier loss: 0.335835; batch adversarial loss: 0.433133\n","epoch 18; iter: 0; batch classifier loss: 0.343717; batch adversarial loss: 0.312303\n","epoch 19; iter: 0; batch classifier loss: 0.317013; batch adversarial loss: 0.306942\n","epoch 20; iter: 0; batch classifier loss: 0.216351; batch adversarial loss: 0.472645\n","epoch 21; iter: 0; batch classifier loss: 0.311360; batch adversarial loss: 0.460691\n","epoch 22; iter: 0; batch classifier loss: 0.230725; batch adversarial loss: 0.494641\n","epoch 23; iter: 0; batch classifier loss: 0.217846; batch adversarial loss: 0.426002\n","epoch 24; iter: 0; batch classifier loss: 0.270601; batch adversarial loss: 0.353580\n","epoch 25; iter: 0; batch classifier loss: 0.251552; batch adversarial loss: 0.285975\n","epoch 26; iter: 0; batch classifier loss: 0.362898; batch adversarial loss: 0.402406\n","epoch 27; iter: 0; batch classifier loss: 0.432780; batch adversarial loss: 0.440784\n","epoch 28; iter: 0; batch classifier loss: 0.230920; batch adversarial loss: 0.349381\n","epoch 29; iter: 0; batch classifier loss: 0.273900; batch adversarial loss: 0.389201\n","epoch 30; iter: 0; batch classifier loss: 0.265986; batch adversarial loss: 0.371972\n","epoch 31; iter: 0; batch classifier loss: 0.231672; batch adversarial loss: 0.451317\n","epoch 32; iter: 0; batch classifier loss: 0.204468; batch adversarial loss: 0.350169\n","epoch 33; iter: 0; batch classifier loss: 0.341998; batch adversarial loss: 0.422605\n","epoch 34; iter: 0; batch classifier loss: 0.248854; batch adversarial loss: 0.505508\n","epoch 35; iter: 0; batch classifier loss: 0.305697; batch adversarial loss: 0.383099\n","epoch 36; iter: 0; batch classifier loss: 0.252883; batch adversarial loss: 0.433168\n","epoch 37; iter: 0; batch classifier loss: 0.272622; batch adversarial loss: 0.457134\n","epoch 38; iter: 0; batch classifier loss: 0.300659; batch adversarial loss: 0.349581\n","epoch 39; iter: 0; batch classifier loss: 0.325659; batch adversarial loss: 0.439324\n","epoch 40; iter: 0; batch classifier loss: 0.216171; batch adversarial loss: 0.320870\n","epoch 41; iter: 0; batch classifier loss: 0.234686; batch adversarial loss: 0.540490\n","epoch 42; iter: 0; batch classifier loss: 0.241930; batch adversarial loss: 0.366146\n","epoch 43; iter: 0; batch classifier loss: 0.180596; batch adversarial loss: 0.380529\n","epoch 44; iter: 0; batch classifier loss: 0.278181; batch adversarial loss: 0.398191\n","epoch 45; iter: 0; batch classifier loss: 0.239584; batch adversarial loss: 0.410907\n","epoch 46; iter: 0; batch classifier loss: 0.276582; batch adversarial loss: 0.444971\n","epoch 47; iter: 0; batch classifier loss: 0.289256; batch adversarial loss: 0.487456\n","epoch 48; iter: 0; batch classifier loss: 0.436921; batch adversarial loss: 0.504881\n","epoch 49; iter: 0; batch classifier loss: 2.318569; batch adversarial loss: 0.657466\n"],"name":"stdout"},{"output_type":"stream","text":["divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.18058742542450665\n","epoch 0; iter: 0; batch classifier loss: 0.751039; batch adversarial loss: 0.490770\n","epoch 1; iter: 0; batch classifier loss: 1.526014; batch adversarial loss: 0.745376\n","epoch 2; iter: 0; batch classifier loss: 1.846992; batch adversarial loss: 0.697538\n","epoch 3; iter: 0; batch classifier loss: 1.910505; batch adversarial loss: 0.608225\n","epoch 4; iter: 0; batch classifier loss: 1.591550; batch adversarial loss: 0.667726\n","epoch 5; iter: 0; batch classifier loss: 1.313511; batch adversarial loss: 0.526667\n","epoch 6; iter: 0; batch classifier loss: 0.613012; batch adversarial loss: 0.503637\n","epoch 7; iter: 0; batch classifier loss: 0.405781; batch adversarial loss: 0.521066\n","epoch 8; iter: 0; batch classifier loss: 0.265540; batch adversarial loss: 0.314063\n","epoch 9; iter: 0; batch classifier loss: 0.267622; batch adversarial loss: 0.366096\n","epoch 10; iter: 0; batch classifier loss: 0.343063; batch adversarial loss: 0.496529\n","epoch 11; iter: 0; batch classifier loss: 0.301399; batch adversarial loss: 0.482428\n","epoch 12; iter: 0; batch classifier loss: 0.298801; batch adversarial loss: 0.529977\n","epoch 13; iter: 0; batch classifier loss: 0.329188; batch adversarial loss: 0.489836\n","epoch 14; iter: 0; batch classifier loss: 0.282511; batch adversarial loss: 0.402925\n","epoch 15; iter: 0; batch classifier loss: 0.332120; batch adversarial loss: 0.423323\n","epoch 16; iter: 0; batch classifier loss: 0.332056; batch adversarial loss: 0.516922\n","epoch 17; iter: 0; batch classifier loss: 0.263253; batch adversarial loss: 0.335924\n","epoch 18; iter: 0; batch classifier loss: 0.208336; batch adversarial loss: 0.510017\n","epoch 19; iter: 0; batch classifier loss: 0.250202; batch adversarial loss: 0.391244\n","epoch 20; iter: 0; batch classifier loss: 0.402321; batch adversarial loss: 0.426356\n","epoch 21; iter: 0; batch classifier loss: 0.418593; batch adversarial loss: 0.420526\n","epoch 22; iter: 0; batch classifier loss: 0.313314; batch adversarial loss: 0.439631\n","epoch 23; iter: 0; batch classifier loss: 0.169327; batch adversarial loss: 0.474312\n","epoch 24; iter: 0; batch classifier loss: 0.336885; batch adversarial loss: 0.368339\n","epoch 25; iter: 0; batch classifier loss: 0.285616; batch adversarial loss: 0.453657\n","epoch 26; iter: 0; batch classifier loss: 0.196444; batch adversarial loss: 0.291285\n","epoch 27; iter: 0; batch classifier loss: 0.242656; batch adversarial loss: 0.493978\n","epoch 28; iter: 0; batch classifier loss: 0.313182; batch adversarial loss: 0.401620\n","epoch 29; iter: 0; batch classifier loss: 0.344242; batch adversarial loss: 0.426336\n","epoch 30; iter: 0; batch classifier loss: 0.260508; batch adversarial loss: 0.382787\n","epoch 31; iter: 0; batch classifier loss: 0.297925; batch adversarial loss: 0.434174\n","epoch 32; iter: 0; batch classifier loss: 0.244812; batch adversarial loss: 0.336137\n","epoch 33; iter: 0; batch classifier loss: 0.220511; batch adversarial loss: 0.426013\n","epoch 34; iter: 0; batch classifier loss: 0.186405; batch adversarial loss: 0.456823\n","epoch 35; iter: 0; batch classifier loss: 0.320354; batch adversarial loss: 0.412649\n","epoch 36; iter: 0; batch classifier loss: 0.268862; batch adversarial loss: 0.323851\n","epoch 37; iter: 0; batch classifier loss: 0.244299; batch adversarial loss: 0.405411\n","epoch 38; iter: 0; batch classifier loss: 0.324728; batch adversarial loss: 0.387544\n","epoch 39; iter: 0; batch classifier loss: 0.268049; batch adversarial loss: 0.377405\n","epoch 40; iter: 0; batch classifier loss: 0.275751; batch adversarial loss: 0.412649\n","epoch 41; iter: 0; batch classifier loss: 0.320119; batch adversarial loss: 0.430633\n","epoch 42; iter: 0; batch classifier loss: 0.232008; batch adversarial loss: 0.380464\n","epoch 43; iter: 0; batch classifier loss: 0.270633; batch adversarial loss: 0.477576\n","epoch 44; iter: 0; batch classifier loss: 0.261152; batch adversarial loss: 0.327336\n","epoch 45; iter: 0; batch classifier loss: 0.301613; batch adversarial loss: 0.407993\n","epoch 46; iter: 0; batch classifier loss: 0.309389; batch adversarial loss: 0.413453\n","epoch 47; iter: 0; batch classifier loss: 0.280070; batch adversarial loss: 0.423286\n","epoch 48; iter: 0; batch classifier loss: 0.327948; batch adversarial loss: 0.346139\n","epoch 49; iter: 0; batch classifier loss: 0.278057; batch adversarial loss: 0.519497\n","Accuracy 0.8976594768242313\n","epoch 0; iter: 0; batch classifier loss: 0.717683; batch adversarial loss: 0.551716\n","epoch 1; iter: 0; batch classifier loss: 1.360526; batch adversarial loss: 0.726818\n","epoch 2; iter: 0; batch classifier loss: 1.812605; batch adversarial loss: 0.621294\n","epoch 3; iter: 0; batch classifier loss: 1.684550; batch adversarial loss: 0.638161\n","epoch 4; iter: 0; batch classifier loss: 1.549265; batch adversarial loss: 0.570035\n","epoch 5; iter: 0; batch classifier loss: 0.787343; batch adversarial loss: 0.507626\n","epoch 6; iter: 0; batch classifier loss: 0.359538; batch adversarial loss: 0.391032\n","epoch 7; iter: 0; batch classifier loss: 0.324443; batch adversarial loss: 0.348903\n","epoch 8; iter: 0; batch classifier loss: 0.310473; batch adversarial loss: 0.395354\n","epoch 9; iter: 0; batch classifier loss: 0.242162; batch adversarial loss: 0.392052\n","epoch 10; iter: 0; batch classifier loss: 0.312057; batch adversarial loss: 0.458019\n","epoch 11; iter: 0; batch classifier loss: 0.318773; batch adversarial loss: 0.353113\n","epoch 12; iter: 0; batch classifier loss: 0.272621; batch adversarial loss: 0.379588\n","epoch 13; iter: 0; batch classifier loss: 0.202125; batch adversarial loss: 0.431583\n","epoch 14; iter: 0; batch classifier loss: 0.308378; batch adversarial loss: 0.370395\n","epoch 15; iter: 0; batch classifier loss: 0.202369; batch adversarial loss: 0.322741\n","epoch 16; iter: 0; batch classifier loss: 0.263518; batch adversarial loss: 0.477015\n","epoch 17; iter: 0; batch classifier loss: 0.218748; batch adversarial loss: 0.376660\n","epoch 18; iter: 0; batch classifier loss: 0.265068; batch adversarial loss: 0.447745\n","epoch 19; iter: 0; batch classifier loss: 0.222505; batch adversarial loss: 0.294453\n","epoch 20; iter: 0; batch classifier loss: 0.265031; batch adversarial loss: 0.321862\n","epoch 21; iter: 0; batch classifier loss: 0.141424; batch adversarial loss: 0.370610\n","epoch 22; iter: 0; batch classifier loss: 0.213677; batch adversarial loss: 0.370195\n","epoch 23; iter: 0; batch classifier loss: 0.354614; batch adversarial loss: 0.436879\n","epoch 24; iter: 0; batch classifier loss: 0.340201; batch adversarial loss: 0.408213\n","epoch 25; iter: 0; batch classifier loss: 0.292752; batch adversarial loss: 0.479468\n","epoch 26; iter: 0; batch classifier loss: 0.277466; batch adversarial loss: 0.485467\n","epoch 27; iter: 0; batch classifier loss: 0.274957; batch adversarial loss: 0.369617\n","epoch 28; iter: 0; batch classifier loss: 0.160792; batch adversarial loss: 0.359470\n","epoch 29; iter: 0; batch classifier loss: 0.351602; batch adversarial loss: 0.501491\n","epoch 30; iter: 0; batch classifier loss: 0.298913; batch adversarial loss: 0.403187\n","epoch 31; iter: 0; batch classifier loss: 0.339145; batch adversarial loss: 0.370725\n","epoch 32; iter: 0; batch classifier loss: 0.313577; batch adversarial loss: 0.438377\n","epoch 33; iter: 0; batch classifier loss: 0.289609; batch adversarial loss: 0.398368\n","epoch 34; iter: 0; batch classifier loss: 0.356179; batch adversarial loss: 0.353671\n","epoch 35; iter: 0; batch classifier loss: 0.240816; batch adversarial loss: 0.413348\n","epoch 36; iter: 0; batch classifier loss: 0.207360; batch adversarial loss: 0.370839\n","epoch 37; iter: 0; batch classifier loss: 0.304735; batch adversarial loss: 0.423122\n","epoch 38; iter: 0; batch classifier loss: 0.265449; batch adversarial loss: 0.432730\n","epoch 39; iter: 0; batch classifier loss: 0.246163; batch adversarial loss: 0.412433\n","epoch 40; iter: 0; batch classifier loss: 0.308615; batch adversarial loss: 0.352606\n","epoch 41; iter: 0; batch classifier loss: 0.221976; batch adversarial loss: 0.401044\n","epoch 42; iter: 0; batch classifier loss: 0.307445; batch adversarial loss: 0.490453\n","epoch 43; iter: 0; batch classifier loss: 0.433853; batch adversarial loss: 0.466021\n","epoch 44; iter: 0; batch classifier loss: 1.948843; batch adversarial loss: 0.559367\n","epoch 45; iter: 0; batch classifier loss: 1.534691; batch adversarial loss: 0.495141\n","epoch 46; iter: 0; batch classifier loss: 0.511824; batch adversarial loss: 0.496244\n","epoch 47; iter: 0; batch classifier loss: 0.302876; batch adversarial loss: 0.476471\n","epoch 48; iter: 0; batch classifier loss: 0.219272; batch adversarial loss: 0.381775\n","epoch 49; iter: 0; batch classifier loss: 0.276099; batch adversarial loss: 0.334693\n","Accuracy 0.8946764570904084\n","epoch 0; iter: 0; batch classifier loss: 0.821257; batch adversarial loss: 0.634299\n","epoch 1; iter: 0; batch classifier loss: 1.320362; batch adversarial loss: 0.669803\n","epoch 2; iter: 0; batch classifier loss: 1.462663; batch adversarial loss: 0.657324\n","epoch 3; iter: 0; batch classifier loss: 1.567190; batch adversarial loss: 0.578370\n","epoch 4; iter: 0; batch classifier loss: 0.402425; batch adversarial loss: 0.530290\n","epoch 5; iter: 0; batch classifier loss: 0.485993; batch adversarial loss: 0.512594\n","epoch 6; iter: 0; batch classifier loss: 0.609070; batch adversarial loss: 0.484828\n","epoch 7; iter: 0; batch classifier loss: 0.839203; batch adversarial loss: 0.506691\n","epoch 8; iter: 0; batch classifier loss: 0.823273; batch adversarial loss: 0.535612\n","epoch 9; iter: 0; batch classifier loss: 0.672406; batch adversarial loss: 0.482413\n","epoch 10; iter: 0; batch classifier loss: 0.475106; batch adversarial loss: 0.501412\n","epoch 11; iter: 0; batch classifier loss: 0.348117; batch adversarial loss: 0.470693\n","epoch 12; iter: 0; batch classifier loss: 0.270022; batch adversarial loss: 0.505862\n","epoch 13; iter: 0; batch classifier loss: 0.408081; batch adversarial loss: 0.397689\n","epoch 14; iter: 0; batch classifier loss: 0.278359; batch adversarial loss: 0.364947\n","epoch 15; iter: 0; batch classifier loss: 0.209736; batch adversarial loss: 0.402335\n","epoch 16; iter: 0; batch classifier loss: 0.301232; batch adversarial loss: 0.476652\n","epoch 17; iter: 0; batch classifier loss: 0.236156; batch adversarial loss: 0.364323\n","epoch 18; iter: 0; batch classifier loss: 0.302603; batch adversarial loss: 0.574035\n","epoch 19; iter: 0; batch classifier loss: 0.235529; batch adversarial loss: 0.399450\n","epoch 20; iter: 0; batch classifier loss: 0.206603; batch adversarial loss: 0.401469\n","epoch 21; iter: 0; batch classifier loss: 0.272313; batch adversarial loss: 0.379432\n","epoch 22; iter: 0; batch classifier loss: 0.300867; batch adversarial loss: 0.481277\n","epoch 23; iter: 0; batch classifier loss: 0.222510; batch adversarial loss: 0.347844\n","epoch 24; iter: 0; batch classifier loss: 0.283553; batch adversarial loss: 0.376346\n","epoch 25; iter: 0; batch classifier loss: 0.427736; batch adversarial loss: 0.357881\n","epoch 26; iter: 0; batch classifier loss: 0.276319; batch adversarial loss: 0.466069\n","epoch 27; iter: 0; batch classifier loss: 0.257835; batch adversarial loss: 0.342575\n","epoch 28; iter: 0; batch classifier loss: 0.229801; batch adversarial loss: 0.296068\n","epoch 29; iter: 0; batch classifier loss: 0.221611; batch adversarial loss: 0.425335\n","epoch 30; iter: 0; batch classifier loss: 0.377514; batch adversarial loss: 0.387924\n","epoch 31; iter: 0; batch classifier loss: 0.178506; batch adversarial loss: 0.414387\n","epoch 32; iter: 0; batch classifier loss: 0.236433; batch adversarial loss: 0.351747\n","epoch 33; iter: 0; batch classifier loss: 0.308488; batch adversarial loss: 0.429139\n","epoch 34; iter: 0; batch classifier loss: 0.306247; batch adversarial loss: 0.473581\n","epoch 35; iter: 0; batch classifier loss: 0.219676; batch adversarial loss: 0.384260\n","epoch 36; iter: 0; batch classifier loss: 0.221433; batch adversarial loss: 0.459600\n","epoch 37; iter: 0; batch classifier loss: 0.248620; batch adversarial loss: 0.378378\n","epoch 38; iter: 0; batch classifier loss: 0.302024; batch adversarial loss: 0.397355\n","epoch 39; iter: 0; batch classifier loss: 0.265893; batch adversarial loss: 0.503395\n","epoch 40; iter: 0; batch classifier loss: 0.225895; batch adversarial loss: 0.415395\n","epoch 41; iter: 0; batch classifier loss: 0.262812; batch adversarial loss: 0.395420\n","epoch 42; iter: 0; batch classifier loss: 0.299500; batch adversarial loss: 0.292040\n","epoch 43; iter: 0; batch classifier loss: 0.279274; batch adversarial loss: 0.391042\n","epoch 44; iter: 0; batch classifier loss: 0.270318; batch adversarial loss: 0.512475\n","epoch 45; iter: 0; batch classifier loss: 0.200391; batch adversarial loss: 0.411819\n","epoch 46; iter: 0; batch classifier loss: 0.312812; batch adversarial loss: 0.450042\n","epoch 47; iter: 0; batch classifier loss: 0.316528; batch adversarial loss: 0.434224\n","epoch 48; iter: 0; batch classifier loss: 0.223195; batch adversarial loss: 0.323081\n","epoch 49; iter: 0; batch classifier loss: 0.247447; batch adversarial loss: 0.363169\n","Accuracy 0.8942175309775127\n","epoch 0; iter: 0; batch classifier loss: 0.775549; batch adversarial loss: 0.752681\n","epoch 1; iter: 0; batch classifier loss: 0.356457; batch adversarial loss: 0.680470\n","epoch 2; iter: 0; batch classifier loss: 0.223425; batch adversarial loss: 0.526817\n","epoch 3; iter: 0; batch classifier loss: 0.278765; batch adversarial loss: 0.495151\n","epoch 4; iter: 0; batch classifier loss: 0.326375; batch adversarial loss: 0.471828\n","epoch 5; iter: 0; batch classifier loss: 0.348439; batch adversarial loss: 0.447765\n","epoch 6; iter: 0; batch classifier loss: 0.288960; batch adversarial loss: 0.512377\n","epoch 7; iter: 0; batch classifier loss: 0.309916; batch adversarial loss: 0.421939\n","epoch 8; iter: 0; batch classifier loss: 0.346308; batch adversarial loss: 0.474602\n","epoch 9; iter: 0; batch classifier loss: 0.244275; batch adversarial loss: 0.472319\n","epoch 10; iter: 0; batch classifier loss: 0.390506; batch adversarial loss: 0.369032\n","epoch 11; iter: 0; batch classifier loss: 0.385742; batch adversarial loss: 0.449986\n","epoch 12; iter: 0; batch classifier loss: 1.508797; batch adversarial loss: 0.539407\n","epoch 13; iter: 0; batch classifier loss: 1.821244; batch adversarial loss: 0.591313\n","epoch 14; iter: 0; batch classifier loss: 1.769223; batch adversarial loss: 0.497540\n","epoch 15; iter: 0; batch classifier loss: 0.740055; batch adversarial loss: 0.437318\n","epoch 16; iter: 0; batch classifier loss: 0.272436; batch adversarial loss: 0.466940\n","epoch 17; iter: 0; batch classifier loss: 0.269870; batch adversarial loss: 0.406120\n","epoch 18; iter: 0; batch classifier loss: 0.336309; batch adversarial loss: 0.443570\n","epoch 19; iter: 0; batch classifier loss: 0.211964; batch adversarial loss: 0.454250\n","epoch 20; iter: 0; batch classifier loss: 0.232993; batch adversarial loss: 0.416605\n","epoch 21; iter: 0; batch classifier loss: 0.361536; batch adversarial loss: 0.380080\n","epoch 22; iter: 0; batch classifier loss: 0.233729; batch adversarial loss: 0.461341\n","epoch 23; iter: 0; batch classifier loss: 0.282734; batch adversarial loss: 0.464196\n","epoch 24; iter: 0; batch classifier loss: 0.347223; batch adversarial loss: 0.421461\n","epoch 25; iter: 0; batch classifier loss: 0.348425; batch adversarial loss: 0.370305\n","epoch 26; iter: 0; batch classifier loss: 0.262911; batch adversarial loss: 0.352754\n","epoch 27; iter: 0; batch classifier loss: 0.206901; batch adversarial loss: 0.295448\n","epoch 28; iter: 0; batch classifier loss: 0.307823; batch adversarial loss: 0.340427\n","epoch 29; iter: 0; batch classifier loss: 0.301239; batch adversarial loss: 0.358253\n","epoch 30; iter: 0; batch classifier loss: 0.277772; batch adversarial loss: 0.360491\n","epoch 31; iter: 0; batch classifier loss: 0.241899; batch adversarial loss: 0.412390\n","epoch 32; iter: 0; batch classifier loss: 0.271712; batch adversarial loss: 0.398864\n","epoch 33; iter: 0; batch classifier loss: 0.255359; batch adversarial loss: 0.475920\n","epoch 34; iter: 0; batch classifier loss: 0.234829; batch adversarial loss: 0.513265\n","epoch 35; iter: 0; batch classifier loss: 0.248585; batch adversarial loss: 0.419475\n","epoch 36; iter: 0; batch classifier loss: 0.293978; batch adversarial loss: 0.499925\n","epoch 37; iter: 0; batch classifier loss: 0.339062; batch adversarial loss: 0.343729\n","epoch 38; iter: 0; batch classifier loss: 0.250503; batch adversarial loss: 0.388223\n","epoch 39; iter: 0; batch classifier loss: 0.309562; batch adversarial loss: 0.379484\n","epoch 40; iter: 0; batch classifier loss: 0.424071; batch adversarial loss: 0.491442\n","epoch 41; iter: 0; batch classifier loss: 0.261715; batch adversarial loss: 0.367391\n","epoch 42; iter: 0; batch classifier loss: 0.209184; batch adversarial loss: 0.462192\n","epoch 43; iter: 0; batch classifier loss: 0.306251; batch adversarial loss: 0.486105\n","epoch 44; iter: 0; batch classifier loss: 0.260055; batch adversarial loss: 0.445384\n","epoch 45; iter: 0; batch classifier loss: 0.217226; batch adversarial loss: 0.366117\n","epoch 46; iter: 0; batch classifier loss: 0.297692; batch adversarial loss: 0.400413\n","epoch 47; iter: 0; batch classifier loss: 0.307673; batch adversarial loss: 0.362652\n","epoch 48; iter: 0; batch classifier loss: 0.243814; batch adversarial loss: 0.363307\n","epoch 49; iter: 0; batch classifier loss: 0.244544; batch adversarial loss: 0.386836\n","Accuracy 0.8878183069511356\n","epoch 0; iter: 0; batch classifier loss: 0.685348; batch adversarial loss: 0.790425\n","epoch 1; iter: 0; batch classifier loss: 0.452682; batch adversarial loss: 0.772776\n","epoch 2; iter: 0; batch classifier loss: 0.331495; batch adversarial loss: 0.650438\n","epoch 3; iter: 0; batch classifier loss: 0.250757; batch adversarial loss: 0.545618\n","epoch 4; iter: 0; batch classifier loss: 0.249320; batch adversarial loss: 0.524808\n","epoch 5; iter: 0; batch classifier loss: 0.246834; batch adversarial loss: 0.450325\n","epoch 6; iter: 0; batch classifier loss: 0.223756; batch adversarial loss: 0.435802\n","epoch 7; iter: 0; batch classifier loss: 0.236307; batch adversarial loss: 0.458566\n","epoch 8; iter: 0; batch classifier loss: 0.240681; batch adversarial loss: 0.379878\n","epoch 9; iter: 0; batch classifier loss: 0.222807; batch adversarial loss: 0.340298\n","epoch 10; iter: 0; batch classifier loss: 0.156265; batch adversarial loss: 0.462074\n","epoch 11; iter: 0; batch classifier loss: 0.246940; batch adversarial loss: 0.469000\n","epoch 12; iter: 0; batch classifier loss: 0.321509; batch adversarial loss: 0.421372\n","epoch 13; iter: 0; batch classifier loss: 0.250763; batch adversarial loss: 0.425497\n","epoch 14; iter: 0; batch classifier loss: 0.347274; batch adversarial loss: 0.432164\n","epoch 15; iter: 0; batch classifier loss: 0.150545; batch adversarial loss: 0.434547\n","epoch 16; iter: 0; batch classifier loss: 0.290434; batch adversarial loss: 0.478784\n","epoch 17; iter: 0; batch classifier loss: 0.255264; batch adversarial loss: 0.416670\n","epoch 18; iter: 0; batch classifier loss: 0.351765; batch adversarial loss: 0.453022\n","epoch 19; iter: 0; batch classifier loss: 0.405961; batch adversarial loss: 0.419795\n","epoch 20; iter: 0; batch classifier loss: 0.256081; batch adversarial loss: 0.437700\n","epoch 21; iter: 0; batch classifier loss: 0.218374; batch adversarial loss: 0.491309\n","epoch 22; iter: 0; batch classifier loss: 0.171774; batch adversarial loss: 0.327974\n","epoch 23; iter: 0; batch classifier loss: 0.226528; batch adversarial loss: 0.514568\n","epoch 24; iter: 0; batch classifier loss: 0.152011; batch adversarial loss: 0.423839\n","epoch 25; iter: 0; batch classifier loss: 0.267407; batch adversarial loss: 0.328517\n","epoch 26; iter: 0; batch classifier loss: 0.276714; batch adversarial loss: 0.400589\n","epoch 27; iter: 0; batch classifier loss: 0.338073; batch adversarial loss: 0.398326\n","epoch 28; iter: 0; batch classifier loss: 0.227165; batch adversarial loss: 0.337033\n","epoch 29; iter: 0; batch classifier loss: 0.259450; batch adversarial loss: 0.423371\n","epoch 30; iter: 0; batch classifier loss: 0.273595; batch adversarial loss: 0.409102\n","epoch 31; iter: 0; batch classifier loss: 0.232083; batch adversarial loss: 0.417774\n","epoch 32; iter: 0; batch classifier loss: 0.221074; batch adversarial loss: 0.443236\n","epoch 33; iter: 0; batch classifier loss: 0.186106; batch adversarial loss: 0.348517\n","epoch 34; iter: 0; batch classifier loss: 0.294005; batch adversarial loss: 0.480619\n","epoch 35; iter: 0; batch classifier loss: 0.328092; batch adversarial loss: 0.300738\n","epoch 36; iter: 0; batch classifier loss: 0.283670; batch adversarial loss: 0.429660\n","epoch 37; iter: 0; batch classifier loss: 0.306485; batch adversarial loss: 0.393795\n","epoch 38; iter: 0; batch classifier loss: 0.250140; batch adversarial loss: 0.346971\n","epoch 39; iter: 0; batch classifier loss: 0.331502; batch adversarial loss: 0.357458\n","epoch 40; iter: 0; batch classifier loss: 0.243521; batch adversarial loss: 0.429225\n","epoch 41; iter: 0; batch classifier loss: 0.241999; batch adversarial loss: 0.321218\n","epoch 42; iter: 0; batch classifier loss: 0.279488; batch adversarial loss: 0.441833\n","epoch 43; iter: 0; batch classifier loss: 0.221680; batch adversarial loss: 0.382074\n","epoch 44; iter: 0; batch classifier loss: 0.280553; batch adversarial loss: 0.429490\n","epoch 45; iter: 0; batch classifier loss: 0.207719; batch adversarial loss: 0.434200\n","epoch 46; iter: 0; batch classifier loss: 0.308131; batch adversarial loss: 0.555190\n","epoch 47; iter: 0; batch classifier loss: 0.302399; batch adversarial loss: 0.348300\n","epoch 48; iter: 0; batch classifier loss: 0.228854; batch adversarial loss: 0.379121\n","epoch 49; iter: 0; batch classifier loss: 0.276645; batch adversarial loss: 0.434284\n","Accuracy 0.8939880679210647\n","epoch 0; iter: 0; batch classifier loss: 0.715264; batch adversarial loss: 0.490769\n","epoch 1; iter: 0; batch classifier loss: 1.444133; batch adversarial loss: 0.685470\n","epoch 2; iter: 0; batch classifier loss: 1.615008; batch adversarial loss: 0.670788\n","epoch 3; iter: 0; batch classifier loss: 1.630861; batch adversarial loss: 0.631957\n","epoch 4; iter: 0; batch classifier loss: 1.393380; batch adversarial loss: 0.527362\n","epoch 5; iter: 0; batch classifier loss: 0.737285; batch adversarial loss: 0.497484\n","epoch 6; iter: 0; batch classifier loss: 0.547977; batch adversarial loss: 0.464820\n","epoch 7; iter: 0; batch classifier loss: 0.535981; batch adversarial loss: 0.504050\n","epoch 8; iter: 0; batch classifier loss: 0.658875; batch adversarial loss: 0.535383\n","epoch 9; iter: 0; batch classifier loss: 0.717561; batch adversarial loss: 0.401622\n","epoch 10; iter: 0; batch classifier loss: 0.457892; batch adversarial loss: 0.420820\n","epoch 11; iter: 0; batch classifier loss: 0.297397; batch adversarial loss: 0.351968\n","epoch 12; iter: 0; batch classifier loss: 0.257260; batch adversarial loss: 0.370123\n","epoch 13; iter: 0; batch classifier loss: 0.255856; batch adversarial loss: 0.290316\n","epoch 14; iter: 0; batch classifier loss: 0.349551; batch adversarial loss: 0.479880\n","epoch 15; iter: 0; batch classifier loss: 0.304958; batch adversarial loss: 0.480007\n","epoch 16; iter: 0; batch classifier loss: 0.284819; batch adversarial loss: 0.389947\n","epoch 17; iter: 0; batch classifier loss: 0.244160; batch adversarial loss: 0.451208\n","epoch 18; iter: 0; batch classifier loss: 0.255253; batch adversarial loss: 0.535402\n","epoch 19; iter: 0; batch classifier loss: 0.324082; batch adversarial loss: 0.512513\n","epoch 20; iter: 0; batch classifier loss: 0.276344; batch adversarial loss: 0.335140\n","epoch 21; iter: 0; batch classifier loss: 0.252242; batch adversarial loss: 0.417451\n","epoch 22; iter: 0; batch classifier loss: 0.331124; batch adversarial loss: 0.477393\n","epoch 23; iter: 0; batch classifier loss: 0.276353; batch adversarial loss: 0.421415\n","epoch 24; iter: 0; batch classifier loss: 0.253082; batch adversarial loss: 0.355859\n","epoch 25; iter: 0; batch classifier loss: 0.284461; batch adversarial loss: 0.449452\n","epoch 26; iter: 0; batch classifier loss: 0.277977; batch adversarial loss: 0.393213\n","epoch 27; iter: 0; batch classifier loss: 0.196663; batch adversarial loss: 0.381450\n","epoch 28; iter: 0; batch classifier loss: 0.236318; batch adversarial loss: 0.396107\n","epoch 29; iter: 0; batch classifier loss: 0.322949; batch adversarial loss: 0.416098\n","epoch 30; iter: 0; batch classifier loss: 0.171996; batch adversarial loss: 0.452284\n","epoch 31; iter: 0; batch classifier loss: 0.324429; batch adversarial loss: 0.421543\n","epoch 32; iter: 0; batch classifier loss: 0.271118; batch adversarial loss: 0.354403\n","epoch 33; iter: 0; batch classifier loss: 0.380968; batch adversarial loss: 0.460214\n","epoch 34; iter: 0; batch classifier loss: 0.319094; batch adversarial loss: 0.416169\n","epoch 35; iter: 0; batch classifier loss: 0.233077; batch adversarial loss: 0.396409\n","epoch 36; iter: 0; batch classifier loss: 0.306778; batch adversarial loss: 0.368041\n","epoch 37; iter: 0; batch classifier loss: 0.210736; batch adversarial loss: 0.417132\n","epoch 38; iter: 0; batch classifier loss: 0.214707; batch adversarial loss: 0.441399\n","epoch 39; iter: 0; batch classifier loss: 0.259249; batch adversarial loss: 0.354285\n","epoch 40; iter: 0; batch classifier loss: 0.254348; batch adversarial loss: 0.426839\n","epoch 41; iter: 0; batch classifier loss: 0.333236; batch adversarial loss: 0.425882\n","epoch 42; iter: 0; batch classifier loss: 0.286408; batch adversarial loss: 0.395815\n","epoch 43; iter: 0; batch classifier loss: 0.319216; batch adversarial loss: 0.347070\n","epoch 44; iter: 0; batch classifier loss: 0.245753; batch adversarial loss: 0.458902\n","epoch 45; iter: 0; batch classifier loss: 0.371267; batch adversarial loss: 0.407626\n","epoch 46; iter: 0; batch classifier loss: 0.285068; batch adversarial loss: 0.445661\n","epoch 47; iter: 0; batch classifier loss: 0.356860; batch adversarial loss: 0.452369\n","epoch 48; iter: 0; batch classifier loss: 0.248121; batch adversarial loss: 0.426673\n","epoch 49; iter: 0; batch classifier loss: 0.284708; batch adversarial loss: 0.387469\n","Accuracy 0.8983478659935751\n","epoch 0; iter: 0; batch classifier loss: 0.808594; batch adversarial loss: 0.829641\n","epoch 1; iter: 0; batch classifier loss: 0.318724; batch adversarial loss: 0.901230\n","epoch 2; iter: 0; batch classifier loss: 0.257453; batch adversarial loss: 0.758011\n","epoch 3; iter: 0; batch classifier loss: 0.246803; batch adversarial loss: 0.649860\n","epoch 4; iter: 0; batch classifier loss: 0.313499; batch adversarial loss: 0.572739\n","epoch 5; iter: 0; batch classifier loss: 0.307034; batch adversarial loss: 0.537491\n","epoch 6; iter: 0; batch classifier loss: 0.299662; batch adversarial loss: 0.515079\n","epoch 7; iter: 0; batch classifier loss: 0.301802; batch adversarial loss: 0.517396\n","epoch 8; iter: 0; batch classifier loss: 0.317258; batch adversarial loss: 0.445076\n","epoch 9; iter: 0; batch classifier loss: 0.274598; batch adversarial loss: 0.392858\n","epoch 10; iter: 0; batch classifier loss: 0.313085; batch adversarial loss: 0.451470\n","epoch 11; iter: 0; batch classifier loss: 0.230517; batch adversarial loss: 0.456943\n","epoch 12; iter: 0; batch classifier loss: 0.337415; batch adversarial loss: 0.504996\n","epoch 13; iter: 0; batch classifier loss: 0.286077; batch adversarial loss: 0.343055\n","epoch 14; iter: 0; batch classifier loss: 0.260633; batch adversarial loss: 0.461444\n","epoch 15; iter: 0; batch classifier loss: 0.243538; batch adversarial loss: 0.380528\n","epoch 16; iter: 0; batch classifier loss: 0.179353; batch adversarial loss: 0.337825\n","epoch 17; iter: 0; batch classifier loss: 0.254282; batch adversarial loss: 0.506508\n","epoch 18; iter: 0; batch classifier loss: 0.290841; batch adversarial loss: 0.462735\n","epoch 19; iter: 0; batch classifier loss: 0.244618; batch adversarial loss: 0.374277\n","epoch 20; iter: 0; batch classifier loss: 0.282062; batch adversarial loss: 0.402513\n","epoch 21; iter: 0; batch classifier loss: 0.237134; batch adversarial loss: 0.439300\n","epoch 22; iter: 0; batch classifier loss: 0.330367; batch adversarial loss: 0.483571\n","epoch 23; iter: 0; batch classifier loss: 0.239050; batch adversarial loss: 0.439310\n","epoch 24; iter: 0; batch classifier loss: 0.221732; batch adversarial loss: 0.383050\n","epoch 25; iter: 0; batch classifier loss: 0.274398; batch adversarial loss: 0.378770\n","epoch 26; iter: 0; batch classifier loss: 0.277011; batch adversarial loss: 0.426326\n","epoch 27; iter: 0; batch classifier loss: 0.277575; batch adversarial loss: 0.388214\n","epoch 28; iter: 0; batch classifier loss: 0.283145; batch adversarial loss: 0.480066\n","epoch 29; iter: 0; batch classifier loss: 0.265355; batch adversarial loss: 0.493494\n","epoch 30; iter: 0; batch classifier loss: 0.290209; batch adversarial loss: 0.310681\n","epoch 31; iter: 0; batch classifier loss: 0.250270; batch adversarial loss: 0.479941\n","epoch 32; iter: 0; batch classifier loss: 0.231168; batch adversarial loss: 0.379310\n","epoch 33; iter: 0; batch classifier loss: 0.194189; batch adversarial loss: 0.443981\n","epoch 34; iter: 0; batch classifier loss: 0.247462; batch adversarial loss: 0.425633\n","epoch 35; iter: 0; batch classifier loss: 0.204611; batch adversarial loss: 0.396515\n","epoch 36; iter: 0; batch classifier loss: 0.297147; batch adversarial loss: 0.443262\n","epoch 37; iter: 0; batch classifier loss: 0.340810; batch adversarial loss: 0.390887\n","epoch 38; iter: 0; batch classifier loss: 0.313688; batch adversarial loss: 0.445107\n","epoch 39; iter: 0; batch classifier loss: 0.234865; batch adversarial loss: 0.397026\n","epoch 40; iter: 0; batch classifier loss: 0.346809; batch adversarial loss: 0.353684\n","epoch 41; iter: 0; batch classifier loss: 0.237586; batch adversarial loss: 0.332169\n","epoch 42; iter: 0; batch classifier loss: 0.341235; batch adversarial loss: 0.369504\n","epoch 43; iter: 0; batch classifier loss: 0.238022; batch adversarial loss: 0.329064\n","epoch 44; iter: 0; batch classifier loss: 0.286928; batch adversarial loss: 0.371018\n","epoch 45; iter: 0; batch classifier loss: 0.268129; batch adversarial loss: 0.435343\n","epoch 46; iter: 0; batch classifier loss: 0.330283; batch adversarial loss: 0.347945\n","epoch 47; iter: 0; batch classifier loss: 0.149813; batch adversarial loss: 0.392914\n","epoch 48; iter: 0; batch classifier loss: 0.225908; batch adversarial loss: 0.295174\n","epoch 49; iter: 0; batch classifier loss: 0.233980; batch adversarial loss: 0.413210\n","Accuracy 0.8884809545663148\n","epoch 0; iter: 0; batch classifier loss: 0.623101; batch adversarial loss: 0.921162\n","epoch 1; iter: 0; batch classifier loss: 0.229860; batch adversarial loss: 0.815918\n","epoch 2; iter: 0; batch classifier loss: 0.287130; batch adversarial loss: 0.749394\n","epoch 3; iter: 0; batch classifier loss: 0.309629; batch adversarial loss: 0.641204\n","epoch 4; iter: 0; batch classifier loss: 0.273910; batch adversarial loss: 0.573940\n","epoch 5; iter: 0; batch classifier loss: 0.211461; batch adversarial loss: 0.491945\n","epoch 6; iter: 0; batch classifier loss: 0.316827; batch adversarial loss: 0.481571\n","epoch 7; iter: 0; batch classifier loss: 0.244739; batch adversarial loss: 0.428401\n","epoch 8; iter: 0; batch classifier loss: 0.254550; batch adversarial loss: 0.404355\n","epoch 9; iter: 0; batch classifier loss: 0.253164; batch adversarial loss: 0.401621\n","epoch 10; iter: 0; batch classifier loss: 0.357871; batch adversarial loss: 0.379776\n","epoch 11; iter: 0; batch classifier loss: 0.294794; batch adversarial loss: 0.485150\n","epoch 12; iter: 0; batch classifier loss: 0.329232; batch adversarial loss: 0.422668\n","epoch 13; iter: 0; batch classifier loss: 0.271257; batch adversarial loss: 0.393124\n","epoch 14; iter: 0; batch classifier loss: 0.323796; batch adversarial loss: 0.375988\n","epoch 15; iter: 0; batch classifier loss: 0.363217; batch adversarial loss: 0.363902\n","epoch 16; iter: 0; batch classifier loss: 0.330991; batch adversarial loss: 0.451026\n","epoch 17; iter: 0; batch classifier loss: 0.251851; batch adversarial loss: 0.326238\n","epoch 18; iter: 0; batch classifier loss: 0.244737; batch adversarial loss: 0.363816\n","epoch 19; iter: 0; batch classifier loss: 0.263530; batch adversarial loss: 0.358977\n","epoch 20; iter: 0; batch classifier loss: 0.297669; batch adversarial loss: 0.459970\n","epoch 21; iter: 0; batch classifier loss: 0.271083; batch adversarial loss: 0.382506\n","epoch 22; iter: 0; batch classifier loss: 0.256971; batch adversarial loss: 0.482853\n","epoch 23; iter: 0; batch classifier loss: 0.297045; batch adversarial loss: 0.450853\n","epoch 24; iter: 0; batch classifier loss: 0.310061; batch adversarial loss: 0.450664\n","epoch 25; iter: 0; batch classifier loss: 0.236254; batch adversarial loss: 0.426737\n","epoch 26; iter: 0; batch classifier loss: 0.319163; batch adversarial loss: 0.432557\n","epoch 27; iter: 0; batch classifier loss: 0.299027; batch adversarial loss: 0.437569\n","epoch 28; iter: 0; batch classifier loss: 0.272145; batch adversarial loss: 0.425860\n","epoch 29; iter: 0; batch classifier loss: 0.287398; batch adversarial loss: 0.361205\n","epoch 30; iter: 0; batch classifier loss: 0.320597; batch adversarial loss: 0.409440\n","epoch 31; iter: 0; batch classifier loss: 0.235585; batch adversarial loss: 0.484473\n","epoch 32; iter: 0; batch classifier loss: 0.210461; batch adversarial loss: 0.440383\n","epoch 33; iter: 0; batch classifier loss: 0.294927; batch adversarial loss: 0.377883\n","epoch 34; iter: 0; batch classifier loss: 0.157299; batch adversarial loss: 0.356916\n","epoch 35; iter: 0; batch classifier loss: 0.312814; batch adversarial loss: 0.458588\n","epoch 36; iter: 0; batch classifier loss: 0.272535; batch adversarial loss: 0.413622\n","epoch 37; iter: 0; batch classifier loss: 0.235640; batch adversarial loss: 0.445820\n","epoch 38; iter: 0; batch classifier loss: 0.238427; batch adversarial loss: 0.441706\n","epoch 39; iter: 0; batch classifier loss: 0.259535; batch adversarial loss: 0.459667\n","epoch 40; iter: 0; batch classifier loss: 0.272087; batch adversarial loss: 0.482272\n","epoch 41; iter: 0; batch classifier loss: 0.174354; batch adversarial loss: 0.401027\n","epoch 42; iter: 0; batch classifier loss: 0.204770; batch adversarial loss: 0.423483\n","epoch 43; iter: 0; batch classifier loss: 0.331194; batch adversarial loss: 0.435845\n","epoch 44; iter: 0; batch classifier loss: 0.250944; batch adversarial loss: 0.389150\n","epoch 45; iter: 0; batch classifier loss: 0.190044; batch adversarial loss: 0.350113\n","epoch 46; iter: 0; batch classifier loss: 0.246001; batch adversarial loss: 0.405354\n","epoch 47; iter: 0; batch classifier loss: 0.304893; batch adversarial loss: 0.373040\n","epoch 48; iter: 0; batch classifier loss: 0.281707; batch adversarial loss: 0.374734\n","epoch 49; iter: 0; batch classifier loss: 0.204787; batch adversarial loss: 0.351277\n","Accuracy 0.9024782010096375\n","epoch 0; iter: 0; batch classifier loss: 0.728812; batch adversarial loss: 0.822722\n","epoch 1; iter: 0; batch classifier loss: 0.395491; batch adversarial loss: 0.792601\n","epoch 2; iter: 0; batch classifier loss: 0.227552; batch adversarial loss: 0.686598\n","epoch 3; iter: 0; batch classifier loss: 0.256768; batch adversarial loss: 0.588296\n","epoch 4; iter: 0; batch classifier loss: 0.270294; batch adversarial loss: 0.545545\n","epoch 5; iter: 0; batch classifier loss: 0.296339; batch adversarial loss: 0.514990\n","epoch 6; iter: 0; batch classifier loss: 0.231902; batch adversarial loss: 0.516084\n","epoch 7; iter: 0; batch classifier loss: 0.203749; batch adversarial loss: 0.493578\n","epoch 8; iter: 0; batch classifier loss: 0.209200; batch adversarial loss: 0.467113\n","epoch 9; iter: 0; batch classifier loss: 0.268245; batch adversarial loss: 0.398318\n","epoch 10; iter: 0; batch classifier loss: 0.323021; batch adversarial loss: 0.381278\n","epoch 11; iter: 0; batch classifier loss: 0.305270; batch adversarial loss: 0.495594\n","epoch 12; iter: 0; batch classifier loss: 0.288762; batch adversarial loss: 0.396686\n","epoch 13; iter: 0; batch classifier loss: 0.162608; batch adversarial loss: 0.333212\n","epoch 14; iter: 0; batch classifier loss: 0.181412; batch adversarial loss: 0.337288\n","epoch 15; iter: 0; batch classifier loss: 0.261592; batch adversarial loss: 0.399735\n","epoch 16; iter: 0; batch classifier loss: 0.256405; batch adversarial loss: 0.420791\n","epoch 17; iter: 0; batch classifier loss: 0.234100; batch adversarial loss: 0.523510\n","epoch 18; iter: 0; batch classifier loss: 0.369488; batch adversarial loss: 0.370432\n","epoch 19; iter: 0; batch classifier loss: 0.208342; batch adversarial loss: 0.390596\n","epoch 20; iter: 0; batch classifier loss: 0.367476; batch adversarial loss: 0.469921\n","epoch 21; iter: 0; batch classifier loss: 0.258188; batch adversarial loss: 0.392685\n","epoch 22; iter: 0; batch classifier loss: 0.264232; batch adversarial loss: 0.399981\n","epoch 23; iter: 0; batch classifier loss: 0.265602; batch adversarial loss: 0.371163\n","epoch 24; iter: 0; batch classifier loss: 0.238785; batch adversarial loss: 0.505980\n","epoch 25; iter: 0; batch classifier loss: 0.348259; batch adversarial loss: 0.478659\n","epoch 26; iter: 0; batch classifier loss: 0.296690; batch adversarial loss: 0.397645\n","epoch 27; iter: 0; batch classifier loss: 0.210992; batch adversarial loss: 0.404142\n","epoch 28; iter: 0; batch classifier loss: 0.246032; batch adversarial loss: 0.460818\n","epoch 29; iter: 0; batch classifier loss: 0.262147; batch adversarial loss: 0.379482\n","epoch 30; iter: 0; batch classifier loss: 0.323539; batch adversarial loss: 0.423535\n","epoch 31; iter: 0; batch classifier loss: 0.191076; batch adversarial loss: 0.294886\n","epoch 32; iter: 0; batch classifier loss: 0.303532; batch adversarial loss: 0.410079\n","epoch 33; iter: 0; batch classifier loss: 0.278770; batch adversarial loss: 0.417542\n","epoch 34; iter: 0; batch classifier loss: 0.252104; batch adversarial loss: 0.372143\n","epoch 35; iter: 0; batch classifier loss: 0.210513; batch adversarial loss: 0.391085\n","epoch 36; iter: 0; batch classifier loss: 0.369459; batch adversarial loss: 0.419621\n","epoch 37; iter: 0; batch classifier loss: 0.218621; batch adversarial loss: 0.417646\n","epoch 38; iter: 0; batch classifier loss: 0.296833; batch adversarial loss: 0.412196\n","epoch 39; iter: 0; batch classifier loss: 0.277990; batch adversarial loss: 0.389770\n","epoch 40; iter: 0; batch classifier loss: 0.224234; batch adversarial loss: 0.488715\n","epoch 41; iter: 0; batch classifier loss: 0.234451; batch adversarial loss: 0.375041\n","epoch 42; iter: 0; batch classifier loss: 0.236258; batch adversarial loss: 0.402217\n","epoch 43; iter: 0; batch classifier loss: 0.331919; batch adversarial loss: 0.501460\n","epoch 44; iter: 0; batch classifier loss: 0.319057; batch adversarial loss: 0.497407\n","epoch 45; iter: 0; batch classifier loss: 0.300424; batch adversarial loss: 0.461722\n","epoch 46; iter: 0; batch classifier loss: 0.365069; batch adversarial loss: 0.393617\n","epoch 47; iter: 0; batch classifier loss: 0.228579; batch adversarial loss: 0.480258\n","epoch 48; iter: 0; batch classifier loss: 0.254802; batch adversarial loss: 0.386746\n","epoch 49; iter: 0; batch classifier loss: 0.250756; batch adversarial loss: 0.482656\n","Accuracy 0.8928653360862583\n","epoch 0; iter: 0; batch classifier loss: 0.628453; batch adversarial loss: 0.665499\n","epoch 1; iter: 0; batch classifier loss: 0.273747; batch adversarial loss: 0.520571\n","epoch 2; iter: 0; batch classifier loss: 0.286092; batch adversarial loss: 0.461305\n","epoch 3; iter: 0; batch classifier loss: 0.286176; batch adversarial loss: 0.390966\n","epoch 4; iter: 0; batch classifier loss: 0.327159; batch adversarial loss: 0.446759\n","epoch 5; iter: 0; batch classifier loss: 0.307142; batch adversarial loss: 0.403345\n","epoch 6; iter: 0; batch classifier loss: 0.290007; batch adversarial loss: 0.402429\n","epoch 7; iter: 0; batch classifier loss: 0.281454; batch adversarial loss: 0.394441\n","epoch 8; iter: 0; batch classifier loss: 0.284970; batch adversarial loss: 0.394423\n","epoch 9; iter: 0; batch classifier loss: 0.323959; batch adversarial loss: 0.483300\n","epoch 10; iter: 0; batch classifier loss: 0.284715; batch adversarial loss: 0.434583\n","epoch 11; iter: 0; batch classifier loss: 0.178318; batch adversarial loss: 0.385290\n","epoch 12; iter: 0; batch classifier loss: 0.302049; batch adversarial loss: 0.340680\n","epoch 13; iter: 0; batch classifier loss: 0.268371; batch adversarial loss: 0.460105\n","epoch 14; iter: 0; batch classifier loss: 0.308533; batch adversarial loss: 0.338390\n","epoch 15; iter: 0; batch classifier loss: 0.193383; batch adversarial loss: 0.373590\n","epoch 16; iter: 0; batch classifier loss: 0.274245; batch adversarial loss: 0.441453\n","epoch 17; iter: 0; batch classifier loss: 0.187500; batch adversarial loss: 0.464217\n","epoch 18; iter: 0; batch classifier loss: 0.275582; batch adversarial loss: 0.388462\n","epoch 19; iter: 0; batch classifier loss: 0.279187; batch adversarial loss: 0.446505\n","epoch 20; iter: 0; batch classifier loss: 0.239437; batch adversarial loss: 0.445100\n","epoch 21; iter: 0; batch classifier loss: 0.453925; batch adversarial loss: 0.417306\n","epoch 22; iter: 0; batch classifier loss: 0.235218; batch adversarial loss: 0.480527\n","epoch 23; iter: 0; batch classifier loss: 0.231091; batch adversarial loss: 0.381985\n","epoch 24; iter: 0; batch classifier loss: 0.337592; batch adversarial loss: 0.441095\n","epoch 25; iter: 0; batch classifier loss: 0.210152; batch adversarial loss: 0.431405\n","epoch 26; iter: 0; batch classifier loss: 0.231957; batch adversarial loss: 0.310075\n","epoch 27; iter: 0; batch classifier loss: 0.243625; batch adversarial loss: 0.327703\n","epoch 28; iter: 0; batch classifier loss: 0.292942; batch adversarial loss: 0.359751\n","epoch 29; iter: 0; batch classifier loss: 0.361869; batch adversarial loss: 0.541905\n","epoch 30; iter: 0; batch classifier loss: 0.247995; batch adversarial loss: 0.435874\n","epoch 31; iter: 0; batch classifier loss: 0.259882; batch adversarial loss: 0.432527\n","epoch 32; iter: 0; batch classifier loss: 0.295621; batch adversarial loss: 0.411668\n","epoch 33; iter: 0; batch classifier loss: 0.309396; batch adversarial loss: 0.385932\n","epoch 34; iter: 0; batch classifier loss: 0.286201; batch adversarial loss: 0.369892\n","epoch 35; iter: 0; batch classifier loss: 0.292306; batch adversarial loss: 0.433713\n","epoch 36; iter: 0; batch classifier loss: 0.202847; batch adversarial loss: 0.326764\n","epoch 37; iter: 0; batch classifier loss: 0.240468; batch adversarial loss: 0.506509\n","epoch 38; iter: 0; batch classifier loss: 0.307249; batch adversarial loss: 0.413762\n","epoch 39; iter: 0; batch classifier loss: 0.241873; batch adversarial loss: 0.400293\n","epoch 40; iter: 0; batch classifier loss: 0.250058; batch adversarial loss: 0.427980\n","epoch 41; iter: 0; batch classifier loss: 0.253841; batch adversarial loss: 0.397639\n","epoch 42; iter: 0; batch classifier loss: 0.280552; batch adversarial loss: 0.385104\n","epoch 43; iter: 0; batch classifier loss: 0.276258; batch adversarial loss: 0.412973\n","epoch 44; iter: 0; batch classifier loss: 0.219289; batch adversarial loss: 0.421368\n","epoch 45; iter: 0; batch classifier loss: 0.277173; batch adversarial loss: 0.378028\n","epoch 46; iter: 0; batch classifier loss: 0.220417; batch adversarial loss: 0.417024\n","epoch 47; iter: 0; batch classifier loss: 0.198993; batch adversarial loss: 0.487443\n","epoch 48; iter: 0; batch classifier loss: 0.316881; batch adversarial loss: 0.377745\n","epoch 49; iter: 0; batch classifier loss: 0.304274; batch adversarial loss: 0.533585\n","Accuracy 0.22625057365764112\n","epoch 0; iter: 0; batch classifier loss: 0.802620; batch adversarial loss: 0.600991\n","epoch 1; iter: 0; batch classifier loss: 1.351952; batch adversarial loss: 0.855072\n","epoch 2; iter: 0; batch classifier loss: 1.888985; batch adversarial loss: 0.796236\n","epoch 3; iter: 0; batch classifier loss: 2.041274; batch adversarial loss: 0.663658\n","epoch 4; iter: 0; batch classifier loss: 2.162187; batch adversarial loss: 0.593310\n","epoch 5; iter: 0; batch classifier loss: 2.143653; batch adversarial loss: 0.631917\n","epoch 6; iter: 0; batch classifier loss: 1.963440; batch adversarial loss: 0.566744\n","epoch 7; iter: 0; batch classifier loss: 1.303651; batch adversarial loss: 0.512652\n","epoch 8; iter: 0; batch classifier loss: 0.329271; batch adversarial loss: 0.436262\n","epoch 9; iter: 0; batch classifier loss: 0.273674; batch adversarial loss: 0.405012\n","epoch 10; iter: 0; batch classifier loss: 0.326573; batch adversarial loss: 0.355475\n","epoch 11; iter: 0; batch classifier loss: 0.309657; batch adversarial loss: 0.358073\n","epoch 12; iter: 0; batch classifier loss: 0.289268; batch adversarial loss: 0.424197\n","epoch 13; iter: 0; batch classifier loss: 0.391057; batch adversarial loss: 0.446503\n","epoch 14; iter: 0; batch classifier loss: 0.245557; batch adversarial loss: 0.343989\n","epoch 15; iter: 0; batch classifier loss: 0.318152; batch adversarial loss: 0.384181\n","epoch 16; iter: 0; batch classifier loss: 0.233179; batch adversarial loss: 0.456682\n","epoch 17; iter: 0; batch classifier loss: 0.312141; batch adversarial loss: 0.519134\n","epoch 18; iter: 0; batch classifier loss: 0.276695; batch adversarial loss: 0.493473\n","epoch 19; iter: 0; batch classifier loss: 0.278595; batch adversarial loss: 0.372630\n","epoch 20; iter: 0; batch classifier loss: 0.279073; batch adversarial loss: 0.413571\n","epoch 21; iter: 0; batch classifier loss: 0.247959; batch adversarial loss: 0.400040\n","epoch 22; iter: 0; batch classifier loss: 0.168551; batch adversarial loss: 0.363495\n","epoch 23; iter: 0; batch classifier loss: 0.217834; batch adversarial loss: 0.412427\n","epoch 24; iter: 0; batch classifier loss: 0.340908; batch adversarial loss: 0.494722\n","epoch 25; iter: 0; batch classifier loss: 0.248945; batch adversarial loss: 0.393730\n","epoch 26; iter: 0; batch classifier loss: 0.281591; batch adversarial loss: 0.409800\n","epoch 27; iter: 0; batch classifier loss: 0.325278; batch adversarial loss: 0.397008\n","epoch 28; iter: 0; batch classifier loss: 0.296007; batch adversarial loss: 0.443728\n","epoch 29; iter: 0; batch classifier loss: 0.174250; batch adversarial loss: 0.390910\n","epoch 30; iter: 0; batch classifier loss: 0.234345; batch adversarial loss: 0.380320\n","epoch 31; iter: 0; batch classifier loss: 0.182644; batch adversarial loss: 0.399687\n","epoch 32; iter: 0; batch classifier loss: 0.315473; batch adversarial loss: 0.401212\n","epoch 33; iter: 0; batch classifier loss: 0.314898; batch adversarial loss: 0.396621\n","epoch 34; iter: 0; batch classifier loss: 0.247972; batch adversarial loss: 0.465594\n","epoch 35; iter: 0; batch classifier loss: 0.204352; batch adversarial loss: 0.395348\n","epoch 36; iter: 0; batch classifier loss: 0.282744; batch adversarial loss: 0.294126\n","epoch 37; iter: 0; batch classifier loss: 0.210622; batch adversarial loss: 0.384134\n","epoch 38; iter: 0; batch classifier loss: 0.322470; batch adversarial loss: 0.415722\n","epoch 39; iter: 0; batch classifier loss: 0.227104; batch adversarial loss: 0.298488\n","epoch 40; iter: 0; batch classifier loss: 0.359665; batch adversarial loss: 0.339336\n","epoch 41; iter: 0; batch classifier loss: 0.248049; batch adversarial loss: 0.410331\n","epoch 42; iter: 0; batch classifier loss: 0.254593; batch adversarial loss: 0.368734\n","epoch 43; iter: 0; batch classifier loss: 0.404216; batch adversarial loss: 0.436318\n","epoch 44; iter: 0; batch classifier loss: 0.252100; batch adversarial loss: 0.327998\n","epoch 45; iter: 0; batch classifier loss: 0.229053; batch adversarial loss: 0.369301\n","epoch 46; iter: 0; batch classifier loss: 0.297053; batch adversarial loss: 0.416268\n","epoch 47; iter: 0; batch classifier loss: 0.231930; batch adversarial loss: 0.431878\n","epoch 48; iter: 0; batch classifier loss: 0.244290; batch adversarial loss: 0.499393\n","epoch 49; iter: 0; batch classifier loss: 0.304203; batch adversarial loss: 0.456905\n","Accuracy 0.888022028453419\n","epoch 0; iter: 0; batch classifier loss: 0.745630; batch adversarial loss: 0.824452\n","epoch 1; iter: 0; batch classifier loss: 0.349101; batch adversarial loss: 0.849415\n","epoch 2; iter: 0; batch classifier loss: 0.356589; batch adversarial loss: 0.714414\n","epoch 3; iter: 0; batch classifier loss: 0.229051; batch adversarial loss: 0.616149\n","epoch 4; iter: 0; batch classifier loss: 0.306187; batch adversarial loss: 0.539974\n","epoch 5; iter: 0; batch classifier loss: 0.163914; batch adversarial loss: 0.490765\n","epoch 6; iter: 0; batch classifier loss: 0.186484; batch adversarial loss: 0.449180\n","epoch 7; iter: 0; batch classifier loss: 0.314393; batch adversarial loss: 0.477352\n","epoch 8; iter: 0; batch classifier loss: 0.261794; batch adversarial loss: 0.369465\n","epoch 9; iter: 0; batch classifier loss: 0.344541; batch adversarial loss: 0.463485\n","epoch 10; iter: 0; batch classifier loss: 0.224935; batch adversarial loss: 0.493173\n","epoch 11; iter: 0; batch classifier loss: 0.308690; batch adversarial loss: 0.372763\n","epoch 12; iter: 0; batch classifier loss: 0.303330; batch adversarial loss: 0.407833\n","epoch 13; iter: 0; batch classifier loss: 0.246216; batch adversarial loss: 0.375168\n","epoch 14; iter: 0; batch classifier loss: 0.221441; batch adversarial loss: 0.439627\n","epoch 15; iter: 0; batch classifier loss: 0.280883; batch adversarial loss: 0.430901\n","epoch 16; iter: 0; batch classifier loss: 0.280632; batch adversarial loss: 0.417562\n","epoch 17; iter: 0; batch classifier loss: 0.361761; batch adversarial loss: 0.412966\n","epoch 18; iter: 0; batch classifier loss: 0.257718; batch adversarial loss: 0.457827\n","epoch 19; iter: 0; batch classifier loss: 0.225138; batch adversarial loss: 0.480951\n","epoch 20; iter: 0; batch classifier loss: 0.223496; batch adversarial loss: 0.477553\n","epoch 21; iter: 0; batch classifier loss: 0.217720; batch adversarial loss: 0.443621\n","epoch 22; iter: 0; batch classifier loss: 0.254582; batch adversarial loss: 0.367189\n","epoch 23; iter: 0; batch classifier loss: 0.211700; batch adversarial loss: 0.375082\n","epoch 24; iter: 0; batch classifier loss: 0.242760; batch adversarial loss: 0.314761\n","epoch 25; iter: 0; batch classifier loss: 0.207105; batch adversarial loss: 0.445424\n","epoch 26; iter: 0; batch classifier loss: 0.263545; batch adversarial loss: 0.398380\n","epoch 27; iter: 0; batch classifier loss: 0.194893; batch adversarial loss: 0.444145\n","epoch 28; iter: 0; batch classifier loss: 0.282820; batch adversarial loss: 0.537084\n","epoch 29; iter: 0; batch classifier loss: 0.271821; batch adversarial loss: 0.384086\n","epoch 30; iter: 0; batch classifier loss: 0.280467; batch adversarial loss: 0.368578\n","epoch 31; iter: 0; batch classifier loss: 0.250421; batch adversarial loss: 0.380679\n","epoch 32; iter: 0; batch classifier loss: 0.252290; batch adversarial loss: 0.419804\n","epoch 33; iter: 0; batch classifier loss: 0.338156; batch adversarial loss: 0.427197\n","epoch 34; iter: 0; batch classifier loss: 0.256641; batch adversarial loss: 0.472006\n","epoch 35; iter: 0; batch classifier loss: 0.223513; batch adversarial loss: 0.449542\n","epoch 36; iter: 0; batch classifier loss: 0.286035; batch adversarial loss: 0.259703\n","epoch 37; iter: 0; batch classifier loss: 0.214193; batch adversarial loss: 0.323872\n","epoch 38; iter: 0; batch classifier loss: 0.273713; batch adversarial loss: 0.477941\n","epoch 39; iter: 0; batch classifier loss: 0.293608; batch adversarial loss: 0.506907\n","epoch 40; iter: 0; batch classifier loss: 0.206172; batch adversarial loss: 0.360778\n","epoch 41; iter: 0; batch classifier loss: 0.218664; batch adversarial loss: 0.323233\n","epoch 42; iter: 0; batch classifier loss: 0.239205; batch adversarial loss: 0.432656\n","epoch 43; iter: 0; batch classifier loss: 0.231715; batch adversarial loss: 0.415169\n","epoch 44; iter: 0; batch classifier loss: 0.271600; batch adversarial loss: 0.309830\n","epoch 45; iter: 0; batch classifier loss: 0.288547; batch adversarial loss: 0.353318\n","epoch 46; iter: 0; batch classifier loss: 0.242774; batch adversarial loss: 0.439470\n","epoch 47; iter: 0; batch classifier loss: 0.280321; batch adversarial loss: 0.428299\n","epoch 48; iter: 0; batch classifier loss: 0.263688; batch adversarial loss: 0.473517\n","epoch 49; iter: 0; batch classifier loss: 0.290089; batch adversarial loss: 0.389938\n","Accuracy 0.8916934373565856\n","epoch 0; iter: 0; batch classifier loss: 0.649722; batch adversarial loss: 0.596183\n","epoch 1; iter: 0; batch classifier loss: 1.213303; batch adversarial loss: 0.673257\n","epoch 2; iter: 0; batch classifier loss: 1.318383; batch adversarial loss: 0.616505\n","epoch 3; iter: 0; batch classifier loss: 0.861293; batch adversarial loss: 0.584161\n","epoch 4; iter: 0; batch classifier loss: 0.723690; batch adversarial loss: 0.532134\n","epoch 5; iter: 0; batch classifier loss: 0.726755; batch adversarial loss: 0.473037\n","epoch 6; iter: 0; batch classifier loss: 0.797554; batch adversarial loss: 0.446026\n","epoch 7; iter: 0; batch classifier loss: 0.667458; batch adversarial loss: 0.480500\n","epoch 8; iter: 0; batch classifier loss: 0.597583; batch adversarial loss: 0.427403\n","epoch 9; iter: 0; batch classifier loss: 0.524022; batch adversarial loss: 0.410471\n","epoch 10; iter: 0; batch classifier loss: 0.299561; batch adversarial loss: 0.346182\n","epoch 11; iter: 0; batch classifier loss: 0.237642; batch adversarial loss: 0.405042\n","epoch 12; iter: 0; batch classifier loss: 0.293309; batch adversarial loss: 0.408051\n","epoch 13; iter: 0; batch classifier loss: 0.312368; batch adversarial loss: 0.400954\n","epoch 14; iter: 0; batch classifier loss: 0.316264; batch adversarial loss: 0.441026\n","epoch 15; iter: 0; batch classifier loss: 0.275777; batch adversarial loss: 0.385329\n","epoch 16; iter: 0; batch classifier loss: 0.289822; batch adversarial loss: 0.509339\n","epoch 17; iter: 0; batch classifier loss: 0.237203; batch adversarial loss: 0.476027\n","epoch 18; iter: 0; batch classifier loss: 0.266598; batch adversarial loss: 0.377571\n","epoch 19; iter: 0; batch classifier loss: 0.216786; batch adversarial loss: 0.395438\n","epoch 20; iter: 0; batch classifier loss: 0.181268; batch adversarial loss: 0.318840\n","epoch 21; iter: 0; batch classifier loss: 0.297461; batch adversarial loss: 0.404993\n","epoch 22; iter: 0; batch classifier loss: 0.259600; batch adversarial loss: 0.465849\n","epoch 23; iter: 0; batch classifier loss: 0.255326; batch adversarial loss: 0.383022\n","epoch 24; iter: 0; batch classifier loss: 0.271967; batch adversarial loss: 0.368940\n","epoch 25; iter: 0; batch classifier loss: 0.226017; batch adversarial loss: 0.436593\n","epoch 26; iter: 0; batch classifier loss: 0.308303; batch adversarial loss: 0.472975\n","epoch 27; iter: 0; batch classifier loss: 0.205072; batch adversarial loss: 0.411268\n","epoch 28; iter: 0; batch classifier loss: 0.239416; batch adversarial loss: 0.394756\n","epoch 29; iter: 0; batch classifier loss: 0.264893; batch adversarial loss: 0.402133\n","epoch 30; iter: 0; batch classifier loss: 0.358049; batch adversarial loss: 0.392211\n","epoch 31; iter: 0; batch classifier loss: 0.228573; batch adversarial loss: 0.321610\n","epoch 32; iter: 0; batch classifier loss: 0.258483; batch adversarial loss: 0.499035\n","epoch 33; iter: 0; batch classifier loss: 0.259772; batch adversarial loss: 0.421838\n","epoch 34; iter: 0; batch classifier loss: 0.264501; batch adversarial loss: 0.280128\n","epoch 35; iter: 0; batch classifier loss: 0.197184; batch adversarial loss: 0.436302\n","epoch 36; iter: 0; batch classifier loss: 0.265442; batch adversarial loss: 0.419868\n","epoch 37; iter: 0; batch classifier loss: 0.186561; batch adversarial loss: 0.396998\n","epoch 38; iter: 0; batch classifier loss: 0.280275; batch adversarial loss: 0.380867\n","epoch 39; iter: 0; batch classifier loss: 0.206569; batch adversarial loss: 0.437582\n","epoch 40; iter: 0; batch classifier loss: 0.285266; batch adversarial loss: 0.413585\n","epoch 41; iter: 0; batch classifier loss: 0.262710; batch adversarial loss: 0.438822\n","epoch 42; iter: 0; batch classifier loss: 0.189796; batch adversarial loss: 0.420901\n","epoch 43; iter: 0; batch classifier loss: 0.298324; batch adversarial loss: 0.412603\n","epoch 44; iter: 0; batch classifier loss: 0.262449; batch adversarial loss: 0.414208\n","epoch 45; iter: 0; batch classifier loss: 0.241245; batch adversarial loss: 0.419335\n","epoch 46; iter: 0; batch classifier loss: 0.301029; batch adversarial loss: 0.305144\n","epoch 47; iter: 0; batch classifier loss: 0.218506; batch adversarial loss: 0.371886\n","epoch 48; iter: 0; batch classifier loss: 0.355186; batch adversarial loss: 0.359785\n","epoch 49; iter: 0; batch classifier loss: 0.236488; batch adversarial loss: 0.359091\n","Accuracy 0.8942175309775127\n","epoch 0; iter: 0; batch classifier loss: 0.766179; batch adversarial loss: 0.516690\n","epoch 1; iter: 0; batch classifier loss: 1.412111; batch adversarial loss: 0.676359\n","epoch 2; iter: 0; batch classifier loss: 1.611056; batch adversarial loss: 0.707124\n","epoch 3; iter: 0; batch classifier loss: 1.612152; batch adversarial loss: 0.587071\n","epoch 4; iter: 0; batch classifier loss: 1.223878; batch adversarial loss: 0.542900\n","epoch 5; iter: 0; batch classifier loss: 0.612038; batch adversarial loss: 0.565733\n","epoch 6; iter: 0; batch classifier loss: 0.668579; batch adversarial loss: 0.514669\n","epoch 7; iter: 0; batch classifier loss: 0.625445; batch adversarial loss: 0.443747\n","epoch 8; iter: 0; batch classifier loss: 0.596543; batch adversarial loss: 0.529492\n","epoch 9; iter: 0; batch classifier loss: 0.477158; batch adversarial loss: 0.477511\n","epoch 10; iter: 0; batch classifier loss: 0.320490; batch adversarial loss: 0.422573\n","epoch 11; iter: 0; batch classifier loss: 0.282630; batch adversarial loss: 0.461637\n","epoch 12; iter: 0; batch classifier loss: 0.288802; batch adversarial loss: 0.395466\n","epoch 13; iter: 0; batch classifier loss: 0.287625; batch adversarial loss: 0.377779\n","epoch 14; iter: 0; batch classifier loss: 0.233844; batch adversarial loss: 0.396668\n","epoch 15; iter: 0; batch classifier loss: 0.219983; batch adversarial loss: 0.363375\n","epoch 16; iter: 0; batch classifier loss: 0.279521; batch adversarial loss: 0.376106\n","epoch 17; iter: 0; batch classifier loss: 0.248107; batch adversarial loss: 0.387753\n","epoch 18; iter: 0; batch classifier loss: 0.302256; batch adversarial loss: 0.404781\n","epoch 19; iter: 0; batch classifier loss: 0.246802; batch adversarial loss: 0.541198\n","epoch 20; iter: 0; batch classifier loss: 0.262286; batch adversarial loss: 0.417796\n","epoch 21; iter: 0; batch classifier loss: 0.317368; batch adversarial loss: 0.363126\n","epoch 22; iter: 0; batch classifier loss: 0.269195; batch adversarial loss: 0.393620\n","epoch 23; iter: 0; batch classifier loss: 0.285840; batch adversarial loss: 0.443310\n","epoch 24; iter: 0; batch classifier loss: 0.242734; batch adversarial loss: 0.340528\n","epoch 25; iter: 0; batch classifier loss: 0.354298; batch adversarial loss: 0.529307\n","epoch 26; iter: 0; batch classifier loss: 0.326176; batch adversarial loss: 0.490993\n","epoch 27; iter: 0; batch classifier loss: 0.220317; batch adversarial loss: 0.338600\n","epoch 28; iter: 0; batch classifier loss: 0.247889; batch adversarial loss: 0.410584\n","epoch 29; iter: 0; batch classifier loss: 0.311548; batch adversarial loss: 0.424748\n","epoch 30; iter: 0; batch classifier loss: 0.231643; batch adversarial loss: 0.401454\n","epoch 31; iter: 0; batch classifier loss: 0.244371; batch adversarial loss: 0.325856\n","epoch 32; iter: 0; batch classifier loss: 0.312937; batch adversarial loss: 0.363155\n","epoch 33; iter: 0; batch classifier loss: 0.290600; batch adversarial loss: 0.349246\n","epoch 34; iter: 0; batch classifier loss: 0.283178; batch adversarial loss: 0.385375\n","epoch 35; iter: 0; batch classifier loss: 0.355159; batch adversarial loss: 0.401354\n","epoch 36; iter: 0; batch classifier loss: 0.207934; batch adversarial loss: 0.378865\n","epoch 37; iter: 0; batch classifier loss: 0.325267; batch adversarial loss: 0.423524\n","epoch 38; iter: 0; batch classifier loss: 0.190996; batch adversarial loss: 0.460659\n","epoch 39; iter: 0; batch classifier loss: 0.313324; batch adversarial loss: 0.355668\n","epoch 40; iter: 0; batch classifier loss: 0.286074; batch adversarial loss: 0.413583\n","epoch 41; iter: 0; batch classifier loss: 0.221048; batch adversarial loss: 0.385370\n","epoch 42; iter: 0; batch classifier loss: 0.250046; batch adversarial loss: 0.345854\n","epoch 43; iter: 0; batch classifier loss: 0.254204; batch adversarial loss: 0.405085\n","epoch 44; iter: 0; batch classifier loss: 0.249570; batch adversarial loss: 0.341582\n","epoch 45; iter: 0; batch classifier loss: 0.354576; batch adversarial loss: 0.387601\n","epoch 46; iter: 0; batch classifier loss: 0.231058; batch adversarial loss: 0.375777\n","epoch 47; iter: 0; batch classifier loss: 0.280368; batch adversarial loss: 0.443659\n","epoch 48; iter: 0; batch classifier loss: 0.392007; batch adversarial loss: 0.416499\n","epoch 49; iter: 0; batch classifier loss: 0.317225; batch adversarial loss: 0.480722\n","Accuracy 0.8942417985776554\n","epoch 0; iter: 0; batch classifier loss: 0.744246; batch adversarial loss: 0.862455\n","epoch 1; iter: 0; batch classifier loss: 0.248802; batch adversarial loss: 0.958904\n","epoch 2; iter: 0; batch classifier loss: 0.229789; batch adversarial loss: 0.794609\n","epoch 3; iter: 0; batch classifier loss: 0.168426; batch adversarial loss: 0.674806\n","epoch 4; iter: 0; batch classifier loss: 0.266974; batch adversarial loss: 0.591985\n","epoch 5; iter: 0; batch classifier loss: 0.301995; batch adversarial loss: 0.523246\n","epoch 6; iter: 0; batch classifier loss: 0.363416; batch adversarial loss: 0.480485\n","epoch 7; iter: 0; batch classifier loss: 0.296398; batch adversarial loss: 0.441604\n","epoch 8; iter: 0; batch classifier loss: 0.191300; batch adversarial loss: 0.480026\n","epoch 9; iter: 0; batch classifier loss: 0.360525; batch adversarial loss: 0.462060\n","epoch 10; iter: 0; batch classifier loss: 0.297213; batch adversarial loss: 0.441967\n","epoch 11; iter: 0; batch classifier loss: 0.289562; batch adversarial loss: 0.319547\n","epoch 12; iter: 0; batch classifier loss: 0.354050; batch adversarial loss: 0.481570\n","epoch 13; iter: 0; batch classifier loss: 0.234931; batch adversarial loss: 0.516281\n","epoch 14; iter: 0; batch classifier loss: 0.264800; batch adversarial loss: 0.382232\n","epoch 15; iter: 0; batch classifier loss: 0.200696; batch adversarial loss: 0.401701\n","epoch 16; iter: 0; batch classifier loss: 0.261677; batch adversarial loss: 0.459325\n","epoch 17; iter: 0; batch classifier loss: 0.223943; batch adversarial loss: 0.433269\n","epoch 18; iter: 0; batch classifier loss: 0.275145; batch adversarial loss: 0.476956\n","epoch 19; iter: 0; batch classifier loss: 0.325769; batch adversarial loss: 0.405730\n","epoch 20; iter: 0; batch classifier loss: 0.190711; batch adversarial loss: 0.329799\n","epoch 21; iter: 0; batch classifier loss: 0.252811; batch adversarial loss: 0.383447\n","epoch 22; iter: 0; batch classifier loss: 0.293276; batch adversarial loss: 0.391545\n","epoch 23; iter: 0; batch classifier loss: 0.208987; batch adversarial loss: 0.400475\n","epoch 24; iter: 0; batch classifier loss: 0.253448; batch adversarial loss: 0.414611\n","epoch 25; iter: 0; batch classifier loss: 0.248964; batch adversarial loss: 0.441403\n","epoch 26; iter: 0; batch classifier loss: 0.275502; batch adversarial loss: 0.280860\n","epoch 27; iter: 0; batch classifier loss: 0.314526; batch adversarial loss: 0.410426\n","epoch 28; iter: 0; batch classifier loss: 0.283454; batch adversarial loss: 0.366877\n","epoch 29; iter: 0; batch classifier loss: 0.199663; batch adversarial loss: 0.329855\n","epoch 30; iter: 0; batch classifier loss: 0.154339; batch adversarial loss: 0.365172\n","epoch 31; iter: 0; batch classifier loss: 0.314917; batch adversarial loss: 0.388658\n","epoch 32; iter: 0; batch classifier loss: 0.237558; batch adversarial loss: 0.346856\n","epoch 33; iter: 0; batch classifier loss: 0.336206; batch adversarial loss: 0.356783\n","epoch 34; iter: 0; batch classifier loss: 0.243678; batch adversarial loss: 0.423385\n","epoch 35; iter: 0; batch classifier loss: 0.300259; batch adversarial loss: 0.424584\n","epoch 36; iter: 0; batch classifier loss: 0.230262; batch adversarial loss: 0.403923\n","epoch 37; iter: 0; batch classifier loss: 0.213129; batch adversarial loss: 0.381812\n","epoch 38; iter: 0; batch classifier loss: 0.283070; batch adversarial loss: 0.359087\n","epoch 39; iter: 0; batch classifier loss: 0.176961; batch adversarial loss: 0.388763\n","epoch 40; iter: 0; batch classifier loss: 0.282815; batch adversarial loss: 0.409629\n","epoch 41; iter: 0; batch classifier loss: 0.266851; batch adversarial loss: 0.435785\n","epoch 42; iter: 0; batch classifier loss: 0.302348; batch adversarial loss: 0.419105\n","epoch 43; iter: 0; batch classifier loss: 0.291071; batch adversarial loss: 0.367881\n","epoch 44; iter: 0; batch classifier loss: 0.282924; batch adversarial loss: 0.505087\n","epoch 45; iter: 0; batch classifier loss: 0.269136; batch adversarial loss: 0.398341\n","epoch 46; iter: 0; batch classifier loss: 0.234503; batch adversarial loss: 0.404966\n","epoch 47; iter: 0; batch classifier loss: 0.309378; batch adversarial loss: 0.422379\n","epoch 48; iter: 0; batch classifier loss: 0.250608; batch adversarial loss: 0.396065\n","epoch 49; iter: 0; batch classifier loss: 0.227226; batch adversarial loss: 0.331731\n","Accuracy 0.8921523634694815\n","epoch 0; iter: 0; batch classifier loss: 0.699163; batch adversarial loss: 0.740804\n","epoch 1; iter: 0; batch classifier loss: 0.237518; batch adversarial loss: 0.662305\n","epoch 2; iter: 0; batch classifier loss: 0.348888; batch adversarial loss: 0.583831\n","epoch 3; iter: 0; batch classifier loss: 0.271484; batch adversarial loss: 0.476685\n","epoch 4; iter: 0; batch classifier loss: 0.278537; batch adversarial loss: 0.560798\n","epoch 5; iter: 0; batch classifier loss: 0.276691; batch adversarial loss: 0.472980\n","epoch 6; iter: 0; batch classifier loss: 0.220577; batch adversarial loss: 0.430990\n","epoch 7; iter: 0; batch classifier loss: 0.311841; batch adversarial loss: 0.411678\n","epoch 8; iter: 0; batch classifier loss: 0.304742; batch adversarial loss: 0.422226\n","epoch 9; iter: 0; batch classifier loss: 0.317717; batch adversarial loss: 0.457797\n","epoch 10; iter: 0; batch classifier loss: 0.287618; batch adversarial loss: 0.393982\n","epoch 11; iter: 0; batch classifier loss: 0.257340; batch adversarial loss: 0.605749\n","epoch 12; iter: 0; batch classifier loss: 0.314094; batch adversarial loss: 0.466734\n","epoch 13; iter: 0; batch classifier loss: 0.435542; batch adversarial loss: 0.356497\n","epoch 14; iter: 0; batch classifier loss: 1.564286; batch adversarial loss: 0.528013\n","epoch 15; iter: 0; batch classifier loss: 1.781790; batch adversarial loss: 0.492976\n","epoch 16; iter: 0; batch classifier loss: 1.269390; batch adversarial loss: 0.479406\n","epoch 17; iter: 0; batch classifier loss: 0.434260; batch adversarial loss: 0.404130\n","epoch 18; iter: 0; batch classifier loss: 0.219658; batch adversarial loss: 0.330303\n","epoch 19; iter: 0; batch classifier loss: 0.315348; batch adversarial loss: 0.491407\n","epoch 20; iter: 0; batch classifier loss: 0.319112; batch adversarial loss: 0.401907\n","epoch 21; iter: 0; batch classifier loss: 0.274315; batch adversarial loss: 0.496300\n","epoch 22; iter: 0; batch classifier loss: 0.313889; batch adversarial loss: 0.445065\n","epoch 23; iter: 0; batch classifier loss: 0.251544; batch adversarial loss: 0.318495\n","epoch 24; iter: 0; batch classifier loss: 0.254232; batch adversarial loss: 0.465657\n","epoch 25; iter: 0; batch classifier loss: 0.260710; batch adversarial loss: 0.375008\n","epoch 26; iter: 0; batch classifier loss: 0.285258; batch adversarial loss: 0.429031\n","epoch 27; iter: 0; batch classifier loss: 0.199095; batch adversarial loss: 0.440283\n","epoch 28; iter: 0; batch classifier loss: 0.302577; batch adversarial loss: 0.354602\n","epoch 29; iter: 0; batch classifier loss: 0.301637; batch adversarial loss: 0.489710\n","epoch 30; iter: 0; batch classifier loss: 0.248096; batch adversarial loss: 0.411995\n","epoch 31; iter: 0; batch classifier loss: 0.283706; batch adversarial loss: 0.470348\n","epoch 32; iter: 0; batch classifier loss: 0.314211; batch adversarial loss: 0.400205\n","epoch 33; iter: 0; batch classifier loss: 0.226483; batch adversarial loss: 0.430084\n","epoch 34; iter: 0; batch classifier loss: 0.275221; batch adversarial loss: 0.354511\n","epoch 35; iter: 0; batch classifier loss: 0.275695; batch adversarial loss: 0.436094\n","epoch 36; iter: 0; batch classifier loss: 0.196569; batch adversarial loss: 0.428972\n","epoch 37; iter: 0; batch classifier loss: 0.269230; batch adversarial loss: 0.412590\n","epoch 38; iter: 0; batch classifier loss: 0.153378; batch adversarial loss: 0.305782\n","epoch 39; iter: 0; batch classifier loss: 0.226851; batch adversarial loss: 0.407865\n","epoch 40; iter: 0; batch classifier loss: 0.313101; batch adversarial loss: 0.405303\n","epoch 41; iter: 0; batch classifier loss: 0.246975; batch adversarial loss: 0.394360\n","epoch 42; iter: 0; batch classifier loss: 0.325899; batch adversarial loss: 0.425010\n","epoch 43; iter: 0; batch classifier loss: 0.282008; batch adversarial loss: 0.345088\n","epoch 44; iter: 0; batch classifier loss: 0.333421; batch adversarial loss: 0.307580\n","epoch 45; iter: 0; batch classifier loss: 0.298597; batch adversarial loss: 0.402758\n","epoch 46; iter: 0; batch classifier loss: 0.257498; batch adversarial loss: 0.424286\n","epoch 47; iter: 0; batch classifier loss: 0.291232; batch adversarial loss: 0.357168\n","epoch 48; iter: 0; batch classifier loss: 0.327077; batch adversarial loss: 0.299980\n","epoch 49; iter: 0; batch classifier loss: 0.338572; batch adversarial loss: 0.419752\n","Accuracy 0.8976594768242313\n","epoch 0; iter: 0; batch classifier loss: 0.734037; batch adversarial loss: 0.857947\n","epoch 1; iter: 0; batch classifier loss: 0.430461; batch adversarial loss: 0.877529\n","epoch 2; iter: 0; batch classifier loss: 0.228136; batch adversarial loss: 0.736269\n","epoch 3; iter: 0; batch classifier loss: 0.297639; batch adversarial loss: 0.631585\n","epoch 4; iter: 0; batch classifier loss: 0.219684; batch adversarial loss: 0.560213\n","epoch 5; iter: 0; batch classifier loss: 0.264842; batch adversarial loss: 0.522129\n","epoch 6; iter: 0; batch classifier loss: 0.248693; batch adversarial loss: 0.507195\n","epoch 7; iter: 0; batch classifier loss: 0.279887; batch adversarial loss: 0.497709\n","epoch 8; iter: 0; batch classifier loss: 0.322549; batch adversarial loss: 0.465932\n","epoch 9; iter: 0; batch classifier loss: 0.197702; batch adversarial loss: 0.434758\n","epoch 10; iter: 0; batch classifier loss: 0.248911; batch adversarial loss: 0.484659\n","epoch 11; iter: 0; batch classifier loss: 0.243767; batch adversarial loss: 0.447301\n","epoch 12; iter: 0; batch classifier loss: 0.283009; batch adversarial loss: 0.382312\n","epoch 13; iter: 0; batch classifier loss: 0.419244; batch adversarial loss: 0.423477\n","epoch 14; iter: 0; batch classifier loss: 0.210227; batch adversarial loss: 0.463193\n","epoch 15; iter: 0; batch classifier loss: 0.275521; batch adversarial loss: 0.440109\n","epoch 16; iter: 0; batch classifier loss: 0.249644; batch adversarial loss: 0.502419\n","epoch 17; iter: 0; batch classifier loss: 0.367345; batch adversarial loss: 0.469764\n","epoch 18; iter: 0; batch classifier loss: 0.247365; batch adversarial loss: 0.422128\n","epoch 19; iter: 0; batch classifier loss: 0.324416; batch adversarial loss: 0.460391\n","epoch 20; iter: 0; batch classifier loss: 0.334340; batch adversarial loss: 0.396929\n","epoch 21; iter: 0; batch classifier loss: 0.255461; batch adversarial loss: 0.379261\n","epoch 22; iter: 0; batch classifier loss: 0.316124; batch adversarial loss: 0.387331\n","epoch 23; iter: 0; batch classifier loss: 0.300456; batch adversarial loss: 0.394035\n","epoch 24; iter: 0; batch classifier loss: 0.168329; batch adversarial loss: 0.389118\n","epoch 25; iter: 0; batch classifier loss: 0.160097; batch adversarial loss: 0.313794\n","epoch 26; iter: 0; batch classifier loss: 0.275584; batch adversarial loss: 0.455335\n","epoch 27; iter: 0; batch classifier loss: 0.207454; batch adversarial loss: 0.374700\n","epoch 28; iter: 0; batch classifier loss: 0.301821; batch adversarial loss: 0.382435\n","epoch 29; iter: 0; batch classifier loss: 0.202627; batch adversarial loss: 0.408763\n","epoch 30; iter: 0; batch classifier loss: 0.272941; batch adversarial loss: 0.336518\n","epoch 31; iter: 0; batch classifier loss: 0.333430; batch adversarial loss: 0.461008\n","epoch 32; iter: 0; batch classifier loss: 0.263985; batch adversarial loss: 0.460536\n","epoch 33; iter: 0; batch classifier loss: 0.347505; batch adversarial loss: 0.451895\n","epoch 34; iter: 0; batch classifier loss: 0.318763; batch adversarial loss: 0.457599\n","epoch 35; iter: 0; batch classifier loss: 0.242809; batch adversarial loss: 0.396838\n","epoch 36; iter: 0; batch classifier loss: 0.239199; batch adversarial loss: 0.435535\n","epoch 37; iter: 0; batch classifier loss: 0.331668; batch adversarial loss: 0.352650\n","epoch 38; iter: 0; batch classifier loss: 0.176943; batch adversarial loss: 0.475117\n","epoch 39; iter: 0; batch classifier loss: 0.280590; batch adversarial loss: 0.527195\n","epoch 40; iter: 0; batch classifier loss: 0.226722; batch adversarial loss: 0.349505\n","epoch 41; iter: 0; batch classifier loss: 0.301807; batch adversarial loss: 0.391158\n","epoch 42; iter: 0; batch classifier loss: 0.313498; batch adversarial loss: 0.467471\n","epoch 43; iter: 0; batch classifier loss: 0.319066; batch adversarial loss: 0.395671\n","epoch 44; iter: 0; batch classifier loss: 0.288489; batch adversarial loss: 0.467015\n","epoch 45; iter: 0; batch classifier loss: 0.230248; batch adversarial loss: 0.419936\n","epoch 46; iter: 0; batch classifier loss: 0.237793; batch adversarial loss: 0.380965\n","epoch 47; iter: 0; batch classifier loss: 0.318566; batch adversarial loss: 0.363857\n","epoch 48; iter: 0; batch classifier loss: 0.281007; batch adversarial loss: 0.430247\n","epoch 49; iter: 0; batch classifier loss: 0.374281; batch adversarial loss: 0.474351\n","Accuracy 0.8969710876548875\n","epoch 0; iter: 0; batch classifier loss: 0.748842; batch adversarial loss: 0.851399\n","epoch 1; iter: 0; batch classifier loss: 0.405041; batch adversarial loss: 0.963789\n","epoch 2; iter: 0; batch classifier loss: 0.246523; batch adversarial loss: 0.709971\n","epoch 3; iter: 0; batch classifier loss: 0.202169; batch adversarial loss: 0.565808\n","epoch 4; iter: 0; batch classifier loss: 0.273349; batch adversarial loss: 0.517338\n","epoch 5; iter: 0; batch classifier loss: 0.312786; batch adversarial loss: 0.526462\n","epoch 6; iter: 0; batch classifier loss: 0.256611; batch adversarial loss: 0.478702\n","epoch 7; iter: 0; batch classifier loss: 0.319871; batch adversarial loss: 0.486425\n","epoch 8; iter: 0; batch classifier loss: 0.389583; batch adversarial loss: 0.445856\n","epoch 9; iter: 0; batch classifier loss: 0.253817; batch adversarial loss: 0.348821\n","epoch 10; iter: 0; batch classifier loss: 0.296550; batch adversarial loss: 0.401508\n","epoch 11; iter: 0; batch classifier loss: 0.268198; batch adversarial loss: 0.337840\n","epoch 12; iter: 0; batch classifier loss: 0.267749; batch adversarial loss: 0.407255\n","epoch 13; iter: 0; batch classifier loss: 0.349775; batch adversarial loss: 0.472126\n","epoch 14; iter: 0; batch classifier loss: 0.311729; batch adversarial loss: 0.384725\n","epoch 15; iter: 0; batch classifier loss: 0.312094; batch adversarial loss: 0.411267\n","epoch 16; iter: 0; batch classifier loss: 0.253341; batch adversarial loss: 0.352722\n","epoch 17; iter: 0; batch classifier loss: 0.245554; batch adversarial loss: 0.532184\n","epoch 18; iter: 0; batch classifier loss: 0.334071; batch adversarial loss: 0.509698\n","epoch 19; iter: 0; batch classifier loss: 0.248481; batch adversarial loss: 0.355566\n","epoch 20; iter: 0; batch classifier loss: 0.207302; batch adversarial loss: 0.434995\n","epoch 21; iter: 0; batch classifier loss: 0.329613; batch adversarial loss: 0.373576\n","epoch 22; iter: 0; batch classifier loss: 0.235923; batch adversarial loss: 0.352499\n","epoch 23; iter: 0; batch classifier loss: 0.267709; batch adversarial loss: 0.450798\n","epoch 24; iter: 0; batch classifier loss: 0.262419; batch adversarial loss: 0.305877\n","epoch 25; iter: 0; batch classifier loss: 0.306249; batch adversarial loss: 0.386644\n","epoch 26; iter: 0; batch classifier loss: 0.350339; batch adversarial loss: 0.452120\n","epoch 27; iter: 0; batch classifier loss: 0.269695; batch adversarial loss: 0.406387\n","epoch 28; iter: 0; batch classifier loss: 0.305284; batch adversarial loss: 0.384933\n","epoch 29; iter: 0; batch classifier loss: 0.156907; batch adversarial loss: 0.362846\n","epoch 30; iter: 0; batch classifier loss: 0.304670; batch adversarial loss: 0.485247\n","epoch 31; iter: 0; batch classifier loss: 0.201238; batch adversarial loss: 0.428963\n","epoch 32; iter: 0; batch classifier loss: 0.190592; batch adversarial loss: 0.305032\n","epoch 33; iter: 0; batch classifier loss: 0.231400; batch adversarial loss: 0.439932\n","epoch 34; iter: 0; batch classifier loss: 0.258809; batch adversarial loss: 0.350522\n","epoch 35; iter: 0; batch classifier loss: 0.287837; batch adversarial loss: 0.365534\n","epoch 36; iter: 0; batch classifier loss: 0.304776; batch adversarial loss: 0.437520\n","epoch 37; iter: 0; batch classifier loss: 0.237965; batch adversarial loss: 0.432212\n","epoch 38; iter: 0; batch classifier loss: 0.256693; batch adversarial loss: 0.485737\n","epoch 39; iter: 0; batch classifier loss: 0.230714; batch adversarial loss: 0.418830\n","epoch 40; iter: 0; batch classifier loss: 0.346429; batch adversarial loss: 0.467998\n","epoch 41; iter: 0; batch classifier loss: 0.230299; batch adversarial loss: 0.418524\n","epoch 42; iter: 0; batch classifier loss: 0.263196; batch adversarial loss: 0.344713\n","epoch 43; iter: 0; batch classifier loss: 0.317722; batch adversarial loss: 0.391234\n","epoch 44; iter: 0; batch classifier loss: 0.284657; batch adversarial loss: 0.447401\n","epoch 45; iter: 0; batch classifier loss: 0.318320; batch adversarial loss: 0.370902\n","epoch 46; iter: 0; batch classifier loss: 0.300166; batch adversarial loss: 0.384953\n","epoch 47; iter: 0; batch classifier loss: 0.220015; batch adversarial loss: 0.461845\n","epoch 48; iter: 0; batch classifier loss: 0.299099; batch adversarial loss: 0.377463\n","epoch 49; iter: 0; batch classifier loss: 0.259174; batch adversarial loss: 0.389431\n","Accuracy 0.8953648462597522\n","epoch 0; iter: 0; batch classifier loss: 0.644405; batch adversarial loss: 0.850428\n","epoch 1; iter: 0; batch classifier loss: 0.401744; batch adversarial loss: 0.761679\n","epoch 2; iter: 0; batch classifier loss: 0.296410; batch adversarial loss: 0.647175\n","epoch 3; iter: 0; batch classifier loss: 0.301639; batch adversarial loss: 0.550535\n","epoch 4; iter: 0; batch classifier loss: 0.251101; batch adversarial loss: 0.495392\n","epoch 5; iter: 0; batch classifier loss: 0.364625; batch adversarial loss: 0.501636\n","epoch 6; iter: 0; batch classifier loss: 0.270228; batch adversarial loss: 0.492426\n","epoch 7; iter: 0; batch classifier loss: 0.263930; batch adversarial loss: 0.517556\n","epoch 8; iter: 0; batch classifier loss: 0.247228; batch adversarial loss: 0.416703\n","epoch 9; iter: 0; batch classifier loss: 0.261503; batch adversarial loss: 0.456081\n","epoch 10; iter: 0; batch classifier loss: 0.251199; batch adversarial loss: 0.418000\n","epoch 11; iter: 0; batch classifier loss: 0.294350; batch adversarial loss: 0.411475\n","epoch 12; iter: 0; batch classifier loss: 0.238795; batch adversarial loss: 0.437231\n","epoch 13; iter: 0; batch classifier loss: 0.257806; batch adversarial loss: 0.361284\n","epoch 14; iter: 0; batch classifier loss: 0.390260; batch adversarial loss: 0.502648\n","epoch 15; iter: 0; batch classifier loss: 0.196457; batch adversarial loss: 0.392535\n","epoch 16; iter: 0; batch classifier loss: 0.272655; batch adversarial loss: 0.460470\n","epoch 17; iter: 0; batch classifier loss: 0.284372; batch adversarial loss: 0.403535\n","epoch 18; iter: 0; batch classifier loss: 0.267576; batch adversarial loss: 0.355974\n","epoch 19; iter: 0; batch classifier loss: 0.157023; batch adversarial loss: 0.334940\n","epoch 20; iter: 0; batch classifier loss: 0.193130; batch adversarial loss: 0.350691\n","epoch 21; iter: 0; batch classifier loss: 0.223553; batch adversarial loss: 0.387174\n","epoch 22; iter: 0; batch classifier loss: 0.213136; batch adversarial loss: 0.394790\n","epoch 23; iter: 0; batch classifier loss: 0.234022; batch adversarial loss: 0.335118\n","epoch 24; iter: 0; batch classifier loss: 0.195249; batch adversarial loss: 0.492083\n","epoch 25; iter: 0; batch classifier loss: 0.263136; batch adversarial loss: 0.480877\n","epoch 26; iter: 0; batch classifier loss: 0.217212; batch adversarial loss: 0.348832\n","epoch 27; iter: 0; batch classifier loss: 0.229363; batch adversarial loss: 0.390744\n","epoch 28; iter: 0; batch classifier loss: 0.265372; batch adversarial loss: 0.484583\n","epoch 29; iter: 0; batch classifier loss: 0.324549; batch adversarial loss: 0.367270\n","epoch 30; iter: 0; batch classifier loss: 0.241725; batch adversarial loss: 0.456299\n","epoch 31; iter: 0; batch classifier loss: 0.281015; batch adversarial loss: 0.371558\n","epoch 32; iter: 0; batch classifier loss: 0.231013; batch adversarial loss: 0.357584\n","epoch 33; iter: 0; batch classifier loss: 0.252075; batch adversarial loss: 0.421341\n","epoch 34; iter: 0; batch classifier loss: 0.198721; batch adversarial loss: 0.421140\n","epoch 35; iter: 0; batch classifier loss: 0.356499; batch adversarial loss: 0.506244\n","epoch 36; iter: 0; batch classifier loss: 0.315313; batch adversarial loss: 0.419880\n","epoch 37; iter: 0; batch classifier loss: 0.230238; batch adversarial loss: 0.369398\n","epoch 38; iter: 0; batch classifier loss: 0.232196; batch adversarial loss: 0.328343\n","epoch 39; iter: 0; batch classifier loss: 0.349339; batch adversarial loss: 0.464051\n","epoch 40; iter: 0; batch classifier loss: 0.200372; batch adversarial loss: 0.379244\n","epoch 41; iter: 0; batch classifier loss: 0.241318; batch adversarial loss: 0.478113\n","epoch 42; iter: 0; batch classifier loss: 0.402142; batch adversarial loss: 0.331207\n","epoch 43; iter: 0; batch classifier loss: 0.328930; batch adversarial loss: 0.401377\n","epoch 44; iter: 0; batch classifier loss: 0.301246; batch adversarial loss: 0.383699\n","epoch 45; iter: 0; batch classifier loss: 0.242108; batch adversarial loss: 0.335121\n","epoch 46; iter: 0; batch classifier loss: 0.308620; batch adversarial loss: 0.371936\n","epoch 47; iter: 0; batch classifier loss: 0.321741; batch adversarial loss: 0.404508\n","epoch 48; iter: 0; batch classifier loss: 0.264439; batch adversarial loss: 0.455149\n","epoch 49; iter: 0; batch classifier loss: 0.236787; batch adversarial loss: 0.428633\n","Accuracy 0.891947694425327\n","epoch 0; iter: 0; batch classifier loss: 0.746598; batch adversarial loss: 0.530497\n","epoch 1; iter: 0; batch classifier loss: 1.361364; batch adversarial loss: 0.736001\n","epoch 2; iter: 0; batch classifier loss: 1.669492; batch adversarial loss: 0.691289\n","epoch 3; iter: 0; batch classifier loss: 1.537102; batch adversarial loss: 0.640440\n","epoch 4; iter: 0; batch classifier loss: 1.357202; batch adversarial loss: 0.481893\n","epoch 5; iter: 0; batch classifier loss: 0.613940; batch adversarial loss: 0.551240\n","epoch 6; iter: 0; batch classifier loss: 0.454330; batch adversarial loss: 0.476489\n","epoch 7; iter: 0; batch classifier loss: 0.243908; batch adversarial loss: 0.411164\n","epoch 8; iter: 0; batch classifier loss: 0.286966; batch adversarial loss: 0.419816\n","epoch 9; iter: 0; batch classifier loss: 0.198857; batch adversarial loss: 0.419868\n","epoch 10; iter: 0; batch classifier loss: 0.329197; batch adversarial loss: 0.432428\n","epoch 11; iter: 0; batch classifier loss: 0.331015; batch adversarial loss: 0.409622\n","epoch 12; iter: 0; batch classifier loss: 0.275308; batch adversarial loss: 0.346255\n","epoch 13; iter: 0; batch classifier loss: 0.320497; batch adversarial loss: 0.300923\n","epoch 14; iter: 0; batch classifier loss: 0.260615; batch adversarial loss: 0.313621\n","epoch 15; iter: 0; batch classifier loss: 0.253832; batch adversarial loss: 0.438329\n","epoch 16; iter: 0; batch classifier loss: 0.257718; batch adversarial loss: 0.468110\n","epoch 17; iter: 0; batch classifier loss: 0.196718; batch adversarial loss: 0.393229\n","epoch 18; iter: 0; batch classifier loss: 0.275524; batch adversarial loss: 0.403632\n","epoch 19; iter: 0; batch classifier loss: 0.240059; batch adversarial loss: 0.350589\n","epoch 20; iter: 0; batch classifier loss: 0.257498; batch adversarial loss: 0.450332\n","epoch 21; iter: 0; batch classifier loss: 0.288797; batch adversarial loss: 0.360537\n","epoch 22; iter: 0; batch classifier loss: 0.222651; batch adversarial loss: 0.404287\n","epoch 23; iter: 0; batch classifier loss: 0.244080; batch adversarial loss: 0.522100\n","epoch 24; iter: 0; batch classifier loss: 0.348385; batch adversarial loss: 0.375863\n","epoch 25; iter: 0; batch classifier loss: 0.343404; batch adversarial loss: 0.403932\n","epoch 26; iter: 0; batch classifier loss: 0.347231; batch adversarial loss: 0.436084\n","epoch 27; iter: 0; batch classifier loss: 0.323888; batch adversarial loss: 0.298119\n","epoch 28; iter: 0; batch classifier loss: 0.152598; batch adversarial loss: 0.444199\n","epoch 29; iter: 0; batch classifier loss: 0.244061; batch adversarial loss: 0.426151\n","epoch 30; iter: 0; batch classifier loss: 0.270722; batch adversarial loss: 0.476596\n","epoch 31; iter: 0; batch classifier loss: 0.225388; batch adversarial loss: 0.459934\n","epoch 32; iter: 0; batch classifier loss: 0.324286; batch adversarial loss: 0.442125\n","epoch 33; iter: 0; batch classifier loss: 0.220750; batch adversarial loss: 0.432572\n","epoch 34; iter: 0; batch classifier loss: 0.291898; batch adversarial loss: 0.447096\n","epoch 35; iter: 0; batch classifier loss: 0.329958; batch adversarial loss: 0.458196\n","epoch 36; iter: 0; batch classifier loss: 0.258665; batch adversarial loss: 0.322131\n","epoch 37; iter: 0; batch classifier loss: 0.264258; batch adversarial loss: 0.380535\n","epoch 38; iter: 0; batch classifier loss: 0.286241; batch adversarial loss: 0.482199\n","epoch 39; iter: 0; batch classifier loss: 0.203030; batch adversarial loss: 0.332432\n","epoch 40; iter: 0; batch classifier loss: 0.248618; batch adversarial loss: 0.366081\n","epoch 41; iter: 0; batch classifier loss: 0.253558; batch adversarial loss: 0.436029\n","epoch 42; iter: 0; batch classifier loss: 0.255101; batch adversarial loss: 0.382748\n","epoch 43; iter: 0; batch classifier loss: 0.204980; batch adversarial loss: 0.404571\n","epoch 44; iter: 0; batch classifier loss: 0.287826; batch adversarial loss: 0.414072\n","epoch 45; iter: 0; batch classifier loss: 0.360442; batch adversarial loss: 0.447507\n","epoch 46; iter: 0; batch classifier loss: 0.349356; batch adversarial loss: 0.361810\n","epoch 47; iter: 0; batch classifier loss: 0.282758; batch adversarial loss: 0.427476\n","epoch 48; iter: 0; batch classifier loss: 0.284550; batch adversarial loss: 0.517582\n","epoch 49; iter: 0; batch classifier loss: 0.332384; batch adversarial loss: 0.477917\n","Accuracy 0.8634694814134924\n","epoch 0; iter: 0; batch classifier loss: 0.720540; batch adversarial loss: 0.707911\n","epoch 1; iter: 0; batch classifier loss: 0.266511; batch adversarial loss: 0.612344\n","epoch 2; iter: 0; batch classifier loss: 0.210095; batch adversarial loss: 0.530867\n","epoch 3; iter: 0; batch classifier loss: 0.267326; batch adversarial loss: 0.482832\n","epoch 4; iter: 0; batch classifier loss: 0.273019; batch adversarial loss: 0.465653\n","epoch 5; iter: 0; batch classifier loss: 0.244845; batch adversarial loss: 0.460051\n","epoch 6; iter: 0; batch classifier loss: 0.328406; batch adversarial loss: 0.442184\n","epoch 7; iter: 0; batch classifier loss: 0.190679; batch adversarial loss: 0.465648\n","epoch 8; iter: 0; batch classifier loss: 0.254456; batch adversarial loss: 0.515007\n","epoch 9; iter: 0; batch classifier loss: 0.196407; batch adversarial loss: 0.428902\n","epoch 10; iter: 0; batch classifier loss: 0.234731; batch adversarial loss: 0.346865\n","epoch 11; iter: 0; batch classifier loss: 0.289589; batch adversarial loss: 0.482886\n","epoch 12; iter: 0; batch classifier loss: 0.232918; batch adversarial loss: 0.477680\n","epoch 13; iter: 0; batch classifier loss: 0.277629; batch adversarial loss: 0.401421\n","epoch 14; iter: 0; batch classifier loss: 0.225138; batch adversarial loss: 0.334525\n","epoch 15; iter: 0; batch classifier loss: 0.260033; batch adversarial loss: 0.346336\n","epoch 16; iter: 0; batch classifier loss: 0.310586; batch adversarial loss: 0.392536\n","epoch 17; iter: 0; batch classifier loss: 0.229660; batch adversarial loss: 0.466820\n","epoch 18; iter: 0; batch classifier loss: 0.242481; batch adversarial loss: 0.496558\n","epoch 19; iter: 0; batch classifier loss: 0.316621; batch adversarial loss: 0.392903\n","epoch 20; iter: 0; batch classifier loss: 0.300970; batch adversarial loss: 0.477986\n","epoch 21; iter: 0; batch classifier loss: 0.364104; batch adversarial loss: 0.437155\n","epoch 22; iter: 0; batch classifier loss: 0.342062; batch adversarial loss: 0.403754\n","epoch 23; iter: 0; batch classifier loss: 0.284139; batch adversarial loss: 0.434948\n","epoch 24; iter: 0; batch classifier loss: 0.293047; batch adversarial loss: 0.385076\n","epoch 25; iter: 0; batch classifier loss: 0.229068; batch adversarial loss: 0.425192\n","epoch 26; iter: 0; batch classifier loss: 0.372992; batch adversarial loss: 0.482913\n","epoch 27; iter: 0; batch classifier loss: 0.247326; batch adversarial loss: 0.407601\n","epoch 28; iter: 0; batch classifier loss: 0.248333; batch adversarial loss: 0.520843\n","epoch 29; iter: 0; batch classifier loss: 0.189856; batch adversarial loss: 0.489322\n","epoch 30; iter: 0; batch classifier loss: 0.215034; batch adversarial loss: 0.433421\n","epoch 31; iter: 0; batch classifier loss: 0.210151; batch adversarial loss: 0.395510\n","epoch 32; iter: 0; batch classifier loss: 0.246504; batch adversarial loss: 0.434953\n","epoch 33; iter: 0; batch classifier loss: 0.326853; batch adversarial loss: 0.402643\n","epoch 34; iter: 0; batch classifier loss: 0.198987; batch adversarial loss: 0.345833\n","epoch 35; iter: 0; batch classifier loss: 0.271859; batch adversarial loss: 0.542527\n","epoch 36; iter: 0; batch classifier loss: 0.276464; batch adversarial loss: 0.400877\n","epoch 37; iter: 0; batch classifier loss: 0.240687; batch adversarial loss: 0.402440\n","epoch 38; iter: 0; batch classifier loss: 0.245217; batch adversarial loss: 0.323781\n","epoch 39; iter: 0; batch classifier loss: 0.235034; batch adversarial loss: 0.389828\n","epoch 40; iter: 0; batch classifier loss: 0.249063; batch adversarial loss: 0.369968\n","epoch 41; iter: 0; batch classifier loss: 0.388573; batch adversarial loss: 0.408833\n","epoch 42; iter: 0; batch classifier loss: 0.215630; batch adversarial loss: 0.425075\n","epoch 43; iter: 0; batch classifier loss: 0.236924; batch adversarial loss: 0.307155\n","epoch 44; iter: 0; batch classifier loss: 0.230245; batch adversarial loss: 0.315479\n","epoch 45; iter: 0; batch classifier loss: 0.183148; batch adversarial loss: 0.357786\n","epoch 46; iter: 0; batch classifier loss: 0.183074; batch adversarial loss: 0.414482\n","epoch 47; iter: 0; batch classifier loss: 0.258275; batch adversarial loss: 0.426204\n","epoch 48; iter: 0; batch classifier loss: 0.260295; batch adversarial loss: 0.478577\n","epoch 49; iter: 0; batch classifier loss: 0.304621; batch adversarial loss: 0.474289\n","Accuracy 0.8946764570904084\n","epoch 0; iter: 0; batch classifier loss: 0.760026; batch adversarial loss: 0.619028\n","epoch 1; iter: 0; batch classifier loss: 1.218753; batch adversarial loss: 0.677309\n","epoch 2; iter: 0; batch classifier loss: 1.517728; batch adversarial loss: 0.599338\n","epoch 3; iter: 0; batch classifier loss: 0.931988; batch adversarial loss: 0.542145\n","epoch 4; iter: 0; batch classifier loss: 0.717979; batch adversarial loss: 0.553328\n","epoch 5; iter: 0; batch classifier loss: 0.906614; batch adversarial loss: 0.520584\n","epoch 6; iter: 0; batch classifier loss: 0.626836; batch adversarial loss: 0.484104\n","epoch 7; iter: 0; batch classifier loss: 0.541561; batch adversarial loss: 0.407291\n","epoch 8; iter: 0; batch classifier loss: 0.779932; batch adversarial loss: 0.503633\n","epoch 9; iter: 0; batch classifier loss: 0.529794; batch adversarial loss: 0.501840\n","epoch 10; iter: 0; batch classifier loss: 0.379977; batch adversarial loss: 0.330298\n","epoch 11; iter: 0; batch classifier loss: 0.275543; batch adversarial loss: 0.368087\n","epoch 12; iter: 0; batch classifier loss: 0.314386; batch adversarial loss: 0.354128\n","epoch 13; iter: 0; batch classifier loss: 0.308829; batch adversarial loss: 0.462042\n","epoch 14; iter: 0; batch classifier loss: 0.248871; batch adversarial loss: 0.391840\n","epoch 15; iter: 0; batch classifier loss: 0.250139; batch adversarial loss: 0.370701\n","epoch 16; iter: 0; batch classifier loss: 0.182299; batch adversarial loss: 0.389803\n","epoch 17; iter: 0; batch classifier loss: 0.194193; batch adversarial loss: 0.452649\n","epoch 18; iter: 0; batch classifier loss: 0.229848; batch adversarial loss: 0.479680\n","epoch 19; iter: 0; batch classifier loss: 0.254180; batch adversarial loss: 0.425494\n","epoch 20; iter: 0; batch classifier loss: 0.310229; batch adversarial loss: 0.399868\n","epoch 21; iter: 0; batch classifier loss: 0.286592; batch adversarial loss: 0.359044\n","epoch 22; iter: 0; batch classifier loss: 0.239837; batch adversarial loss: 0.302566\n","epoch 23; iter: 0; batch classifier loss: 0.314327; batch adversarial loss: 0.417817\n","epoch 24; iter: 0; batch classifier loss: 0.308319; batch adversarial loss: 0.431935\n","epoch 25; iter: 0; batch classifier loss: 0.241897; batch adversarial loss: 0.390786\n","epoch 26; iter: 0; batch classifier loss: 0.324508; batch adversarial loss: 0.432321\n","epoch 27; iter: 0; batch classifier loss: 0.372273; batch adversarial loss: 0.431151\n","epoch 28; iter: 0; batch classifier loss: 0.254186; batch adversarial loss: 0.400493\n","epoch 29; iter: 0; batch classifier loss: 0.240931; batch adversarial loss: 0.457712\n","epoch 30; iter: 0; batch classifier loss: 0.163980; batch adversarial loss: 0.411311\n","epoch 31; iter: 0; batch classifier loss: 0.231189; batch adversarial loss: 0.382602\n","epoch 32; iter: 0; batch classifier loss: 0.216409; batch adversarial loss: 0.440221\n","epoch 33; iter: 0; batch classifier loss: 0.284248; batch adversarial loss: 0.428819\n","epoch 34; iter: 0; batch classifier loss: 0.153122; batch adversarial loss: 0.364467\n","epoch 35; iter: 0; batch classifier loss: 0.237491; batch adversarial loss: 0.413663\n","epoch 36; iter: 0; batch classifier loss: 0.318828; batch adversarial loss: 0.319802\n","epoch 37; iter: 0; batch classifier loss: 0.150136; batch adversarial loss: 0.440175\n","epoch 38; iter: 0; batch classifier loss: 0.225724; batch adversarial loss: 0.333406\n","epoch 39; iter: 0; batch classifier loss: 0.333530; batch adversarial loss: 0.389622\n","epoch 40; iter: 0; batch classifier loss: 0.243760; batch adversarial loss: 0.315789\n","epoch 41; iter: 0; batch classifier loss: 0.330493; batch adversarial loss: 0.426859\n","epoch 42; iter: 0; batch classifier loss: 0.165696; batch adversarial loss: 0.386122\n","epoch 43; iter: 0; batch classifier loss: 0.215564; batch adversarial loss: 0.414098\n","epoch 44; iter: 0; batch classifier loss: 0.293870; batch adversarial loss: 0.376220\n","epoch 45; iter: 0; batch classifier loss: 0.220114; batch adversarial loss: 0.412475\n","epoch 46; iter: 0; batch classifier loss: 0.342767; batch adversarial loss: 0.463515\n","epoch 47; iter: 0; batch classifier loss: 0.314659; batch adversarial loss: 0.402691\n","epoch 48; iter: 0; batch classifier loss: 0.247948; batch adversarial loss: 0.417640\n","epoch 49; iter: 0; batch classifier loss: 0.310668; batch adversarial loss: 0.385717\n","Accuracy 0.8935291418081689\n","epoch 0; iter: 0; batch classifier loss: 0.624359; batch adversarial loss: 0.687953\n","epoch 1; iter: 0; batch classifier loss: 0.339084; batch adversarial loss: 0.570215\n","epoch 2; iter: 0; batch classifier loss: 0.311889; batch adversarial loss: 0.508858\n","epoch 3; iter: 0; batch classifier loss: 0.344309; batch adversarial loss: 0.416173\n","epoch 4; iter: 0; batch classifier loss: 0.313737; batch adversarial loss: 0.426371\n","epoch 5; iter: 0; batch classifier loss: 0.336213; batch adversarial loss: 0.421701\n","epoch 6; iter: 0; batch classifier loss: 0.316196; batch adversarial loss: 0.351968\n","epoch 7; iter: 0; batch classifier loss: 0.235167; batch adversarial loss: 0.408274\n","epoch 8; iter: 0; batch classifier loss: 0.192267; batch adversarial loss: 0.437323\n","epoch 9; iter: 0; batch classifier loss: 0.396867; batch adversarial loss: 0.433926\n","epoch 10; iter: 0; batch classifier loss: 0.297523; batch adversarial loss: 0.433665\n","epoch 11; iter: 0; batch classifier loss: 0.304972; batch adversarial loss: 0.421041\n","epoch 12; iter: 0; batch classifier loss: 0.273305; batch adversarial loss: 0.446906\n","epoch 13; iter: 0; batch classifier loss: 0.215442; batch adversarial loss: 0.359254\n","epoch 14; iter: 0; batch classifier loss: 0.276623; batch adversarial loss: 0.409213\n","epoch 15; iter: 0; batch classifier loss: 0.302528; batch adversarial loss: 0.416398\n","epoch 16; iter: 0; batch classifier loss: 0.188105; batch adversarial loss: 0.429124\n","epoch 17; iter: 0; batch classifier loss: 0.266611; batch adversarial loss: 0.374287\n","epoch 18; iter: 0; batch classifier loss: 0.260216; batch adversarial loss: 0.368147\n","epoch 19; iter: 0; batch classifier loss: 0.273108; batch adversarial loss: 0.421042\n","epoch 20; iter: 0; batch classifier loss: 0.248713; batch adversarial loss: 0.327302\n","epoch 21; iter: 0; batch classifier loss: 0.387742; batch adversarial loss: 0.486719\n","epoch 22; iter: 0; batch classifier loss: 0.289647; batch adversarial loss: 0.495241\n","epoch 23; iter: 0; batch classifier loss: 0.302377; batch adversarial loss: 0.307991\n","epoch 24; iter: 0; batch classifier loss: 0.340328; batch adversarial loss: 0.416183\n","epoch 25; iter: 0; batch classifier loss: 0.213654; batch adversarial loss: 0.333610\n","epoch 26; iter: 0; batch classifier loss: 0.285663; batch adversarial loss: 0.429359\n","epoch 27; iter: 0; batch classifier loss: 0.276217; batch adversarial loss: 0.413734\n","epoch 28; iter: 0; batch classifier loss: 0.237915; batch adversarial loss: 0.513035\n","epoch 29; iter: 0; batch classifier loss: 0.234621; batch adversarial loss: 0.305259\n","epoch 30; iter: 0; batch classifier loss: 0.234804; batch adversarial loss: 0.335116\n","epoch 31; iter: 0; batch classifier loss: 0.232706; batch adversarial loss: 0.364662\n","epoch 32; iter: 0; batch classifier loss: 0.270358; batch adversarial loss: 0.482043\n","epoch 33; iter: 0; batch classifier loss: 0.234465; batch adversarial loss: 0.354492\n","epoch 34; iter: 0; batch classifier loss: 0.191971; batch adversarial loss: 0.418506\n","epoch 35; iter: 0; batch classifier loss: 0.243567; batch adversarial loss: 0.315892\n","epoch 36; iter: 0; batch classifier loss: 0.205279; batch adversarial loss: 0.398413\n","epoch 37; iter: 0; batch classifier loss: 0.244757; batch adversarial loss: 0.385419\n","epoch 38; iter: 0; batch classifier loss: 0.265648; batch adversarial loss: 0.451343\n","epoch 39; iter: 0; batch classifier loss: 0.247237; batch adversarial loss: 0.395000\n","epoch 40; iter: 0; batch classifier loss: 0.345060; batch adversarial loss: 0.511641\n","epoch 41; iter: 0; batch classifier loss: 0.260901; batch adversarial loss: 0.551230\n","epoch 42; iter: 0; batch classifier loss: 0.359475; batch adversarial loss: 0.378477\n","epoch 43; iter: 0; batch classifier loss: 0.294711; batch adversarial loss: 0.371774\n","epoch 44; iter: 0; batch classifier loss: 0.220513; batch adversarial loss: 0.392769\n","epoch 45; iter: 0; batch classifier loss: 0.185918; batch adversarial loss: 0.526939\n","epoch 46; iter: 0; batch classifier loss: 0.257696; batch adversarial loss: 0.500471\n","epoch 47; iter: 0; batch classifier loss: 0.335454; batch adversarial loss: 0.486773\n","epoch 48; iter: 0; batch classifier loss: 0.261870; batch adversarial loss: 0.507330\n","epoch 49; iter: 0; batch classifier loss: 0.211364; batch adversarial loss: 0.337311\n","Accuracy 0.8939880679210647\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"reSfNpjhFH8r"},"source":["# Meta 0.2\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtplOkDrFH8r","executionInfo":{"status":"ok","timestamp":1629959611952,"user_tz":-570,"elapsed":80148,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"2b4fa98e-56ae-4d67-f21f-31b145069ed7"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.2, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta2.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta2.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Accuracy 0.8924065152557926\n","Accuracy 0.888022028453419\n","Accuracy 0.8923818265259293\n","Accuracy 0.8857273978889398\n","Accuracy 0.8900871959614503\n","Accuracy 0.8850653819683414\n","Accuracy 0.8942175309775127\n","Accuracy 0.890546122074346\n","Accuracy 0.8893988067921065\n","Accuracy 0.8891693437356586\n","Accuracy 0.891718284010094\n","Accuracy 0.8871041762276274\n","Accuracy 0.8967416245984396\n","Accuracy 0.8866452501147315\n","Accuracy 0.8857273978889398\n","Accuracy 0.8882771277816013\n","Accuracy 0.882744378155117\n","Accuracy 0.8882514915098669\n","Accuracy 0.8910050481872418\n","Accuracy 0.895823772372648\n","Accuracy 0.8960770818995183\n","Accuracy 0.8799908214777421\n","Accuracy 0.8939880679210647\n","Accuracy 0.8832033042680129\n","Accuracy 0.8937586048646168\n","Accuracy 0.8921771048405598\n","Accuracy 0.8861863240018357\n","Accuracy 0.8935291418081689\n","Accuracy 0.8852684717760441\n","Accuracy 0.890546122074346\n","Accuracy 0.8843771507226428\n","Accuracy 0.8912345112436898\n","Accuracy 0.8928407526388251\n","Accuracy 0.8836622303809086\n","Accuracy 0.8962826984855439\n","Accuracy 0.8905712319339298\n","Accuracy 0.8969710876548875\n","Accuracy 0.8866452501147315\n","Accuracy 0.885497934832492\n","Accuracy 0.8891693437356586\n","Accuracy 0.8908006423491627\n","Accuracy 0.8850390087195962\n","Accuracy 0.8907755851307939\n","Accuracy 0.8910050481872418\n","Accuracy 0.8889398806792106\n","Accuracy 0.8891947694425327\n","Accuracy 0.8882514915098669\n","Accuracy 0.8916934373565856\n","Accuracy 0.8834327673244607\n","Accuracy 0.8946764570904084\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2zGRNHEQFIPE"},"source":["# Meta 0.4\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOUNqFT4FIPG","executionInfo":{"status":"ok","timestamp":1629959731175,"user_tz":-570,"elapsed":119237,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"b3763289-0712-4869-ad0c-f24fd6ccb051"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.4, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta4.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta4.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.8882514915098669\n","Accuracy 0.893299678751721\n","Accuracy 0.8857273978889398\n","Accuracy 0.8903166590178981\n","Accuracy 0.8857536132140399\n","Accuracy 0.8946764570904084\n","Accuracy 0.890546122074346\n","Accuracy 0.8896282698485544\n","Accuracy 0.8891693437356586\n","Accuracy 0.891947694425327\n","Accuracy 0.8873336392840753\n","Accuracy 0.8978889398806792\n","Accuracy 0.888022028453419\n","Accuracy 0.8861863240018357\n","Accuracy 0.888735948612067\n","Accuracy 0.8841211564938045\n","Accuracy 0.8893988067921065\n","Accuracy 0.8921523634694815\n","Accuracy 0.895823772372648\n","Accuracy 0.8969947235604496\n","Accuracy 0.8806792106470858\n","Accuracy 0.8946764570904084\n","Accuracy 0.8834327673244607\n","Accuracy 0.8939880679210647\n","Accuracy 0.891947694425327\n","Accuracy 0.8868747131711794\n","Accuracy 0.8937586048646168\n","Accuracy 0.8864157870582836\n","Accuracy 0.8912345112436898\n","Accuracy 0.8848359715531086\n","Accuracy 0.8914639743001377\n","Accuracy 0.8937586048646168\n","Accuracy 0.8848095456631482\n","Accuracy 0.8969710876548875\n","Accuracy 0.8903418215186969\n","Accuracy 0.8972005507113354\n","Accuracy 0.8864157870582836\n","Accuracy 0.8857273978889398\n","Accuracy 0.8900871959614503\n","Accuracy 0.8912594631796283\n","Accuracy 0.8852684717760441\n","Accuracy 0.893070215695273\n","Accuracy 0.8912345112436898\n","Accuracy 0.8893988067921065\n","Accuracy 0.8896535902729984\n","Accuracy 0.8893988067921065\n","Accuracy 0.8912345112436898\n","Accuracy 0.8857273978889398\n","Accuracy 0.8949059201468563\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SglOigoJKEiy"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vP-IlZfPKFU6"},"source":["# Meta 0.6\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4pHADeEKFU7","executionInfo":{"status":"ok","timestamp":1629959890670,"user_tz":-570,"elapsed":159526,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"0415e5db-cd53-4e35-cb57-d200cf625438"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.6, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta6.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta6.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.8884809545663148\n","Accuracy 0.24988526847177606\n","Accuracy 0.35291418081688847\n","Accuracy 0.890546122074346\n","Accuracy 0.8857536132140399\n","Accuracy 0.8944469940339606\n","Accuracy 0.890546122074346\n","Accuracy 0.8903166590178981\n","Accuracy 0.8896282698485544\n","Accuracy 0.8921771048405598\n","Accuracy 0.3044974759063791\n","Accuracy 0.2333639284075264\n","Accuracy 0.2122533272143185\n","Accuracy 0.8861863240018357\n","Accuracy 0.888735948612067\n","Accuracy 0.23818265259293253\n","Accuracy 0.29807251032583754\n","Accuracy 0.8916934373565856\n","Accuracy 0.8960532354290959\n","Accuracy 0.3457214957559073\n","Accuracy 0.2354290959155576\n","Accuracy 0.3033501606241395\n","Accuracy 0.24575493345571364\n","Accuracy 0.2776502983019734\n","Accuracy 0.8926359256710255\n","Accuracy 0.35796236805874254\n","Accuracy 0.8937586048646168\n","Accuracy 0.8866452501147315\n","Accuracy 0.8910050481872418\n","Accuracy 0.2922688690066529\n","Accuracy 0.8912345112436898\n","Accuracy 0.893299678751721\n","Accuracy 0.8843506195502524\n","Accuracy 0.8969710876548875\n","Accuracy 0.8910300527643955\n","Accuracy 0.8972005507113354\n","Accuracy 0.8864157870582836\n","Accuracy 0.8857273978889398\n","Accuracy 0.8900871959614503\n","Accuracy 0.8912594631796283\n","Accuracy 0.8852684717760441\n","Accuracy 0.893070215695273\n","Accuracy 0.8916934373565856\n","Accuracy 0.8893988067921065\n","Accuracy 0.26405138793301214\n","Accuracy 0.8891693437356586\n","Accuracy 0.8919229004130335\n","Accuracy 0.2728315741165672\n","Accuracy 0.23795318953648462\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NDxf1UeRVgOp"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"eNlkgkHyKHkO"},"source":["# Meta 0.8\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25xsmsZAKHkS","executionInfo":{"status":"ok","timestamp":1629960087842,"user_tz":-570,"elapsed":197188,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"f298b46c-c2b5-422c-9edd-4f53660c43f8"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.8, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta8.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta8.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.20559889857732905\n","Accuracy 0.893299678751721\n","Accuracy 0.8859568609453878\n","Accuracy 0.25401560348783847\n","Accuracy 0.30488644184445973\n","Accuracy 0.8944469940339606\n","Accuracy 0.1737035337310693\n","Accuracy 0.7833868747131711\n","Accuracy 0.8896282698485544\n","Accuracy 0.8921771048405598\n","Accuracy 0.2411656723267554\n","Accuracy 0.21661312528682883\n","Accuracy 0.887792565396971\n","Accuracy 0.8001376778338688\n","Accuracy 0.888735948612067\n","Accuracy 0.8129876089949518\n","Accuracy 0.20881138136759983\n","Accuracy 0.8916934373565856\n","Accuracy 0.8960532354290959\n","Accuracy 0.8969947235604496\n","Accuracy 0.21684258834327674\n","Accuracy 0.29072969251950437\n","Accuracy 0.8834327673244607\n","Accuracy 0.2602111060119321\n","Accuracy 0.3058040835053911\n","Accuracy 0.17714547957778798\n","Accuracy 0.8937586048646168\n","Accuracy 0.8866452501147315\n","Accuracy 0.8910050481872418\n","Accuracy 0.2296398256480844\n","Accuracy 0.8912345112436898\n","Accuracy 0.286369894446994\n","Accuracy 0.8843506195502524\n","Accuracy 0.8969710876548875\n","Accuracy 0.8910300527643955\n","Accuracy 0.24575493345571364\n","Accuracy 0.8864157870582836\n","Accuracy 0.7386415787058284\n","Accuracy 0.22556218448829737\n","Accuracy 0.8912594631796283\n","Accuracy 0.8852684717760441\n","Accuracy 0.25699862322166134\n","Accuracy 0.8916934373565856\n","Accuracy 0.21202386415787058\n","Accuracy 0.7331956870841936\n","Accuracy 0.8891693437356586\n","Accuracy 0.8919229004130335\n","Accuracy 0.18861863240018356\n","Accuracy 0.7487379531895365\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n7JaK7kHpWVa"},"source":["# Meta 1.0"]},{"cell_type":"code","metadata":{"id":"CMTAhY3NpYUT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629960323070,"user_tz":-570,"elapsed":235279,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"9839e81f-812a-42f4-cdfb-3dbba3b91fbc"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=1.0, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta10.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta10.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Accuracy 0.7983482450103234\n","Accuracy 0.7044515832950895\n","Accuracy 0.893299678751721\n","Accuracy 0.8859568609453878\n","Accuracy 0.692519504359798\n","Accuracy 0.8857536132140399\n","Accuracy 0.8944469940339606\n","Accuracy 0.7232675539238183\n","Accuracy 0.8903166590178981\n","Accuracy 0.8896282698485544\n","Accuracy 0.8921771048405598\n","Accuracy 0.8873336392840753\n","Accuracy 0.6530518586507572\n","Accuracy 0.887792565396971\n","Accuracy 0.8861863240018357\n","Accuracy 0.888735948612067\n","Accuracy 0.7480495640201927\n","Accuracy 0.8891693437356586\n","Accuracy 0.689995410738871\n","Accuracy 0.8960532354290959\n","Accuracy 0.8969947235604496\n","Accuracy 0.6782927948600276\n","Accuracy 0.8942175309775127\n","Accuracy 0.7049105094079853\n","Accuracy 0.7134006424965581\n","Accuracy 0.8926359256710255\n","Accuracy 0.8868747131711794\n","Accuracy 0.8937586048646168\n","Accuracy 0.7296925195043598\n","Accuracy 0.8910050481872418\n","Accuracy 0.7497132369809589\n","Accuracy 0.8912345112436898\n","Accuracy 0.7907296925195043\n","Accuracy 0.7058283616337769\n","Accuracy 0.7592932537861404\n","Accuracy 0.8910300527643955\n","Accuracy 0.8972005507113354\n","Accuracy 0.8864157870582836\n","Accuracy 0.8857273978889398\n","Accuracy 0.7905002294630564\n","Accuracy 0.8912594631796283\n","Accuracy 0.723955943093162\n","Accuracy 0.7677833868747131\n","Accuracy 0.8352455254703993\n","Accuracy 0.8893988067921065\n","Accuracy 0.7033723331039229\n","Accuracy 0.8891693437356586\n","Accuracy 0.708122992198256\n","Accuracy 0.8850390087195962\n","Accuracy 0.8949059201468563\n"],"name":"stdout"}]}]}