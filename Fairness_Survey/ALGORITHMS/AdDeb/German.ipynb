{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"German.ipynb","provenance":[{"file_id":"1-ar5jhY8kGUSwnnZRMZsNOt02wwgn6dV","timestamp":1629951202085},{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"authorship_tag":"ABX9TyPsMBQ7AaXgq47vsZoXHmEs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5qYRG8zufHw","executionInfo":{"status":"ok","timestamp":1629970931945,"user_tz":-570,"elapsed":15837,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"d4320c5e-48b8-45a9-e25e-65f7d6123a7a"},"source":["!pip install aif360\n","!pip install fairlearn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting aif360\n","  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n","Collecting tempeh\n","  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.3.1)\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n","Collecting memory-profiler\n","  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.10.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (21.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.62.0)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.34.0)\n","Building wheels for collected packages: memory-profiler, shap\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=9662cfd11b437ec8a3920d1b8ea76dc2a9eb2e33d0c55187b669c67a770f6b4d\n","  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491648 sha256=f3b0dd88c072ad40cf3944c9dc2b60868afe55592efa59dc40b952c4b9ed3300\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built memory-profiler shap\n","Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n","Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n","Collecting fairlearn\n","  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n","Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\n","Installing collected packages: fairlearn\n","Successfully installed fairlearn-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TltW3iPkux0Q","executionInfo":{"status":"ok","timestamp":1629970933781,"user_tz":-570,"elapsed":1845,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"8bd6f15c-30fe-4816-fc3d-ae004c1e416b"},"source":["!apt-get install -jre\n","!java -version"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Command line option 'j' [from -jre] is not understood in combination with the other options.\n","openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KssrNl8GvDYU","executionInfo":{"status":"ok","timestamp":1629970965251,"user_tz":-570,"elapsed":31479,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"6005cf9d-d9a1-45c5-d09d-82de7af98d88"},"source":["!pip install h2o"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting h2o\n","  Downloading h2o-3.32.1.6.tar.gz (168.4 MB)\n","\u001b[K     |████████████████████████████████| 168.4 MB 38 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n","Collecting colorama>=0.3.8\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2021.5.30)\n","Building wheels for collected packages: h2o\n","  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for h2o: filename=h2o-3.32.1.6-py2.py3-none-any.whl size=168439194 sha256=210928bec2d57022ec05dff6c4880b0a3d9f23b8370c20d069cdc70de7526f50\n","  Stored in directory: /root/.cache/pip/wheels/ee/0f/51/849ba221c4c1b11a04efb4a3427dc9cb1c4dcde218c6c98b13\n","Successfully built h2o\n","Installing collected packages: colorama, h2o\n","Successfully installed colorama-0.4.4 h2o-3.32.1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NQn2JJ0uw6u","executionInfo":{"status":"ok","timestamp":1629970968165,"user_tz":-570,"elapsed":2935,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"f3849b0b-67fc-40e6-e2a3-69ae3cce63b4"},"source":["!pip install xlsxwriter"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n","\u001b[K     |████████████████████████████████| 148 kB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0YklbHpAxd8","executionInfo":{"status":"ok","timestamp":1629970973741,"user_tz":-570,"elapsed":5591,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"b91906e9-7919-4b72-a6d1-793d05dc02f3"},"source":["!pip install BlackBoxAuditing"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting BlackBoxAuditing\n","  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->BlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n","Building wheels for collected packages: BlackBoxAuditing\n","  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394771 sha256=319373a14aeb702dca95aa4992c65204b8e32a21570cd88c58ef8140f10b7630\n","  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n","Successfully built BlackBoxAuditing\n","Installing collected packages: BlackBoxAuditing\n","Successfully installed BlackBoxAuditing-0.1.54\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rf1aISz6vGfR","executionInfo":{"status":"ok","timestamp":1629970985263,"user_tz":-570,"elapsed":11528,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"fc760b84-284e-4a16-acfa-d8b28a4f18bb"},"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover, MetaFairClassifier, AdversarialDebiasing\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","import h2o\n","from h2o.automl import H2OAutoML\n","from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"RcxQeeX7vUXz","executionInfo":{"status":"ok","timestamp":1629970993025,"user_tz":-570,"elapsed":7788,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"8712001b-d040-4199-fd9e-2439e8177d81"},"source":["h2o.init()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n","Attempting to start a local H2O server...\n","  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n","  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n","  Ice root: /tmp/tmpcp078v42\n","  JVM stdout: /tmp/tmpcp078v42/h2o_unknownUser_started_from_python.out\n","  JVM stderr: /tmp/tmpcp078v42/h2o_unknownUser_started_from_python.err\n","  Server is running at http://127.0.0.1:54321\n","Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n","<td>03 secs</td></tr>\n","<tr><td>H2O_cluster_timezone:</td>\n","<td>Etc/UTC</td></tr>\n","<tr><td>H2O_data_parsing_timezone:</td>\n","<td>UTC</td></tr>\n","<tr><td>H2O_cluster_version:</td>\n","<td>3.32.1.6</td></tr>\n","<tr><td>H2O_cluster_version_age:</td>\n","<td>6 days </td></tr>\n","<tr><td>H2O_cluster_name:</td>\n","<td>H2O_from_python_unknownUser_bkeswt</td></tr>\n","<tr><td>H2O_cluster_total_nodes:</td>\n","<td>1</td></tr>\n","<tr><td>H2O_cluster_free_memory:</td>\n","<td>3.172 Gb</td></tr>\n","<tr><td>H2O_cluster_total_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_allowed_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_status:</td>\n","<td>accepting new members, healthy</td></tr>\n","<tr><td>H2O_connection_url:</td>\n","<td>http://127.0.0.1:54321</td></tr>\n","<tr><td>H2O_connection_proxy:</td>\n","<td>{\"http\": null, \"https\": null}</td></tr>\n","<tr><td>H2O_internal_security:</td>\n","<td>False</td></tr>\n","<tr><td>H2O_API_Extensions:</td>\n","<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n","<tr><td>Python_version:</td>\n","<td>3.7.11 final</td></tr></table></div>"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O_cluster_uptime:         03 secs\n","H2O_cluster_timezone:       Etc/UTC\n","H2O_data_parsing_timezone:  UTC\n","H2O_cluster_version:        3.32.1.6\n","H2O_cluster_version_age:    6 days\n","H2O_cluster_name:           H2O_from_python_unknownUser_bkeswt\n","H2O_cluster_total_nodes:    1\n","H2O_cluster_free_memory:    3.172 Gb\n","H2O_cluster_total_cores:    2\n","H2O_cluster_allowed_cores:  2\n","H2O_cluster_status:         accepting new members, healthy\n","H2O_connection_url:         http://127.0.0.1:54321\n","H2O_connection_proxy:       {\"http\": null, \"https\": null}\n","H2O_internal_security:      False\n","H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python_version:             3.7.11 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEGPULDrvk3g","executionInfo":{"status":"ok","timestamp":1629971043381,"user_tz":-570,"elapsed":50370,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"e9799a33-701e-4c2a-ba48-c36e2c8a3033"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# AdDeb\n","\n"]},{"cell_type":"code","metadata":{"id":"7yjikSofGWK1","executionInfo":{"status":"ok","timestamp":1629971043382,"user_tz":-570,"elapsed":34,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["#initialize Tf\n","sess = tf.Session() #initialize Tf"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uN9VfZBAvxCj","executionInfo":{"status":"ok","timestamp":1629971240546,"user_tz":-570,"elapsed":197196,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"a9b52a3a-8b03-4080-eb5c-02ef4c0ecc1f"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('default')\n","  train.insert(0, 'default', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('default')\n","  test.insert(0, 'default', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** AdDeb Classifier regularizer*****************************\n","  \n","  sess.close() # This closse would close the previous iteration  and start a new session for the current iteration\n","  tf.reset_default_graph()\n","  sess = tf.Session()\n","  Classifier = AdversarialDebiasing(privileged_groups = advantagedGroup,\n","                          unprivileged_groups = disadvantagedGroup,\n","                          scope_name='debiased_classifier',\n","                          debias=True,\n","                          sess=sess)\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['default']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/AdDeb/AdDeb.xlsx')\n","  German= excelBook['German']\n","  data= German.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/AdDeb/AdDeb.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='German', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","epoch 0; iter: 0; batch classifier loss: 59.075226; batch adversarial loss: 0.654011\n","epoch 1; iter: 0; batch classifier loss: 52.718719; batch adversarial loss: 0.588240\n","epoch 2; iter: 0; batch classifier loss: 50.947002; batch adversarial loss: 0.532953\n","epoch 3; iter: 0; batch classifier loss: 38.561420; batch adversarial loss: 0.619163\n","epoch 4; iter: 0; batch classifier loss: 34.264961; batch adversarial loss: 0.636145\n","epoch 5; iter: 0; batch classifier loss: 35.760395; batch adversarial loss: 0.558105\n","epoch 6; iter: 0; batch classifier loss: 42.866306; batch adversarial loss: 0.634921\n","epoch 7; iter: 0; batch classifier loss: 34.742107; batch adversarial loss: 0.582085\n","epoch 8; iter: 0; batch classifier loss: 46.348377; batch adversarial loss: 0.616482\n","epoch 9; iter: 0; batch classifier loss: 37.768593; batch adversarial loss: 0.569958\n","epoch 10; iter: 0; batch classifier loss: 40.081955; batch adversarial loss: 0.555973\n","epoch 11; iter: 0; batch classifier loss: 38.195789; batch adversarial loss: 0.584024\n","epoch 12; iter: 0; batch classifier loss: 42.785992; batch adversarial loss: 0.613354\n","epoch 13; iter: 0; batch classifier loss: 28.139986; batch adversarial loss: 0.597010\n","epoch 14; iter: 0; batch classifier loss: 31.174915; batch adversarial loss: 0.525329\n","epoch 15; iter: 0; batch classifier loss: 39.419304; batch adversarial loss: 0.505625\n","epoch 16; iter: 0; batch classifier loss: 22.065639; batch adversarial loss: 0.526737\n","epoch 17; iter: 0; batch classifier loss: 23.269470; batch adversarial loss: 0.604066\n","epoch 18; iter: 0; batch classifier loss: 15.532710; batch adversarial loss: 0.596070\n","epoch 19; iter: 0; batch classifier loss: 22.493793; batch adversarial loss: 0.556880\n","epoch 20; iter: 0; batch classifier loss: 20.612955; batch adversarial loss: 0.567099\n","epoch 21; iter: 0; batch classifier loss: 21.352070; batch adversarial loss: 0.564661\n","epoch 22; iter: 0; batch classifier loss: 17.747948; batch adversarial loss: 0.584492\n","epoch 23; iter: 0; batch classifier loss: 16.593613; batch adversarial loss: 0.579053\n","epoch 24; iter: 0; batch classifier loss: 16.645510; batch adversarial loss: 0.605215\n","epoch 25; iter: 0; batch classifier loss: 14.474936; batch adversarial loss: 0.606449\n","epoch 26; iter: 0; batch classifier loss: 19.338383; batch adversarial loss: 0.525978\n","epoch 27; iter: 0; batch classifier loss: 12.300013; batch adversarial loss: 0.625977\n","epoch 28; iter: 0; batch classifier loss: 10.759251; batch adversarial loss: 0.527946\n","epoch 29; iter: 0; batch classifier loss: 12.473135; batch adversarial loss: 0.530331\n","epoch 30; iter: 0; batch classifier loss: 12.954727; batch adversarial loss: 0.539319\n","epoch 31; iter: 0; batch classifier loss: 12.147531; batch adversarial loss: 0.559320\n","epoch 32; iter: 0; batch classifier loss: 18.136379; batch adversarial loss: 0.538697\n","epoch 33; iter: 0; batch classifier loss: 10.842783; batch adversarial loss: 0.593964\n","epoch 34; iter: 0; batch classifier loss: 10.821940; batch adversarial loss: 0.524832\n","epoch 35; iter: 0; batch classifier loss: 6.555073; batch adversarial loss: 0.590914\n","epoch 36; iter: 0; batch classifier loss: 5.813878; batch adversarial loss: 0.630995\n","epoch 37; iter: 0; batch classifier loss: 8.990696; batch adversarial loss: 0.580709\n","epoch 38; iter: 0; batch classifier loss: 11.496592; batch adversarial loss: 0.511380\n","epoch 39; iter: 0; batch classifier loss: 10.184321; batch adversarial loss: 0.506826\n","epoch 40; iter: 0; batch classifier loss: 4.435070; batch adversarial loss: 0.538760\n","epoch 41; iter: 0; batch classifier loss: 4.878257; batch adversarial loss: 0.496729\n","epoch 42; iter: 0; batch classifier loss: 11.503790; batch adversarial loss: 0.587818\n","epoch 43; iter: 0; batch classifier loss: 5.637986; batch adversarial loss: 0.509195\n","epoch 44; iter: 0; batch classifier loss: 5.036736; batch adversarial loss: 0.501802\n","epoch 45; iter: 0; batch classifier loss: 5.086717; batch adversarial loss: 0.604329\n","epoch 46; iter: 0; batch classifier loss: 4.512427; batch adversarial loss: 0.607427\n","epoch 47; iter: 0; batch classifier loss: 5.639185; batch adversarial loss: 0.474995\n","epoch 48; iter: 0; batch classifier loss: 2.918006; batch adversarial loss: 0.600962\n","epoch 49; iter: 0; batch classifier loss: 3.752258; batch adversarial loss: 0.603987\n","Accuracy 0.29\n","epoch 0; iter: 0; batch classifier loss: 179.464172; batch adversarial loss: 0.742165\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.67\n","epoch 0; iter: 0; batch classifier loss: 60.979080; batch adversarial loss: 1.086597\n","epoch 1; iter: 0; batch classifier loss: 39.778931; batch adversarial loss: 0.888958\n","epoch 2; iter: 0; batch classifier loss: 36.223614; batch adversarial loss: 0.844042\n","epoch 3; iter: 0; batch classifier loss: 39.522217; batch adversarial loss: 0.833324\n","epoch 4; iter: 0; batch classifier loss: 32.923801; batch adversarial loss: 0.906341\n","epoch 5; iter: 0; batch classifier loss: 30.519772; batch adversarial loss: 0.970447\n","epoch 6; iter: 0; batch classifier loss: 39.864101; batch adversarial loss: 0.855606\n","epoch 7; iter: 0; batch classifier loss: 32.616360; batch adversarial loss: 0.896798\n","epoch 8; iter: 0; batch classifier loss: 28.257942; batch adversarial loss: 0.876323\n","epoch 9; iter: 0; batch classifier loss: 28.410351; batch adversarial loss: 0.890717\n","epoch 10; iter: 0; batch classifier loss: 20.738997; batch adversarial loss: 0.855175\n","epoch 11; iter: 0; batch classifier loss: 31.243828; batch adversarial loss: 0.878688\n","epoch 12; iter: 0; batch classifier loss: 17.020794; batch adversarial loss: 0.881305\n","epoch 13; iter: 0; batch classifier loss: 26.053543; batch adversarial loss: 0.797870\n","epoch 14; iter: 0; batch classifier loss: 19.142448; batch adversarial loss: 0.886834\n","epoch 15; iter: 0; batch classifier loss: 15.247902; batch adversarial loss: 0.844306\n","epoch 16; iter: 0; batch classifier loss: 12.303545; batch adversarial loss: 0.789114\n","epoch 17; iter: 0; batch classifier loss: 14.197437; batch adversarial loss: 0.869080\n","epoch 18; iter: 0; batch classifier loss: 9.984799; batch adversarial loss: 0.809430\n","epoch 19; iter: 0; batch classifier loss: 11.880154; batch adversarial loss: 0.799456\n","epoch 20; iter: 0; batch classifier loss: 9.510201; batch adversarial loss: 0.830116\n","epoch 21; iter: 0; batch classifier loss: 8.878485; batch adversarial loss: 0.868580\n","epoch 22; iter: 0; batch classifier loss: 11.460882; batch adversarial loss: 0.856288\n","epoch 23; iter: 0; batch classifier loss: 10.280510; batch adversarial loss: 0.808436\n","epoch 24; iter: 0; batch classifier loss: 8.974867; batch adversarial loss: 0.789727\n","epoch 25; iter: 0; batch classifier loss: 5.916882; batch adversarial loss: 0.756196\n","epoch 26; iter: 0; batch classifier loss: 9.082569; batch adversarial loss: 0.764551\n","epoch 27; iter: 0; batch classifier loss: 6.029654; batch adversarial loss: 0.790197\n","epoch 28; iter: 0; batch classifier loss: 5.669752; batch adversarial loss: 0.818462\n","epoch 29; iter: 0; batch classifier loss: 3.003443; batch adversarial loss: 0.770501\n","epoch 30; iter: 0; batch classifier loss: 3.859003; batch adversarial loss: 0.780967\n","epoch 31; iter: 0; batch classifier loss: 3.217137; batch adversarial loss: 0.715172\n","epoch 32; iter: 0; batch classifier loss: 5.346352; batch adversarial loss: 0.727095\n","epoch 33; iter: 0; batch classifier loss: 3.420956; batch adversarial loss: 0.761783\n","epoch 34; iter: 0; batch classifier loss: 3.192156; batch adversarial loss: 0.753296\n","epoch 35; iter: 0; batch classifier loss: 2.588020; batch adversarial loss: 0.740339\n","epoch 36; iter: 0; batch classifier loss: 2.410369; batch adversarial loss: 0.708293\n","epoch 37; iter: 0; batch classifier loss: 2.383441; batch adversarial loss: 0.790038\n","epoch 38; iter: 0; batch classifier loss: 2.569102; batch adversarial loss: 0.812367\n","epoch 39; iter: 0; batch classifier loss: 1.734708; batch adversarial loss: 0.771795\n","epoch 40; iter: 0; batch classifier loss: 1.158581; batch adversarial loss: 0.739431\n","epoch 41; iter: 0; batch classifier loss: 1.755729; batch adversarial loss: 0.728394\n","epoch 42; iter: 0; batch classifier loss: 1.915317; batch adversarial loss: 0.753378\n","epoch 43; iter: 0; batch classifier loss: 1.789919; batch adversarial loss: 0.777924\n","epoch 44; iter: 0; batch classifier loss: 1.927085; batch adversarial loss: 0.844614\n","epoch 45; iter: 0; batch classifier loss: 2.037673; batch adversarial loss: 0.817151\n","epoch 46; iter: 0; batch classifier loss: 1.262823; batch adversarial loss: 0.744430\n","epoch 47; iter: 0; batch classifier loss: 1.289382; batch adversarial loss: 0.743811\n","epoch 48; iter: 0; batch classifier loss: 1.170789; batch adversarial loss: 0.719177\n","epoch 49; iter: 0; batch classifier loss: 1.312248; batch adversarial loss: 0.777962\n","Accuracy 0.285\n","epoch 0; iter: 0; batch classifier loss: 118.225021; batch adversarial loss: 0.894932\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.715\n","epoch 0; iter: 0; batch classifier loss: 101.407990; batch adversarial loss: 0.622453\n","epoch 1; iter: 0; batch classifier loss: 77.653595; batch adversarial loss: 0.648477\n","epoch 2; iter: 0; batch classifier loss: 65.979462; batch adversarial loss: 0.643972\n","epoch 3; iter: 0; batch classifier loss: 62.837502; batch adversarial loss: 0.665367\n","epoch 4; iter: 0; batch classifier loss: 52.249699; batch adversarial loss: 0.650139\n","epoch 5; iter: 0; batch classifier loss: 45.556873; batch adversarial loss: 0.658660\n","epoch 6; iter: 0; batch classifier loss: 69.798470; batch adversarial loss: 0.648497\n","epoch 7; iter: 0; batch classifier loss: 50.698380; batch adversarial loss: 0.641100\n","epoch 8; iter: 0; batch classifier loss: 53.976341; batch adversarial loss: 0.633927\n","epoch 9; iter: 0; batch classifier loss: 62.554161; batch adversarial loss: 0.615174\n","epoch 10; iter: 0; batch classifier loss: 64.041191; batch adversarial loss: 0.636145\n","epoch 11; iter: 0; batch classifier loss: 34.454178; batch adversarial loss: 0.624772\n","epoch 12; iter: 0; batch classifier loss: 31.811674; batch adversarial loss: 0.636742\n","epoch 13; iter: 0; batch classifier loss: 42.389252; batch adversarial loss: 0.626329\n","epoch 14; iter: 0; batch classifier loss: 52.469311; batch adversarial loss: 0.616710\n","epoch 15; iter: 0; batch classifier loss: 33.619640; batch adversarial loss: 0.596873\n","epoch 16; iter: 0; batch classifier loss: 31.354546; batch adversarial loss: 0.607421\n","epoch 17; iter: 0; batch classifier loss: 31.992729; batch adversarial loss: 0.616271\n","epoch 18; iter: 0; batch classifier loss: 29.783382; batch adversarial loss: 0.605499\n","epoch 19; iter: 0; batch classifier loss: 39.032997; batch adversarial loss: 0.595296\n","epoch 20; iter: 0; batch classifier loss: 32.129559; batch adversarial loss: 0.594819\n","epoch 21; iter: 0; batch classifier loss: 26.038086; batch adversarial loss: 0.585951\n","epoch 22; iter: 0; batch classifier loss: 35.620960; batch adversarial loss: 0.580109\n","epoch 23; iter: 0; batch classifier loss: 29.510754; batch adversarial loss: 0.615816\n","epoch 24; iter: 0; batch classifier loss: 23.370274; batch adversarial loss: 0.600336\n","epoch 25; iter: 0; batch classifier loss: 18.745617; batch adversarial loss: 0.594047\n","epoch 26; iter: 0; batch classifier loss: 30.803238; batch adversarial loss: 0.599683\n","epoch 27; iter: 0; batch classifier loss: 20.782040; batch adversarial loss: 0.596245\n","epoch 28; iter: 0; batch classifier loss: 27.259588; batch adversarial loss: 0.601397\n","epoch 29; iter: 0; batch classifier loss: 23.864603; batch adversarial loss: 0.561427\n","epoch 30; iter: 0; batch classifier loss: 29.990313; batch adversarial loss: 0.576986\n","epoch 31; iter: 0; batch classifier loss: 17.532631; batch adversarial loss: 0.610397\n","epoch 32; iter: 0; batch classifier loss: 18.798759; batch adversarial loss: 0.559897\n","epoch 33; iter: 0; batch classifier loss: 13.689909; batch adversarial loss: 0.589304\n","epoch 34; iter: 0; batch classifier loss: 21.226864; batch adversarial loss: 0.550152\n","epoch 35; iter: 0; batch classifier loss: 9.211555; batch adversarial loss: 0.575170\n","epoch 36; iter: 0; batch classifier loss: 16.686504; batch adversarial loss: 0.594860\n","epoch 37; iter: 0; batch classifier loss: 15.528321; batch adversarial loss: 0.571239\n","epoch 38; iter: 0; batch classifier loss: 15.713357; batch adversarial loss: 0.564642\n","epoch 39; iter: 0; batch classifier loss: 11.077520; batch adversarial loss: 0.566309\n","epoch 40; iter: 0; batch classifier loss: 10.720414; batch adversarial loss: 0.589361\n","epoch 41; iter: 0; batch classifier loss: 14.225223; batch adversarial loss: 0.583674\n","epoch 42; iter: 0; batch classifier loss: 12.007865; batch adversarial loss: 0.540989\n","epoch 43; iter: 0; batch classifier loss: 13.439760; batch adversarial loss: 0.587320\n","epoch 44; iter: 0; batch classifier loss: 8.076536; batch adversarial loss: 0.568248\n","epoch 45; iter: 0; batch classifier loss: 8.335070; batch adversarial loss: 0.550101\n","epoch 46; iter: 0; batch classifier loss: 8.241550; batch adversarial loss: 0.595226\n","epoch 47; iter: 0; batch classifier loss: 7.739653; batch adversarial loss: 0.591503\n","epoch 48; iter: 0; batch classifier loss: 8.741514; batch adversarial loss: 0.533672\n","epoch 49; iter: 0; batch classifier loss: 6.981358; batch adversarial loss: 0.570726\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.66\n","epoch 0; iter: 0; batch classifier loss: 284.100830; batch adversarial loss: 0.480455\n","epoch 1; iter: 0; batch classifier loss: 123.643974; batch adversarial loss: 0.531260\n","epoch 2; iter: 0; batch classifier loss: 56.455872; batch adversarial loss: 0.614408\n","epoch 3; iter: 0; batch classifier loss: 44.348274; batch adversarial loss: 0.663927\n","epoch 4; iter: 0; batch classifier loss: 40.758568; batch adversarial loss: 0.662502\n","epoch 5; iter: 0; batch classifier loss: 73.833893; batch adversarial loss: 0.635731\n","epoch 6; iter: 0; batch classifier loss: 41.316475; batch adversarial loss: 0.612674\n","epoch 7; iter: 0; batch classifier loss: 48.359200; batch adversarial loss: 0.622689\n","epoch 8; iter: 0; batch classifier loss: 57.266525; batch adversarial loss: 0.620406\n","epoch 9; iter: 0; batch classifier loss: 38.207008; batch adversarial loss: 0.594654\n","epoch 10; iter: 0; batch classifier loss: 47.029644; batch adversarial loss: 0.617912\n","epoch 11; iter: 0; batch classifier loss: 50.543274; batch adversarial loss: 0.606090\n","epoch 12; iter: 0; batch classifier loss: 50.346569; batch adversarial loss: 0.599622\n","epoch 13; iter: 0; batch classifier loss: 51.216827; batch adversarial loss: 0.581021\n","epoch 14; iter: 0; batch classifier loss: 44.288010; batch adversarial loss: 0.582209\n","epoch 15; iter: 0; batch classifier loss: 30.440628; batch adversarial loss: 0.626619\n","epoch 16; iter: 0; batch classifier loss: 42.245239; batch adversarial loss: 0.580244\n","epoch 17; iter: 0; batch classifier loss: 22.607635; batch adversarial loss: 0.565073\n","epoch 18; iter: 0; batch classifier loss: 45.558811; batch adversarial loss: 0.547681\n","epoch 19; iter: 0; batch classifier loss: 46.897251; batch adversarial loss: 0.557066\n","epoch 20; iter: 0; batch classifier loss: 24.190506; batch adversarial loss: 0.601241\n","epoch 21; iter: 0; batch classifier loss: 27.574286; batch adversarial loss: 0.657097\n","epoch 22; iter: 0; batch classifier loss: 26.721344; batch adversarial loss: 0.567017\n","epoch 23; iter: 0; batch classifier loss: 31.349531; batch adversarial loss: 0.588581\n","epoch 24; iter: 0; batch classifier loss: 33.816620; batch adversarial loss: 0.552863\n","epoch 25; iter: 0; batch classifier loss: 40.018448; batch adversarial loss: 0.576929\n","epoch 26; iter: 0; batch classifier loss: 45.790844; batch adversarial loss: 0.584804\n","epoch 27; iter: 0; batch classifier loss: 35.966934; batch adversarial loss: 0.577804\n","epoch 28; iter: 0; batch classifier loss: 18.782158; batch adversarial loss: 0.572101\n","epoch 29; iter: 0; batch classifier loss: 22.059902; batch adversarial loss: 0.562987\n","epoch 30; iter: 0; batch classifier loss: 29.359619; batch adversarial loss: 0.604175\n","epoch 31; iter: 0; batch classifier loss: 32.203964; batch adversarial loss: 0.601187\n","epoch 32; iter: 0; batch classifier loss: 28.353455; batch adversarial loss: 0.540317\n","epoch 33; iter: 0; batch classifier loss: 19.851782; batch adversarial loss: 0.538961\n","epoch 34; iter: 0; batch classifier loss: 18.463297; batch adversarial loss: 0.569947\n","epoch 35; iter: 0; batch classifier loss: 22.890978; batch adversarial loss: 0.539044\n","epoch 36; iter: 0; batch classifier loss: 22.083483; batch adversarial loss: 0.592228\n","epoch 37; iter: 0; batch classifier loss: 23.197735; batch adversarial loss: 0.592546\n","epoch 38; iter: 0; batch classifier loss: 20.573730; batch adversarial loss: 0.554803\n","epoch 39; iter: 0; batch classifier loss: 16.768682; batch adversarial loss: 0.595678\n","epoch 40; iter: 0; batch classifier loss: 22.060917; batch adversarial loss: 0.585464\n","epoch 41; iter: 0; batch classifier loss: 23.551287; batch adversarial loss: 0.575782\n","epoch 42; iter: 0; batch classifier loss: 16.334827; batch adversarial loss: 0.581999\n","epoch 43; iter: 0; batch classifier loss: 24.659760; batch adversarial loss: 0.547211\n","epoch 44; iter: 0; batch classifier loss: 12.138058; batch adversarial loss: 0.543831\n","epoch 45; iter: 0; batch classifier loss: 11.502355; batch adversarial loss: 0.594757\n","epoch 46; iter: 0; batch classifier loss: 13.512537; batch adversarial loss: 0.532821\n","epoch 47; iter: 0; batch classifier loss: 19.686609; batch adversarial loss: 0.545183\n","epoch 48; iter: 0; batch classifier loss: 11.721582; batch adversarial loss: 0.578920\n","epoch 49; iter: 0; batch classifier loss: 15.648640; batch adversarial loss: 0.486014\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7\n","epoch 0; iter: 0; batch classifier loss: 66.124763; batch adversarial loss: 0.772469\n","epoch 1; iter: 0; batch classifier loss: 52.232063; batch adversarial loss: 0.760738\n","epoch 2; iter: 0; batch classifier loss: 42.560081; batch adversarial loss: 0.732397\n","epoch 3; iter: 0; batch classifier loss: 65.361481; batch adversarial loss: 0.747669\n","epoch 4; iter: 0; batch classifier loss: 62.697765; batch adversarial loss: 0.759463\n","epoch 5; iter: 0; batch classifier loss: 29.638279; batch adversarial loss: 0.737528\n","epoch 6; iter: 0; batch classifier loss: 62.266808; batch adversarial loss: 0.756409\n","epoch 7; iter: 0; batch classifier loss: 43.125427; batch adversarial loss: 0.740583\n","epoch 8; iter: 0; batch classifier loss: 38.938019; batch adversarial loss: 0.719167\n","epoch 9; iter: 0; batch classifier loss: 31.795397; batch adversarial loss: 0.725226\n","epoch 10; iter: 0; batch classifier loss: 31.594360; batch adversarial loss: 0.715743\n","epoch 11; iter: 0; batch classifier loss: 31.070353; batch adversarial loss: 0.738214\n","epoch 12; iter: 0; batch classifier loss: 30.438005; batch adversarial loss: 0.726181\n","epoch 13; iter: 0; batch classifier loss: 21.644527; batch adversarial loss: 0.717811\n","epoch 14; iter: 0; batch classifier loss: 25.529724; batch adversarial loss: 0.705845\n","epoch 15; iter: 0; batch classifier loss: 25.417437; batch adversarial loss: 0.696771\n","epoch 16; iter: 0; batch classifier loss: 24.685469; batch adversarial loss: 0.702475\n","epoch 17; iter: 0; batch classifier loss: 23.292786; batch adversarial loss: 0.685384\n","epoch 18; iter: 0; batch classifier loss: 22.157789; batch adversarial loss: 0.713215\n","epoch 19; iter: 0; batch classifier loss: 20.824783; batch adversarial loss: 0.681481\n","epoch 20; iter: 0; batch classifier loss: 20.502436; batch adversarial loss: 0.669209\n","epoch 21; iter: 0; batch classifier loss: 22.243233; batch adversarial loss: 0.703074\n","epoch 22; iter: 0; batch classifier loss: 21.907684; batch adversarial loss: 0.671533\n","epoch 23; iter: 0; batch classifier loss: 22.076796; batch adversarial loss: 0.660374\n","epoch 24; iter: 0; batch classifier loss: 14.505348; batch adversarial loss: 0.684859\n","epoch 25; iter: 0; batch classifier loss: 14.373659; batch adversarial loss: 0.688730\n","epoch 26; iter: 0; batch classifier loss: 12.674268; batch adversarial loss: 0.673379\n","epoch 27; iter: 0; batch classifier loss: 16.056782; batch adversarial loss: 0.661206\n","epoch 28; iter: 0; batch classifier loss: 12.849770; batch adversarial loss: 0.662653\n","epoch 29; iter: 0; batch classifier loss: 11.149118; batch adversarial loss: 0.662324\n","epoch 30; iter: 0; batch classifier loss: 8.614779; batch adversarial loss: 0.643861\n","epoch 31; iter: 0; batch classifier loss: 7.852307; batch adversarial loss: 0.630830\n","epoch 32; iter: 0; batch classifier loss: 11.037395; batch adversarial loss: 0.647609\n","epoch 33; iter: 0; batch classifier loss: 8.067665; batch adversarial loss: 0.648105\n","epoch 34; iter: 0; batch classifier loss: 6.157765; batch adversarial loss: 0.651316\n","epoch 35; iter: 0; batch classifier loss: 5.318310; batch adversarial loss: 0.636168\n","epoch 36; iter: 0; batch classifier loss: 7.903533; batch adversarial loss: 0.632477\n","epoch 37; iter: 0; batch classifier loss: 6.949680; batch adversarial loss: 0.631164\n","epoch 38; iter: 0; batch classifier loss: 4.609147; batch adversarial loss: 0.631079\n","epoch 39; iter: 0; batch classifier loss: 4.616364; batch adversarial loss: 0.617136\n","epoch 40; iter: 0; batch classifier loss: 4.330707; batch adversarial loss: 0.614950\n","epoch 41; iter: 0; batch classifier loss: 3.311181; batch adversarial loss: 0.624878\n","epoch 42; iter: 0; batch classifier loss: 3.766686; batch adversarial loss: 0.621315\n","epoch 43; iter: 0; batch classifier loss: 3.325998; batch adversarial loss: 0.619999\n","epoch 44; iter: 0; batch classifier loss: 2.537911; batch adversarial loss: 0.617818\n","epoch 45; iter: 0; batch classifier loss: 1.935466; batch adversarial loss: 0.611605\n","epoch 46; iter: 0; batch classifier loss: 2.022840; batch adversarial loss: 0.605082\n","epoch 47; iter: 0; batch classifier loss: 2.284179; batch adversarial loss: 0.596531\n","epoch 48; iter: 0; batch classifier loss: 2.386419; batch adversarial loss: 0.625565\n","epoch 49; iter: 0; batch classifier loss: 1.905120; batch adversarial loss: 0.596262\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.72\n","epoch 0; iter: 0; batch classifier loss: 152.098526; batch adversarial loss: 0.693334\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.77\n","epoch 0; iter: 0; batch classifier loss: 132.020508; batch adversarial loss: 0.702404\n","epoch 1; iter: 0; batch classifier loss: 52.187008; batch adversarial loss: 0.711991\n","epoch 2; iter: 0; batch classifier loss: 50.818726; batch adversarial loss: 0.790486\n","epoch 3; iter: 0; batch classifier loss: 55.683079; batch adversarial loss: 0.797973\n","epoch 4; iter: 0; batch classifier loss: 65.251175; batch adversarial loss: 0.804395\n","epoch 5; iter: 0; batch classifier loss: 35.426064; batch adversarial loss: 0.728393\n","epoch 6; iter: 0; batch classifier loss: 62.195900; batch adversarial loss: 0.725658\n","epoch 7; iter: 0; batch classifier loss: 56.718502; batch adversarial loss: 0.736948\n","epoch 8; iter: 0; batch classifier loss: 46.878681; batch adversarial loss: 0.753069\n","epoch 9; iter: 0; batch classifier loss: 37.704285; batch adversarial loss: 0.740126\n","epoch 10; iter: 0; batch classifier loss: 53.618004; batch adversarial loss: 0.749981\n","epoch 11; iter: 0; batch classifier loss: 39.412334; batch adversarial loss: 0.733187\n","epoch 12; iter: 0; batch classifier loss: 41.609394; batch adversarial loss: 0.701607\n","epoch 13; iter: 0; batch classifier loss: 32.010635; batch adversarial loss: 0.698493\n","epoch 14; iter: 0; batch classifier loss: 33.039364; batch adversarial loss: 0.713218\n","epoch 15; iter: 0; batch classifier loss: 41.741058; batch adversarial loss: 0.711965\n","epoch 16; iter: 0; batch classifier loss: 28.251966; batch adversarial loss: 0.706514\n","epoch 17; iter: 0; batch classifier loss: 25.850937; batch adversarial loss: 0.715070\n","epoch 18; iter: 0; batch classifier loss: 30.795206; batch adversarial loss: 0.690455\n","epoch 19; iter: 0; batch classifier loss: 32.886162; batch adversarial loss: 0.708409\n","epoch 20; iter: 0; batch classifier loss: 28.028412; batch adversarial loss: 0.708545\n","epoch 21; iter: 0; batch classifier loss: 32.110367; batch adversarial loss: 0.671977\n","epoch 22; iter: 0; batch classifier loss: 16.516211; batch adversarial loss: 0.668822\n","epoch 23; iter: 0; batch classifier loss: 16.595573; batch adversarial loss: 0.655990\n","epoch 24; iter: 0; batch classifier loss: 23.771515; batch adversarial loss: 0.683841\n","epoch 25; iter: 0; batch classifier loss: 18.745653; batch adversarial loss: 0.676397\n","epoch 26; iter: 0; batch classifier loss: 13.153200; batch adversarial loss: 0.666711\n","epoch 27; iter: 0; batch classifier loss: 26.456573; batch adversarial loss: 0.661351\n","epoch 28; iter: 0; batch classifier loss: 20.048599; batch adversarial loss: 0.668568\n","epoch 29; iter: 0; batch classifier loss: 18.894180; batch adversarial loss: 0.649736\n","epoch 30; iter: 0; batch classifier loss: 18.492870; batch adversarial loss: 0.663074\n","epoch 31; iter: 0; batch classifier loss: 24.554146; batch adversarial loss: 0.661007\n","epoch 32; iter: 0; batch classifier loss: 16.290089; batch adversarial loss: 0.668848\n","epoch 33; iter: 0; batch classifier loss: 17.029226; batch adversarial loss: 0.666518\n","epoch 34; iter: 0; batch classifier loss: 16.515022; batch adversarial loss: 0.652985\n","epoch 35; iter: 0; batch classifier loss: 10.930897; batch adversarial loss: 0.648452\n","epoch 36; iter: 0; batch classifier loss: 14.634476; batch adversarial loss: 0.638619\n","epoch 37; iter: 0; batch classifier loss: 6.847994; batch adversarial loss: 0.632004\n","epoch 38; iter: 0; batch classifier loss: 8.622352; batch adversarial loss: 0.636778\n","epoch 39; iter: 0; batch classifier loss: 9.351690; batch adversarial loss: 0.630553\n","epoch 40; iter: 0; batch classifier loss: 10.397576; batch adversarial loss: 0.640593\n","epoch 41; iter: 0; batch classifier loss: 7.950511; batch adversarial loss: 0.628679\n","epoch 42; iter: 0; batch classifier loss: 7.236295; batch adversarial loss: 0.629963\n","epoch 43; iter: 0; batch classifier loss: 8.228092; batch adversarial loss: 0.621083\n","epoch 44; iter: 0; batch classifier loss: 11.398049; batch adversarial loss: 0.625595\n","epoch 45; iter: 0; batch classifier loss: 7.212685; batch adversarial loss: 0.630550\n","epoch 46; iter: 0; batch classifier loss: 6.912283; batch adversarial loss: 0.616332\n","epoch 47; iter: 0; batch classifier loss: 7.823759; batch adversarial loss: 0.632335\n","epoch 48; iter: 0; batch classifier loss: 6.005497; batch adversarial loss: 0.607352\n","epoch 49; iter: 0; batch classifier loss: 6.121902; batch adversarial loss: 0.608204\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.625\n","epoch 0; iter: 0; batch classifier loss: 64.622086; batch adversarial loss: 0.920245\n","epoch 1; iter: 0; batch classifier loss: 39.639706; batch adversarial loss: 0.830627\n","epoch 2; iter: 0; batch classifier loss: 46.492767; batch adversarial loss: 0.769847\n","epoch 3; iter: 0; batch classifier loss: 67.734810; batch adversarial loss: 0.734202\n","epoch 4; iter: 0; batch classifier loss: 44.415092; batch adversarial loss: 0.725444\n","epoch 5; iter: 0; batch classifier loss: 37.231583; batch adversarial loss: 0.746652\n","epoch 6; iter: 0; batch classifier loss: 33.135506; batch adversarial loss: 0.816703\n","epoch 7; iter: 0; batch classifier loss: 47.214722; batch adversarial loss: 0.803130\n","epoch 8; iter: 0; batch classifier loss: 40.667057; batch adversarial loss: 0.763489\n","epoch 9; iter: 0; batch classifier loss: 30.456879; batch adversarial loss: 0.748636\n","epoch 10; iter: 0; batch classifier loss: 37.468826; batch adversarial loss: 0.772102\n","epoch 11; iter: 0; batch classifier loss: 38.542843; batch adversarial loss: 0.759840\n","epoch 12; iter: 0; batch classifier loss: 24.120155; batch adversarial loss: 0.746064\n","epoch 13; iter: 0; batch classifier loss: 30.219971; batch adversarial loss: 0.750337\n","epoch 14; iter: 0; batch classifier loss: 35.454243; batch adversarial loss: 0.762393\n","epoch 15; iter: 0; batch classifier loss: 27.917913; batch adversarial loss: 0.719722\n","epoch 16; iter: 0; batch classifier loss: 24.503536; batch adversarial loss: 0.773052\n","epoch 17; iter: 0; batch classifier loss: 38.981628; batch adversarial loss: 0.772444\n","epoch 18; iter: 0; batch classifier loss: 16.820663; batch adversarial loss: 0.747757\n","epoch 19; iter: 0; batch classifier loss: 19.256264; batch adversarial loss: 0.734953\n","epoch 20; iter: 0; batch classifier loss: 19.579262; batch adversarial loss: 0.719616\n","epoch 21; iter: 0; batch classifier loss: 19.605309; batch adversarial loss: 0.759406\n","epoch 22; iter: 0; batch classifier loss: 21.050327; batch adversarial loss: 0.749358\n","epoch 23; iter: 0; batch classifier loss: 18.372952; batch adversarial loss: 0.706454\n","epoch 24; iter: 0; batch classifier loss: 19.307323; batch adversarial loss: 0.695862\n","epoch 25; iter: 0; batch classifier loss: 15.353416; batch adversarial loss: 0.688088\n","epoch 26; iter: 0; batch classifier loss: 9.426277; batch adversarial loss: 0.702215\n","epoch 27; iter: 0; batch classifier loss: 10.010999; batch adversarial loss: 0.692655\n","epoch 28; iter: 0; batch classifier loss: 16.995741; batch adversarial loss: 0.678598\n","epoch 29; iter: 0; batch classifier loss: 12.875289; batch adversarial loss: 0.677140\n","epoch 30; iter: 0; batch classifier loss: 8.807169; batch adversarial loss: 0.669204\n","epoch 31; iter: 0; batch classifier loss: 8.732149; batch adversarial loss: 0.692905\n","epoch 32; iter: 0; batch classifier loss: 8.560596; batch adversarial loss: 0.684699\n","epoch 33; iter: 0; batch classifier loss: 6.437522; batch adversarial loss: 0.674696\n","epoch 34; iter: 0; batch classifier loss: 8.938182; batch adversarial loss: 0.677319\n","epoch 35; iter: 0; batch classifier loss: 7.419217; batch adversarial loss: 0.657465\n","epoch 36; iter: 0; batch classifier loss: 7.319328; batch adversarial loss: 0.653487\n","epoch 37; iter: 0; batch classifier loss: 6.775392; batch adversarial loss: 0.655343\n","epoch 38; iter: 0; batch classifier loss: 6.559276; batch adversarial loss: 0.649495\n","epoch 39; iter: 0; batch classifier loss: 5.713975; batch adversarial loss: 0.651159\n","epoch 40; iter: 0; batch classifier loss: 6.233941; batch adversarial loss: 0.634433\n","epoch 41; iter: 0; batch classifier loss: 6.096676; batch adversarial loss: 0.638056\n","epoch 42; iter: 0; batch classifier loss: 4.982205; batch adversarial loss: 0.645282\n","epoch 43; iter: 0; batch classifier loss: 4.508744; batch adversarial loss: 0.635915\n","epoch 44; iter: 0; batch classifier loss: 3.669087; batch adversarial loss: 0.635577\n","epoch 45; iter: 0; batch classifier loss: 3.422279; batch adversarial loss: 0.633851\n","epoch 46; iter: 0; batch classifier loss: 3.187580; batch adversarial loss: 0.631686\n","epoch 47; iter: 0; batch classifier loss: 2.159353; batch adversarial loss: 0.633443\n","epoch 48; iter: 0; batch classifier loss: 2.185960; batch adversarial loss: 0.615773\n","epoch 49; iter: 0; batch classifier loss: 1.733911; batch adversarial loss: 0.622204\n","Accuracy 0.69\n","epoch 0; iter: 0; batch classifier loss: 183.156631; batch adversarial loss: 0.635069\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.665\n","epoch 0; iter: 0; batch classifier loss: 75.172646; batch adversarial loss: 0.652250\n","epoch 1; iter: 0; batch classifier loss: 63.801193; batch adversarial loss: 0.615372\n","epoch 2; iter: 0; batch classifier loss: 56.445580; batch adversarial loss: 0.537538\n","epoch 3; iter: 0; batch classifier loss: 47.096310; batch adversarial loss: 0.596475\n","epoch 4; iter: 0; batch classifier loss: 34.049416; batch adversarial loss: 0.614671\n","epoch 5; iter: 0; batch classifier loss: 43.427166; batch adversarial loss: 0.593065\n","epoch 6; iter: 0; batch classifier loss: 51.664757; batch adversarial loss: 0.565149\n","epoch 7; iter: 0; batch classifier loss: 31.680532; batch adversarial loss: 0.572175\n","epoch 8; iter: 0; batch classifier loss: 38.438969; batch adversarial loss: 0.549749\n","epoch 9; iter: 0; batch classifier loss: 45.884251; batch adversarial loss: 0.612053\n","epoch 10; iter: 0; batch classifier loss: 23.546453; batch adversarial loss: 0.541331\n","epoch 11; iter: 0; batch classifier loss: 27.275053; batch adversarial loss: 0.695743\n","epoch 12; iter: 0; batch classifier loss: 39.042553; batch adversarial loss: 0.600074\n","epoch 13; iter: 0; batch classifier loss: 38.236755; batch adversarial loss: 0.584702\n","epoch 14; iter: 0; batch classifier loss: 26.798515; batch adversarial loss: 0.559645\n","epoch 15; iter: 0; batch classifier loss: 26.113001; batch adversarial loss: 0.651230\n","epoch 16; iter: 0; batch classifier loss: 29.072418; batch adversarial loss: 0.593131\n","epoch 17; iter: 0; batch classifier loss: 31.664766; batch adversarial loss: 0.598275\n","epoch 18; iter: 0; batch classifier loss: 25.108189; batch adversarial loss: 0.535510\n","epoch 19; iter: 0; batch classifier loss: 27.067200; batch adversarial loss: 0.529166\n","epoch 20; iter: 0; batch classifier loss: 13.630106; batch adversarial loss: 0.587887\n","epoch 21; iter: 0; batch classifier loss: 14.793261; batch adversarial loss: 0.571690\n","epoch 22; iter: 0; batch classifier loss: 13.136404; batch adversarial loss: 0.538920\n","epoch 23; iter: 0; batch classifier loss: 19.945774; batch adversarial loss: 0.586018\n","epoch 24; iter: 0; batch classifier loss: 17.136776; batch adversarial loss: 0.603326\n","epoch 25; iter: 0; batch classifier loss: 11.229782; batch adversarial loss: 0.575617\n","epoch 26; iter: 0; batch classifier loss: 13.668933; batch adversarial loss: 0.549117\n","epoch 27; iter: 0; batch classifier loss: 15.342786; batch adversarial loss: 0.542630\n","epoch 28; iter: 0; batch classifier loss: 11.582150; batch adversarial loss: 0.547094\n","epoch 29; iter: 0; batch classifier loss: 13.854968; batch adversarial loss: 0.573753\n","epoch 30; iter: 0; batch classifier loss: 9.796433; batch adversarial loss: 0.585520\n","epoch 31; iter: 0; batch classifier loss: 7.666016; batch adversarial loss: 0.598248\n","epoch 32; iter: 0; batch classifier loss: 15.691710; batch adversarial loss: 0.461092\n","epoch 33; iter: 0; batch classifier loss: 8.529300; batch adversarial loss: 0.541488\n","epoch 34; iter: 0; batch classifier loss: 8.121260; batch adversarial loss: 0.609397\n","epoch 35; iter: 0; batch classifier loss: 9.738436; batch adversarial loss: 0.548539\n","epoch 36; iter: 0; batch classifier loss: 8.449509; batch adversarial loss: 0.544631\n","epoch 37; iter: 0; batch classifier loss: 5.672618; batch adversarial loss: 0.603108\n","epoch 38; iter: 0; batch classifier loss: 5.111108; batch adversarial loss: 0.498694\n","epoch 39; iter: 0; batch classifier loss: 8.016783; batch adversarial loss: 0.616251\n","epoch 40; iter: 0; batch classifier loss: 4.523909; batch adversarial loss: 0.564736\n","epoch 41; iter: 0; batch classifier loss: 3.980783; batch adversarial loss: 0.549923\n","epoch 42; iter: 0; batch classifier loss: 4.010345; batch adversarial loss: 0.587538\n","epoch 43; iter: 0; batch classifier loss: 4.006624; batch adversarial loss: 0.505057\n","epoch 44; iter: 0; batch classifier loss: 3.508141; batch adversarial loss: 0.584458\n","epoch 45; iter: 0; batch classifier loss: 3.253889; batch adversarial loss: 0.581383\n","epoch 46; iter: 0; batch classifier loss: 3.583698; batch adversarial loss: 0.511273\n","epoch 47; iter: 0; batch classifier loss: 3.298602; batch adversarial loss: 0.494912\n","epoch 48; iter: 0; batch classifier loss: 2.223345; batch adversarial loss: 0.529780\n","epoch 49; iter: 0; batch classifier loss: 2.741033; batch adversarial loss: 0.565764\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7\n","epoch 0; iter: 0; batch classifier loss: 48.319141; batch adversarial loss: 0.685846\n","epoch 1; iter: 0; batch classifier loss: 36.293976; batch adversarial loss: 0.677632\n","epoch 2; iter: 0; batch classifier loss: 56.789406; batch adversarial loss: 0.680999\n","epoch 3; iter: 0; batch classifier loss: 55.793743; batch adversarial loss: 0.675957\n","epoch 4; iter: 0; batch classifier loss: 35.825829; batch adversarial loss: 0.665277\n","epoch 5; iter: 0; batch classifier loss: 32.905666; batch adversarial loss: 0.652469\n","epoch 6; iter: 0; batch classifier loss: 21.839870; batch adversarial loss: 0.658015\n","epoch 7; iter: 0; batch classifier loss: 36.544205; batch adversarial loss: 0.666897\n","epoch 8; iter: 0; batch classifier loss: 37.715233; batch adversarial loss: 0.666100\n","epoch 9; iter: 0; batch classifier loss: 13.342719; batch adversarial loss: 0.648725\n","epoch 10; iter: 0; batch classifier loss: 31.236042; batch adversarial loss: 0.642677\n","epoch 11; iter: 0; batch classifier loss: 28.231327; batch adversarial loss: 0.636222\n","epoch 12; iter: 0; batch classifier loss: 27.173569; batch adversarial loss: 0.640815\n","epoch 13; iter: 0; batch classifier loss: 17.682648; batch adversarial loss: 0.638246\n","epoch 14; iter: 0; batch classifier loss: 19.590359; batch adversarial loss: 0.636930\n","epoch 15; iter: 0; batch classifier loss: 22.373646; batch adversarial loss: 0.644559\n","epoch 16; iter: 0; batch classifier loss: 22.772652; batch adversarial loss: 0.635416\n","epoch 17; iter: 0; batch classifier loss: 19.287041; batch adversarial loss: 0.607983\n","epoch 18; iter: 0; batch classifier loss: 13.617599; batch adversarial loss: 0.626662\n","epoch 19; iter: 0; batch classifier loss: 17.468884; batch adversarial loss: 0.631492\n","epoch 20; iter: 0; batch classifier loss: 18.842110; batch adversarial loss: 0.626838\n","epoch 21; iter: 0; batch classifier loss: 20.598856; batch adversarial loss: 0.648856\n","epoch 22; iter: 0; batch classifier loss: 14.335717; batch adversarial loss: 0.585879\n","epoch 23; iter: 0; batch classifier loss: 19.896755; batch adversarial loss: 0.625593\n","epoch 24; iter: 0; batch classifier loss: 11.057489; batch adversarial loss: 0.621611\n","epoch 25; iter: 0; batch classifier loss: 15.749968; batch adversarial loss: 0.609303\n","epoch 26; iter: 0; batch classifier loss: 10.263890; batch adversarial loss: 0.625484\n","epoch 27; iter: 0; batch classifier loss: 10.074876; batch adversarial loss: 0.627816\n","epoch 28; iter: 0; batch classifier loss: 13.079782; batch adversarial loss: 0.603379\n","epoch 29; iter: 0; batch classifier loss: 7.490207; batch adversarial loss: 0.581137\n","epoch 30; iter: 0; batch classifier loss: 11.811890; batch adversarial loss: 0.594858\n","epoch 31; iter: 0; batch classifier loss: 11.103072; batch adversarial loss: 0.634116\n","epoch 32; iter: 0; batch classifier loss: 7.615582; batch adversarial loss: 0.590336\n","epoch 33; iter: 0; batch classifier loss: 6.119157; batch adversarial loss: 0.610173\n","epoch 34; iter: 0; batch classifier loss: 5.275620; batch adversarial loss: 0.630803\n","epoch 35; iter: 0; batch classifier loss: 5.927670; batch adversarial loss: 0.595801\n","epoch 36; iter: 0; batch classifier loss: 7.258407; batch adversarial loss: 0.571977\n","epoch 37; iter: 0; batch classifier loss: 5.557486; batch adversarial loss: 0.600176\n","epoch 38; iter: 0; batch classifier loss: 6.760756; batch adversarial loss: 0.631032\n","epoch 39; iter: 0; batch classifier loss: 13.289663; batch adversarial loss: 0.530635\n","epoch 40; iter: 0; batch classifier loss: 2.328693; batch adversarial loss: 0.570522\n","epoch 41; iter: 0; batch classifier loss: 4.260735; batch adversarial loss: 0.611546\n","epoch 42; iter: 0; batch classifier loss: 1.626984; batch adversarial loss: 0.584960\n","epoch 43; iter: 0; batch classifier loss: 1.955990; batch adversarial loss: 0.569160\n","epoch 44; iter: 0; batch classifier loss: 2.579186; batch adversarial loss: 0.535369\n","epoch 45; iter: 0; batch classifier loss: 1.797425; batch adversarial loss: 0.595349\n","epoch 46; iter: 0; batch classifier loss: 1.831330; batch adversarial loss: 0.576105\n","epoch 47; iter: 0; batch classifier loss: 1.434004; batch adversarial loss: 0.598220\n","epoch 48; iter: 0; batch classifier loss: 1.214564; batch adversarial loss: 0.537255\n","epoch 49; iter: 0; batch classifier loss: 1.053269; batch adversarial loss: 0.526577\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7\n","epoch 0; iter: 0; batch classifier loss: 50.851601; batch adversarial loss: 0.709216\n","epoch 1; iter: 0; batch classifier loss: 66.695236; batch adversarial loss: 0.712454\n","epoch 2; iter: 0; batch classifier loss: 43.165981; batch adversarial loss: 0.744198\n","epoch 3; iter: 0; batch classifier loss: 45.146404; batch adversarial loss: 0.744846\n","epoch 4; iter: 0; batch classifier loss: 53.927219; batch adversarial loss: 0.713336\n","epoch 5; iter: 0; batch classifier loss: 38.214287; batch adversarial loss: 0.728967\n","epoch 6; iter: 0; batch classifier loss: 38.521141; batch adversarial loss: 0.745400\n","epoch 7; iter: 0; batch classifier loss: 40.332031; batch adversarial loss: 0.755877\n","epoch 8; iter: 0; batch classifier loss: 38.906292; batch adversarial loss: 0.745872\n","epoch 9; iter: 0; batch classifier loss: 27.403351; batch adversarial loss: 0.726707\n","epoch 10; iter: 0; batch classifier loss: 35.562473; batch adversarial loss: 0.702127\n","epoch 11; iter: 0; batch classifier loss: 34.142487; batch adversarial loss: 0.696290\n","epoch 12; iter: 0; batch classifier loss: 42.000008; batch adversarial loss: 0.709648\n","epoch 13; iter: 0; batch classifier loss: 42.234688; batch adversarial loss: 0.686480\n","epoch 14; iter: 0; batch classifier loss: 31.850277; batch adversarial loss: 0.689946\n","epoch 15; iter: 0; batch classifier loss: 25.664486; batch adversarial loss: 0.680832\n","epoch 16; iter: 0; batch classifier loss: 29.247208; batch adversarial loss: 0.676954\n","epoch 17; iter: 0; batch classifier loss: 31.571968; batch adversarial loss: 0.696193\n","epoch 18; iter: 0; batch classifier loss: 26.949371; batch adversarial loss: 0.713907\n","epoch 19; iter: 0; batch classifier loss: 28.205360; batch adversarial loss: 0.675413\n","epoch 20; iter: 0; batch classifier loss: 27.606115; batch adversarial loss: 0.694318\n","epoch 21; iter: 0; batch classifier loss: 18.009708; batch adversarial loss: 0.676395\n","epoch 22; iter: 0; batch classifier loss: 24.048317; batch adversarial loss: 0.680153\n","epoch 23; iter: 0; batch classifier loss: 19.828966; batch adversarial loss: 0.662445\n","epoch 24; iter: 0; batch classifier loss: 12.676239; batch adversarial loss: 0.669957\n","epoch 25; iter: 0; batch classifier loss: 13.832217; batch adversarial loss: 0.663283\n","epoch 26; iter: 0; batch classifier loss: 10.849676; batch adversarial loss: 0.642768\n","epoch 27; iter: 0; batch classifier loss: 15.278894; batch adversarial loss: 0.648515\n","epoch 28; iter: 0; batch classifier loss: 10.685705; batch adversarial loss: 0.650613\n","epoch 29; iter: 0; batch classifier loss: 18.113033; batch adversarial loss: 0.658494\n","epoch 30; iter: 0; batch classifier loss: 14.941227; batch adversarial loss: 0.641375\n","epoch 31; iter: 0; batch classifier loss: 17.941879; batch adversarial loss: 0.624038\n","epoch 32; iter: 0; batch classifier loss: 9.171193; batch adversarial loss: 0.645463\n","epoch 33; iter: 0; batch classifier loss: 8.997101; batch adversarial loss: 0.638684\n","epoch 34; iter: 0; batch classifier loss: 12.262003; batch adversarial loss: 0.629706\n","epoch 35; iter: 0; batch classifier loss: 7.949781; batch adversarial loss: 0.621363\n","epoch 36; iter: 0; batch classifier loss: 8.090104; batch adversarial loss: 0.600527\n","epoch 37; iter: 0; batch classifier loss: 5.191443; batch adversarial loss: 0.625713\n","epoch 38; iter: 0; batch classifier loss: 5.924150; batch adversarial loss: 0.632873\n","epoch 39; iter: 0; batch classifier loss: 7.335929; batch adversarial loss: 0.620157\n","epoch 40; iter: 0; batch classifier loss: 7.049336; batch adversarial loss: 0.630402\n","epoch 41; iter: 0; batch classifier loss: 5.157481; batch adversarial loss: 0.617375\n","epoch 42; iter: 0; batch classifier loss: 4.832512; batch adversarial loss: 0.616065\n","epoch 43; iter: 0; batch classifier loss: 6.771963; batch adversarial loss: 0.613528\n","epoch 44; iter: 0; batch classifier loss: 9.399979; batch adversarial loss: 0.608639\n","epoch 45; iter: 0; batch classifier loss: 3.905702; batch adversarial loss: 0.618657\n","epoch 46; iter: 0; batch classifier loss: 4.497960; batch adversarial loss: 0.597770\n","epoch 47; iter: 0; batch classifier loss: 6.850784; batch adversarial loss: 0.602984\n","epoch 48; iter: 0; batch classifier loss: 3.576770; batch adversarial loss: 0.602752\n","epoch 49; iter: 0; batch classifier loss: 3.571347; batch adversarial loss: 0.589968\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.71\n","epoch 0; iter: 0; batch classifier loss: 105.008774; batch adversarial loss: 0.430363\n","epoch 1; iter: 0; batch classifier loss: 91.432343; batch adversarial loss: 0.458916\n","epoch 2; iter: 0; batch classifier loss: 58.202599; batch adversarial loss: 0.487551\n","epoch 3; iter: 0; batch classifier loss: 64.652077; batch adversarial loss: 0.653798\n","epoch 4; iter: 0; batch classifier loss: 46.856033; batch adversarial loss: 0.654521\n","epoch 5; iter: 0; batch classifier loss: 43.822823; batch adversarial loss: 0.654615\n","epoch 6; iter: 0; batch classifier loss: 64.915352; batch adversarial loss: 0.607653\n","epoch 7; iter: 0; batch classifier loss: 49.016808; batch adversarial loss: 0.552684\n","epoch 8; iter: 0; batch classifier loss: 56.148132; batch adversarial loss: 0.577385\n","epoch 9; iter: 0; batch classifier loss: 38.418411; batch adversarial loss: 0.576048\n","epoch 10; iter: 0; batch classifier loss: 39.240807; batch adversarial loss: 0.603476\n","epoch 11; iter: 0; batch classifier loss: 53.068073; batch adversarial loss: 0.623536\n","epoch 12; iter: 0; batch classifier loss: 44.759190; batch adversarial loss: 0.598982\n","epoch 13; iter: 0; batch classifier loss: 33.245430; batch adversarial loss: 0.592010\n","epoch 14; iter: 0; batch classifier loss: 44.043831; batch adversarial loss: 0.567095\n","epoch 15; iter: 0; batch classifier loss: 31.211323; batch adversarial loss: 0.557519\n","epoch 16; iter: 0; batch classifier loss: 27.770683; batch adversarial loss: 0.540873\n","epoch 17; iter: 0; batch classifier loss: 29.609730; batch adversarial loss: 0.608226\n","epoch 18; iter: 0; batch classifier loss: 21.224787; batch adversarial loss: 0.603245\n","epoch 19; iter: 0; batch classifier loss: 26.530396; batch adversarial loss: 0.634944\n","epoch 20; iter: 0; batch classifier loss: 38.560303; batch adversarial loss: 0.577214\n","epoch 21; iter: 0; batch classifier loss: 37.667053; batch adversarial loss: 0.561836\n","epoch 22; iter: 0; batch classifier loss: 31.396046; batch adversarial loss: 0.512170\n","epoch 23; iter: 0; batch classifier loss: 21.936602; batch adversarial loss: 0.559027\n","epoch 24; iter: 0; batch classifier loss: 29.566437; batch adversarial loss: 0.549738\n","epoch 25; iter: 0; batch classifier loss: 28.545397; batch adversarial loss: 0.536374\n","epoch 26; iter: 0; batch classifier loss: 23.067593; batch adversarial loss: 0.514258\n","epoch 27; iter: 0; batch classifier loss: 16.644096; batch adversarial loss: 0.552526\n","epoch 28; iter: 0; batch classifier loss: 29.020477; batch adversarial loss: 0.525394\n","epoch 29; iter: 0; batch classifier loss: 24.718388; batch adversarial loss: 0.574133\n","epoch 30; iter: 0; batch classifier loss: 20.907520; batch adversarial loss: 0.594265\n","epoch 31; iter: 0; batch classifier loss: 18.227385; batch adversarial loss: 0.586329\n","epoch 32; iter: 0; batch classifier loss: 17.723312; batch adversarial loss: 0.585389\n","epoch 33; iter: 0; batch classifier loss: 15.263178; batch adversarial loss: 0.541527\n","epoch 34; iter: 0; batch classifier loss: 23.715385; batch adversarial loss: 0.541195\n","epoch 35; iter: 0; batch classifier loss: 14.612417; batch adversarial loss: 0.536288\n","epoch 36; iter: 0; batch classifier loss: 15.808701; batch adversarial loss: 0.529046\n","epoch 37; iter: 0; batch classifier loss: 11.399724; batch adversarial loss: 0.529132\n","epoch 38; iter: 0; batch classifier loss: 12.705511; batch adversarial loss: 0.551792\n","epoch 39; iter: 0; batch classifier loss: 15.675000; batch adversarial loss: 0.574806\n","epoch 40; iter: 0; batch classifier loss: 14.044534; batch adversarial loss: 0.534175\n","epoch 41; iter: 0; batch classifier loss: 11.524075; batch adversarial loss: 0.541556\n","epoch 42; iter: 0; batch classifier loss: 12.117543; batch adversarial loss: 0.577826\n","epoch 43; iter: 0; batch classifier loss: 10.806767; batch adversarial loss: 0.612662\n","epoch 44; iter: 0; batch classifier loss: 8.641762; batch adversarial loss: 0.506082\n","epoch 45; iter: 0; batch classifier loss: 9.282707; batch adversarial loss: 0.593962\n","epoch 46; iter: 0; batch classifier loss: 11.857615; batch adversarial loss: 0.538182\n","epoch 47; iter: 0; batch classifier loss: 7.190752; batch adversarial loss: 0.515246\n","epoch 48; iter: 0; batch classifier loss: 12.588542; batch adversarial loss: 0.557061\n","epoch 49; iter: 0; batch classifier loss: 9.742853; batch adversarial loss: 0.532727\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.725\n","epoch 0; iter: 0; batch classifier loss: 72.486130; batch adversarial loss: 0.587515\n","epoch 1; iter: 0; batch classifier loss: 51.469673; batch adversarial loss: 0.644283\n","epoch 2; iter: 0; batch classifier loss: 59.557678; batch adversarial loss: 0.635415\n","epoch 3; iter: 0; batch classifier loss: 45.196602; batch adversarial loss: 0.616868\n","epoch 4; iter: 0; batch classifier loss: 60.920631; batch adversarial loss: 0.590518\n","epoch 5; iter: 0; batch classifier loss: 31.595657; batch adversarial loss: 0.617473\n","epoch 6; iter: 0; batch classifier loss: 40.589329; batch adversarial loss: 0.632723\n","epoch 7; iter: 0; batch classifier loss: 39.753357; batch adversarial loss: 0.634876\n","epoch 8; iter: 0; batch classifier loss: 39.247505; batch adversarial loss: 0.619824\n","epoch 9; iter: 0; batch classifier loss: 38.595173; batch adversarial loss: 0.593432\n","epoch 10; iter: 0; batch classifier loss: 32.826046; batch adversarial loss: 0.602107\n","epoch 11; iter: 0; batch classifier loss: 33.036354; batch adversarial loss: 0.602700\n","epoch 12; iter: 0; batch classifier loss: 22.363113; batch adversarial loss: 0.603777\n","epoch 13; iter: 0; batch classifier loss: 33.122894; batch adversarial loss: 0.582375\n","epoch 14; iter: 0; batch classifier loss: 32.436909; batch adversarial loss: 0.598310\n","epoch 15; iter: 0; batch classifier loss: 21.623177; batch adversarial loss: 0.623756\n","epoch 16; iter: 0; batch classifier loss: 28.552073; batch adversarial loss: 0.584096\n","epoch 17; iter: 0; batch classifier loss: 22.331402; batch adversarial loss: 0.630314\n","epoch 18; iter: 0; batch classifier loss: 19.544186; batch adversarial loss: 0.583355\n","epoch 19; iter: 0; batch classifier loss: 22.809692; batch adversarial loss: 0.561320\n","epoch 20; iter: 0; batch classifier loss: 26.600418; batch adversarial loss: 0.604635\n","epoch 21; iter: 0; batch classifier loss: 23.502005; batch adversarial loss: 0.590589\n","epoch 22; iter: 0; batch classifier loss: 17.629612; batch adversarial loss: 0.597395\n","epoch 23; iter: 0; batch classifier loss: 13.173522; batch adversarial loss: 0.554927\n","epoch 24; iter: 0; batch classifier loss: 12.352789; batch adversarial loss: 0.608034\n","epoch 25; iter: 0; batch classifier loss: 10.492233; batch adversarial loss: 0.597526\n","epoch 26; iter: 0; batch classifier loss: 9.921947; batch adversarial loss: 0.602191\n","epoch 27; iter: 0; batch classifier loss: 12.354690; batch adversarial loss: 0.537247\n","epoch 28; iter: 0; batch classifier loss: 9.118745; batch adversarial loss: 0.573376\n","epoch 29; iter: 0; batch classifier loss: 10.970171; batch adversarial loss: 0.592243\n","epoch 30; iter: 0; batch classifier loss: 10.370575; batch adversarial loss: 0.534760\n","epoch 31; iter: 0; batch classifier loss: 8.657692; batch adversarial loss: 0.637753\n","epoch 32; iter: 0; batch classifier loss: 5.664038; batch adversarial loss: 0.548374\n","epoch 33; iter: 0; batch classifier loss: 4.930923; batch adversarial loss: 0.532111\n","epoch 34; iter: 0; batch classifier loss: 6.689296; batch adversarial loss: 0.574420\n","epoch 35; iter: 0; batch classifier loss: 7.038933; batch adversarial loss: 0.545865\n","epoch 36; iter: 0; batch classifier loss: 5.658751; batch adversarial loss: 0.539585\n","epoch 37; iter: 0; batch classifier loss: 5.535723; batch adversarial loss: 0.562719\n","epoch 38; iter: 0; batch classifier loss: 5.084653; batch adversarial loss: 0.499663\n","epoch 39; iter: 0; batch classifier loss: 3.642268; batch adversarial loss: 0.545827\n","epoch 40; iter: 0; batch classifier loss: 2.717335; batch adversarial loss: 0.530422\n","epoch 41; iter: 0; batch classifier loss: 3.570293; batch adversarial loss: 0.541490\n","epoch 42; iter: 0; batch classifier loss: 4.203721; batch adversarial loss: 0.608925\n","epoch 43; iter: 0; batch classifier loss: 6.788245; batch adversarial loss: 0.508591\n","epoch 44; iter: 0; batch classifier loss: 2.799689; batch adversarial loss: 0.517010\n","epoch 45; iter: 0; batch classifier loss: 2.711049; batch adversarial loss: 0.592452\n","epoch 46; iter: 0; batch classifier loss: 2.424643; batch adversarial loss: 0.517698\n","epoch 47; iter: 0; batch classifier loss: 2.659703; batch adversarial loss: 0.510656\n","epoch 48; iter: 0; batch classifier loss: 1.226769; batch adversarial loss: 0.555216\n","epoch 49; iter: 0; batch classifier loss: 1.630425; batch adversarial loss: 0.580277\n","Accuracy 0.73\n","epoch 0; iter: 0; batch classifier loss: 160.616379; batch adversarial loss: 0.745732\n","epoch 1; iter: 0; batch classifier loss: 127.020798; batch adversarial loss: 0.741573\n","epoch 2; iter: 0; batch classifier loss: 51.159042; batch adversarial loss: 0.704693\n","epoch 3; iter: 0; batch classifier loss: 60.514606; batch adversarial loss: 0.697679\n","epoch 4; iter: 0; batch classifier loss: 74.554588; batch adversarial loss: 0.691215\n","epoch 5; iter: 0; batch classifier loss: 40.534431; batch adversarial loss: 0.702073\n","epoch 6; iter: 0; batch classifier loss: 65.620178; batch adversarial loss: 0.696680\n","epoch 7; iter: 0; batch classifier loss: 40.370033; batch adversarial loss: 0.696199\n","epoch 8; iter: 0; batch classifier loss: 62.637554; batch adversarial loss: 0.686196\n","epoch 9; iter: 0; batch classifier loss: 30.995941; batch adversarial loss: 0.692483\n","epoch 10; iter: 0; batch classifier loss: 38.925644; batch adversarial loss: 0.682579\n","epoch 11; iter: 0; batch classifier loss: 55.265961; batch adversarial loss: 0.679768\n","epoch 12; iter: 0; batch classifier loss: 30.175356; batch adversarial loss: 0.680710\n","epoch 13; iter: 0; batch classifier loss: 37.732437; batch adversarial loss: 0.674298\n","epoch 14; iter: 0; batch classifier loss: 36.449501; batch adversarial loss: 0.664593\n","epoch 15; iter: 0; batch classifier loss: 34.437988; batch adversarial loss: 0.662617\n","epoch 16; iter: 0; batch classifier loss: 36.148720; batch adversarial loss: 0.666283\n","epoch 17; iter: 0; batch classifier loss: 31.140928; batch adversarial loss: 0.652611\n","epoch 18; iter: 0; batch classifier loss: 30.938839; batch adversarial loss: 0.658803\n","epoch 19; iter: 0; batch classifier loss: 28.316372; batch adversarial loss: 0.654394\n","epoch 20; iter: 0; batch classifier loss: 28.070862; batch adversarial loss: 0.659843\n","epoch 21; iter: 0; batch classifier loss: 20.149628; batch adversarial loss: 0.665078\n","epoch 22; iter: 0; batch classifier loss: 22.982729; batch adversarial loss: 0.643237\n","epoch 23; iter: 0; batch classifier loss: 18.966051; batch adversarial loss: 0.626404\n","epoch 24; iter: 0; batch classifier loss: 17.848179; batch adversarial loss: 0.635425\n","epoch 25; iter: 0; batch classifier loss: 22.026176; batch adversarial loss: 0.629810\n","epoch 26; iter: 0; batch classifier loss: 19.755606; batch adversarial loss: 0.642741\n","epoch 27; iter: 0; batch classifier loss: 21.948975; batch adversarial loss: 0.629727\n","epoch 28; iter: 0; batch classifier loss: 16.448107; batch adversarial loss: 0.635460\n","epoch 29; iter: 0; batch classifier loss: 13.845051; batch adversarial loss: 0.616910\n","epoch 30; iter: 0; batch classifier loss: 14.760683; batch adversarial loss: 0.630524\n","epoch 31; iter: 0; batch classifier loss: 21.960678; batch adversarial loss: 0.627642\n","epoch 32; iter: 0; batch classifier loss: 16.182861; batch adversarial loss: 0.610310\n","epoch 33; iter: 0; batch classifier loss: 15.922206; batch adversarial loss: 0.620502\n","epoch 34; iter: 0; batch classifier loss: 15.368832; batch adversarial loss: 0.613091\n","epoch 35; iter: 0; batch classifier loss: 14.390969; batch adversarial loss: 0.605141\n","epoch 36; iter: 0; batch classifier loss: 11.499971; batch adversarial loss: 0.597045\n","epoch 37; iter: 0; batch classifier loss: 22.156141; batch adversarial loss: 0.615630\n","epoch 38; iter: 0; batch classifier loss: 14.140684; batch adversarial loss: 0.609250\n","epoch 39; iter: 0; batch classifier loss: 12.337626; batch adversarial loss: 0.594590\n","epoch 40; iter: 0; batch classifier loss: 10.119455; batch adversarial loss: 0.589587\n","epoch 41; iter: 0; batch classifier loss: 8.013980; batch adversarial loss: 0.602035\n","epoch 42; iter: 0; batch classifier loss: 9.365238; batch adversarial loss: 0.590831\n","epoch 43; iter: 0; batch classifier loss: 12.130058; batch adversarial loss: 0.591411\n","epoch 44; iter: 0; batch classifier loss: 6.660901; batch adversarial loss: 0.595314\n","epoch 45; iter: 0; batch classifier loss: 9.525818; batch adversarial loss: 0.599478\n","epoch 46; iter: 0; batch classifier loss: 9.915024; batch adversarial loss: 0.575795\n","epoch 47; iter: 0; batch classifier loss: 6.328322; batch adversarial loss: 0.576050\n","epoch 48; iter: 0; batch classifier loss: 5.361384; batch adversarial loss: 0.586788\n","epoch 49; iter: 0; batch classifier loss: 7.147820; batch adversarial loss: 0.576403\n","Accuracy 0.68\n","epoch 0; iter: 0; batch classifier loss: 66.692566; batch adversarial loss: 0.801930\n","epoch 1; iter: 0; batch classifier loss: 47.240318; batch adversarial loss: 0.722601\n","epoch 2; iter: 0; batch classifier loss: 56.331303; batch adversarial loss: 0.741768\n","epoch 3; iter: 0; batch classifier loss: 58.443703; batch adversarial loss: 0.773000\n","epoch 4; iter: 0; batch classifier loss: 53.735119; batch adversarial loss: 0.759332\n","epoch 5; iter: 0; batch classifier loss: 49.679932; batch adversarial loss: 0.760462\n","epoch 6; iter: 0; batch classifier loss: 36.320637; batch adversarial loss: 0.709938\n","epoch 7; iter: 0; batch classifier loss: 41.846931; batch adversarial loss: 0.715796\n","epoch 8; iter: 0; batch classifier loss: 36.093636; batch adversarial loss: 0.709861\n","epoch 9; iter: 0; batch classifier loss: 34.368835; batch adversarial loss: 0.735509\n","epoch 10; iter: 0; batch classifier loss: 26.873753; batch adversarial loss: 0.707920\n","epoch 11; iter: 0; batch classifier loss: 37.444397; batch adversarial loss: 0.723494\n","epoch 12; iter: 0; batch classifier loss: 34.105133; batch adversarial loss: 0.717973\n","epoch 13; iter: 0; batch classifier loss: 34.231266; batch adversarial loss: 0.704348\n","epoch 14; iter: 0; batch classifier loss: 29.110380; batch adversarial loss: 0.691895\n","epoch 15; iter: 0; batch classifier loss: 27.371769; batch adversarial loss: 0.699472\n","epoch 16; iter: 0; batch classifier loss: 27.633244; batch adversarial loss: 0.713870\n","epoch 17; iter: 0; batch classifier loss: 17.955772; batch adversarial loss: 0.702381\n","epoch 18; iter: 0; batch classifier loss: 18.368389; batch adversarial loss: 0.681497\n","epoch 19; iter: 0; batch classifier loss: 28.304611; batch adversarial loss: 0.689624\n","epoch 20; iter: 0; batch classifier loss: 21.617863; batch adversarial loss: 0.681506\n","epoch 21; iter: 0; batch classifier loss: 15.240503; batch adversarial loss: 0.677100\n","epoch 22; iter: 0; batch classifier loss: 23.901976; batch adversarial loss: 0.684740\n","epoch 23; iter: 0; batch classifier loss: 16.517349; batch adversarial loss: 0.676235\n","epoch 24; iter: 0; batch classifier loss: 14.266598; batch adversarial loss: 0.662031\n","epoch 25; iter: 0; batch classifier loss: 18.327778; batch adversarial loss: 0.661065\n","epoch 26; iter: 0; batch classifier loss: 15.821041; batch adversarial loss: 0.664400\n","epoch 27; iter: 0; batch classifier loss: 10.192595; batch adversarial loss: 0.652201\n","epoch 28; iter: 0; batch classifier loss: 21.791636; batch adversarial loss: 0.667596\n","epoch 29; iter: 0; batch classifier loss: 18.874359; batch adversarial loss: 0.656829\n","epoch 30; iter: 0; batch classifier loss: 13.397468; batch adversarial loss: 0.644600\n","epoch 31; iter: 0; batch classifier loss: 17.633183; batch adversarial loss: 0.657506\n","epoch 32; iter: 0; batch classifier loss: 12.544596; batch adversarial loss: 0.656928\n","epoch 33; iter: 0; batch classifier loss: 10.015720; batch adversarial loss: 0.643417\n","epoch 34; iter: 0; batch classifier loss: 10.891959; batch adversarial loss: 0.636274\n","epoch 35; iter: 0; batch classifier loss: 11.915543; batch adversarial loss: 0.643505\n","epoch 36; iter: 0; batch classifier loss: 7.475903; batch adversarial loss: 0.624813\n","epoch 37; iter: 0; batch classifier loss: 6.874394; batch adversarial loss: 0.628370\n","epoch 38; iter: 0; batch classifier loss: 5.088033; batch adversarial loss: 0.613193\n","epoch 39; iter: 0; batch classifier loss: 9.261108; batch adversarial loss: 0.618277\n","epoch 40; iter: 0; batch classifier loss: 5.736512; batch adversarial loss: 0.628001\n","epoch 41; iter: 0; batch classifier loss: 5.295818; batch adversarial loss: 0.619358\n","epoch 42; iter: 0; batch classifier loss: 5.782886; batch adversarial loss: 0.612845\n","epoch 43; iter: 0; batch classifier loss: 3.704888; batch adversarial loss: 0.613280\n","epoch 44; iter: 0; batch classifier loss: 5.158030; batch adversarial loss: 0.618614\n","epoch 45; iter: 0; batch classifier loss: 4.498587; batch adversarial loss: 0.609104\n","epoch 46; iter: 0; batch classifier loss: 4.501668; batch adversarial loss: 0.598700\n","epoch 47; iter: 0; batch classifier loss: 4.697452; batch adversarial loss: 0.608244\n","epoch 48; iter: 0; batch classifier loss: 2.465288; batch adversarial loss: 0.594303\n","epoch 49; iter: 0; batch classifier loss: 3.644880; batch adversarial loss: 0.598767\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.69\n","epoch 0; iter: 0; batch classifier loss: 105.780380; batch adversarial loss: 0.706486\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.68\n","epoch 0; iter: 0; batch classifier loss: 182.672272; batch adversarial loss: 1.458374\n","epoch 1; iter: 0; batch classifier loss: 118.979080; batch adversarial loss: 1.342716\n","epoch 2; iter: 0; batch classifier loss: 91.956276; batch adversarial loss: 1.202822\n","epoch 3; iter: 0; batch classifier loss: 40.458862; batch adversarial loss: 1.049492\n","epoch 4; iter: 0; batch classifier loss: 50.562630; batch adversarial loss: 0.860544\n","epoch 5; iter: 0; batch classifier loss: 83.396111; batch adversarial loss: 0.825613\n","epoch 6; iter: 0; batch classifier loss: 35.789265; batch adversarial loss: 0.814580\n","epoch 7; iter: 0; batch classifier loss: 68.218239; batch adversarial loss: 0.913124\n","epoch 8; iter: 0; batch classifier loss: 42.649712; batch adversarial loss: 0.964866\n","epoch 9; iter: 0; batch classifier loss: 46.453918; batch adversarial loss: 1.020621\n","epoch 10; iter: 0; batch classifier loss: 44.841064; batch adversarial loss: 0.988492\n","epoch 11; iter: 0; batch classifier loss: 41.630775; batch adversarial loss: 0.910017\n","epoch 12; iter: 0; batch classifier loss: 58.974270; batch adversarial loss: 0.871860\n","epoch 13; iter: 0; batch classifier loss: 42.604973; batch adversarial loss: 0.846822\n","epoch 14; iter: 0; batch classifier loss: 48.275341; batch adversarial loss: 0.919635\n","epoch 15; iter: 0; batch classifier loss: 32.399429; batch adversarial loss: 0.844770\n","epoch 16; iter: 0; batch classifier loss: 42.666821; batch adversarial loss: 0.894739\n","epoch 17; iter: 0; batch classifier loss: 46.248528; batch adversarial loss: 0.908917\n","epoch 18; iter: 0; batch classifier loss: 44.829491; batch adversarial loss: 0.904313\n","epoch 19; iter: 0; batch classifier loss: 25.826067; batch adversarial loss: 0.797798\n","epoch 20; iter: 0; batch classifier loss: 30.882011; batch adversarial loss: 0.815023\n","epoch 21; iter: 0; batch classifier loss: 35.215275; batch adversarial loss: 0.792783\n","epoch 22; iter: 0; batch classifier loss: 39.245281; batch adversarial loss: 0.868752\n","epoch 23; iter: 0; batch classifier loss: 26.940256; batch adversarial loss: 0.929455\n","epoch 24; iter: 0; batch classifier loss: 26.727922; batch adversarial loss: 0.959972\n","epoch 25; iter: 0; batch classifier loss: 39.639503; batch adversarial loss: 0.845944\n","epoch 26; iter: 0; batch classifier loss: 24.423531; batch adversarial loss: 0.806145\n","epoch 27; iter: 0; batch classifier loss: 26.404522; batch adversarial loss: 0.841399\n","epoch 28; iter: 0; batch classifier loss: 30.140873; batch adversarial loss: 0.839589\n","epoch 29; iter: 0; batch classifier loss: 31.396067; batch adversarial loss: 0.814789\n","epoch 30; iter: 0; batch classifier loss: 23.733624; batch adversarial loss: 0.785954\n","epoch 31; iter: 0; batch classifier loss: 15.822960; batch adversarial loss: 0.795709\n","epoch 32; iter: 0; batch classifier loss: 18.278761; batch adversarial loss: 0.840685\n","epoch 33; iter: 0; batch classifier loss: 22.165592; batch adversarial loss: 0.910572\n","epoch 34; iter: 0; batch classifier loss: 16.624359; batch adversarial loss: 0.796323\n","epoch 35; iter: 0; batch classifier loss: 12.847321; batch adversarial loss: 0.819844\n","epoch 36; iter: 0; batch classifier loss: 13.182606; batch adversarial loss: 0.772060\n","epoch 37; iter: 0; batch classifier loss: 22.011797; batch adversarial loss: 0.703995\n","epoch 38; iter: 0; batch classifier loss: 13.197122; batch adversarial loss: 0.799676\n","epoch 39; iter: 0; batch classifier loss: 12.956303; batch adversarial loss: 0.818240\n","epoch 40; iter: 0; batch classifier loss: 14.626497; batch adversarial loss: 0.828246\n","epoch 41; iter: 0; batch classifier loss: 16.210684; batch adversarial loss: 0.782126\n","epoch 42; iter: 0; batch classifier loss: 15.438494; batch adversarial loss: 0.736334\n","epoch 43; iter: 0; batch classifier loss: 13.768544; batch adversarial loss: 0.763660\n","epoch 44; iter: 0; batch classifier loss: 13.451078; batch adversarial loss: 0.757568\n","epoch 45; iter: 0; batch classifier loss: 9.293136; batch adversarial loss: 0.761309\n","epoch 46; iter: 0; batch classifier loss: 10.917483; batch adversarial loss: 0.761871\n","epoch 47; iter: 0; batch classifier loss: 13.786538; batch adversarial loss: 0.807242\n","epoch 48; iter: 0; batch classifier loss: 10.044855; batch adversarial loss: 0.795616\n","epoch 49; iter: 0; batch classifier loss: 11.259860; batch adversarial loss: 0.695878\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.67\n","epoch 0; iter: 0; batch classifier loss: 229.879944; batch adversarial loss: 1.202815\n","epoch 1; iter: 0; batch classifier loss: 91.581306; batch adversarial loss: 1.169290\n","epoch 2; iter: 0; batch classifier loss: 43.153358; batch adversarial loss: 0.908799\n","epoch 3; iter: 0; batch classifier loss: 51.778881; batch adversarial loss: 0.755933\n","epoch 4; iter: 0; batch classifier loss: 49.897110; batch adversarial loss: 0.757579\n","epoch 5; iter: 0; batch classifier loss: 36.424847; batch adversarial loss: 0.750483\n","epoch 6; iter: 0; batch classifier loss: 43.496735; batch adversarial loss: 0.779473\n","epoch 7; iter: 0; batch classifier loss: 37.411167; batch adversarial loss: 0.863320\n","epoch 8; iter: 0; batch classifier loss: 46.747604; batch adversarial loss: 0.957508\n","epoch 9; iter: 0; batch classifier loss: 26.193083; batch adversarial loss: 0.912809\n","epoch 10; iter: 0; batch classifier loss: 43.427727; batch adversarial loss: 0.807685\n","epoch 11; iter: 0; batch classifier loss: 39.031277; batch adversarial loss: 0.892190\n","epoch 12; iter: 0; batch classifier loss: 43.644672; batch adversarial loss: 0.900074\n","epoch 13; iter: 0; batch classifier loss: 44.807018; batch adversarial loss: 0.806445\n","epoch 14; iter: 0; batch classifier loss: 40.069927; batch adversarial loss: 0.824074\n","epoch 15; iter: 0; batch classifier loss: 38.103798; batch adversarial loss: 0.775872\n","epoch 16; iter: 0; batch classifier loss: 50.440262; batch adversarial loss: 0.812760\n","epoch 17; iter: 0; batch classifier loss: 30.145226; batch adversarial loss: 0.814186\n","epoch 18; iter: 0; batch classifier loss: 35.367233; batch adversarial loss: 0.824157\n","epoch 19; iter: 0; batch classifier loss: 23.130497; batch adversarial loss: 0.854892\n","epoch 20; iter: 0; batch classifier loss: 31.467113; batch adversarial loss: 0.789536\n","epoch 21; iter: 0; batch classifier loss: 30.639429; batch adversarial loss: 0.794262\n","epoch 22; iter: 0; batch classifier loss: 23.633919; batch adversarial loss: 0.772723\n","epoch 23; iter: 0; batch classifier loss: 19.227776; batch adversarial loss: 0.817954\n","epoch 24; iter: 0; batch classifier loss: 23.115152; batch adversarial loss: 0.767349\n","epoch 25; iter: 0; batch classifier loss: 22.294495; batch adversarial loss: 0.803775\n","epoch 26; iter: 0; batch classifier loss: 23.913301; batch adversarial loss: 0.812438\n","epoch 27; iter: 0; batch classifier loss: 22.803226; batch adversarial loss: 0.746421\n","epoch 28; iter: 0; batch classifier loss: 28.832804; batch adversarial loss: 0.754629\n","epoch 29; iter: 0; batch classifier loss: 34.155693; batch adversarial loss: 0.822786\n","epoch 30; iter: 0; batch classifier loss: 18.117821; batch adversarial loss: 0.762881\n","epoch 31; iter: 0; batch classifier loss: 17.040409; batch adversarial loss: 0.708442\n","epoch 32; iter: 0; batch classifier loss: 21.894878; batch adversarial loss: 0.743820\n","epoch 33; iter: 0; batch classifier loss: 22.150928; batch adversarial loss: 0.733430\n","epoch 34; iter: 0; batch classifier loss: 17.537882; batch adversarial loss: 0.773772\n","epoch 35; iter: 0; batch classifier loss: 20.041416; batch adversarial loss: 0.782147\n","epoch 36; iter: 0; batch classifier loss: 23.348637; batch adversarial loss: 0.753407\n","epoch 37; iter: 0; batch classifier loss: 15.834558; batch adversarial loss: 0.714574\n","epoch 38; iter: 0; batch classifier loss: 19.786375; batch adversarial loss: 0.715324\n","epoch 39; iter: 0; batch classifier loss: 13.362852; batch adversarial loss: 0.730140\n","epoch 40; iter: 0; batch classifier loss: 19.171867; batch adversarial loss: 0.725902\n","epoch 41; iter: 0; batch classifier loss: 15.106391; batch adversarial loss: 0.736769\n","epoch 42; iter: 0; batch classifier loss: 14.564680; batch adversarial loss: 0.723428\n","epoch 43; iter: 0; batch classifier loss: 17.875134; batch adversarial loss: 0.710696\n","epoch 44; iter: 0; batch classifier loss: 13.343918; batch adversarial loss: 0.717435\n","epoch 45; iter: 0; batch classifier loss: 12.199242; batch adversarial loss: 0.743063\n","epoch 46; iter: 0; batch classifier loss: 21.260019; batch adversarial loss: 0.707170\n","epoch 47; iter: 0; batch classifier loss: 10.642933; batch adversarial loss: 0.665443\n","epoch 48; iter: 0; batch classifier loss: 8.897156; batch adversarial loss: 0.653883\n","epoch 49; iter: 0; batch classifier loss: 10.133145; batch adversarial loss: 0.659241\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.685\n","epoch 0; iter: 0; batch classifier loss: 61.269184; batch adversarial loss: 0.621140\n","epoch 1; iter: 0; batch classifier loss: 50.571884; batch adversarial loss: 0.648637\n","epoch 2; iter: 0; batch classifier loss: 43.031906; batch adversarial loss: 0.673359\n","epoch 3; iter: 0; batch classifier loss: 47.078434; batch adversarial loss: 0.665740\n","epoch 4; iter: 0; batch classifier loss: 41.583454; batch adversarial loss: 0.623647\n","epoch 5; iter: 0; batch classifier loss: 30.805452; batch adversarial loss: 0.644886\n","epoch 6; iter: 0; batch classifier loss: 49.359619; batch adversarial loss: 0.645529\n","epoch 7; iter: 0; batch classifier loss: 44.604431; batch adversarial loss: 0.621845\n","epoch 8; iter: 0; batch classifier loss: 38.301662; batch adversarial loss: 0.641279\n","epoch 9; iter: 0; batch classifier loss: 37.794109; batch adversarial loss: 0.631873\n","epoch 10; iter: 0; batch classifier loss: 33.125477; batch adversarial loss: 0.614444\n","epoch 11; iter: 0; batch classifier loss: 27.976831; batch adversarial loss: 0.610172\n","epoch 12; iter: 0; batch classifier loss: 29.410858; batch adversarial loss: 0.630318\n","epoch 13; iter: 0; batch classifier loss: 27.502235; batch adversarial loss: 0.622728\n","epoch 14; iter: 0; batch classifier loss: 24.607662; batch adversarial loss: 0.580621\n","epoch 15; iter: 0; batch classifier loss: 34.112232; batch adversarial loss: 0.605594\n","epoch 16; iter: 0; batch classifier loss: 29.225853; batch adversarial loss: 0.614363\n","epoch 17; iter: 0; batch classifier loss: 27.868467; batch adversarial loss: 0.609473\n","epoch 18; iter: 0; batch classifier loss: 23.468712; batch adversarial loss: 0.619276\n","epoch 19; iter: 0; batch classifier loss: 16.349766; batch adversarial loss: 0.602754\n","epoch 20; iter: 0; batch classifier loss: 13.306595; batch adversarial loss: 0.594795\n","epoch 21; iter: 0; batch classifier loss: 28.670010; batch adversarial loss: 0.616701\n","epoch 22; iter: 0; batch classifier loss: 16.482912; batch adversarial loss: 0.634460\n","epoch 23; iter: 0; batch classifier loss: 17.845457; batch adversarial loss: 0.580322\n","epoch 24; iter: 0; batch classifier loss: 18.625401; batch adversarial loss: 0.549551\n","epoch 25; iter: 0; batch classifier loss: 15.434539; batch adversarial loss: 0.594281\n","epoch 26; iter: 0; batch classifier loss: 17.570490; batch adversarial loss: 0.610723\n","epoch 27; iter: 0; batch classifier loss: 12.658545; batch adversarial loss: 0.592408\n","epoch 28; iter: 0; batch classifier loss: 17.400667; batch adversarial loss: 0.616390\n","epoch 29; iter: 0; batch classifier loss: 16.651091; batch adversarial loss: 0.610495\n","epoch 30; iter: 0; batch classifier loss: 19.257469; batch adversarial loss: 0.616686\n","epoch 31; iter: 0; batch classifier loss: 11.125509; batch adversarial loss: 0.587217\n","epoch 32; iter: 0; batch classifier loss: 9.109177; batch adversarial loss: 0.619404\n","epoch 33; iter: 0; batch classifier loss: 10.268051; batch adversarial loss: 0.512566\n","epoch 34; iter: 0; batch classifier loss: 8.173955; batch adversarial loss: 0.590421\n","epoch 35; iter: 0; batch classifier loss: 11.040590; batch adversarial loss: 0.614520\n","epoch 36; iter: 0; batch classifier loss: 5.575962; batch adversarial loss: 0.548034\n","epoch 37; iter: 0; batch classifier loss: 12.899177; batch adversarial loss: 0.450568\n","epoch 38; iter: 0; batch classifier loss: 5.857589; batch adversarial loss: 0.536935\n","epoch 39; iter: 0; batch classifier loss: 6.954049; batch adversarial loss: 0.604293\n","epoch 40; iter: 0; batch classifier loss: 6.141155; batch adversarial loss: 0.554244\n","epoch 41; iter: 0; batch classifier loss: 4.214937; batch adversarial loss: 0.575316\n","epoch 42; iter: 0; batch classifier loss: 3.736217; batch adversarial loss: 0.596757\n","epoch 43; iter: 0; batch classifier loss: 3.654359; batch adversarial loss: 0.571768\n","epoch 44; iter: 0; batch classifier loss: 3.361865; batch adversarial loss: 0.531711\n","epoch 45; iter: 0; batch classifier loss: 3.929823; batch adversarial loss: 0.488451\n","epoch 46; iter: 0; batch classifier loss: 3.476710; batch adversarial loss: 0.565016\n","epoch 47; iter: 0; batch classifier loss: 3.673647; batch adversarial loss: 0.577310\n","epoch 48; iter: 0; batch classifier loss: 2.411405; batch adversarial loss: 0.571300\n","epoch 49; iter: 0; batch classifier loss: 1.862136; batch adversarial loss: 0.538642\n","Accuracy 0.73\n","epoch 0; iter: 0; batch classifier loss: 545.359741; batch adversarial loss: 1.302729\n","epoch 1; iter: 0; batch classifier loss: 311.461365; batch adversarial loss: 1.409865\n","epoch 2; iter: 0; batch classifier loss: 134.978729; batch adversarial loss: 1.316352\n","epoch 3; iter: 0; batch classifier loss: 55.589020; batch adversarial loss: 0.987745\n","epoch 4; iter: 0; batch classifier loss: 47.622879; batch adversarial loss: 0.790996\n","epoch 5; iter: 0; batch classifier loss: 68.055740; batch adversarial loss: 0.724907\n","epoch 6; iter: 0; batch classifier loss: 79.671196; batch adversarial loss: 0.748707\n","epoch 7; iter: 0; batch classifier loss: 57.448593; batch adversarial loss: 0.693880\n","epoch 8; iter: 0; batch classifier loss: 50.909309; batch adversarial loss: 0.798439\n","epoch 9; iter: 0; batch classifier loss: 47.342903; batch adversarial loss: 0.841074\n","epoch 10; iter: 0; batch classifier loss: 50.986008; batch adversarial loss: 0.917451\n","epoch 11; iter: 0; batch classifier loss: 52.346920; batch adversarial loss: 0.990363\n","epoch 12; iter: 0; batch classifier loss: 43.123108; batch adversarial loss: 0.878190\n","epoch 13; iter: 0; batch classifier loss: 36.987450; batch adversarial loss: 0.964758\n","epoch 14; iter: 0; batch classifier loss: 47.659164; batch adversarial loss: 0.841457\n","epoch 15; iter: 0; batch classifier loss: 48.382053; batch adversarial loss: 0.912209\n","epoch 16; iter: 0; batch classifier loss: 52.459217; batch adversarial loss: 0.815912\n","epoch 17; iter: 0; batch classifier loss: 45.168327; batch adversarial loss: 0.824896\n","epoch 18; iter: 0; batch classifier loss: 40.599277; batch adversarial loss: 0.812350\n","epoch 19; iter: 0; batch classifier loss: 46.418251; batch adversarial loss: 0.769990\n","epoch 20; iter: 0; batch classifier loss: 43.232819; batch adversarial loss: 0.843798\n","epoch 21; iter: 0; batch classifier loss: 56.551334; batch adversarial loss: 0.827342\n","epoch 22; iter: 0; batch classifier loss: 43.443153; batch adversarial loss: 0.906372\n","epoch 23; iter: 0; batch classifier loss: 58.359421; batch adversarial loss: 0.841576\n","epoch 24; iter: 0; batch classifier loss: 38.066303; batch adversarial loss: 0.849563\n","epoch 25; iter: 0; batch classifier loss: 46.601547; batch adversarial loss: 0.882450\n","epoch 26; iter: 0; batch classifier loss: 56.684799; batch adversarial loss: 0.739799\n","epoch 27; iter: 0; batch classifier loss: 35.525238; batch adversarial loss: 0.773158\n","epoch 28; iter: 0; batch classifier loss: 24.290918; batch adversarial loss: 0.839911\n","epoch 29; iter: 0; batch classifier loss: 34.959625; batch adversarial loss: 0.824128\n","epoch 30; iter: 0; batch classifier loss: 35.842903; batch adversarial loss: 0.806240\n","epoch 31; iter: 0; batch classifier loss: 58.401638; batch adversarial loss: 0.717859\n","epoch 32; iter: 0; batch classifier loss: 39.875320; batch adversarial loss: 0.807145\n","epoch 33; iter: 0; batch classifier loss: 31.644207; batch adversarial loss: 0.779702\n","epoch 34; iter: 0; batch classifier loss: 31.883694; batch adversarial loss: 0.827903\n","epoch 35; iter: 0; batch classifier loss: 32.755146; batch adversarial loss: 0.838515\n","epoch 36; iter: 0; batch classifier loss: 34.062408; batch adversarial loss: 0.817131\n","epoch 37; iter: 0; batch classifier loss: 27.182806; batch adversarial loss: 0.794449\n","epoch 38; iter: 0; batch classifier loss: 32.221981; batch adversarial loss: 0.758951\n","epoch 39; iter: 0; batch classifier loss: 32.981930; batch adversarial loss: 0.746797\n","epoch 40; iter: 0; batch classifier loss: 22.665392; batch adversarial loss: 0.756771\n","epoch 41; iter: 0; batch classifier loss: 25.671150; batch adversarial loss: 0.776167\n","epoch 42; iter: 0; batch classifier loss: 35.753727; batch adversarial loss: 0.754054\n","epoch 43; iter: 0; batch classifier loss: 34.036854; batch adversarial loss: 0.754544\n","epoch 44; iter: 0; batch classifier loss: 26.227097; batch adversarial loss: 0.797078\n","epoch 45; iter: 0; batch classifier loss: 24.568310; batch adversarial loss: 0.754017\n","epoch 46; iter: 0; batch classifier loss: 28.601692; batch adversarial loss: 0.734329\n","epoch 47; iter: 0; batch classifier loss: 19.327499; batch adversarial loss: 0.731879\n","epoch 48; iter: 0; batch classifier loss: 28.399082; batch adversarial loss: 0.733942\n","epoch 49; iter: 0; batch classifier loss: 21.275873; batch adversarial loss: 0.728570\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.675\n","epoch 0; iter: 0; batch classifier loss: 61.080986; batch adversarial loss: 0.606158\n","epoch 1; iter: 0; batch classifier loss: 43.316994; batch adversarial loss: 0.559145\n","epoch 2; iter: 0; batch classifier loss: 54.845467; batch adversarial loss: 0.527460\n","epoch 3; iter: 0; batch classifier loss: 44.109009; batch adversarial loss: 0.592263\n","epoch 4; iter: 0; batch classifier loss: 39.083244; batch adversarial loss: 0.618742\n","epoch 5; iter: 0; batch classifier loss: 50.087868; batch adversarial loss: 0.606645\n","epoch 6; iter: 0; batch classifier loss: 31.933674; batch adversarial loss: 0.537604\n","epoch 7; iter: 0; batch classifier loss: 37.839653; batch adversarial loss: 0.591935\n","epoch 8; iter: 0; batch classifier loss: 35.163456; batch adversarial loss: 0.562146\n","epoch 9; iter: 0; batch classifier loss: 41.256168; batch adversarial loss: 0.575136\n","epoch 10; iter: 0; batch classifier loss: 36.245819; batch adversarial loss: 0.580985\n","epoch 11; iter: 0; batch classifier loss: 29.980198; batch adversarial loss: 0.593489\n","epoch 12; iter: 0; batch classifier loss: 27.268894; batch adversarial loss: 0.526810\n","epoch 13; iter: 0; batch classifier loss: 29.703474; batch adversarial loss: 0.584332\n","epoch 14; iter: 0; batch classifier loss: 18.797390; batch adversarial loss: 0.567266\n","epoch 15; iter: 0; batch classifier loss: 28.688694; batch adversarial loss: 0.557091\n","epoch 16; iter: 0; batch classifier loss: 27.445385; batch adversarial loss: 0.552152\n","epoch 17; iter: 0; batch classifier loss: 34.983864; batch adversarial loss: 0.599089\n","epoch 18; iter: 0; batch classifier loss: 20.732883; batch adversarial loss: 0.551275\n","epoch 19; iter: 0; batch classifier loss: 21.370962; batch adversarial loss: 0.539744\n","epoch 20; iter: 0; batch classifier loss: 19.315998; batch adversarial loss: 0.559074\n","epoch 21; iter: 0; batch classifier loss: 15.264247; batch adversarial loss: 0.539961\n","epoch 22; iter: 0; batch classifier loss: 16.173683; batch adversarial loss: 0.578301\n","epoch 23; iter: 0; batch classifier loss: 15.591011; batch adversarial loss: 0.647664\n","epoch 24; iter: 0; batch classifier loss: 21.690100; batch adversarial loss: 0.560993\n","epoch 25; iter: 0; batch classifier loss: 16.885201; batch adversarial loss: 0.521518\n","epoch 26; iter: 0; batch classifier loss: 13.069302; batch adversarial loss: 0.539432\n","epoch 27; iter: 0; batch classifier loss: 13.799417; batch adversarial loss: 0.550131\n","epoch 28; iter: 0; batch classifier loss: 12.591675; batch adversarial loss: 0.583697\n","epoch 29; iter: 0; batch classifier loss: 14.036019; batch adversarial loss: 0.595711\n","epoch 30; iter: 0; batch classifier loss: 10.316444; batch adversarial loss: 0.557945\n","epoch 31; iter: 0; batch classifier loss: 8.625029; batch adversarial loss: 0.535103\n","epoch 32; iter: 0; batch classifier loss: 6.607462; batch adversarial loss: 0.561989\n","epoch 33; iter: 0; batch classifier loss: 8.827982; batch adversarial loss: 0.597470\n","epoch 34; iter: 0; batch classifier loss: 6.534039; batch adversarial loss: 0.550550\n","epoch 35; iter: 0; batch classifier loss: 5.815136; batch adversarial loss: 0.502445\n","epoch 36; iter: 0; batch classifier loss: 8.505002; batch adversarial loss: 0.660701\n","epoch 37; iter: 0; batch classifier loss: 8.117055; batch adversarial loss: 0.480498\n","epoch 38; iter: 0; batch classifier loss: 6.199056; batch adversarial loss: 0.643877\n","epoch 39; iter: 0; batch classifier loss: 6.265574; batch adversarial loss: 0.527824\n","epoch 40; iter: 0; batch classifier loss: 4.433149; batch adversarial loss: 0.549693\n","epoch 41; iter: 0; batch classifier loss: 4.202985; batch adversarial loss: 0.572995\n","epoch 42; iter: 0; batch classifier loss: 5.228307; batch adversarial loss: 0.583740\n","epoch 43; iter: 0; batch classifier loss: 4.014332; batch adversarial loss: 0.576707\n","epoch 44; iter: 0; batch classifier loss: 2.802276; batch adversarial loss: 0.497590\n","epoch 45; iter: 0; batch classifier loss: 3.645106; batch adversarial loss: 0.584176\n","epoch 46; iter: 0; batch classifier loss: 2.687443; batch adversarial loss: 0.462808\n","epoch 47; iter: 0; batch classifier loss: 2.135528; batch adversarial loss: 0.536964\n","epoch 48; iter: 0; batch classifier loss: 3.775789; batch adversarial loss: 0.540800\n","epoch 49; iter: 0; batch classifier loss: 2.851249; batch adversarial loss: 0.553303\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.68\n","epoch 0; iter: 0; batch classifier loss: 108.747772; batch adversarial loss: 0.696927\n","epoch 1; iter: 0; batch classifier loss: 69.687340; batch adversarial loss: 0.709245\n","epoch 2; iter: 0; batch classifier loss: 39.107506; batch adversarial loss: 0.728506\n","epoch 3; iter: 0; batch classifier loss: 61.899193; batch adversarial loss: 0.766427\n","epoch 4; iter: 0; batch classifier loss: 46.747322; batch adversarial loss: 0.754212\n","epoch 5; iter: 0; batch classifier loss: 27.207441; batch adversarial loss: 0.731508\n","epoch 6; iter: 0; batch classifier loss: 46.547428; batch adversarial loss: 0.710892\n","epoch 7; iter: 0; batch classifier loss: 53.124229; batch adversarial loss: 0.716759\n","epoch 8; iter: 0; batch classifier loss: 38.323769; batch adversarial loss: 0.732572\n","epoch 9; iter: 0; batch classifier loss: 25.576370; batch adversarial loss: 0.720597\n","epoch 10; iter: 0; batch classifier loss: 51.241871; batch adversarial loss: 0.711691\n","epoch 11; iter: 0; batch classifier loss: 44.939568; batch adversarial loss: 0.720587\n","epoch 12; iter: 0; batch classifier loss: 34.233929; batch adversarial loss: 0.710869\n","epoch 13; iter: 0; batch classifier loss: 35.899376; batch adversarial loss: 0.717703\n","epoch 14; iter: 0; batch classifier loss: 27.812176; batch adversarial loss: 0.703508\n","epoch 15; iter: 0; batch classifier loss: 34.089195; batch adversarial loss: 0.680493\n","epoch 16; iter: 0; batch classifier loss: 26.840611; batch adversarial loss: 0.696110\n","epoch 17; iter: 0; batch classifier loss: 31.500553; batch adversarial loss: 0.690674\n","epoch 18; iter: 0; batch classifier loss: 34.824799; batch adversarial loss: 0.688803\n","epoch 19; iter: 0; batch classifier loss: 17.620043; batch adversarial loss: 0.673643\n","epoch 20; iter: 0; batch classifier loss: 25.385611; batch adversarial loss: 0.692382\n","epoch 21; iter: 0; batch classifier loss: 18.629795; batch adversarial loss: 0.672078\n","epoch 22; iter: 0; batch classifier loss: 25.024839; batch adversarial loss: 0.668989\n","epoch 23; iter: 0; batch classifier loss: 13.059622; batch adversarial loss: 0.658241\n","epoch 24; iter: 0; batch classifier loss: 15.495730; batch adversarial loss: 0.678096\n","epoch 25; iter: 0; batch classifier loss: 14.243742; batch adversarial loss: 0.667079\n","epoch 26; iter: 0; batch classifier loss: 12.075280; batch adversarial loss: 0.674353\n","epoch 27; iter: 0; batch classifier loss: 11.407014; batch adversarial loss: 0.660511\n","epoch 28; iter: 0; batch classifier loss: 12.049508; batch adversarial loss: 0.654425\n","epoch 29; iter: 0; batch classifier loss: 16.430847; batch adversarial loss: 0.656570\n","epoch 30; iter: 0; batch classifier loss: 11.635771; batch adversarial loss: 0.648856\n","epoch 31; iter: 0; batch classifier loss: 11.970928; batch adversarial loss: 0.653403\n","epoch 32; iter: 0; batch classifier loss: 13.681029; batch adversarial loss: 0.644451\n","epoch 33; iter: 0; batch classifier loss: 8.389081; batch adversarial loss: 0.637963\n","epoch 34; iter: 0; batch classifier loss: 9.385002; batch adversarial loss: 0.631291\n","epoch 35; iter: 0; batch classifier loss: 8.991872; batch adversarial loss: 0.642278\n","epoch 36; iter: 0; batch classifier loss: 7.533717; batch adversarial loss: 0.635359\n","epoch 37; iter: 0; batch classifier loss: 10.979841; batch adversarial loss: 0.631253\n","epoch 38; iter: 0; batch classifier loss: 6.252627; batch adversarial loss: 0.620701\n","epoch 39; iter: 0; batch classifier loss: 7.753504; batch adversarial loss: 0.623261\n","epoch 40; iter: 0; batch classifier loss: 9.180782; batch adversarial loss: 0.626821\n","epoch 41; iter: 0; batch classifier loss: 6.869807; batch adversarial loss: 0.611537\n","epoch 42; iter: 0; batch classifier loss: 9.504693; batch adversarial loss: 0.603693\n","epoch 43; iter: 0; batch classifier loss: 6.497971; batch adversarial loss: 0.604868\n","epoch 44; iter: 0; batch classifier loss: 6.763429; batch adversarial loss: 0.607584\n","epoch 45; iter: 0; batch classifier loss: 5.401827; batch adversarial loss: 0.616577\n","epoch 46; iter: 0; batch classifier loss: 3.531110; batch adversarial loss: 0.609290\n","epoch 47; iter: 0; batch classifier loss: 4.581002; batch adversarial loss: 0.600683\n","epoch 48; iter: 0; batch classifier loss: 2.883250; batch adversarial loss: 0.616599\n","epoch 49; iter: 0; batch classifier loss: 3.073116; batch adversarial loss: 0.628925\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.76\n","epoch 0; iter: 0; batch classifier loss: 108.430977; batch adversarial loss: 0.691682\n","epoch 1; iter: 0; batch classifier loss: 66.309814; batch adversarial loss: 0.688623\n","epoch 2; iter: 0; batch classifier loss: 43.873589; batch adversarial loss: 0.679082\n","epoch 3; iter: 0; batch classifier loss: 69.120216; batch adversarial loss: 0.663871\n","epoch 4; iter: 0; batch classifier loss: 58.209038; batch adversarial loss: 0.665353\n","epoch 5; iter: 0; batch classifier loss: 56.294815; batch adversarial loss: 0.665145\n","epoch 6; iter: 0; batch classifier loss: 57.692810; batch adversarial loss: 0.673173\n","epoch 7; iter: 0; batch classifier loss: 46.603687; batch adversarial loss: 0.664625\n","epoch 8; iter: 0; batch classifier loss: 57.772430; batch adversarial loss: 0.658776\n","epoch 9; iter: 0; batch classifier loss: 38.901421; batch adversarial loss: 0.647937\n","epoch 10; iter: 0; batch classifier loss: 41.572784; batch adversarial loss: 0.656809\n","epoch 11; iter: 0; batch classifier loss: 23.139236; batch adversarial loss: 0.648358\n","epoch 12; iter: 0; batch classifier loss: 34.384010; batch adversarial loss: 0.644376\n","epoch 13; iter: 0; batch classifier loss: 39.229858; batch adversarial loss: 0.648569\n","epoch 14; iter: 0; batch classifier loss: 41.470123; batch adversarial loss: 0.638065\n","epoch 15; iter: 0; batch classifier loss: 28.201748; batch adversarial loss: 0.639849\n","epoch 16; iter: 0; batch classifier loss: 31.041637; batch adversarial loss: 0.645123\n","epoch 17; iter: 0; batch classifier loss: 27.202961; batch adversarial loss: 0.637171\n","epoch 18; iter: 0; batch classifier loss: 35.409462; batch adversarial loss: 0.614480\n","epoch 19; iter: 0; batch classifier loss: 26.101887; batch adversarial loss: 0.622860\n","epoch 20; iter: 0; batch classifier loss: 21.984726; batch adversarial loss: 0.627316\n","epoch 21; iter: 0; batch classifier loss: 31.326595; batch adversarial loss: 0.626918\n","epoch 22; iter: 0; batch classifier loss: 19.732988; batch adversarial loss: 0.599136\n","epoch 23; iter: 0; batch classifier loss: 27.782516; batch adversarial loss: 0.608610\n","epoch 24; iter: 0; batch classifier loss: 25.535938; batch adversarial loss: 0.630615\n","epoch 25; iter: 0; batch classifier loss: 19.484297; batch adversarial loss: 0.611106\n","epoch 26; iter: 0; batch classifier loss: 26.556519; batch adversarial loss: 0.613061\n","epoch 27; iter: 0; batch classifier loss: 26.507406; batch adversarial loss: 0.605265\n","epoch 28; iter: 0; batch classifier loss: 16.431520; batch adversarial loss: 0.605985\n","epoch 29; iter: 0; batch classifier loss: 15.329815; batch adversarial loss: 0.620492\n","epoch 30; iter: 0; batch classifier loss: 15.575108; batch adversarial loss: 0.606224\n","epoch 31; iter: 0; batch classifier loss: 21.131451; batch adversarial loss: 0.595244\n","epoch 32; iter: 0; batch classifier loss: 21.878326; batch adversarial loss: 0.567123\n","epoch 33; iter: 0; batch classifier loss: 18.069420; batch adversarial loss: 0.591468\n","epoch 34; iter: 0; batch classifier loss: 15.914429; batch adversarial loss: 0.592944\n","epoch 35; iter: 0; batch classifier loss: 12.355932; batch adversarial loss: 0.583326\n","epoch 36; iter: 0; batch classifier loss: 13.560434; batch adversarial loss: 0.595170\n","epoch 37; iter: 0; batch classifier loss: 10.698414; batch adversarial loss: 0.591439\n","epoch 38; iter: 0; batch classifier loss: 14.099332; batch adversarial loss: 0.582952\n","epoch 39; iter: 0; batch classifier loss: 10.277930; batch adversarial loss: 0.586683\n","epoch 40; iter: 0; batch classifier loss: 14.970440; batch adversarial loss: 0.599469\n","epoch 41; iter: 0; batch classifier loss: 11.724016; batch adversarial loss: 0.563634\n","epoch 42; iter: 0; batch classifier loss: 12.529584; batch adversarial loss: 0.595981\n","epoch 43; iter: 0; batch classifier loss: 7.687887; batch adversarial loss: 0.566198\n","epoch 44; iter: 0; batch classifier loss: 10.421628; batch adversarial loss: 0.553850\n","epoch 45; iter: 0; batch classifier loss: 7.936929; batch adversarial loss: 0.552560\n","epoch 46; iter: 0; batch classifier loss: 5.716635; batch adversarial loss: 0.556331\n","epoch 47; iter: 0; batch classifier loss: 7.566221; batch adversarial loss: 0.548907\n","epoch 48; iter: 0; batch classifier loss: 5.347538; batch adversarial loss: 0.585826\n","epoch 49; iter: 0; batch classifier loss: 4.711260; batch adversarial loss: 0.569165\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.715\n","epoch 0; iter: 0; batch classifier loss: 144.874527; batch adversarial loss: 0.740954\n","epoch 1; iter: 0; batch classifier loss: 89.481445; batch adversarial loss: 0.760728\n","epoch 2; iter: 0; batch classifier loss: 29.821655; batch adversarial loss: 0.702852\n","epoch 3; iter: 0; batch classifier loss: 44.933548; batch adversarial loss: 0.685207\n","epoch 4; iter: 0; batch classifier loss: 57.438141; batch adversarial loss: 0.692963\n","epoch 5; iter: 0; batch classifier loss: 49.386940; batch adversarial loss: 0.705236\n","epoch 6; iter: 0; batch classifier loss: 38.292515; batch adversarial loss: 0.675552\n","epoch 7; iter: 0; batch classifier loss: 54.680145; batch adversarial loss: 0.666945\n","epoch 8; iter: 0; batch classifier loss: 23.541315; batch adversarial loss: 0.660427\n","epoch 9; iter: 0; batch classifier loss: 38.559750; batch adversarial loss: 0.670974\n","epoch 10; iter: 0; batch classifier loss: 30.785603; batch adversarial loss: 0.701248\n","epoch 11; iter: 0; batch classifier loss: 32.112587; batch adversarial loss: 0.656530\n","epoch 12; iter: 0; batch classifier loss: 50.028229; batch adversarial loss: 0.688406\n","epoch 13; iter: 0; batch classifier loss: 22.752514; batch adversarial loss: 0.698075\n","epoch 14; iter: 0; batch classifier loss: 30.415869; batch adversarial loss: 0.673344\n","epoch 15; iter: 0; batch classifier loss: 32.883129; batch adversarial loss: 0.669264\n","epoch 16; iter: 0; batch classifier loss: 40.839233; batch adversarial loss: 0.621235\n","epoch 17; iter: 0; batch classifier loss: 41.831039; batch adversarial loss: 0.658770\n","epoch 18; iter: 0; batch classifier loss: 30.777496; batch adversarial loss: 0.670385\n","epoch 19; iter: 0; batch classifier loss: 27.321762; batch adversarial loss: 0.675533\n","epoch 20; iter: 0; batch classifier loss: 24.117224; batch adversarial loss: 0.658225\n","epoch 21; iter: 0; batch classifier loss: 20.858135; batch adversarial loss: 0.653193\n","epoch 22; iter: 0; batch classifier loss: 27.470200; batch adversarial loss: 0.627489\n","epoch 23; iter: 0; batch classifier loss: 33.660870; batch adversarial loss: 0.640156\n","epoch 24; iter: 0; batch classifier loss: 23.007435; batch adversarial loss: 0.672735\n","epoch 25; iter: 0; batch classifier loss: 23.397194; batch adversarial loss: 0.687406\n","epoch 26; iter: 0; batch classifier loss: 24.024403; batch adversarial loss: 0.614952\n","epoch 27; iter: 0; batch classifier loss: 24.315847; batch adversarial loss: 0.642728\n","epoch 28; iter: 0; batch classifier loss: 15.146562; batch adversarial loss: 0.647686\n","epoch 29; iter: 0; batch classifier loss: 24.442095; batch adversarial loss: 0.617765\n","epoch 30; iter: 0; batch classifier loss: 20.294754; batch adversarial loss: 0.652104\n","epoch 31; iter: 0; batch classifier loss: 23.803783; batch adversarial loss: 0.600273\n","epoch 32; iter: 0; batch classifier loss: 21.275066; batch adversarial loss: 0.641353\n","epoch 33; iter: 0; batch classifier loss: 19.438393; batch adversarial loss: 0.602028\n","epoch 34; iter: 0; batch classifier loss: 18.553093; batch adversarial loss: 0.617993\n","epoch 35; iter: 0; batch classifier loss: 22.471066; batch adversarial loss: 0.621627\n","epoch 36; iter: 0; batch classifier loss: 14.650377; batch adversarial loss: 0.630669\n","epoch 37; iter: 0; batch classifier loss: 15.239774; batch adversarial loss: 0.562107\n","epoch 38; iter: 0; batch classifier loss: 10.738222; batch adversarial loss: 0.612566\n","epoch 39; iter: 0; batch classifier loss: 9.357233; batch adversarial loss: 0.654062\n","epoch 40; iter: 0; batch classifier loss: 13.479910; batch adversarial loss: 0.624953\n","epoch 41; iter: 0; batch classifier loss: 11.873882; batch adversarial loss: 0.614209\n","epoch 42; iter: 0; batch classifier loss: 12.315959; batch adversarial loss: 0.585157\n","epoch 43; iter: 0; batch classifier loss: 8.834592; batch adversarial loss: 0.627225\n","epoch 44; iter: 0; batch classifier loss: 8.064168; batch adversarial loss: 0.609346\n","epoch 45; iter: 0; batch classifier loss: 7.540745; batch adversarial loss: 0.595363\n","epoch 46; iter: 0; batch classifier loss: 11.011748; batch adversarial loss: 0.601828\n","epoch 47; iter: 0; batch classifier loss: 10.740698; batch adversarial loss: 0.589506\n","epoch 48; iter: 0; batch classifier loss: 9.812440; batch adversarial loss: 0.571411\n","epoch 49; iter: 0; batch classifier loss: 7.413597; batch adversarial loss: 0.615243\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.675\n","epoch 0; iter: 0; batch classifier loss: 240.851196; batch adversarial loss: 0.693147\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.715\n","epoch 0; iter: 0; batch classifier loss: 82.877281; batch adversarial loss: 0.854314\n","epoch 1; iter: 0; batch classifier loss: 70.072380; batch adversarial loss: 0.801536\n","epoch 2; iter: 0; batch classifier loss: 54.457775; batch adversarial loss: 0.744207\n","epoch 3; iter: 0; batch classifier loss: 48.858208; batch adversarial loss: 0.733353\n","epoch 4; iter: 0; batch classifier loss: 49.633373; batch adversarial loss: 0.779265\n","epoch 5; iter: 0; batch classifier loss: 52.906761; batch adversarial loss: 0.806479\n","epoch 6; iter: 0; batch classifier loss: 50.380558; batch adversarial loss: 0.758994\n","epoch 7; iter: 0; batch classifier loss: 51.720131; batch adversarial loss: 0.743608\n","epoch 8; iter: 0; batch classifier loss: 52.929127; batch adversarial loss: 0.748225\n","epoch 9; iter: 0; batch classifier loss: 52.734428; batch adversarial loss: 0.765027\n","epoch 10; iter: 0; batch classifier loss: 36.786339; batch adversarial loss: 0.756591\n","epoch 11; iter: 0; batch classifier loss: 35.332603; batch adversarial loss: 0.737778\n","epoch 12; iter: 0; batch classifier loss: 40.669746; batch adversarial loss: 0.724219\n","epoch 13; iter: 0; batch classifier loss: 39.752220; batch adversarial loss: 0.717974\n","epoch 14; iter: 0; batch classifier loss: 54.733513; batch adversarial loss: 0.719485\n","epoch 15; iter: 0; batch classifier loss: 23.651943; batch adversarial loss: 0.717871\n","epoch 16; iter: 0; batch classifier loss: 33.759056; batch adversarial loss: 0.738655\n","epoch 17; iter: 0; batch classifier loss: 35.101727; batch adversarial loss: 0.712543\n","epoch 18; iter: 0; batch classifier loss: 29.362167; batch adversarial loss: 0.705017\n","epoch 19; iter: 0; batch classifier loss: 25.476021; batch adversarial loss: 0.721026\n","epoch 20; iter: 0; batch classifier loss: 17.510607; batch adversarial loss: 0.695938\n","epoch 21; iter: 0; batch classifier loss: 28.423916; batch adversarial loss: 0.706652\n","epoch 22; iter: 0; batch classifier loss: 28.423325; batch adversarial loss: 0.715217\n","epoch 23; iter: 0; batch classifier loss: 20.157928; batch adversarial loss: 0.711470\n","epoch 24; iter: 0; batch classifier loss: 25.946587; batch adversarial loss: 0.669841\n","epoch 25; iter: 0; batch classifier loss: 21.032187; batch adversarial loss: 0.707777\n","epoch 26; iter: 0; batch classifier loss: 19.069588; batch adversarial loss: 0.708933\n","epoch 27; iter: 0; batch classifier loss: 25.218964; batch adversarial loss: 0.669767\n","epoch 28; iter: 0; batch classifier loss: 16.437664; batch adversarial loss: 0.671097\n","epoch 29; iter: 0; batch classifier loss: 17.672510; batch adversarial loss: 0.657248\n","epoch 30; iter: 0; batch classifier loss: 12.032755; batch adversarial loss: 0.668597\n","epoch 31; iter: 0; batch classifier loss: 16.962574; batch adversarial loss: 0.670770\n","epoch 32; iter: 0; batch classifier loss: 28.615177; batch adversarial loss: 0.669773\n","epoch 33; iter: 0; batch classifier loss: 19.144403; batch adversarial loss: 0.646919\n","epoch 34; iter: 0; batch classifier loss: 17.415773; batch adversarial loss: 0.675133\n","epoch 35; iter: 0; batch classifier loss: 10.937152; batch adversarial loss: 0.655261\n","epoch 36; iter: 0; batch classifier loss: 12.863348; batch adversarial loss: 0.637541\n","epoch 37; iter: 0; batch classifier loss: 10.524612; batch adversarial loss: 0.654541\n","epoch 38; iter: 0; batch classifier loss: 9.235046; batch adversarial loss: 0.644852\n","epoch 39; iter: 0; batch classifier loss: 8.602926; batch adversarial loss: 0.646400\n","epoch 40; iter: 0; batch classifier loss: 7.552694; batch adversarial loss: 0.640405\n","epoch 41; iter: 0; batch classifier loss: 6.822054; batch adversarial loss: 0.634497\n","epoch 42; iter: 0; batch classifier loss: 7.034853; batch adversarial loss: 0.628792\n","epoch 43; iter: 0; batch classifier loss: 7.405224; batch adversarial loss: 0.624274\n","epoch 44; iter: 0; batch classifier loss: 5.657763; batch adversarial loss: 0.624233\n","epoch 45; iter: 0; batch classifier loss: 7.753927; batch adversarial loss: 0.636279\n","epoch 46; iter: 0; batch classifier loss: 5.406754; batch adversarial loss: 0.626910\n","epoch 47; iter: 0; batch classifier loss: 5.641239; batch adversarial loss: 0.619972\n","epoch 48; iter: 0; batch classifier loss: 6.453032; batch adversarial loss: 0.609640\n","epoch 49; iter: 0; batch classifier loss: 5.941066; batch adversarial loss: 0.640166\n","Accuracy 0.445\n","epoch 0; iter: 0; batch classifier loss: 128.409943; batch adversarial loss: 1.135161\n","epoch 1; iter: 0; batch classifier loss: 126.603333; batch adversarial loss: 1.084985\n","epoch 2; iter: 0; batch classifier loss: 53.180000; batch adversarial loss: 0.961209\n","epoch 3; iter: 0; batch classifier loss: 51.016876; batch adversarial loss: 0.820524\n","epoch 4; iter: 0; batch classifier loss: 42.342361; batch adversarial loss: 0.800377\n","epoch 5; iter: 0; batch classifier loss: 49.903851; batch adversarial loss: 0.790806\n","epoch 6; iter: 0; batch classifier loss: 29.406265; batch adversarial loss: 0.805350\n","epoch 7; iter: 0; batch classifier loss: 38.971535; batch adversarial loss: 0.792308\n","epoch 8; iter: 0; batch classifier loss: 32.439930; batch adversarial loss: 0.848007\n","epoch 9; iter: 0; batch classifier loss: 58.088066; batch adversarial loss: 0.808412\n","epoch 10; iter: 0; batch classifier loss: 41.284424; batch adversarial loss: 0.820966\n","epoch 11; iter: 0; batch classifier loss: 37.973007; batch adversarial loss: 0.833837\n","epoch 12; iter: 0; batch classifier loss: 29.271709; batch adversarial loss: 0.796314\n","epoch 13; iter: 0; batch classifier loss: 38.898834; batch adversarial loss: 0.798908\n","epoch 14; iter: 0; batch classifier loss: 25.344307; batch adversarial loss: 0.762955\n","epoch 15; iter: 0; batch classifier loss: 22.510883; batch adversarial loss: 0.794416\n","epoch 16; iter: 0; batch classifier loss: 36.276802; batch adversarial loss: 0.729169\n","epoch 17; iter: 0; batch classifier loss: 33.291191; batch adversarial loss: 0.770238\n","epoch 18; iter: 0; batch classifier loss: 32.087536; batch adversarial loss: 0.766194\n","epoch 19; iter: 0; batch classifier loss: 31.891529; batch adversarial loss: 0.816775\n","epoch 20; iter: 0; batch classifier loss: 15.104513; batch adversarial loss: 0.794633\n","epoch 21; iter: 0; batch classifier loss: 25.347000; batch adversarial loss: 0.819918\n","epoch 22; iter: 0; batch classifier loss: 39.396542; batch adversarial loss: 0.798307\n","epoch 23; iter: 0; batch classifier loss: 27.458820; batch adversarial loss: 0.734225\n","epoch 24; iter: 0; batch classifier loss: 26.536774; batch adversarial loss: 0.734944\n","epoch 25; iter: 0; batch classifier loss: 20.832706; batch adversarial loss: 0.703336\n","epoch 26; iter: 0; batch classifier loss: 22.730768; batch adversarial loss: 0.707847\n","epoch 27; iter: 0; batch classifier loss: 17.898317; batch adversarial loss: 0.796209\n","epoch 28; iter: 0; batch classifier loss: 19.537035; batch adversarial loss: 0.785366\n","epoch 29; iter: 0; batch classifier loss: 20.098528; batch adversarial loss: 0.766964\n","epoch 30; iter: 0; batch classifier loss: 27.738285; batch adversarial loss: 0.688054\n","epoch 31; iter: 0; batch classifier loss: 13.706490; batch adversarial loss: 0.708982\n","epoch 32; iter: 0; batch classifier loss: 18.489780; batch adversarial loss: 0.752042\n","epoch 33; iter: 0; batch classifier loss: 21.402220; batch adversarial loss: 0.788294\n","epoch 34; iter: 0; batch classifier loss: 17.424992; batch adversarial loss: 0.707265\n","epoch 35; iter: 0; batch classifier loss: 16.971266; batch adversarial loss: 0.662955\n","epoch 36; iter: 0; batch classifier loss: 11.242581; batch adversarial loss: 0.709175\n","epoch 37; iter: 0; batch classifier loss: 13.385665; batch adversarial loss: 0.730177\n","epoch 38; iter: 0; batch classifier loss: 9.068203; batch adversarial loss: 0.730463\n","epoch 39; iter: 0; batch classifier loss: 10.060051; batch adversarial loss: 0.727383\n","epoch 40; iter: 0; batch classifier loss: 9.041866; batch adversarial loss: 0.668615\n","epoch 41; iter: 0; batch classifier loss: 8.877787; batch adversarial loss: 0.696554\n","epoch 42; iter: 0; batch classifier loss: 8.964476; batch adversarial loss: 0.705744\n","epoch 43; iter: 0; batch classifier loss: 9.025948; batch adversarial loss: 0.679758\n","epoch 44; iter: 0; batch classifier loss: 9.431437; batch adversarial loss: 0.714257\n","epoch 45; iter: 0; batch classifier loss: 6.852868; batch adversarial loss: 0.682855\n","epoch 46; iter: 0; batch classifier loss: 5.498736; batch adversarial loss: 0.672167\n","epoch 47; iter: 0; batch classifier loss: 7.579103; batch adversarial loss: 0.663920\n","epoch 48; iter: 0; batch classifier loss: 7.579703; batch adversarial loss: 0.681024\n","epoch 49; iter: 0; batch classifier loss: 6.225484; batch adversarial loss: 0.677198\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.695\n","epoch 0; iter: 0; batch classifier loss: 104.719788; batch adversarial loss: 0.419015\n","epoch 1; iter: 0; batch classifier loss: 113.849312; batch adversarial loss: 0.410564\n","epoch 2; iter: 0; batch classifier loss: 49.800438; batch adversarial loss: 0.576939\n","epoch 3; iter: 0; batch classifier loss: 62.358139; batch adversarial loss: 0.623038\n","epoch 4; iter: 0; batch classifier loss: 36.295998; batch adversarial loss: 0.619812\n","epoch 5; iter: 0; batch classifier loss: 41.722824; batch adversarial loss: 0.629354\n","epoch 6; iter: 0; batch classifier loss: 33.533516; batch adversarial loss: 0.615065\n","epoch 7; iter: 0; batch classifier loss: 45.529495; batch adversarial loss: 0.578259\n","epoch 8; iter: 0; batch classifier loss: 36.802967; batch adversarial loss: 0.581468\n","epoch 9; iter: 0; batch classifier loss: 26.031931; batch adversarial loss: 0.538279\n","epoch 10; iter: 0; batch classifier loss: 36.155006; batch adversarial loss: 0.671856\n","epoch 11; iter: 0; batch classifier loss: 38.178909; batch adversarial loss: 0.599460\n","epoch 12; iter: 0; batch classifier loss: 39.172264; batch adversarial loss: 0.580927\n","epoch 13; iter: 0; batch classifier loss: 26.037125; batch adversarial loss: 0.573448\n","epoch 14; iter: 0; batch classifier loss: 38.057144; batch adversarial loss: 0.559179\n","epoch 15; iter: 0; batch classifier loss: 30.382816; batch adversarial loss: 0.571638\n","epoch 16; iter: 0; batch classifier loss: 49.670334; batch adversarial loss: 0.504719\n","epoch 17; iter: 0; batch classifier loss: 34.837791; batch adversarial loss: 0.534463\n","epoch 18; iter: 0; batch classifier loss: 30.126333; batch adversarial loss: 0.579093\n","epoch 19; iter: 0; batch classifier loss: 32.982689; batch adversarial loss: 0.597463\n","epoch 20; iter: 0; batch classifier loss: 29.555920; batch adversarial loss: 0.577120\n","epoch 21; iter: 0; batch classifier loss: 39.004684; batch adversarial loss: 0.585769\n","epoch 22; iter: 0; batch classifier loss: 29.331257; batch adversarial loss: 0.573614\n","epoch 23; iter: 0; batch classifier loss: 19.750626; batch adversarial loss: 0.595987\n","epoch 24; iter: 0; batch classifier loss: 36.525192; batch adversarial loss: 0.600007\n","epoch 25; iter: 0; batch classifier loss: 35.270065; batch adversarial loss: 0.573857\n","epoch 26; iter: 0; batch classifier loss: 20.900187; batch adversarial loss: 0.580392\n","epoch 27; iter: 0; batch classifier loss: 20.509352; batch adversarial loss: 0.615862\n","epoch 28; iter: 0; batch classifier loss: 18.564295; batch adversarial loss: 0.602988\n","epoch 29; iter: 0; batch classifier loss: 17.791317; batch adversarial loss: 0.641410\n","epoch 30; iter: 0; batch classifier loss: 24.690838; batch adversarial loss: 0.596835\n","epoch 31; iter: 0; batch classifier loss: 19.826183; batch adversarial loss: 0.536367\n","epoch 32; iter: 0; batch classifier loss: 10.981341; batch adversarial loss: 0.621734\n","epoch 33; iter: 0; batch classifier loss: 11.992965; batch adversarial loss: 0.577806\n","epoch 34; iter: 0; batch classifier loss: 15.291388; batch adversarial loss: 0.568928\n","epoch 35; iter: 0; batch classifier loss: 16.937878; batch adversarial loss: 0.509810\n","epoch 36; iter: 0; batch classifier loss: 13.786228; batch adversarial loss: 0.547780\n","epoch 37; iter: 0; batch classifier loss: 15.824409; batch adversarial loss: 0.518322\n","epoch 38; iter: 0; batch classifier loss: 10.191321; batch adversarial loss: 0.557857\n","epoch 39; iter: 0; batch classifier loss: 6.840837; batch adversarial loss: 0.556077\n","epoch 40; iter: 0; batch classifier loss: 8.138897; batch adversarial loss: 0.572563\n","epoch 41; iter: 0; batch classifier loss: 11.036066; batch adversarial loss: 0.559052\n","epoch 42; iter: 0; batch classifier loss: 9.813947; batch adversarial loss: 0.558152\n","epoch 43; iter: 0; batch classifier loss: 9.824523; batch adversarial loss: 0.581672\n","epoch 44; iter: 0; batch classifier loss: 11.658964; batch adversarial loss: 0.459879\n","epoch 45; iter: 0; batch classifier loss: 12.066681; batch adversarial loss: 0.560064\n","epoch 46; iter: 0; batch classifier loss: 12.791741; batch adversarial loss: 0.630645\n","epoch 47; iter: 0; batch classifier loss: 9.606537; batch adversarial loss: 0.546330\n","epoch 48; iter: 0; batch classifier loss: 10.398576; batch adversarial loss: 0.561882\n","epoch 49; iter: 0; batch classifier loss: 7.392600; batch adversarial loss: 0.529186\n","Accuracy 0.54\n","epoch 0; iter: 0; batch classifier loss: 97.813721; batch adversarial loss: 0.462016\n","epoch 1; iter: 0; batch classifier loss: 89.181007; batch adversarial loss: 0.440416\n","epoch 2; iter: 0; batch classifier loss: 35.881901; batch adversarial loss: 0.582632\n","epoch 3; iter: 0; batch classifier loss: 56.953892; batch adversarial loss: 0.617367\n","epoch 4; iter: 0; batch classifier loss: 61.896461; batch adversarial loss: 0.634802\n","epoch 5; iter: 0; batch classifier loss: 50.051865; batch adversarial loss: 0.666671\n","epoch 6; iter: 0; batch classifier loss: 38.751507; batch adversarial loss: 0.625580\n","epoch 7; iter: 0; batch classifier loss: 30.240097; batch adversarial loss: 0.616483\n","epoch 8; iter: 0; batch classifier loss: 42.105507; batch adversarial loss: 0.528610\n","epoch 9; iter: 0; batch classifier loss: 36.281677; batch adversarial loss: 0.591658\n","epoch 10; iter: 0; batch classifier loss: 26.120531; batch adversarial loss: 0.569087\n","epoch 11; iter: 0; batch classifier loss: 47.139565; batch adversarial loss: 0.530651\n","epoch 12; iter: 0; batch classifier loss: 22.501415; batch adversarial loss: 0.548731\n","epoch 13; iter: 0; batch classifier loss: 30.588427; batch adversarial loss: 0.578346\n","epoch 14; iter: 0; batch classifier loss: 32.406582; batch adversarial loss: 0.628112\n","epoch 15; iter: 0; batch classifier loss: 33.303089; batch adversarial loss: 0.504505\n","epoch 16; iter: 0; batch classifier loss: 21.782850; batch adversarial loss: 0.565799\n","epoch 17; iter: 0; batch classifier loss: 36.482979; batch adversarial loss: 0.530681\n","epoch 18; iter: 0; batch classifier loss: 21.333969; batch adversarial loss: 0.594523\n","epoch 19; iter: 0; batch classifier loss: 35.800491; batch adversarial loss: 0.539825\n","epoch 20; iter: 0; batch classifier loss: 25.724327; batch adversarial loss: 0.557028\n","epoch 21; iter: 0; batch classifier loss: 32.016193; batch adversarial loss: 0.583806\n","epoch 22; iter: 0; batch classifier loss: 18.656921; batch adversarial loss: 0.582913\n","epoch 23; iter: 0; batch classifier loss: 27.793972; batch adversarial loss: 0.512665\n","epoch 24; iter: 0; batch classifier loss: 15.476595; batch adversarial loss: 0.568468\n","epoch 25; iter: 0; batch classifier loss: 26.677994; batch adversarial loss: 0.570183\n","epoch 26; iter: 0; batch classifier loss: 25.694118; batch adversarial loss: 0.506440\n","epoch 27; iter: 0; batch classifier loss: 27.507992; batch adversarial loss: 0.604292\n","epoch 28; iter: 0; batch classifier loss: 25.278740; batch adversarial loss: 0.562634\n","epoch 29; iter: 0; batch classifier loss: 16.178062; batch adversarial loss: 0.530637\n","epoch 30; iter: 0; batch classifier loss: 24.620392; batch adversarial loss: 0.584205\n","epoch 31; iter: 0; batch classifier loss: 14.523776; batch adversarial loss: 0.620823\n","epoch 32; iter: 0; batch classifier loss: 16.180426; batch adversarial loss: 0.467595\n","epoch 33; iter: 0; batch classifier loss: 21.758207; batch adversarial loss: 0.536915\n","epoch 34; iter: 0; batch classifier loss: 18.234360; batch adversarial loss: 0.606508\n","epoch 35; iter: 0; batch classifier loss: 14.340951; batch adversarial loss: 0.593775\n","epoch 36; iter: 0; batch classifier loss: 19.054808; batch adversarial loss: 0.465415\n","epoch 37; iter: 0; batch classifier loss: 14.463125; batch adversarial loss: 0.605797\n","epoch 38; iter: 0; batch classifier loss: 14.300425; batch adversarial loss: 0.517723\n","epoch 39; iter: 0; batch classifier loss: 11.193426; batch adversarial loss: 0.573851\n","epoch 40; iter: 0; batch classifier loss: 13.279797; batch adversarial loss: 0.544331\n","epoch 41; iter: 0; batch classifier loss: 10.749436; batch adversarial loss: 0.556280\n","epoch 42; iter: 0; batch classifier loss: 8.454045; batch adversarial loss: 0.573005\n","epoch 43; iter: 0; batch classifier loss: 11.184210; batch adversarial loss: 0.636764\n","epoch 44; iter: 0; batch classifier loss: 4.849586; batch adversarial loss: 0.529092\n","epoch 45; iter: 0; batch classifier loss: 9.022362; batch adversarial loss: 0.478896\n","epoch 46; iter: 0; batch classifier loss: 7.758525; batch adversarial loss: 0.571935\n","epoch 47; iter: 0; batch classifier loss: 7.277491; batch adversarial loss: 0.566941\n","epoch 48; iter: 0; batch classifier loss: 8.894936; batch adversarial loss: 0.528389\n","epoch 49; iter: 0; batch classifier loss: 7.588106; batch adversarial loss: 0.567310\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.645\n","epoch 0; iter: 0; batch classifier loss: 150.231598; batch adversarial loss: 0.698632\n","epoch 1; iter: 0; batch classifier loss: 70.691650; batch adversarial loss: 0.724636\n","epoch 2; iter: 0; batch classifier loss: 55.502285; batch adversarial loss: 0.768489\n","epoch 3; iter: 0; batch classifier loss: 55.101734; batch adversarial loss: 0.837838\n","epoch 4; iter: 0; batch classifier loss: 38.389580; batch adversarial loss: 0.779305\n","epoch 5; iter: 0; batch classifier loss: 38.328285; batch adversarial loss: 0.752972\n","epoch 6; iter: 0; batch classifier loss: 50.224403; batch adversarial loss: 0.727733\n","epoch 7; iter: 0; batch classifier loss: 48.577507; batch adversarial loss: 0.720966\n","epoch 8; iter: 0; batch classifier loss: 53.615536; batch adversarial loss: 0.729858\n","epoch 9; iter: 0; batch classifier loss: 50.170444; batch adversarial loss: 0.732756\n","epoch 10; iter: 0; batch classifier loss: 34.255219; batch adversarial loss: 0.754923\n","epoch 11; iter: 0; batch classifier loss: 32.643909; batch adversarial loss: 0.742400\n","epoch 12; iter: 0; batch classifier loss: 48.797310; batch adversarial loss: 0.696755\n","epoch 13; iter: 0; batch classifier loss: 36.836433; batch adversarial loss: 0.713860\n","epoch 14; iter: 0; batch classifier loss: 40.525158; batch adversarial loss: 0.719708\n","epoch 15; iter: 0; batch classifier loss: 31.085741; batch adversarial loss: 0.709565\n","epoch 16; iter: 0; batch classifier loss: 23.398403; batch adversarial loss: 0.709103\n","epoch 17; iter: 0; batch classifier loss: 43.132515; batch adversarial loss: 0.709087\n","epoch 18; iter: 0; batch classifier loss: 21.118380; batch adversarial loss: 0.725830\n","epoch 19; iter: 0; batch classifier loss: 24.510408; batch adversarial loss: 0.670341\n","epoch 20; iter: 0; batch classifier loss: 24.574545; batch adversarial loss: 0.680392\n","epoch 21; iter: 0; batch classifier loss: 26.248093; batch adversarial loss: 0.712260\n","epoch 22; iter: 0; batch classifier loss: 16.622129; batch adversarial loss: 0.688620\n","epoch 23; iter: 0; batch classifier loss: 23.605915; batch adversarial loss: 0.676480\n","epoch 24; iter: 0; batch classifier loss: 26.936790; batch adversarial loss: 0.702521\n","epoch 25; iter: 0; batch classifier loss: 22.171082; batch adversarial loss: 0.684185\n","epoch 26; iter: 0; batch classifier loss: 26.015570; batch adversarial loss: 0.667534\n","epoch 27; iter: 0; batch classifier loss: 20.768723; batch adversarial loss: 0.663218\n","epoch 28; iter: 0; batch classifier loss: 20.078182; batch adversarial loss: 0.675696\n","epoch 29; iter: 0; batch classifier loss: 22.380859; batch adversarial loss: 0.649069\n","epoch 30; iter: 0; batch classifier loss: 15.992215; batch adversarial loss: 0.664213\n","epoch 31; iter: 0; batch classifier loss: 19.875549; batch adversarial loss: 0.659786\n","epoch 32; iter: 0; batch classifier loss: 15.970074; batch adversarial loss: 0.660186\n","epoch 33; iter: 0; batch classifier loss: 13.131918; batch adversarial loss: 0.656381\n","epoch 34; iter: 0; batch classifier loss: 16.211103; batch adversarial loss: 0.637783\n","epoch 35; iter: 0; batch classifier loss: 17.119694; batch adversarial loss: 0.631980\n","epoch 36; iter: 0; batch classifier loss: 13.174653; batch adversarial loss: 0.640041\n","epoch 37; iter: 0; batch classifier loss: 10.872106; batch adversarial loss: 0.641524\n","epoch 38; iter: 0; batch classifier loss: 9.720659; batch adversarial loss: 0.633564\n","epoch 39; iter: 0; batch classifier loss: 11.852846; batch adversarial loss: 0.632725\n","epoch 40; iter: 0; batch classifier loss: 7.543620; batch adversarial loss: 0.642501\n","epoch 41; iter: 0; batch classifier loss: 10.202805; batch adversarial loss: 0.635594\n","epoch 42; iter: 0; batch classifier loss: 10.375339; batch adversarial loss: 0.606546\n","epoch 43; iter: 0; batch classifier loss: 9.346899; batch adversarial loss: 0.613135\n","epoch 44; iter: 0; batch classifier loss: 6.251407; batch adversarial loss: 0.611879\n","epoch 45; iter: 0; batch classifier loss: 10.211844; batch adversarial loss: 0.616719\n","epoch 46; iter: 0; batch classifier loss: 6.235696; batch adversarial loss: 0.621656\n","epoch 47; iter: 0; batch classifier loss: 6.604786; batch adversarial loss: 0.612356\n","epoch 48; iter: 0; batch classifier loss: 6.150537; batch adversarial loss: 0.615108\n","epoch 49; iter: 0; batch classifier loss: 5.592623; batch adversarial loss: 0.625159\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.725\n","epoch 0; iter: 0; batch classifier loss: 97.767593; batch adversarial loss: 0.780837\n","epoch 1; iter: 0; batch classifier loss: 62.249252; batch adversarial loss: 0.719728\n","epoch 2; iter: 0; batch classifier loss: 58.343681; batch adversarial loss: 0.693675\n","epoch 3; iter: 0; batch classifier loss: 50.989830; batch adversarial loss: 0.706814\n","epoch 4; iter: 0; batch classifier loss: 49.361256; batch adversarial loss: 0.708961\n","epoch 5; iter: 0; batch classifier loss: 76.671783; batch adversarial loss: 0.712666\n","epoch 6; iter: 0; batch classifier loss: 57.558315; batch adversarial loss: 0.719965\n","epoch 7; iter: 0; batch classifier loss: 37.380630; batch adversarial loss: 0.718700\n","epoch 8; iter: 0; batch classifier loss: 62.785397; batch adversarial loss: 0.693240\n","epoch 9; iter: 0; batch classifier loss: 40.397610; batch adversarial loss: 0.690626\n","epoch 10; iter: 0; batch classifier loss: 33.141449; batch adversarial loss: 0.685752\n","epoch 11; iter: 0; batch classifier loss: 37.338249; batch adversarial loss: 0.674269\n","epoch 12; iter: 0; batch classifier loss: 42.607193; batch adversarial loss: 0.693739\n","epoch 13; iter: 0; batch classifier loss: 28.180899; batch adversarial loss: 0.669975\n","epoch 14; iter: 0; batch classifier loss: 32.425362; batch adversarial loss: 0.692151\n","epoch 15; iter: 0; batch classifier loss: 37.427883; batch adversarial loss: 0.695450\n","epoch 16; iter: 0; batch classifier loss: 47.054790; batch adversarial loss: 0.696871\n","epoch 17; iter: 0; batch classifier loss: 43.086826; batch adversarial loss: 0.663429\n","epoch 18; iter: 0; batch classifier loss: 22.233133; batch adversarial loss: 0.651938\n","epoch 19; iter: 0; batch classifier loss: 38.924255; batch adversarial loss: 0.654440\n","epoch 20; iter: 0; batch classifier loss: 39.343445; batch adversarial loss: 0.651140\n","epoch 21; iter: 0; batch classifier loss: 27.274597; batch adversarial loss: 0.661477\n","epoch 22; iter: 0; batch classifier loss: 29.754253; batch adversarial loss: 0.668541\n","epoch 23; iter: 0; batch classifier loss: 18.409193; batch adversarial loss: 0.646641\n","epoch 24; iter: 0; batch classifier loss: 24.557570; batch adversarial loss: 0.654659\n","epoch 25; iter: 0; batch classifier loss: 18.606285; batch adversarial loss: 0.644531\n","epoch 26; iter: 0; batch classifier loss: 14.437863; batch adversarial loss: 0.645800\n","epoch 27; iter: 0; batch classifier loss: 19.544571; batch adversarial loss: 0.640180\n","epoch 28; iter: 0; batch classifier loss: 19.299374; batch adversarial loss: 0.651498\n","epoch 29; iter: 0; batch classifier loss: 14.845749; batch adversarial loss: 0.627034\n","epoch 30; iter: 0; batch classifier loss: 16.360041; batch adversarial loss: 0.641106\n","epoch 31; iter: 0; batch classifier loss: 15.319278; batch adversarial loss: 0.621967\n","epoch 32; iter: 0; batch classifier loss: 11.539897; batch adversarial loss: 0.630187\n","epoch 33; iter: 0; batch classifier loss: 10.737141; batch adversarial loss: 0.619518\n","epoch 34; iter: 0; batch classifier loss: 8.370695; batch adversarial loss: 0.634842\n","epoch 35; iter: 0; batch classifier loss: 14.055025; batch adversarial loss: 0.615658\n","epoch 36; iter: 0; batch classifier loss: 9.166133; batch adversarial loss: 0.616597\n","epoch 37; iter: 0; batch classifier loss: 16.147312; batch adversarial loss: 0.620777\n","epoch 38; iter: 0; batch classifier loss: 10.198420; batch adversarial loss: 0.611810\n","epoch 39; iter: 0; batch classifier loss: 9.991509; batch adversarial loss: 0.617435\n","epoch 40; iter: 0; batch classifier loss: 8.708090; batch adversarial loss: 0.610993\n","epoch 41; iter: 0; batch classifier loss: 9.669089; batch adversarial loss: 0.618909\n","epoch 42; iter: 0; batch classifier loss: 9.088297; batch adversarial loss: 0.605295\n","epoch 43; iter: 0; batch classifier loss: 8.336666; batch adversarial loss: 0.577817\n","epoch 44; iter: 0; batch classifier loss: 7.625595; batch adversarial loss: 0.590429\n","epoch 45; iter: 0; batch classifier loss: 11.462835; batch adversarial loss: 0.614824\n","epoch 46; iter: 0; batch classifier loss: 6.093282; batch adversarial loss: 0.612446\n","epoch 47; iter: 0; batch classifier loss: 7.898067; batch adversarial loss: 0.563243\n","epoch 48; iter: 0; batch classifier loss: 7.596194; batch adversarial loss: 0.586178\n","epoch 49; iter: 0; batch classifier loss: 6.572180; batch adversarial loss: 0.577142\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.685\n","epoch 0; iter: 0; batch classifier loss: 60.521187; batch adversarial loss: 0.595190\n","epoch 1; iter: 0; batch classifier loss: 45.154495; batch adversarial loss: 0.609215\n","epoch 2; iter: 0; batch classifier loss: 49.083691; batch adversarial loss: 0.627867\n","epoch 3; iter: 0; batch classifier loss: 36.062653; batch adversarial loss: 0.637491\n","epoch 4; iter: 0; batch classifier loss: 39.390160; batch adversarial loss: 0.596728\n","epoch 5; iter: 0; batch classifier loss: 33.056786; batch adversarial loss: 0.589241\n","epoch 6; iter: 0; batch classifier loss: 59.300831; batch adversarial loss: 0.623348\n","epoch 7; iter: 0; batch classifier loss: 33.485954; batch adversarial loss: 0.634468\n","epoch 8; iter: 0; batch classifier loss: 49.552704; batch adversarial loss: 0.615934\n","epoch 9; iter: 0; batch classifier loss: 34.950157; batch adversarial loss: 0.625413\n","epoch 10; iter: 0; batch classifier loss: 39.488594; batch adversarial loss: 0.590450\n","epoch 11; iter: 0; batch classifier loss: 29.863323; batch adversarial loss: 0.583631\n","epoch 12; iter: 0; batch classifier loss: 34.788403; batch adversarial loss: 0.606144\n","epoch 13; iter: 0; batch classifier loss: 27.009205; batch adversarial loss: 0.613980\n","epoch 14; iter: 0; batch classifier loss: 27.819845; batch adversarial loss: 0.603595\n","epoch 15; iter: 0; batch classifier loss: 28.778112; batch adversarial loss: 0.589112\n","epoch 16; iter: 0; batch classifier loss: 25.027864; batch adversarial loss: 0.571178\n","epoch 17; iter: 0; batch classifier loss: 18.246805; batch adversarial loss: 0.571993\n","epoch 18; iter: 0; batch classifier loss: 20.304739; batch adversarial loss: 0.554410\n","epoch 19; iter: 0; batch classifier loss: 27.387974; batch adversarial loss: 0.580422\n","epoch 20; iter: 0; batch classifier loss: 14.875013; batch adversarial loss: 0.565853\n","epoch 21; iter: 0; batch classifier loss: 17.146900; batch adversarial loss: 0.574238\n","epoch 22; iter: 0; batch classifier loss: 12.376536; batch adversarial loss: 0.576054\n","epoch 23; iter: 0; batch classifier loss: 15.887207; batch adversarial loss: 0.561861\n","epoch 24; iter: 0; batch classifier loss: 19.683830; batch adversarial loss: 0.601201\n","epoch 25; iter: 0; batch classifier loss: 19.043625; batch adversarial loss: 0.548871\n","epoch 26; iter: 0; batch classifier loss: 13.667977; batch adversarial loss: 0.502599\n","epoch 27; iter: 0; batch classifier loss: 11.435137; batch adversarial loss: 0.626952\n","epoch 28; iter: 0; batch classifier loss: 9.279287; batch adversarial loss: 0.631719\n","epoch 29; iter: 0; batch classifier loss: 8.032226; batch adversarial loss: 0.558777\n","epoch 30; iter: 0; batch classifier loss: 7.164995; batch adversarial loss: 0.563200\n","epoch 31; iter: 0; batch classifier loss: 11.700017; batch adversarial loss: 0.627735\n","epoch 32; iter: 0; batch classifier loss: 6.373670; batch adversarial loss: 0.636537\n","epoch 33; iter: 0; batch classifier loss: 8.857460; batch adversarial loss: 0.571907\n","epoch 34; iter: 0; batch classifier loss: 8.125025; batch adversarial loss: 0.602242\n","epoch 35; iter: 0; batch classifier loss: 7.706061; batch adversarial loss: 0.465739\n","epoch 36; iter: 0; batch classifier loss: 7.728709; batch adversarial loss: 0.476402\n","epoch 37; iter: 0; batch classifier loss: 4.403633; batch adversarial loss: 0.597604\n","epoch 38; iter: 0; batch classifier loss: 5.471889; batch adversarial loss: 0.595331\n","epoch 39; iter: 0; batch classifier loss: 5.178502; batch adversarial loss: 0.556412\n","epoch 40; iter: 0; batch classifier loss: 4.251149; batch adversarial loss: 0.566417\n","epoch 41; iter: 0; batch classifier loss: 4.890347; batch adversarial loss: 0.606430\n","epoch 42; iter: 0; batch classifier loss: 3.122273; batch adversarial loss: 0.567233\n","epoch 43; iter: 0; batch classifier loss: 3.837423; batch adversarial loss: 0.598190\n","epoch 44; iter: 0; batch classifier loss: 2.426616; batch adversarial loss: 0.600313\n","epoch 45; iter: 0; batch classifier loss: 2.839484; batch adversarial loss: 0.551021\n","epoch 46; iter: 0; batch classifier loss: 2.299981; batch adversarial loss: 0.574712\n","epoch 47; iter: 0; batch classifier loss: 2.390059; batch adversarial loss: 0.571560\n","epoch 48; iter: 0; batch classifier loss: 1.885373; batch adversarial loss: 0.586676\n","epoch 49; iter: 0; batch classifier loss: 2.573778; batch adversarial loss: 0.565537\n","Accuracy 0.455\n","epoch 0; iter: 0; batch classifier loss: 99.228897; batch adversarial loss: 0.693148\n","epoch 1; iter: 0; batch classifier loss: 59.228523; batch adversarial loss: 0.699855\n","epoch 2; iter: 0; batch classifier loss: 47.182220; batch adversarial loss: 0.733396\n","epoch 3; iter: 0; batch classifier loss: 50.193939; batch adversarial loss: 0.742243\n","epoch 4; iter: 0; batch classifier loss: 65.249405; batch adversarial loss: 0.734852\n","epoch 5; iter: 0; batch classifier loss: 64.262634; batch adversarial loss: 0.722948\n","epoch 6; iter: 0; batch classifier loss: 54.181114; batch adversarial loss: 0.715283\n","epoch 7; iter: 0; batch classifier loss: 49.830406; batch adversarial loss: 0.709017\n","epoch 8; iter: 0; batch classifier loss: 27.493786; batch adversarial loss: 0.693757\n","epoch 9; iter: 0; batch classifier loss: 39.657558; batch adversarial loss: 0.708234\n","epoch 10; iter: 0; batch classifier loss: 41.274727; batch adversarial loss: 0.714139\n","epoch 11; iter: 0; batch classifier loss: 33.976128; batch adversarial loss: 0.695730\n","epoch 12; iter: 0; batch classifier loss: 31.440023; batch adversarial loss: 0.693231\n","epoch 13; iter: 0; batch classifier loss: 35.355583; batch adversarial loss: 0.710240\n","epoch 14; iter: 0; batch classifier loss: 22.665810; batch adversarial loss: 0.688013\n","epoch 15; iter: 0; batch classifier loss: 30.206856; batch adversarial loss: 0.691785\n","epoch 16; iter: 0; batch classifier loss: 22.448025; batch adversarial loss: 0.677728\n","epoch 17; iter: 0; batch classifier loss: 31.708691; batch adversarial loss: 0.664305\n","epoch 18; iter: 0; batch classifier loss: 43.138802; batch adversarial loss: 0.663044\n","epoch 19; iter: 0; batch classifier loss: 25.328703; batch adversarial loss: 0.666254\n","epoch 20; iter: 0; batch classifier loss: 25.512020; batch adversarial loss: 0.677494\n","epoch 21; iter: 0; batch classifier loss: 25.362295; batch adversarial loss: 0.659255\n","epoch 22; iter: 0; batch classifier loss: 27.881739; batch adversarial loss: 0.673106\n","epoch 23; iter: 0; batch classifier loss: 16.907093; batch adversarial loss: 0.666456\n","epoch 24; iter: 0; batch classifier loss: 28.108532; batch adversarial loss: 0.657522\n","epoch 25; iter: 0; batch classifier loss: 18.071974; batch adversarial loss: 0.663714\n","epoch 26; iter: 0; batch classifier loss: 21.881674; batch adversarial loss: 0.649796\n","epoch 27; iter: 0; batch classifier loss: 22.197887; batch adversarial loss: 0.647102\n","epoch 28; iter: 0; batch classifier loss: 18.592979; batch adversarial loss: 0.632574\n","epoch 29; iter: 0; batch classifier loss: 21.176971; batch adversarial loss: 0.636145\n","epoch 30; iter: 0; batch classifier loss: 19.255566; batch adversarial loss: 0.644098\n","epoch 31; iter: 0; batch classifier loss: 18.696690; batch adversarial loss: 0.634802\n","epoch 32; iter: 0; batch classifier loss: 14.559792; batch adversarial loss: 0.631760\n","epoch 33; iter: 0; batch classifier loss: 14.884666; batch adversarial loss: 0.628456\n","epoch 34; iter: 0; batch classifier loss: 10.723702; batch adversarial loss: 0.636513\n","epoch 35; iter: 0; batch classifier loss: 11.108316; batch adversarial loss: 0.636707\n","epoch 36; iter: 0; batch classifier loss: 13.802239; batch adversarial loss: 0.617169\n","epoch 37; iter: 0; batch classifier loss: 14.932911; batch adversarial loss: 0.631966\n","epoch 38; iter: 0; batch classifier loss: 7.725796; batch adversarial loss: 0.619186\n","epoch 39; iter: 0; batch classifier loss: 7.748185; batch adversarial loss: 0.630698\n","epoch 40; iter: 0; batch classifier loss: 8.256344; batch adversarial loss: 0.612680\n","epoch 41; iter: 0; batch classifier loss: 10.157774; batch adversarial loss: 0.612806\n","epoch 42; iter: 0; batch classifier loss: 6.528358; batch adversarial loss: 0.623266\n","epoch 43; iter: 0; batch classifier loss: 7.819805; batch adversarial loss: 0.614310\n","epoch 44; iter: 0; batch classifier loss: 4.226231; batch adversarial loss: 0.608642\n","epoch 45; iter: 0; batch classifier loss: 4.330630; batch adversarial loss: 0.613372\n","epoch 46; iter: 0; batch classifier loss: 7.577841; batch adversarial loss: 0.576256\n","epoch 47; iter: 0; batch classifier loss: 4.992987; batch adversarial loss: 0.592331\n","epoch 48; iter: 0; batch classifier loss: 6.234829; batch adversarial loss: 0.608161\n","epoch 49; iter: 0; batch classifier loss: 6.089993; batch adversarial loss: 0.608055\n","Accuracy 0.45\n","epoch 0; iter: 0; batch classifier loss: 66.275558; batch adversarial loss: 0.608101\n","epoch 1; iter: 0; batch classifier loss: 57.273869; batch adversarial loss: 0.598191\n","epoch 2; iter: 0; batch classifier loss: 67.843430; batch adversarial loss: 0.543225\n","epoch 3; iter: 0; batch classifier loss: 60.273903; batch adversarial loss: 0.570525\n","epoch 4; iter: 0; batch classifier loss: 49.130447; batch adversarial loss: 0.549953\n","epoch 5; iter: 0; batch classifier loss: 54.526802; batch adversarial loss: 0.573862\n","epoch 6; iter: 0; batch classifier loss: 50.749844; batch adversarial loss: 0.589611\n","epoch 7; iter: 0; batch classifier loss: 36.785217; batch adversarial loss: 0.545008\n","epoch 8; iter: 0; batch classifier loss: 29.901714; batch adversarial loss: 0.519003\n","epoch 9; iter: 0; batch classifier loss: 46.070099; batch adversarial loss: 0.501763\n","epoch 10; iter: 0; batch classifier loss: 31.653210; batch adversarial loss: 0.562180\n","epoch 11; iter: 0; batch classifier loss: 42.141724; batch adversarial loss: 0.575412\n","epoch 12; iter: 0; batch classifier loss: 47.583527; batch adversarial loss: 0.620031\n","epoch 13; iter: 0; batch classifier loss: 33.012890; batch adversarial loss: 0.581563\n","epoch 14; iter: 0; batch classifier loss: 41.440639; batch adversarial loss: 0.606648\n","epoch 15; iter: 0; batch classifier loss: 37.253769; batch adversarial loss: 0.565614\n","epoch 16; iter: 0; batch classifier loss: 27.076700; batch adversarial loss: 0.614007\n","epoch 17; iter: 0; batch classifier loss: 29.073380; batch adversarial loss: 0.600047\n","epoch 18; iter: 0; batch classifier loss: 25.856567; batch adversarial loss: 0.545143\n","epoch 19; iter: 0; batch classifier loss: 33.994576; batch adversarial loss: 0.585433\n","epoch 20; iter: 0; batch classifier loss: 21.628035; batch adversarial loss: 0.529892\n","epoch 21; iter: 0; batch classifier loss: 25.839001; batch adversarial loss: 0.611676\n","epoch 22; iter: 0; batch classifier loss: 27.022793; batch adversarial loss: 0.638646\n","epoch 23; iter: 0; batch classifier loss: 22.000107; batch adversarial loss: 0.532770\n","epoch 24; iter: 0; batch classifier loss: 14.162426; batch adversarial loss: 0.578693\n","epoch 25; iter: 0; batch classifier loss: 17.999435; batch adversarial loss: 0.562372\n","epoch 26; iter: 0; batch classifier loss: 20.877552; batch adversarial loss: 0.526288\n","epoch 27; iter: 0; batch classifier loss: 14.904062; batch adversarial loss: 0.575541\n","epoch 28; iter: 0; batch classifier loss: 16.072975; batch adversarial loss: 0.543799\n","epoch 29; iter: 0; batch classifier loss: 15.103605; batch adversarial loss: 0.569636\n","epoch 30; iter: 0; batch classifier loss: 11.297175; batch adversarial loss: 0.554809\n","epoch 31; iter: 0; batch classifier loss: 14.775503; batch adversarial loss: 0.576759\n","epoch 32; iter: 0; batch classifier loss: 13.255232; batch adversarial loss: 0.566835\n","epoch 33; iter: 0; batch classifier loss: 12.971207; batch adversarial loss: 0.544535\n","epoch 34; iter: 0; batch classifier loss: 12.331647; batch adversarial loss: 0.532141\n","epoch 35; iter: 0; batch classifier loss: 9.097766; batch adversarial loss: 0.518697\n","epoch 36; iter: 0; batch classifier loss: 8.085787; batch adversarial loss: 0.533985\n","epoch 37; iter: 0; batch classifier loss: 8.005999; batch adversarial loss: 0.509663\n","epoch 38; iter: 0; batch classifier loss: 7.154656; batch adversarial loss: 0.548901\n","epoch 39; iter: 0; batch classifier loss: 10.480735; batch adversarial loss: 0.470551\n","epoch 40; iter: 0; batch classifier loss: 11.626140; batch adversarial loss: 0.575993\n","epoch 41; iter: 0; batch classifier loss: 13.928968; batch adversarial loss: 0.587731\n","epoch 42; iter: 0; batch classifier loss: 7.891677; batch adversarial loss: 0.499299\n","epoch 43; iter: 0; batch classifier loss: 8.890759; batch adversarial loss: 0.399891\n","epoch 44; iter: 0; batch classifier loss: 5.842691; batch adversarial loss: 0.582767\n","epoch 45; iter: 0; batch classifier loss: 8.273004; batch adversarial loss: 0.600233\n","epoch 46; iter: 0; batch classifier loss: 6.001447; batch adversarial loss: 0.573332\n","epoch 47; iter: 0; batch classifier loss: 6.676395; batch adversarial loss: 0.412281\n","epoch 48; iter: 0; batch classifier loss: 3.523346; batch adversarial loss: 0.570914\n","epoch 49; iter: 0; batch classifier loss: 3.737658; batch adversarial loss: 0.476566\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.715\n","epoch 0; iter: 0; batch classifier loss: 379.721649; batch adversarial loss: 0.474997\n","epoch 1; iter: 0; batch classifier loss: 179.843475; batch adversarial loss: 0.444831\n","epoch 2; iter: 0; batch classifier loss: 80.479385; batch adversarial loss: 0.492820\n","epoch 3; iter: 0; batch classifier loss: 46.538433; batch adversarial loss: 0.584007\n","epoch 4; iter: 0; batch classifier loss: 24.320379; batch adversarial loss: 0.660942\n","epoch 5; iter: 0; batch classifier loss: 54.091770; batch adversarial loss: 0.655934\n","epoch 6; iter: 0; batch classifier loss: 67.915237; batch adversarial loss: 0.653255\n","epoch 7; iter: 0; batch classifier loss: 44.650475; batch adversarial loss: 0.650149\n","epoch 8; iter: 0; batch classifier loss: 45.771515; batch adversarial loss: 0.583293\n","epoch 9; iter: 0; batch classifier loss: 45.382221; batch adversarial loss: 0.590547\n","epoch 10; iter: 0; batch classifier loss: 49.359703; batch adversarial loss: 0.581652\n","epoch 11; iter: 0; batch classifier loss: 45.880127; batch adversarial loss: 0.548220\n","epoch 12; iter: 0; batch classifier loss: 27.897064; batch adversarial loss: 0.613094\n","epoch 13; iter: 0; batch classifier loss: 34.909885; batch adversarial loss: 0.588398\n","epoch 14; iter: 0; batch classifier loss: 35.239777; batch adversarial loss: 0.598837\n","epoch 15; iter: 0; batch classifier loss: 48.418110; batch adversarial loss: 0.566030\n","epoch 16; iter: 0; batch classifier loss: 50.290680; batch adversarial loss: 0.544287\n","epoch 17; iter: 0; batch classifier loss: 49.178986; batch adversarial loss: 0.605500\n","epoch 18; iter: 0; batch classifier loss: 39.541061; batch adversarial loss: 0.550713\n","epoch 19; iter: 0; batch classifier loss: 36.530876; batch adversarial loss: 0.554954\n","epoch 20; iter: 0; batch classifier loss: 30.753801; batch adversarial loss: 0.591436\n","epoch 21; iter: 0; batch classifier loss: 29.748781; batch adversarial loss: 0.623281\n","epoch 22; iter: 0; batch classifier loss: 28.893246; batch adversarial loss: 0.593571\n","epoch 23; iter: 0; batch classifier loss: 42.910164; batch adversarial loss: 0.588367\n","epoch 24; iter: 0; batch classifier loss: 38.357941; batch adversarial loss: 0.557067\n","epoch 25; iter: 0; batch classifier loss: 30.600212; batch adversarial loss: 0.576409\n","epoch 26; iter: 0; batch classifier loss: 26.631336; batch adversarial loss: 0.571625\n","epoch 27; iter: 0; batch classifier loss: 32.520653; batch adversarial loss: 0.543754\n","epoch 28; iter: 0; batch classifier loss: 36.799805; batch adversarial loss: 0.585862\n","epoch 29; iter: 0; batch classifier loss: 28.741770; batch adversarial loss: 0.581831\n","epoch 30; iter: 0; batch classifier loss: 37.621510; batch adversarial loss: 0.572990\n","epoch 31; iter: 0; batch classifier loss: 27.547228; batch adversarial loss: 0.558195\n","epoch 32; iter: 0; batch classifier loss: 28.629854; batch adversarial loss: 0.567622\n","epoch 33; iter: 0; batch classifier loss: 26.207514; batch adversarial loss: 0.568857\n","epoch 34; iter: 0; batch classifier loss: 24.422909; batch adversarial loss: 0.512652\n","epoch 35; iter: 0; batch classifier loss: 27.034500; batch adversarial loss: 0.542550\n","epoch 36; iter: 0; batch classifier loss: 17.861673; batch adversarial loss: 0.586868\n","epoch 37; iter: 0; batch classifier loss: 16.724960; batch adversarial loss: 0.594121\n","epoch 38; iter: 0; batch classifier loss: 29.864363; batch adversarial loss: 0.520558\n","epoch 39; iter: 0; batch classifier loss: 26.583384; batch adversarial loss: 0.533313\n","epoch 40; iter: 0; batch classifier loss: 19.664871; batch adversarial loss: 0.563285\n","epoch 41; iter: 0; batch classifier loss: 25.155029; batch adversarial loss: 0.535104\n","epoch 42; iter: 0; batch classifier loss: 19.298218; batch adversarial loss: 0.551233\n","epoch 43; iter: 0; batch classifier loss: 21.611141; batch adversarial loss: 0.560583\n","epoch 44; iter: 0; batch classifier loss: 17.691055; batch adversarial loss: 0.511070\n","epoch 45; iter: 0; batch classifier loss: 15.975826; batch adversarial loss: 0.475845\n","epoch 46; iter: 0; batch classifier loss: 18.347664; batch adversarial loss: 0.545062\n","epoch 47; iter: 0; batch classifier loss: 15.493797; batch adversarial loss: 0.499079\n","epoch 48; iter: 0; batch classifier loss: 19.660774; batch adversarial loss: 0.558307\n","epoch 49; iter: 0; batch classifier loss: 12.948355; batch adversarial loss: 0.484226\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.69\n","epoch 0; iter: 0; batch classifier loss: 182.466095; batch adversarial loss: 0.693147\n","epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n","epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.69\n","epoch 0; iter: 0; batch classifier loss: 81.120010; batch adversarial loss: 0.522235\n","epoch 1; iter: 0; batch classifier loss: 74.133568; batch adversarial loss: 0.628555\n","epoch 2; iter: 0; batch classifier loss: 41.944061; batch adversarial loss: 0.635566\n","epoch 3; iter: 0; batch classifier loss: 29.021141; batch adversarial loss: 0.630400\n","epoch 4; iter: 0; batch classifier loss: 43.961681; batch adversarial loss: 0.638041\n","epoch 5; iter: 0; batch classifier loss: 62.292343; batch adversarial loss: 0.650585\n","epoch 6; iter: 0; batch classifier loss: 45.304066; batch adversarial loss: 0.582873\n","epoch 7; iter: 0; batch classifier loss: 41.397614; batch adversarial loss: 0.594035\n","epoch 8; iter: 0; batch classifier loss: 39.857185; batch adversarial loss: 0.633266\n","epoch 9; iter: 0; batch classifier loss: 55.675396; batch adversarial loss: 0.595662\n","epoch 10; iter: 0; batch classifier loss: 42.605583; batch adversarial loss: 0.609203\n","epoch 11; iter: 0; batch classifier loss: 41.872864; batch adversarial loss: 0.655374\n","epoch 12; iter: 0; batch classifier loss: 33.235542; batch adversarial loss: 0.593274\n","epoch 13; iter: 0; batch classifier loss: 48.287392; batch adversarial loss: 0.597434\n","epoch 14; iter: 0; batch classifier loss: 27.858803; batch adversarial loss: 0.571838\n","epoch 15; iter: 0; batch classifier loss: 25.066463; batch adversarial loss: 0.575211\n","epoch 16; iter: 0; batch classifier loss: 22.850193; batch adversarial loss: 0.624613\n","epoch 17; iter: 0; batch classifier loss: 23.213081; batch adversarial loss: 0.618424\n","epoch 18; iter: 0; batch classifier loss: 26.800968; batch adversarial loss: 0.652988\n","epoch 19; iter: 0; batch classifier loss: 29.197365; batch adversarial loss: 0.615249\n","epoch 20; iter: 0; batch classifier loss: 14.313173; batch adversarial loss: 0.593656\n","epoch 21; iter: 0; batch classifier loss: 21.278759; batch adversarial loss: 0.532415\n","epoch 22; iter: 0; batch classifier loss: 25.773006; batch adversarial loss: 0.617420\n","epoch 23; iter: 0; batch classifier loss: 28.313980; batch adversarial loss: 0.599006\n","epoch 24; iter: 0; batch classifier loss: 30.494064; batch adversarial loss: 0.643705\n","epoch 25; iter: 0; batch classifier loss: 22.280602; batch adversarial loss: 0.628938\n","epoch 26; iter: 0; batch classifier loss: 13.612358; batch adversarial loss: 0.621594\n","epoch 27; iter: 0; batch classifier loss: 14.105647; batch adversarial loss: 0.544513\n","epoch 28; iter: 0; batch classifier loss: 18.206339; batch adversarial loss: 0.544020\n","epoch 29; iter: 0; batch classifier loss: 15.634335; batch adversarial loss: 0.610845\n","epoch 30; iter: 0; batch classifier loss: 17.935566; batch adversarial loss: 0.610867\n","epoch 31; iter: 0; batch classifier loss: 10.631243; batch adversarial loss: 0.569114\n","epoch 32; iter: 0; batch classifier loss: 12.047862; batch adversarial loss: 0.550708\n","epoch 33; iter: 0; batch classifier loss: 15.996658; batch adversarial loss: 0.560372\n","epoch 34; iter: 0; batch classifier loss: 12.994595; batch adversarial loss: 0.616946\n","epoch 35; iter: 0; batch classifier loss: 10.999972; batch adversarial loss: 0.579991\n","epoch 36; iter: 0; batch classifier loss: 11.661040; batch adversarial loss: 0.602563\n","epoch 37; iter: 0; batch classifier loss: 11.567565; batch adversarial loss: 0.610111\n","epoch 38; iter: 0; batch classifier loss: 7.864160; batch adversarial loss: 0.630415\n","epoch 39; iter: 0; batch classifier loss: 4.920724; batch adversarial loss: 0.575227\n","epoch 40; iter: 0; batch classifier loss: 12.503086; batch adversarial loss: 0.595182\n","epoch 41; iter: 0; batch classifier loss: 15.742277; batch adversarial loss: 0.459117\n","epoch 42; iter: 0; batch classifier loss: 9.125151; batch adversarial loss: 0.567855\n","epoch 43; iter: 0; batch classifier loss: 12.531673; batch adversarial loss: 0.613787\n","epoch 44; iter: 0; batch classifier loss: 9.002247; batch adversarial loss: 0.583457\n","epoch 45; iter: 0; batch classifier loss: 8.203793; batch adversarial loss: 0.498024\n","epoch 46; iter: 0; batch classifier loss: 5.358717; batch adversarial loss: 0.565913\n","epoch 47; iter: 0; batch classifier loss: 6.707631; batch adversarial loss: 0.595635\n","epoch 48; iter: 0; batch classifier loss: 3.412755; batch adversarial loss: 0.574805\n","epoch 49; iter: 0; batch classifier loss: 4.565135; batch adversarial loss: 0.563955\n","Accuracy 0.655\n","epoch 0; iter: 0; batch classifier loss: 250.322418; batch adversarial loss: 0.530647\n","epoch 1; iter: 0; batch classifier loss: 173.615906; batch adversarial loss: 0.520261\n","epoch 2; iter: 0; batch classifier loss: 108.115990; batch adversarial loss: 0.508012\n","epoch 3; iter: 0; batch classifier loss: 100.526405; batch adversarial loss: 0.595546\n","epoch 4; iter: 0; batch classifier loss: 56.820938; batch adversarial loss: 0.609056\n","epoch 5; iter: 0; batch classifier loss: 40.814331; batch adversarial loss: 0.664800\n","epoch 6; iter: 0; batch classifier loss: 62.539265; batch adversarial loss: 0.641068\n","epoch 7; iter: 0; batch classifier loss: 41.466766; batch adversarial loss: 0.605107\n","epoch 8; iter: 0; batch classifier loss: 44.885895; batch adversarial loss: 0.618000\n","epoch 9; iter: 0; batch classifier loss: 55.501617; batch adversarial loss: 0.564087\n","epoch 10; iter: 0; batch classifier loss: 50.874752; batch adversarial loss: 0.567236\n","epoch 11; iter: 0; batch classifier loss: 44.361961; batch adversarial loss: 0.616590\n","epoch 12; iter: 0; batch classifier loss: 52.614288; batch adversarial loss: 0.599702\n","epoch 13; iter: 0; batch classifier loss: 37.078403; batch adversarial loss: 0.594207\n","epoch 14; iter: 0; batch classifier loss: 36.334427; batch adversarial loss: 0.586753\n","epoch 15; iter: 0; batch classifier loss: 39.597588; batch adversarial loss: 0.558227\n","epoch 16; iter: 0; batch classifier loss: 46.093109; batch adversarial loss: 0.592880\n","epoch 17; iter: 0; batch classifier loss: 29.181379; batch adversarial loss: 0.602071\n","epoch 18; iter: 0; batch classifier loss: 55.369087; batch adversarial loss: 0.574965\n","epoch 19; iter: 0; batch classifier loss: 25.350697; batch adversarial loss: 0.591193\n","epoch 20; iter: 0; batch classifier loss: 28.201025; batch adversarial loss: 0.567797\n","epoch 21; iter: 0; batch classifier loss: 38.675259; batch adversarial loss: 0.569168\n","epoch 22; iter: 0; batch classifier loss: 29.548082; batch adversarial loss: 0.618720\n","epoch 23; iter: 0; batch classifier loss: 20.055717; batch adversarial loss: 0.561527\n","epoch 24; iter: 0; batch classifier loss: 42.807144; batch adversarial loss: 0.551311\n","epoch 25; iter: 0; batch classifier loss: 36.220230; batch adversarial loss: 0.544947\n","epoch 26; iter: 0; batch classifier loss: 27.620512; batch adversarial loss: 0.585720\n","epoch 27; iter: 0; batch classifier loss: 34.564545; batch adversarial loss: 0.613551\n","epoch 28; iter: 0; batch classifier loss: 15.885309; batch adversarial loss: 0.558202\n","epoch 29; iter: 0; batch classifier loss: 21.378468; batch adversarial loss: 0.553724\n","epoch 30; iter: 0; batch classifier loss: 24.030130; batch adversarial loss: 0.576945\n","epoch 31; iter: 0; batch classifier loss: 25.808361; batch adversarial loss: 0.557677\n","epoch 32; iter: 0; batch classifier loss: 36.247833; batch adversarial loss: 0.584771\n","epoch 33; iter: 0; batch classifier loss: 21.035961; batch adversarial loss: 0.572268\n","epoch 34; iter: 0; batch classifier loss: 21.833862; batch adversarial loss: 0.558872\n","epoch 35; iter: 0; batch classifier loss: 20.355978; batch adversarial loss: 0.601063\n","epoch 36; iter: 0; batch classifier loss: 19.353931; batch adversarial loss: 0.518187\n","epoch 37; iter: 0; batch classifier loss: 22.191702; batch adversarial loss: 0.551159\n","epoch 38; iter: 0; batch classifier loss: 21.262289; batch adversarial loss: 0.579215\n","epoch 39; iter: 0; batch classifier loss: 15.437832; batch adversarial loss: 0.574115\n","epoch 40; iter: 0; batch classifier loss: 19.178913; batch adversarial loss: 0.539432\n","epoch 41; iter: 0; batch classifier loss: 14.087920; batch adversarial loss: 0.509409\n","epoch 42; iter: 0; batch classifier loss: 17.854786; batch adversarial loss: 0.552704\n","epoch 43; iter: 0; batch classifier loss: 12.714293; batch adversarial loss: 0.568866\n","epoch 44; iter: 0; batch classifier loss: 11.886263; batch adversarial loss: 0.538399\n","epoch 45; iter: 0; batch classifier loss: 15.681358; batch adversarial loss: 0.463962\n","epoch 46; iter: 0; batch classifier loss: 15.700746; batch adversarial loss: 0.513455\n","epoch 47; iter: 0; batch classifier loss: 13.408947; batch adversarial loss: 0.561340\n","epoch 48; iter: 0; batch classifier loss: 8.806050; batch adversarial loss: 0.537872\n","epoch 49; iter: 0; batch classifier loss: 15.289622; batch adversarial loss: 0.536624\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.71\n","epoch 0; iter: 0; batch classifier loss: 211.405289; batch adversarial loss: 0.580411\n","epoch 1; iter: 0; batch classifier loss: 131.271759; batch adversarial loss: 0.588730\n","epoch 2; iter: 0; batch classifier loss: 60.886887; batch adversarial loss: 0.614059\n","epoch 3; iter: 0; batch classifier loss: 70.110352; batch adversarial loss: 0.657897\n","epoch 4; iter: 0; batch classifier loss: 45.204857; batch adversarial loss: 0.669390\n","epoch 5; iter: 0; batch classifier loss: 48.567398; batch adversarial loss: 0.658372\n","epoch 6; iter: 0; batch classifier loss: 46.634232; batch adversarial loss: 0.657911\n","epoch 7; iter: 0; batch classifier loss: 57.903732; batch adversarial loss: 0.641340\n","epoch 8; iter: 0; batch classifier loss: 57.116203; batch adversarial loss: 0.621639\n","epoch 9; iter: 0; batch classifier loss: 42.494743; batch adversarial loss: 0.615134\n","epoch 10; iter: 0; batch classifier loss: 40.919106; batch adversarial loss: 0.618767\n","epoch 11; iter: 0; batch classifier loss: 44.555378; batch adversarial loss: 0.620934\n","epoch 12; iter: 0; batch classifier loss: 42.681923; batch adversarial loss: 0.617219\n","epoch 13; iter: 0; batch classifier loss: 43.270069; batch adversarial loss: 0.617664\n","epoch 14; iter: 0; batch classifier loss: 26.248405; batch adversarial loss: 0.614486\n","epoch 15; iter: 0; batch classifier loss: 39.814411; batch adversarial loss: 0.614612\n","epoch 16; iter: 0; batch classifier loss: 30.400169; batch adversarial loss: 0.616921\n","epoch 17; iter: 0; batch classifier loss: 39.418125; batch adversarial loss: 0.624023\n","epoch 18; iter: 0; batch classifier loss: 47.229694; batch adversarial loss: 0.630654\n","epoch 19; iter: 0; batch classifier loss: 41.688976; batch adversarial loss: 0.618403\n","epoch 20; iter: 0; batch classifier loss: 33.127010; batch adversarial loss: 0.589791\n","epoch 21; iter: 0; batch classifier loss: 25.746914; batch adversarial loss: 0.607991\n","epoch 22; iter: 0; batch classifier loss: 35.899860; batch adversarial loss: 0.614027\n","epoch 23; iter: 0; batch classifier loss: 43.770279; batch adversarial loss: 0.592618\n","epoch 24; iter: 0; batch classifier loss: 28.545963; batch adversarial loss: 0.564492\n","epoch 25; iter: 0; batch classifier loss: 22.041393; batch adversarial loss: 0.587045\n","epoch 26; iter: 0; batch classifier loss: 25.342749; batch adversarial loss: 0.612701\n","epoch 27; iter: 0; batch classifier loss: 34.015690; batch adversarial loss: 0.605261\n","epoch 28; iter: 0; batch classifier loss: 29.201309; batch adversarial loss: 0.582255\n","epoch 29; iter: 0; batch classifier loss: 27.643490; batch adversarial loss: 0.555666\n","epoch 30; iter: 0; batch classifier loss: 29.460281; batch adversarial loss: 0.589074\n","epoch 31; iter: 0; batch classifier loss: 22.908377; batch adversarial loss: 0.607406\n","epoch 32; iter: 0; batch classifier loss: 31.279018; batch adversarial loss: 0.574928\n","epoch 33; iter: 0; batch classifier loss: 18.921232; batch adversarial loss: 0.550999\n","epoch 34; iter: 0; batch classifier loss: 23.383904; batch adversarial loss: 0.580342\n","epoch 35; iter: 0; batch classifier loss: 20.588646; batch adversarial loss: 0.587242\n","epoch 36; iter: 0; batch classifier loss: 18.296469; batch adversarial loss: 0.579165\n","epoch 37; iter: 0; batch classifier loss: 18.727564; batch adversarial loss: 0.596702\n","epoch 38; iter: 0; batch classifier loss: 26.416815; batch adversarial loss: 0.590602\n","epoch 39; iter: 0; batch classifier loss: 25.496742; batch adversarial loss: 0.601023\n","epoch 40; iter: 0; batch classifier loss: 23.510040; batch adversarial loss: 0.593293\n","epoch 41; iter: 0; batch classifier loss: 15.788423; batch adversarial loss: 0.542706\n","epoch 42; iter: 0; batch classifier loss: 19.580521; batch adversarial loss: 0.554270\n","epoch 43; iter: 0; batch classifier loss: 14.848820; batch adversarial loss: 0.552210\n","epoch 44; iter: 0; batch classifier loss: 12.696829; batch adversarial loss: 0.549504\n","epoch 45; iter: 0; batch classifier loss: 18.591965; batch adversarial loss: 0.561759\n","epoch 46; iter: 0; batch classifier loss: 20.034670; batch adversarial loss: 0.556010\n","epoch 47; iter: 0; batch classifier loss: 12.156286; batch adversarial loss: 0.531577\n","epoch 48; iter: 0; batch classifier loss: 14.303839; batch adversarial loss: 0.526524\n","epoch 49; iter: 0; batch classifier loss: 16.215982; batch adversarial loss: 0.530478\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.75\n","epoch 0; iter: 0; batch classifier loss: 69.986053; batch adversarial loss: 0.802074\n","epoch 1; iter: 0; batch classifier loss: 60.967930; batch adversarial loss: 0.898644\n","epoch 2; iter: 0; batch classifier loss: 42.704269; batch adversarial loss: 0.872169\n","epoch 3; iter: 0; batch classifier loss: 57.982601; batch adversarial loss: 0.896059\n","epoch 4; iter: 0; batch classifier loss: 44.969093; batch adversarial loss: 0.907918\n","epoch 5; iter: 0; batch classifier loss: 34.561317; batch adversarial loss: 0.835440\n","epoch 6; iter: 0; batch classifier loss: 32.362408; batch adversarial loss: 0.874867\n","epoch 7; iter: 0; batch classifier loss: 37.434250; batch adversarial loss: 0.868851\n","epoch 8; iter: 0; batch classifier loss: 35.241722; batch adversarial loss: 0.832207\n","epoch 9; iter: 0; batch classifier loss: 35.968365; batch adversarial loss: 0.880242\n","epoch 10; iter: 0; batch classifier loss: 28.805286; batch adversarial loss: 0.846194\n","epoch 11; iter: 0; batch classifier loss: 25.641508; batch adversarial loss: 0.848181\n","epoch 12; iter: 0; batch classifier loss: 36.357773; batch adversarial loss: 0.857117\n","epoch 13; iter: 0; batch classifier loss: 17.557346; batch adversarial loss: 0.786009\n","epoch 14; iter: 0; batch classifier loss: 24.233408; batch adversarial loss: 0.844669\n","epoch 15; iter: 0; batch classifier loss: 24.683798; batch adversarial loss: 0.836238\n","epoch 16; iter: 0; batch classifier loss: 12.552231; batch adversarial loss: 0.833934\n","epoch 17; iter: 0; batch classifier loss: 24.373177; batch adversarial loss: 0.800332\n","epoch 18; iter: 0; batch classifier loss: 16.015902; batch adversarial loss: 0.802155\n","epoch 19; iter: 0; batch classifier loss: 14.918093; batch adversarial loss: 0.837472\n","epoch 20; iter: 0; batch classifier loss: 18.512508; batch adversarial loss: 0.888453\n","epoch 21; iter: 0; batch classifier loss: 12.624207; batch adversarial loss: 0.794951\n","epoch 22; iter: 0; batch classifier loss: 13.182274; batch adversarial loss: 0.802836\n","epoch 23; iter: 0; batch classifier loss: 11.474356; batch adversarial loss: 0.798589\n","epoch 24; iter: 0; batch classifier loss: 7.679924; batch adversarial loss: 0.741330\n","epoch 25; iter: 0; batch classifier loss: 14.608822; batch adversarial loss: 0.720649\n","epoch 26; iter: 0; batch classifier loss: 7.374149; batch adversarial loss: 0.789811\n","epoch 27; iter: 0; batch classifier loss: 9.531127; batch adversarial loss: 0.777932\n","epoch 28; iter: 0; batch classifier loss: 8.757132; batch adversarial loss: 0.749868\n","epoch 29; iter: 0; batch classifier loss: 6.670735; batch adversarial loss: 0.719573\n","epoch 30; iter: 0; batch classifier loss: 7.547955; batch adversarial loss: 0.764764\n","epoch 31; iter: 0; batch classifier loss: 5.316577; batch adversarial loss: 0.791125\n","epoch 32; iter: 0; batch classifier loss: 4.403628; batch adversarial loss: 0.741653\n","epoch 33; iter: 0; batch classifier loss: 4.218072; batch adversarial loss: 0.754164\n","epoch 34; iter: 0; batch classifier loss: 4.024442; batch adversarial loss: 0.703017\n","epoch 35; iter: 0; batch classifier loss: 4.281400; batch adversarial loss: 0.785118\n","epoch 36; iter: 0; batch classifier loss: 3.714733; batch adversarial loss: 0.743454\n","epoch 37; iter: 0; batch classifier loss: 1.971145; batch adversarial loss: 0.708165\n","epoch 38; iter: 0; batch classifier loss: 3.555449; batch adversarial loss: 0.718514\n","epoch 39; iter: 0; batch classifier loss: 3.417158; batch adversarial loss: 0.752697\n","epoch 40; iter: 0; batch classifier loss: 2.615267; batch adversarial loss: 0.755416\n","epoch 41; iter: 0; batch classifier loss: 2.473032; batch adversarial loss: 0.804033\n","epoch 42; iter: 0; batch classifier loss: 2.622292; batch adversarial loss: 0.787288\n","epoch 43; iter: 0; batch classifier loss: 1.845838; batch adversarial loss: 0.746285\n","epoch 44; iter: 0; batch classifier loss: 1.423113; batch adversarial loss: 0.742063\n","epoch 45; iter: 0; batch classifier loss: 1.392724; batch adversarial loss: 0.788934\n","epoch 46; iter: 0; batch classifier loss: 2.053238; batch adversarial loss: 0.793727\n","epoch 47; iter: 0; batch classifier loss: 1.582798; batch adversarial loss: 0.803757\n","epoch 48; iter: 0; batch classifier loss: 1.573891; batch adversarial loss: 0.820979\n","epoch 49; iter: 0; batch classifier loss: 1.381276; batch adversarial loss: 0.793874\n","Accuracy 0.335\n","epoch 0; iter: 0; batch classifier loss: 345.681763; batch adversarial loss: 0.543105\n","epoch 1; iter: 0; batch classifier loss: 189.527542; batch adversarial loss: 0.560639\n","epoch 2; iter: 0; batch classifier loss: 79.021393; batch adversarial loss: 0.590233\n","epoch 3; iter: 0; batch classifier loss: 53.995678; batch adversarial loss: 0.625972\n","epoch 4; iter: 0; batch classifier loss: 50.986141; batch adversarial loss: 0.646360\n","epoch 5; iter: 0; batch classifier loss: 55.850250; batch adversarial loss: 0.660175\n","epoch 6; iter: 0; batch classifier loss: 50.459263; batch adversarial loss: 0.669408\n","epoch 7; iter: 0; batch classifier loss: 46.776680; batch adversarial loss: 0.638516\n","epoch 8; iter: 0; batch classifier loss: 41.212105; batch adversarial loss: 0.654098\n","epoch 9; iter: 0; batch classifier loss: 40.910568; batch adversarial loss: 0.645881\n","epoch 10; iter: 0; batch classifier loss: 30.591572; batch adversarial loss: 0.619207\n","epoch 11; iter: 0; batch classifier loss: 51.148674; batch adversarial loss: 0.619269\n","epoch 12; iter: 0; batch classifier loss: 45.862946; batch adversarial loss: 0.619757\n","epoch 13; iter: 0; batch classifier loss: 47.312164; batch adversarial loss: 0.614186\n","epoch 14; iter: 0; batch classifier loss: 56.606079; batch adversarial loss: 0.587870\n","epoch 15; iter: 0; batch classifier loss: 41.075066; batch adversarial loss: 0.631414\n","epoch 16; iter: 0; batch classifier loss: 48.258003; batch adversarial loss: 0.593972\n","epoch 17; iter: 0; batch classifier loss: 31.231148; batch adversarial loss: 0.632507\n","epoch 18; iter: 0; batch classifier loss: 29.707275; batch adversarial loss: 0.617897\n","epoch 19; iter: 0; batch classifier loss: 29.934248; batch adversarial loss: 0.609994\n","epoch 20; iter: 0; batch classifier loss: 34.717590; batch adversarial loss: 0.590059\n","epoch 21; iter: 0; batch classifier loss: 30.957878; batch adversarial loss: 0.591396\n","epoch 22; iter: 0; batch classifier loss: 31.349287; batch adversarial loss: 0.619243\n","epoch 23; iter: 0; batch classifier loss: 27.666300; batch adversarial loss: 0.607701\n","epoch 24; iter: 0; batch classifier loss: 20.188326; batch adversarial loss: 0.583356\n","epoch 25; iter: 0; batch classifier loss: 31.174282; batch adversarial loss: 0.587666\n","epoch 26; iter: 0; batch classifier loss: 23.877539; batch adversarial loss: 0.619455\n","epoch 27; iter: 0; batch classifier loss: 37.030304; batch adversarial loss: 0.580734\n","epoch 28; iter: 0; batch classifier loss: 31.879162; batch adversarial loss: 0.591972\n","epoch 29; iter: 0; batch classifier loss: 37.351040; batch adversarial loss: 0.593677\n","epoch 30; iter: 0; batch classifier loss: 33.412518; batch adversarial loss: 0.591371\n","epoch 31; iter: 0; batch classifier loss: 24.807419; batch adversarial loss: 0.606682\n","epoch 32; iter: 0; batch classifier loss: 32.292488; batch adversarial loss: 0.595949\n","epoch 33; iter: 0; batch classifier loss: 28.594452; batch adversarial loss: 0.572426\n","epoch 34; iter: 0; batch classifier loss: 27.991165; batch adversarial loss: 0.557212\n","epoch 35; iter: 0; batch classifier loss: 30.331188; batch adversarial loss: 0.586987\n","epoch 36; iter: 0; batch classifier loss: 31.743404; batch adversarial loss: 0.566869\n","epoch 37; iter: 0; batch classifier loss: 30.456438; batch adversarial loss: 0.559296\n","epoch 38; iter: 0; batch classifier loss: 25.817743; batch adversarial loss: 0.547293\n","epoch 39; iter: 0; batch classifier loss: 33.567108; batch adversarial loss: 0.579603\n","epoch 40; iter: 0; batch classifier loss: 15.824263; batch adversarial loss: 0.560200\n","epoch 41; iter: 0; batch classifier loss: 20.845980; batch adversarial loss: 0.576529\n","epoch 42; iter: 0; batch classifier loss: 20.299294; batch adversarial loss: 0.560829\n","epoch 43; iter: 0; batch classifier loss: 21.736197; batch adversarial loss: 0.563579\n","epoch 44; iter: 0; batch classifier loss: 21.338840; batch adversarial loss: 0.554898\n","epoch 45; iter: 0; batch classifier loss: 20.803318; batch adversarial loss: 0.543158\n","epoch 46; iter: 0; batch classifier loss: 15.343766; batch adversarial loss: 0.551607\n","epoch 47; iter: 0; batch classifier loss: 15.699562; batch adversarial loss: 0.537604\n","epoch 48; iter: 0; batch classifier loss: 22.779938; batch adversarial loss: 0.562685\n","epoch 49; iter: 0; batch classifier loss: 20.048508; batch adversarial loss: 0.575847\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.67\n","epoch 0; iter: 0; batch classifier loss: 397.127197; batch adversarial loss: 0.958136\n","epoch 1; iter: 0; batch classifier loss: 252.680145; batch adversarial loss: 0.920169\n","epoch 2; iter: 0; batch classifier loss: 122.520325; batch adversarial loss: 0.969198\n","epoch 3; iter: 0; batch classifier loss: 109.707169; batch adversarial loss: 0.978996\n","epoch 4; iter: 0; batch classifier loss: 80.150597; batch adversarial loss: 0.865667\n","epoch 5; iter: 0; batch classifier loss: 57.245777; batch adversarial loss: 0.859193\n","epoch 6; iter: 0; batch classifier loss: 36.150768; batch adversarial loss: 0.778554\n","epoch 7; iter: 0; batch classifier loss: 51.711735; batch adversarial loss: 0.811237\n","epoch 8; iter: 0; batch classifier loss: 50.850792; batch adversarial loss: 0.733060\n","epoch 9; iter: 0; batch classifier loss: 46.591206; batch adversarial loss: 0.752558\n","epoch 10; iter: 0; batch classifier loss: 32.234219; batch adversarial loss: 0.727999\n","epoch 11; iter: 0; batch classifier loss: 46.190857; batch adversarial loss: 0.734129\n","epoch 12; iter: 0; batch classifier loss: 43.057732; batch adversarial loss: 0.760615\n","epoch 13; iter: 0; batch classifier loss: 57.776276; batch adversarial loss: 0.716812\n","epoch 14; iter: 0; batch classifier loss: 52.766792; batch adversarial loss: 0.734791\n","epoch 15; iter: 0; batch classifier loss: 39.327896; batch adversarial loss: 0.720961\n","epoch 16; iter: 0; batch classifier loss: 44.245777; batch adversarial loss: 0.739357\n","epoch 17; iter: 0; batch classifier loss: 43.655125; batch adversarial loss: 0.749729\n","epoch 18; iter: 0; batch classifier loss: 39.187469; batch adversarial loss: 0.810472\n","epoch 19; iter: 0; batch classifier loss: 44.755363; batch adversarial loss: 0.717602\n","epoch 20; iter: 0; batch classifier loss: 40.971939; batch adversarial loss: 0.708618\n","epoch 21; iter: 0; batch classifier loss: 39.160332; batch adversarial loss: 0.716063\n","epoch 22; iter: 0; batch classifier loss: 53.502148; batch adversarial loss: 0.707984\n","epoch 23; iter: 0; batch classifier loss: 39.027084; batch adversarial loss: 0.737599\n","epoch 24; iter: 0; batch classifier loss: 24.997440; batch adversarial loss: 0.721014\n","epoch 25; iter: 0; batch classifier loss: 36.277184; batch adversarial loss: 0.693044\n","epoch 26; iter: 0; batch classifier loss: 41.375092; batch adversarial loss: 0.714790\n","epoch 27; iter: 0; batch classifier loss: 29.615494; batch adversarial loss: 0.705479\n","epoch 28; iter: 0; batch classifier loss: 52.628429; batch adversarial loss: 0.710722\n","epoch 29; iter: 0; batch classifier loss: 38.489769; batch adversarial loss: 0.688871\n","epoch 30; iter: 0; batch classifier loss: 48.997299; batch adversarial loss: 0.697803\n","epoch 31; iter: 0; batch classifier loss: 24.514782; batch adversarial loss: 0.676125\n","epoch 32; iter: 0; batch classifier loss: 36.626217; batch adversarial loss: 0.679127\n","epoch 33; iter: 0; batch classifier loss: 44.123245; batch adversarial loss: 0.697392\n","epoch 34; iter: 0; batch classifier loss: 48.574543; batch adversarial loss: 0.665321\n","epoch 35; iter: 0; batch classifier loss: 39.848438; batch adversarial loss: 0.681751\n","epoch 36; iter: 0; batch classifier loss: 27.714655; batch adversarial loss: 0.703287\n","epoch 37; iter: 0; batch classifier loss: 23.330921; batch adversarial loss: 0.721678\n","epoch 38; iter: 0; batch classifier loss: 36.913612; batch adversarial loss: 0.643546\n","epoch 39; iter: 0; batch classifier loss: 29.591600; batch adversarial loss: 0.685047\n","epoch 40; iter: 0; batch classifier loss: 22.775799; batch adversarial loss: 0.655740\n","epoch 41; iter: 0; batch classifier loss: 33.525524; batch adversarial loss: 0.683461\n","epoch 42; iter: 0; batch classifier loss: 38.887985; batch adversarial loss: 0.641738\n","epoch 43; iter: 0; batch classifier loss: 32.902180; batch adversarial loss: 0.653055\n","epoch 44; iter: 0; batch classifier loss: 28.832493; batch adversarial loss: 0.669417\n","epoch 45; iter: 0; batch classifier loss: 30.779665; batch adversarial loss: 0.636860\n","epoch 46; iter: 0; batch classifier loss: 36.761620; batch adversarial loss: 0.655788\n","epoch 47; iter: 0; batch classifier loss: 25.586889; batch adversarial loss: 0.647349\n","epoch 48; iter: 0; batch classifier loss: 28.869480; batch adversarial loss: 0.654220\n","epoch 49; iter: 0; batch classifier loss: 22.758135; batch adversarial loss: 0.655900\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.705\n","epoch 0; iter: 0; batch classifier loss: 69.670547; batch adversarial loss: 0.552057\n","epoch 1; iter: 0; batch classifier loss: 58.337833; batch adversarial loss: 0.640589\n","epoch 2; iter: 0; batch classifier loss: 45.721439; batch adversarial loss: 0.648702\n","epoch 3; iter: 0; batch classifier loss: 53.307610; batch adversarial loss: 0.604254\n","epoch 4; iter: 0; batch classifier loss: 57.340336; batch adversarial loss: 0.586650\n","epoch 5; iter: 0; batch classifier loss: 51.530003; batch adversarial loss: 0.597830\n","epoch 6; iter: 0; batch classifier loss: 44.645344; batch adversarial loss: 0.590385\n","epoch 7; iter: 0; batch classifier loss: 42.748131; batch adversarial loss: 0.618997\n","epoch 8; iter: 0; batch classifier loss: 40.744286; batch adversarial loss: 0.605942\n","epoch 9; iter: 0; batch classifier loss: 42.744072; batch adversarial loss: 0.588192\n","epoch 10; iter: 0; batch classifier loss: 36.287239; batch adversarial loss: 0.630396\n","epoch 11; iter: 0; batch classifier loss: 29.793804; batch adversarial loss: 0.593178\n","epoch 12; iter: 0; batch classifier loss: 29.563194; batch adversarial loss: 0.556526\n","epoch 13; iter: 0; batch classifier loss: 29.796120; batch adversarial loss: 0.600806\n","epoch 14; iter: 0; batch classifier loss: 29.449080; batch adversarial loss: 0.582093\n","epoch 15; iter: 0; batch classifier loss: 33.460472; batch adversarial loss: 0.579749\n","epoch 16; iter: 0; batch classifier loss: 41.797844; batch adversarial loss: 0.601855\n","epoch 17; iter: 0; batch classifier loss: 30.522833; batch adversarial loss: 0.607587\n","epoch 18; iter: 0; batch classifier loss: 32.059486; batch adversarial loss: 0.557859\n","epoch 19; iter: 0; batch classifier loss: 25.288597; batch adversarial loss: 0.552807\n","epoch 20; iter: 0; batch classifier loss: 30.538153; batch adversarial loss: 0.590863\n","epoch 21; iter: 0; batch classifier loss: 37.283432; batch adversarial loss: 0.632467\n","epoch 22; iter: 0; batch classifier loss: 24.040907; batch adversarial loss: 0.559302\n","epoch 23; iter: 0; batch classifier loss: 28.800127; batch adversarial loss: 0.537897\n","epoch 24; iter: 0; batch classifier loss: 14.595533; batch adversarial loss: 0.564257\n","epoch 25; iter: 0; batch classifier loss: 22.362915; batch adversarial loss: 0.617212\n","epoch 26; iter: 0; batch classifier loss: 19.931366; batch adversarial loss: 0.488218\n","epoch 27; iter: 0; batch classifier loss: 22.173241; batch adversarial loss: 0.534417\n","epoch 28; iter: 0; batch classifier loss: 15.216732; batch adversarial loss: 0.570909\n","epoch 29; iter: 0; batch classifier loss: 16.263554; batch adversarial loss: 0.615978\n","epoch 30; iter: 0; batch classifier loss: 17.688335; batch adversarial loss: 0.560727\n","epoch 31; iter: 0; batch classifier loss: 13.216387; batch adversarial loss: 0.594497\n","epoch 32; iter: 0; batch classifier loss: 9.678852; batch adversarial loss: 0.555370\n","epoch 33; iter: 0; batch classifier loss: 9.442520; batch adversarial loss: 0.592817\n","epoch 34; iter: 0; batch classifier loss: 9.438633; batch adversarial loss: 0.565187\n","epoch 35; iter: 0; batch classifier loss: 12.661530; batch adversarial loss: 0.522564\n","epoch 36; iter: 0; batch classifier loss: 16.322636; batch adversarial loss: 0.569166\n","epoch 37; iter: 0; batch classifier loss: 9.601210; batch adversarial loss: 0.549985\n","epoch 38; iter: 0; batch classifier loss: 10.686726; batch adversarial loss: 0.579603\n","epoch 39; iter: 0; batch classifier loss: 12.248993; batch adversarial loss: 0.538229\n","epoch 40; iter: 0; batch classifier loss: 7.020752; batch adversarial loss: 0.585253\n","epoch 41; iter: 0; batch classifier loss: 6.144182; batch adversarial loss: 0.546900\n","epoch 42; iter: 0; batch classifier loss: 6.939237; batch adversarial loss: 0.558911\n","epoch 43; iter: 0; batch classifier loss: 4.556018; batch adversarial loss: 0.603981\n","epoch 44; iter: 0; batch classifier loss: 6.719530; batch adversarial loss: 0.525211\n","epoch 45; iter: 0; batch classifier loss: 7.342476; batch adversarial loss: 0.558675\n","epoch 46; iter: 0; batch classifier loss: 4.453681; batch adversarial loss: 0.527151\n","epoch 47; iter: 0; batch classifier loss: 5.920810; batch adversarial loss: 0.463848\n","epoch 48; iter: 0; batch classifier loss: 3.741742; batch adversarial loss: 0.570238\n","epoch 49; iter: 0; batch classifier loss: 4.241295; batch adversarial loss: 0.612153\n","Accuracy 0.485\n","epoch 0; iter: 0; batch classifier loss: 103.608170; batch adversarial loss: 0.635650\n","epoch 1; iter: 0; batch classifier loss: 87.270996; batch adversarial loss: 0.670393\n","epoch 2; iter: 0; batch classifier loss: 68.982979; batch adversarial loss: 0.670621\n","epoch 3; iter: 0; batch classifier loss: 72.772949; batch adversarial loss: 0.670570\n","epoch 4; iter: 0; batch classifier loss: 61.932884; batch adversarial loss: 0.635692\n","epoch 5; iter: 0; batch classifier loss: 47.175812; batch adversarial loss: 0.643919\n","epoch 6; iter: 0; batch classifier loss: 49.498333; batch adversarial loss: 0.653707\n","epoch 7; iter: 0; batch classifier loss: 55.332809; batch adversarial loss: 0.658047\n","epoch 8; iter: 0; batch classifier loss: 64.232231; batch adversarial loss: 0.647681\n","epoch 9; iter: 0; batch classifier loss: 55.967880; batch adversarial loss: 0.626582\n","epoch 10; iter: 0; batch classifier loss: 45.990036; batch adversarial loss: 0.594936\n","epoch 11; iter: 0; batch classifier loss: 56.494591; batch adversarial loss: 0.631945\n","epoch 12; iter: 0; batch classifier loss: 42.486809; batch adversarial loss: 0.629877\n","epoch 13; iter: 0; batch classifier loss: 43.307083; batch adversarial loss: 0.647835\n","epoch 14; iter: 0; batch classifier loss: 43.819111; batch adversarial loss: 0.614087\n","epoch 15; iter: 0; batch classifier loss: 35.847458; batch adversarial loss: 0.607729\n","epoch 16; iter: 0; batch classifier loss: 37.583076; batch adversarial loss: 0.616744\n","epoch 17; iter: 0; batch classifier loss: 41.378189; batch adversarial loss: 0.625227\n","epoch 18; iter: 0; batch classifier loss: 51.155472; batch adversarial loss: 0.623127\n","epoch 19; iter: 0; batch classifier loss: 45.809471; batch adversarial loss: 0.601577\n","epoch 20; iter: 0; batch classifier loss: 49.540939; batch adversarial loss: 0.604816\n","epoch 21; iter: 0; batch classifier loss: 30.591303; batch adversarial loss: 0.626361\n","epoch 22; iter: 0; batch classifier loss: 35.773666; batch adversarial loss: 0.638209\n","epoch 23; iter: 0; batch classifier loss: 29.919788; batch adversarial loss: 0.613578\n","epoch 24; iter: 0; batch classifier loss: 39.903233; batch adversarial loss: 0.606302\n","epoch 25; iter: 0; batch classifier loss: 28.007137; batch adversarial loss: 0.611201\n","epoch 26; iter: 0; batch classifier loss: 30.202303; batch adversarial loss: 0.598559\n","epoch 27; iter: 0; batch classifier loss: 25.661276; batch adversarial loss: 0.601228\n","epoch 28; iter: 0; batch classifier loss: 16.497442; batch adversarial loss: 0.577078\n","epoch 29; iter: 0; batch classifier loss: 34.432991; batch adversarial loss: 0.602934\n","epoch 30; iter: 0; batch classifier loss: 26.361092; batch adversarial loss: 0.579843\n","epoch 31; iter: 0; batch classifier loss: 28.206526; batch adversarial loss: 0.583240\n","epoch 32; iter: 0; batch classifier loss: 19.662287; batch adversarial loss: 0.581370\n","epoch 33; iter: 0; batch classifier loss: 23.421066; batch adversarial loss: 0.583153\n","epoch 34; iter: 0; batch classifier loss: 27.233940; batch adversarial loss: 0.602933\n","epoch 35; iter: 0; batch classifier loss: 25.432438; batch adversarial loss: 0.618335\n","epoch 36; iter: 0; batch classifier loss: 27.633385; batch adversarial loss: 0.574997\n","epoch 37; iter: 0; batch classifier loss: 23.929983; batch adversarial loss: 0.569045\n","epoch 38; iter: 0; batch classifier loss: 23.179375; batch adversarial loss: 0.546656\n","epoch 39; iter: 0; batch classifier loss: 22.175634; batch adversarial loss: 0.561751\n","epoch 40; iter: 0; batch classifier loss: 21.822224; batch adversarial loss: 0.545849\n","epoch 41; iter: 0; batch classifier loss: 18.231318; batch adversarial loss: 0.546068\n","epoch 42; iter: 0; batch classifier loss: 18.187094; batch adversarial loss: 0.561496\n","epoch 43; iter: 0; batch classifier loss: 21.013485; batch adversarial loss: 0.597159\n","epoch 44; iter: 0; batch classifier loss: 17.942490; batch adversarial loss: 0.550696\n","epoch 45; iter: 0; batch classifier loss: 12.492517; batch adversarial loss: 0.558931\n","epoch 46; iter: 0; batch classifier loss: 13.252531; batch adversarial loss: 0.592651\n","epoch 47; iter: 0; batch classifier loss: 17.102591; batch adversarial loss: 0.521585\n","epoch 48; iter: 0; batch classifier loss: 23.468307; batch adversarial loss: 0.495646\n","epoch 49; iter: 0; batch classifier loss: 9.839407; batch adversarial loss: 0.585204\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.715\n","epoch 0; iter: 0; batch classifier loss: 310.004517; batch adversarial loss: 0.877402\n","epoch 1; iter: 0; batch classifier loss: 131.507950; batch adversarial loss: 0.867131\n","epoch 2; iter: 0; batch classifier loss: 70.543579; batch adversarial loss: 0.797317\n","epoch 3; iter: 0; batch classifier loss: 51.428364; batch adversarial loss: 0.761384\n","epoch 4; iter: 0; batch classifier loss: 51.478619; batch adversarial loss: 0.731724\n","epoch 5; iter: 0; batch classifier loss: 57.457901; batch adversarial loss: 0.708411\n","epoch 6; iter: 0; batch classifier loss: 35.091446; batch adversarial loss: 0.712698\n","epoch 7; iter: 0; batch classifier loss: 52.112984; batch adversarial loss: 0.705776\n","epoch 8; iter: 0; batch classifier loss: 34.799408; batch adversarial loss: 0.722143\n","epoch 9; iter: 0; batch classifier loss: 47.994320; batch adversarial loss: 0.740460\n","epoch 10; iter: 0; batch classifier loss: 45.342072; batch adversarial loss: 0.728638\n","epoch 11; iter: 0; batch classifier loss: 63.307442; batch adversarial loss: 0.740754\n","epoch 12; iter: 0; batch classifier loss: 47.165787; batch adversarial loss: 0.728126\n","epoch 13; iter: 0; batch classifier loss: 37.816109; batch adversarial loss: 0.709343\n","epoch 14; iter: 0; batch classifier loss: 37.812431; batch adversarial loss: 0.702385\n","epoch 15; iter: 0; batch classifier loss: 40.300941; batch adversarial loss: 0.718931\n","epoch 16; iter: 0; batch classifier loss: 38.584358; batch adversarial loss: 0.701578\n","epoch 17; iter: 0; batch classifier loss: 31.501617; batch adversarial loss: 0.698848\n","epoch 18; iter: 0; batch classifier loss: 41.791107; batch adversarial loss: 0.691614\n","epoch 19; iter: 0; batch classifier loss: 57.758053; batch adversarial loss: 0.707038\n","epoch 20; iter: 0; batch classifier loss: 37.823288; batch adversarial loss: 0.697150\n","epoch 21; iter: 0; batch classifier loss: 21.211716; batch adversarial loss: 0.690402\n","epoch 22; iter: 0; batch classifier loss: 28.102959; batch adversarial loss: 0.694908\n","epoch 23; iter: 0; batch classifier loss: 30.890427; batch adversarial loss: 0.674068\n","epoch 24; iter: 0; batch classifier loss: 24.508293; batch adversarial loss: 0.674235\n","epoch 25; iter: 0; batch classifier loss: 26.151592; batch adversarial loss: 0.667321\n","epoch 26; iter: 0; batch classifier loss: 31.578926; batch adversarial loss: 0.671295\n","epoch 27; iter: 0; batch classifier loss: 29.375191; batch adversarial loss: 0.676195\n","epoch 28; iter: 0; batch classifier loss: 39.270725; batch adversarial loss: 0.673973\n","epoch 29; iter: 0; batch classifier loss: 24.520910; batch adversarial loss: 0.672292\n","epoch 30; iter: 0; batch classifier loss: 24.694057; batch adversarial loss: 0.664992\n","epoch 31; iter: 0; batch classifier loss: 29.520031; batch adversarial loss: 0.660421\n","epoch 32; iter: 0; batch classifier loss: 20.316347; batch adversarial loss: 0.650431\n","epoch 33; iter: 0; batch classifier loss: 29.086359; batch adversarial loss: 0.640442\n","epoch 34; iter: 0; batch classifier loss: 20.346201; batch adversarial loss: 0.650570\n","epoch 35; iter: 0; batch classifier loss: 25.048565; batch adversarial loss: 0.631809\n","epoch 36; iter: 0; batch classifier loss: 22.820526; batch adversarial loss: 0.636815\n","epoch 37; iter: 0; batch classifier loss: 36.543854; batch adversarial loss: 0.636674\n","epoch 38; iter: 0; batch classifier loss: 25.059010; batch adversarial loss: 0.631682\n","epoch 39; iter: 0; batch classifier loss: 37.270538; batch adversarial loss: 0.628559\n","epoch 40; iter: 0; batch classifier loss: 24.219910; batch adversarial loss: 0.633209\n","epoch 41; iter: 0; batch classifier loss: 19.445065; batch adversarial loss: 0.636863\n","epoch 42; iter: 0; batch classifier loss: 15.235590; batch adversarial loss: 0.634168\n","epoch 43; iter: 0; batch classifier loss: 21.113300; batch adversarial loss: 0.627051\n","epoch 44; iter: 0; batch classifier loss: 15.237448; batch adversarial loss: 0.621586\n","epoch 45; iter: 0; batch classifier loss: 14.833755; batch adversarial loss: 0.620141\n","epoch 46; iter: 0; batch classifier loss: 19.912266; batch adversarial loss: 0.616289\n","epoch 47; iter: 0; batch classifier loss: 17.563164; batch adversarial loss: 0.619615\n","epoch 48; iter: 0; batch classifier loss: 13.572029; batch adversarial loss: 0.608457\n","epoch 49; iter: 0; batch classifier loss: 15.051825; batch adversarial loss: 0.627807\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.685\n","epoch 0; iter: 0; batch classifier loss: 151.888260; batch adversarial loss: 0.520474\n","epoch 1; iter: 0; batch classifier loss: 148.583420; batch adversarial loss: 0.491856\n","epoch 2; iter: 0; batch classifier loss: 62.896580; batch adversarial loss: 0.559929\n","epoch 3; iter: 0; batch classifier loss: 50.405495; batch adversarial loss: 0.670577\n","epoch 4; iter: 0; batch classifier loss: 50.295635; batch adversarial loss: 0.662839\n","epoch 5; iter: 0; batch classifier loss: 61.929539; batch adversarial loss: 0.648831\n","epoch 6; iter: 0; batch classifier loss: 40.366241; batch adversarial loss: 0.618281\n","epoch 7; iter: 0; batch classifier loss: 50.096088; batch adversarial loss: 0.612219\n","epoch 8; iter: 0; batch classifier loss: 60.109161; batch adversarial loss: 0.599994\n","epoch 9; iter: 0; batch classifier loss: 44.616871; batch adversarial loss: 0.577381\n","epoch 10; iter: 0; batch classifier loss: 53.251205; batch adversarial loss: 0.609892\n","epoch 11; iter: 0; batch classifier loss: 47.509426; batch adversarial loss: 0.616517\n","epoch 12; iter: 0; batch classifier loss: 37.060860; batch adversarial loss: 0.627761\n","epoch 13; iter: 0; batch classifier loss: 37.612167; batch adversarial loss: 0.600274\n","epoch 14; iter: 0; batch classifier loss: 42.220577; batch adversarial loss: 0.591709\n","epoch 15; iter: 0; batch classifier loss: 51.014194; batch adversarial loss: 0.590720\n","epoch 16; iter: 0; batch classifier loss: 53.607346; batch adversarial loss: 0.569345\n","epoch 17; iter: 0; batch classifier loss: 38.915222; batch adversarial loss: 0.564583\n","epoch 18; iter: 0; batch classifier loss: 36.579659; batch adversarial loss: 0.587448\n","epoch 19; iter: 0; batch classifier loss: 29.816555; batch adversarial loss: 0.586741\n","epoch 20; iter: 0; batch classifier loss: 27.960831; batch adversarial loss: 0.584158\n","epoch 21; iter: 0; batch classifier loss: 31.242455; batch adversarial loss: 0.584577\n","epoch 22; iter: 0; batch classifier loss: 30.878815; batch adversarial loss: 0.539326\n","epoch 23; iter: 0; batch classifier loss: 40.433609; batch adversarial loss: 0.602625\n","epoch 24; iter: 0; batch classifier loss: 30.142736; batch adversarial loss: 0.609368\n","epoch 25; iter: 0; batch classifier loss: 35.135300; batch adversarial loss: 0.528724\n","epoch 26; iter: 0; batch classifier loss: 36.706528; batch adversarial loss: 0.534179\n","epoch 27; iter: 0; batch classifier loss: 35.712429; batch adversarial loss: 0.549075\n","epoch 28; iter: 0; batch classifier loss: 31.114977; batch adversarial loss: 0.590358\n","epoch 29; iter: 0; batch classifier loss: 26.352333; batch adversarial loss: 0.542120\n","epoch 30; iter: 0; batch classifier loss: 30.063927; batch adversarial loss: 0.530084\n","epoch 31; iter: 0; batch classifier loss: 21.969971; batch adversarial loss: 0.586409\n","epoch 32; iter: 0; batch classifier loss: 26.094311; batch adversarial loss: 0.600639\n","epoch 33; iter: 0; batch classifier loss: 20.006224; batch adversarial loss: 0.591847\n","epoch 34; iter: 0; batch classifier loss: 21.846695; batch adversarial loss: 0.546944\n","epoch 35; iter: 0; batch classifier loss: 20.492188; batch adversarial loss: 0.567714\n","epoch 36; iter: 0; batch classifier loss: 25.135262; batch adversarial loss: 0.557220\n","epoch 37; iter: 0; batch classifier loss: 17.996460; batch adversarial loss: 0.530923\n","epoch 38; iter: 0; batch classifier loss: 17.809753; batch adversarial loss: 0.519809\n","epoch 39; iter: 0; batch classifier loss: 16.422577; batch adversarial loss: 0.559745\n","epoch 40; iter: 0; batch classifier loss: 15.384907; batch adversarial loss: 0.585529\n","epoch 41; iter: 0; batch classifier loss: 17.146082; batch adversarial loss: 0.514008\n","epoch 42; iter: 0; batch classifier loss: 15.549939; batch adversarial loss: 0.530913\n","epoch 43; iter: 0; batch classifier loss: 13.424551; batch adversarial loss: 0.570235\n","epoch 44; iter: 0; batch classifier loss: 15.246107; batch adversarial loss: 0.540903\n","epoch 45; iter: 0; batch classifier loss: 8.168281; batch adversarial loss: 0.550930\n","epoch 46; iter: 0; batch classifier loss: 13.282644; batch adversarial loss: 0.546552\n","epoch 47; iter: 0; batch classifier loss: 6.695164; batch adversarial loss: 0.523782\n","epoch 48; iter: 0; batch classifier loss: 12.325645; batch adversarial loss: 0.563929\n","epoch 49; iter: 0; batch classifier loss: 10.248976; batch adversarial loss: 0.531631\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.705\n","epoch 0; iter: 0; batch classifier loss: 95.225632; batch adversarial loss: 0.587021\n","epoch 1; iter: 0; batch classifier loss: 77.828842; batch adversarial loss: 0.607133\n","epoch 2; iter: 0; batch classifier loss: 48.499573; batch adversarial loss: 0.635981\n","epoch 3; iter: 0; batch classifier loss: 48.500801; batch adversarial loss: 0.614274\n","epoch 4; iter: 0; batch classifier loss: 49.227676; batch adversarial loss: 0.625979\n","epoch 5; iter: 0; batch classifier loss: 42.159218; batch adversarial loss: 0.616247\n","epoch 6; iter: 0; batch classifier loss: 47.984398; batch adversarial loss: 0.619082\n","epoch 7; iter: 0; batch classifier loss: 60.153114; batch adversarial loss: 0.595416\n","epoch 8; iter: 0; batch classifier loss: 41.540367; batch adversarial loss: 0.618214\n","epoch 9; iter: 0; batch classifier loss: 36.853340; batch adversarial loss: 0.637085\n","epoch 10; iter: 0; batch classifier loss: 38.274994; batch adversarial loss: 0.623467\n","epoch 11; iter: 0; batch classifier loss: 51.262962; batch adversarial loss: 0.605956\n","epoch 12; iter: 0; batch classifier loss: 25.986763; batch adversarial loss: 0.589380\n","epoch 13; iter: 0; batch classifier loss: 33.795166; batch adversarial loss: 0.583588\n","epoch 14; iter: 0; batch classifier loss: 37.931229; batch adversarial loss: 0.610269\n","epoch 15; iter: 0; batch classifier loss: 39.176994; batch adversarial loss: 0.561894\n","epoch 16; iter: 0; batch classifier loss: 22.054253; batch adversarial loss: 0.599265\n","epoch 17; iter: 0; batch classifier loss: 28.005215; batch adversarial loss: 0.556356\n","epoch 18; iter: 0; batch classifier loss: 28.443756; batch adversarial loss: 0.611192\n","epoch 19; iter: 0; batch classifier loss: 32.837105; batch adversarial loss: 0.633841\n","epoch 20; iter: 0; batch classifier loss: 35.721909; batch adversarial loss: 0.642237\n","epoch 21; iter: 0; batch classifier loss: 28.727997; batch adversarial loss: 0.576757\n","epoch 22; iter: 0; batch classifier loss: 33.764503; batch adversarial loss: 0.610336\n","epoch 23; iter: 0; batch classifier loss: 36.949535; batch adversarial loss: 0.627946\n","epoch 24; iter: 0; batch classifier loss: 32.574768; batch adversarial loss: 0.632104\n","epoch 25; iter: 0; batch classifier loss: 21.071825; batch adversarial loss: 0.610901\n","epoch 26; iter: 0; batch classifier loss: 19.893013; batch adversarial loss: 0.539422\n","epoch 27; iter: 0; batch classifier loss: 18.467817; batch adversarial loss: 0.530503\n","epoch 28; iter: 0; batch classifier loss: 16.119337; batch adversarial loss: 0.584544\n","epoch 29; iter: 0; batch classifier loss: 20.748337; batch adversarial loss: 0.612405\n","epoch 30; iter: 0; batch classifier loss: 17.131783; batch adversarial loss: 0.594633\n","epoch 31; iter: 0; batch classifier loss: 17.474442; batch adversarial loss: 0.579575\n","epoch 32; iter: 0; batch classifier loss: 17.334846; batch adversarial loss: 0.552227\n","epoch 33; iter: 0; batch classifier loss: 14.929632; batch adversarial loss: 0.561470\n","epoch 34; iter: 0; batch classifier loss: 10.970970; batch adversarial loss: 0.577011\n","epoch 35; iter: 0; batch classifier loss: 13.049742; batch adversarial loss: 0.571328\n","epoch 36; iter: 0; batch classifier loss: 9.975882; batch adversarial loss: 0.582135\n","epoch 37; iter: 0; batch classifier loss: 8.514982; batch adversarial loss: 0.529562\n","epoch 38; iter: 0; batch classifier loss: 11.195105; batch adversarial loss: 0.608385\n","epoch 39; iter: 0; batch classifier loss: 12.133714; batch adversarial loss: 0.569368\n","epoch 40; iter: 0; batch classifier loss: 11.434984; batch adversarial loss: 0.594624\n","epoch 41; iter: 0; batch classifier loss: 7.664112; batch adversarial loss: 0.610708\n","epoch 42; iter: 0; batch classifier loss: 9.034712; batch adversarial loss: 0.556595\n","epoch 43; iter: 0; batch classifier loss: 9.192375; batch adversarial loss: 0.543876\n","epoch 44; iter: 0; batch classifier loss: 9.851342; batch adversarial loss: 0.557492\n","epoch 45; iter: 0; batch classifier loss: 7.037615; batch adversarial loss: 0.507962\n","epoch 46; iter: 0; batch classifier loss: 5.961335; batch adversarial loss: 0.625023\n","epoch 47; iter: 0; batch classifier loss: 8.045427; batch adversarial loss: 0.612425\n","epoch 48; iter: 0; batch classifier loss: 8.656252; batch adversarial loss: 0.462255\n","epoch 49; iter: 0; batch classifier loss: 5.899729; batch adversarial loss: 0.481582\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.73\n"],"name":"stdout"}]}]}