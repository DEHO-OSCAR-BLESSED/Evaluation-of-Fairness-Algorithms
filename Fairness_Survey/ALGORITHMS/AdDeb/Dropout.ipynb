{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dropout.ipynb","provenance":[{"file_id":"1-ar5jhY8kGUSwnnZRMZsNOt02wwgn6dV","timestamp":1629951162272},{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"authorship_tag":"ABX9TyN+6niDH3rK6wp5lUypBFvJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5qYRG8zufHw","executionInfo":{"status":"ok","timestamp":1629956373709,"user_tz":-570,"elapsed":13420,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"41409918-eb7f-49b3-ef07-bc74c9629312"},"source":["!pip install aif360\n","!pip install fairlearn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting aif360\n","  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 41.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 29.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n","Collecting tempeh\n","  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n","Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.3.1)\n","Collecting memory-profiler\n","  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 56.2 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (21.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.8.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.10.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.62.0)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.34.0)\n","Building wheels for collected packages: memory-profiler, shap\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=20305dbaaf970c75680eb85b5ae3b158d3011bb443645eceded2b2969aced0e9\n","  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491646 sha256=97fc7e387d7f8d805e838e31248d22c13b313ad72ed544f3212ec98b525925b5\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built memory-profiler shap\n","Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n","Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n","Collecting fairlearn\n","  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 38.7 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n","Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\n","Installing collected packages: fairlearn\n","Successfully installed fairlearn-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TltW3iPkux0Q","executionInfo":{"status":"ok","timestamp":1629956374884,"user_tz":-570,"elapsed":1253,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"0c3917dd-4999-400a-c740-e1fa83702c13"},"source":["!apt-get install -jre\n","!java -version"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Command line option 'j' [from -jre] is not understood in combination with the other options.\n","openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KssrNl8GvDYU","executionInfo":{"status":"ok","timestamp":1629956404502,"user_tz":-570,"elapsed":29654,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"62a32618-21b2-4933-9243-29c25b42936b"},"source":["!pip install h2o"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting h2o\n","  Downloading h2o-3.32.1.6.tar.gz (168.4 MB)\n","\u001b[K     |████████████████████████████████| 168.4 MB 57 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n","Collecting colorama>=0.3.8\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2021.5.30)\n","Building wheels for collected packages: h2o\n","  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for h2o: filename=h2o-3.32.1.6-py2.py3-none-any.whl size=168439194 sha256=0f921e05c010adc93bd0bd108f6300f91235817be89590077aadfe9ca5c8dc9a\n","  Stored in directory: /root/.cache/pip/wheels/ee/0f/51/849ba221c4c1b11a04efb4a3427dc9cb1c4dcde218c6c98b13\n","Successfully built h2o\n","Installing collected packages: colorama, h2o\n","Successfully installed colorama-0.4.4 h2o-3.32.1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NQn2JJ0uw6u","executionInfo":{"status":"ok","timestamp":1629956407410,"user_tz":-570,"elapsed":3008,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"328a87f0-e799-4bb8-f529-7cbd6750032a"},"source":["!pip install xlsxwriter"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n","\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 40 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 40.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71 kB 40.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 81 kB 36.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 92 kB 38.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 112 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 122 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 133 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 143 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 148 kB 40.5 MB/s \n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0YklbHpAxd8","executionInfo":{"status":"ok","timestamp":1629956412414,"user_tz":-570,"elapsed":5055,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"5224874a-72ad-4532-ad1c-b4c23471c89a"},"source":["!pip install BlackBoxAuditing"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting BlackBoxAuditing\n","  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n","\u001b[?25l\r\u001b[K     |▏                               | 10 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |▎                               | 20 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 30 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 40 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 51 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 61 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 81 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 112 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 122 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 133 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 143 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 153 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 163 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 174 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 184 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 194 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 204 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 215 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 225 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 235 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 245 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 256 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 266 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 276 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 286 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 296 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 307 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 317 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 327 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 337 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 348 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 358 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 368 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 378 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 389 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 399 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 409 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 419 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 430 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 440 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 450 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 460 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 471 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 481 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 491 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 501 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 512 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 522 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 532 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 542 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 552 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 563 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 573 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 583 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 593 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 604 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 614 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 624 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 634 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 645 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 655 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 665 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 675 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 686 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 696 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 706 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 716 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 727 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 737 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 747 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 757 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 768 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 778 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 788 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 798 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 808 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 819 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 829 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 839 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 849 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 860 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 870 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 880 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 890 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 901 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 911 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 921 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 931 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 942 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 952 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 962 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 972 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 983 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 993 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.7 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.8 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.4 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.5 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.6 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.6 MB 29.5 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->BlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n","Building wheels for collected packages: BlackBoxAuditing\n","  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394771 sha256=a8d38474d290b12de0ddf7b71d1713de9b8b8cf099abb83f3a951f6292e5cb52\n","  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n","Successfully built BlackBoxAuditing\n","Installing collected packages: BlackBoxAuditing\n","Successfully installed BlackBoxAuditing-0.1.54\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","metadata":{"id":"rf1aISz6vGfR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629956422441,"user_tz":-570,"elapsed":10057,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"d636ecfd-c212-4657-ca4d-0977839694b6"},"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover, MetaFairClassifier, AdversarialDebiasing\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","import h2o\n","from h2o.automl import H2OAutoML\n","from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"RcxQeeX7vUXz","executionInfo":{"status":"ok","timestamp":1629956429124,"user_tz":-570,"elapsed":6761,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"0e8ac434-4f22-4b0d-d931-f52c8240e564"},"source":["h2o.init()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n","Attempting to start a local H2O server...\n","  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n","  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n","  Ice root: /tmp/tmpn5o1lkcs\n","  JVM stdout: /tmp/tmpn5o1lkcs/h2o_unknownUser_started_from_python.out\n","  JVM stderr: /tmp/tmpn5o1lkcs/h2o_unknownUser_started_from_python.err\n","  Server is running at http://127.0.0.1:54321\n","Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n","<td>03 secs</td></tr>\n","<tr><td>H2O_cluster_timezone:</td>\n","<td>Etc/UTC</td></tr>\n","<tr><td>H2O_data_parsing_timezone:</td>\n","<td>UTC</td></tr>\n","<tr><td>H2O_cluster_version:</td>\n","<td>3.32.1.6</td></tr>\n","<tr><td>H2O_cluster_version_age:</td>\n","<td>6 days </td></tr>\n","<tr><td>H2O_cluster_name:</td>\n","<td>H2O_from_python_unknownUser_csb13y</td></tr>\n","<tr><td>H2O_cluster_total_nodes:</td>\n","<td>1</td></tr>\n","<tr><td>H2O_cluster_free_memory:</td>\n","<td>3.172 Gb</td></tr>\n","<tr><td>H2O_cluster_total_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_allowed_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_status:</td>\n","<td>accepting new members, healthy</td></tr>\n","<tr><td>H2O_connection_url:</td>\n","<td>http://127.0.0.1:54321</td></tr>\n","<tr><td>H2O_connection_proxy:</td>\n","<td>{\"http\": null, \"https\": null}</td></tr>\n","<tr><td>H2O_internal_security:</td>\n","<td>False</td></tr>\n","<tr><td>H2O_API_Extensions:</td>\n","<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n","<tr><td>Python_version:</td>\n","<td>3.7.11 final</td></tr></table></div>"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O_cluster_uptime:         03 secs\n","H2O_cluster_timezone:       Etc/UTC\n","H2O_data_parsing_timezone:  UTC\n","H2O_cluster_version:        3.32.1.6\n","H2O_cluster_version_age:    6 days\n","H2O_cluster_name:           H2O_from_python_unknownUser_csb13y\n","H2O_cluster_total_nodes:    1\n","H2O_cluster_free_memory:    3.172 Gb\n","H2O_cluster_total_cores:    2\n","H2O_cluster_allowed_cores:  2\n","H2O_cluster_status:         accepting new members, healthy\n","H2O_connection_url:         http://127.0.0.1:54321\n","H2O_connection_proxy:       {\"http\": null, \"https\": null}\n","H2O_internal_security:      False\n","H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python_version:             3.7.11 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEGPULDrvk3g","executionInfo":{"status":"ok","timestamp":1629956495260,"user_tz":-570,"elapsed":66161,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"259db847-371a-4b1b-81ac-566b18867ac7"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# AdDeb\n","\n"]},{"cell_type":"code","metadata":{"id":"H21cadne_1oh","executionInfo":{"status":"ok","timestamp":1629957232454,"user_tz":-570,"elapsed":9,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["#initialize Tf\n","sess = tf.Session() #initialize Tf"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uN9VfZBAvxCj","executionInfo":{"status":"ok","timestamp":1629957384816,"user_tz":-570,"elapsed":152039,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"8e72ed84-5469-4dd5-afb8-3bbf6feaf88d"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['CAREER_TERM_YEAR', 'STUDENT_KEY'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['CAREER_TERM_YEAR', 'STUDENT_KEY'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  Fitter= MM.fit(train)\n","  transformed_train=Fitter.transform(train)\n","  train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  #test normalization\n","  transformed_test=Fitter.transform(test)\n","  test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** AdDeb Classifier regularizer*****************************\n","  \n","  sess.close() # This closse would close the previous iteration  and start a new session for the current iteration\n","  tf.reset_default_graph()\n","  sess = tf.Session()\n","  Classifier = AdversarialDebiasing(privileged_groups = advantagedGroup,\n","                          unprivileged_groups = disadvantagedGroup,\n","                          scope_name='debiased_classifier',\n","                          debias=True,\n","                          sess=sess)\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/AdDeb/AdDeb.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/AdDeb/AdDeb.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","epoch 0; iter: 0; batch classifier loss: 0.705487; batch adversarial loss: 0.694590\n","epoch 1; iter: 0; batch classifier loss: 0.678624; batch adversarial loss: 0.694554\n","epoch 2; iter: 0; batch classifier loss: 0.673452; batch adversarial loss: 0.690017\n","epoch 3; iter: 0; batch classifier loss: 0.649508; batch adversarial loss: 0.690915\n","epoch 4; iter: 0; batch classifier loss: 0.664835; batch adversarial loss: 0.677316\n","epoch 5; iter: 0; batch classifier loss: 0.639324; batch adversarial loss: 0.680447\n","epoch 6; iter: 0; batch classifier loss: 0.617566; batch adversarial loss: 0.678043\n","epoch 7; iter: 0; batch classifier loss: 0.594215; batch adversarial loss: 0.675188\n","epoch 8; iter: 0; batch classifier loss: 0.589604; batch adversarial loss: 0.671977\n","epoch 9; iter: 0; batch classifier loss: 0.565371; batch adversarial loss: 0.668423\n","epoch 10; iter: 0; batch classifier loss: 0.567535; batch adversarial loss: 0.668859\n","epoch 11; iter: 0; batch classifier loss: 0.547340; batch adversarial loss: 0.662051\n","epoch 12; iter: 0; batch classifier loss: 0.548917; batch adversarial loss: 0.659781\n","epoch 13; iter: 0; batch classifier loss: 0.546197; batch adversarial loss: 0.662572\n","epoch 14; iter: 0; batch classifier loss: 0.533201; batch adversarial loss: 0.656192\n","epoch 15; iter: 0; batch classifier loss: 0.502303; batch adversarial loss: 0.653736\n","epoch 16; iter: 0; batch classifier loss: 0.531815; batch adversarial loss: 0.656354\n","epoch 17; iter: 0; batch classifier loss: 0.494092; batch adversarial loss: 0.651115\n","epoch 18; iter: 0; batch classifier loss: 0.489246; batch adversarial loss: 0.641314\n","epoch 19; iter: 0; batch classifier loss: 0.475382; batch adversarial loss: 0.639216\n","epoch 20; iter: 0; batch classifier loss: 0.514577; batch adversarial loss: 0.644553\n","epoch 21; iter: 0; batch classifier loss: 0.471655; batch adversarial loss: 0.640016\n","epoch 22; iter: 0; batch classifier loss: 0.503769; batch adversarial loss: 0.637210\n","epoch 23; iter: 0; batch classifier loss: 0.463198; batch adversarial loss: 0.625938\n","epoch 24; iter: 0; batch classifier loss: 0.494637; batch adversarial loss: 0.637708\n","epoch 25; iter: 0; batch classifier loss: 0.480374; batch adversarial loss: 0.630283\n","epoch 26; iter: 0; batch classifier loss: 0.517279; batch adversarial loss: 0.616695\n","epoch 27; iter: 0; batch classifier loss: 0.485874; batch adversarial loss: 0.622329\n","epoch 28; iter: 0; batch classifier loss: 0.514771; batch adversarial loss: 0.623790\n","epoch 29; iter: 0; batch classifier loss: 0.500922; batch adversarial loss: 0.621148\n","epoch 30; iter: 0; batch classifier loss: 0.497385; batch adversarial loss: 0.617269\n","epoch 31; iter: 0; batch classifier loss: 0.456064; batch adversarial loss: 0.619396\n","epoch 32; iter: 0; batch classifier loss: 0.470016; batch adversarial loss: 0.611579\n","epoch 33; iter: 0; batch classifier loss: 0.434208; batch adversarial loss: 0.618969\n","epoch 34; iter: 0; batch classifier loss: 0.503139; batch adversarial loss: 0.600880\n","epoch 35; iter: 0; batch classifier loss: 0.474393; batch adversarial loss: 0.607184\n","epoch 36; iter: 0; batch classifier loss: 0.445709; batch adversarial loss: 0.609452\n","epoch 37; iter: 0; batch classifier loss: 0.498395; batch adversarial loss: 0.609998\n","epoch 38; iter: 0; batch classifier loss: 0.479930; batch adversarial loss: 0.609708\n","epoch 39; iter: 0; batch classifier loss: 0.442672; batch adversarial loss: 0.614927\n","epoch 40; iter: 0; batch classifier loss: 0.504157; batch adversarial loss: 0.609696\n","epoch 41; iter: 0; batch classifier loss: 0.518687; batch adversarial loss: 0.620138\n","epoch 42; iter: 0; batch classifier loss: 0.452707; batch adversarial loss: 0.599602\n","epoch 43; iter: 0; batch classifier loss: 0.514678; batch adversarial loss: 0.594603\n","epoch 44; iter: 0; batch classifier loss: 0.375015; batch adversarial loss: 0.584528\n","epoch 45; iter: 0; batch classifier loss: 0.417360; batch adversarial loss: 0.587601\n","epoch 46; iter: 0; batch classifier loss: 0.480551; batch adversarial loss: 0.596133\n","epoch 47; iter: 0; batch classifier loss: 0.463049; batch adversarial loss: 0.577899\n","epoch 48; iter: 0; batch classifier loss: 0.464572; batch adversarial loss: 0.597303\n","epoch 49; iter: 0; batch classifier loss: 0.516143; batch adversarial loss: 0.611774\n","Accuracy 0.7338129496402878\n","epoch 0; iter: 0; batch classifier loss: 0.745861; batch adversarial loss: 0.653405\n","epoch 1; iter: 0; batch classifier loss: 0.713582; batch adversarial loss: 0.675178\n","epoch 2; iter: 0; batch classifier loss: 0.678668; batch adversarial loss: 0.656005\n","epoch 3; iter: 0; batch classifier loss: 0.658206; batch adversarial loss: 0.649207\n","epoch 4; iter: 0; batch classifier loss: 0.637203; batch adversarial loss: 0.645193\n","epoch 5; iter: 0; batch classifier loss: 0.633199; batch adversarial loss: 0.647058\n","epoch 6; iter: 0; batch classifier loss: 0.636905; batch adversarial loss: 0.646443\n","epoch 7; iter: 0; batch classifier loss: 0.612345; batch adversarial loss: 0.656925\n","epoch 8; iter: 0; batch classifier loss: 0.610108; batch adversarial loss: 0.646010\n","epoch 9; iter: 0; batch classifier loss: 0.598843; batch adversarial loss: 0.667145\n","epoch 10; iter: 0; batch classifier loss: 0.578001; batch adversarial loss: 0.641546\n","epoch 11; iter: 0; batch classifier loss: 0.558948; batch adversarial loss: 0.629900\n","epoch 12; iter: 0; batch classifier loss: 0.553034; batch adversarial loss: 0.648866\n","epoch 13; iter: 0; batch classifier loss: 0.563200; batch adversarial loss: 0.652336\n","epoch 14; iter: 0; batch classifier loss: 0.538768; batch adversarial loss: 0.640163\n","epoch 15; iter: 0; batch classifier loss: 0.555257; batch adversarial loss: 0.632051\n","epoch 16; iter: 0; batch classifier loss: 0.540236; batch adversarial loss: 0.638809\n","epoch 17; iter: 0; batch classifier loss: 0.523207; batch adversarial loss: 0.634158\n","epoch 18; iter: 0; batch classifier loss: 0.599527; batch adversarial loss: 0.673666\n","epoch 19; iter: 0; batch classifier loss: 0.514696; batch adversarial loss: 0.640132\n","epoch 20; iter: 0; batch classifier loss: 0.552506; batch adversarial loss: 0.619135\n","epoch 21; iter: 0; batch classifier loss: 0.511108; batch adversarial loss: 0.626001\n","epoch 22; iter: 0; batch classifier loss: 0.591410; batch adversarial loss: 0.615680\n","epoch 23; iter: 0; batch classifier loss: 0.538949; batch adversarial loss: 0.642472\n","epoch 24; iter: 0; batch classifier loss: 0.551364; batch adversarial loss: 0.605758\n","epoch 25; iter: 0; batch classifier loss: 0.508936; batch adversarial loss: 0.615538\n","epoch 26; iter: 0; batch classifier loss: 0.484491; batch adversarial loss: 0.630091\n","epoch 27; iter: 0; batch classifier loss: 0.535391; batch adversarial loss: 0.636311\n","epoch 28; iter: 0; batch classifier loss: 0.501631; batch adversarial loss: 0.601191\n","epoch 29; iter: 0; batch classifier loss: 0.559920; batch adversarial loss: 0.644544\n","epoch 30; iter: 0; batch classifier loss: 0.562732; batch adversarial loss: 0.614968\n","epoch 31; iter: 0; batch classifier loss: 0.489507; batch adversarial loss: 0.649452\n","epoch 32; iter: 0; batch classifier loss: 0.526447; batch adversarial loss: 0.601361\n","epoch 33; iter: 0; batch classifier loss: 0.541452; batch adversarial loss: 0.627232\n","epoch 34; iter: 0; batch classifier loss: 0.457563; batch adversarial loss: 0.589185\n","epoch 35; iter: 0; batch classifier loss: 0.468620; batch adversarial loss: 0.607078\n","epoch 36; iter: 0; batch classifier loss: 0.529969; batch adversarial loss: 0.606476\n","epoch 37; iter: 0; batch classifier loss: 0.564819; batch adversarial loss: 0.603705\n","epoch 38; iter: 0; batch classifier loss: 0.554714; batch adversarial loss: 0.660173\n","epoch 39; iter: 0; batch classifier loss: 0.511904; batch adversarial loss: 0.607006\n","epoch 40; iter: 0; batch classifier loss: 0.501754; batch adversarial loss: 0.650907\n","epoch 41; iter: 0; batch classifier loss: 0.494022; batch adversarial loss: 0.604151\n","epoch 42; iter: 0; batch classifier loss: 0.542120; batch adversarial loss: 0.588347\n","epoch 43; iter: 0; batch classifier loss: 0.471573; batch adversarial loss: 0.636321\n","epoch 44; iter: 0; batch classifier loss: 0.534163; batch adversarial loss: 0.656159\n","epoch 45; iter: 0; batch classifier loss: 0.534483; batch adversarial loss: 0.644627\n","epoch 46; iter: 0; batch classifier loss: 0.549985; batch adversarial loss: 0.634093\n","epoch 47; iter: 0; batch classifier loss: 0.509644; batch adversarial loss: 0.602314\n","epoch 48; iter: 0; batch classifier loss: 0.523523; batch adversarial loss: 0.621478\n","epoch 49; iter: 0; batch classifier loss: 0.478324; batch adversarial loss: 0.628029\n","Accuracy 0.6690647482014388\n","epoch 0; iter: 0; batch classifier loss: 0.684951; batch adversarial loss: 0.784664\n","epoch 1; iter: 0; batch classifier loss: 0.654808; batch adversarial loss: 0.773795\n","epoch 2; iter: 0; batch classifier loss: 0.641427; batch adversarial loss: 0.776624\n","epoch 3; iter: 0; batch classifier loss: 0.623122; batch adversarial loss: 0.781128\n","epoch 4; iter: 0; batch classifier loss: 0.582430; batch adversarial loss: 0.778976\n","epoch 5; iter: 0; batch classifier loss: 0.587980; batch adversarial loss: 0.773623\n","epoch 6; iter: 0; batch classifier loss: 0.555682; batch adversarial loss: 0.774099\n","epoch 7; iter: 0; batch classifier loss: 0.576898; batch adversarial loss: 0.767433\n","epoch 8; iter: 0; batch classifier loss: 0.556199; batch adversarial loss: 0.757836\n","epoch 9; iter: 0; batch classifier loss: 0.545225; batch adversarial loss: 0.757642\n","epoch 10; iter: 0; batch classifier loss: 0.561673; batch adversarial loss: 0.762400\n","epoch 11; iter: 0; batch classifier loss: 0.535906; batch adversarial loss: 0.751997\n","epoch 12; iter: 0; batch classifier loss: 0.525287; batch adversarial loss: 0.753880\n","epoch 13; iter: 0; batch classifier loss: 0.551115; batch adversarial loss: 0.739578\n","epoch 14; iter: 0; batch classifier loss: 0.506083; batch adversarial loss: 0.741151\n","epoch 15; iter: 0; batch classifier loss: 0.537020; batch adversarial loss: 0.751022\n","epoch 16; iter: 0; batch classifier loss: 0.497098; batch adversarial loss: 0.744808\n","epoch 17; iter: 0; batch classifier loss: 0.472808; batch adversarial loss: 0.747710\n","epoch 18; iter: 0; batch classifier loss: 0.466024; batch adversarial loss: 0.744351\n","epoch 19; iter: 0; batch classifier loss: 0.532761; batch adversarial loss: 0.729051\n","epoch 20; iter: 0; batch classifier loss: 0.514565; batch adversarial loss: 0.730894\n","epoch 21; iter: 0; batch classifier loss: 0.429629; batch adversarial loss: 0.731402\n","epoch 22; iter: 0; batch classifier loss: 0.499905; batch adversarial loss: 0.722708\n","epoch 23; iter: 0; batch classifier loss: 0.499561; batch adversarial loss: 0.724230\n","epoch 24; iter: 0; batch classifier loss: 0.479040; batch adversarial loss: 0.729590\n","epoch 25; iter: 0; batch classifier loss: 0.464739; batch adversarial loss: 0.722914\n","epoch 26; iter: 0; batch classifier loss: 0.512414; batch adversarial loss: 0.704250\n","epoch 27; iter: 0; batch classifier loss: 0.470755; batch adversarial loss: 0.715261\n","epoch 28; iter: 0; batch classifier loss: 0.493863; batch adversarial loss: 0.712396\n","epoch 29; iter: 0; batch classifier loss: 0.458678; batch adversarial loss: 0.713221\n","epoch 30; iter: 0; batch classifier loss: 0.513161; batch adversarial loss: 0.696772\n","epoch 31; iter: 0; batch classifier loss: 0.416681; batch adversarial loss: 0.704073\n","epoch 32; iter: 0; batch classifier loss: 0.455940; batch adversarial loss: 0.702176\n","epoch 33; iter: 0; batch classifier loss: 0.447603; batch adversarial loss: 0.695299\n","epoch 34; iter: 0; batch classifier loss: 0.461433; batch adversarial loss: 0.696385\n","epoch 35; iter: 0; batch classifier loss: 0.523029; batch adversarial loss: 0.686095\n","epoch 36; iter: 0; batch classifier loss: 0.413742; batch adversarial loss: 0.696792\n","epoch 37; iter: 0; batch classifier loss: 0.519256; batch adversarial loss: 0.683469\n","epoch 38; iter: 0; batch classifier loss: 0.465082; batch adversarial loss: 0.684789\n","epoch 39; iter: 0; batch classifier loss: 0.386101; batch adversarial loss: 0.678068\n","epoch 40; iter: 0; batch classifier loss: 0.480378; batch adversarial loss: 0.676548\n","epoch 41; iter: 0; batch classifier loss: 0.431488; batch adversarial loss: 0.676586\n","epoch 42; iter: 0; batch classifier loss: 0.506149; batch adversarial loss: 0.671230\n","epoch 43; iter: 0; batch classifier loss: 0.443591; batch adversarial loss: 0.674158\n","epoch 44; iter: 0; batch classifier loss: 0.472441; batch adversarial loss: 0.666536\n","epoch 45; iter: 0; batch classifier loss: 0.500407; batch adversarial loss: 0.675203\n","epoch 46; iter: 0; batch classifier loss: 0.502857; batch adversarial loss: 0.667551\n","epoch 47; iter: 0; batch classifier loss: 0.477416; batch adversarial loss: 0.664138\n","epoch 48; iter: 0; batch classifier loss: 0.403380; batch adversarial loss: 0.669227\n","epoch 49; iter: 0; batch classifier loss: 0.423607; batch adversarial loss: 0.662500\n","Accuracy 0.6594202898550725\n","epoch 0; iter: 0; batch classifier loss: 0.664309; batch adversarial loss: 0.839729\n","epoch 1; iter: 0; batch classifier loss: 0.654435; batch adversarial loss: 0.843391\n","epoch 2; iter: 0; batch classifier loss: 0.627715; batch adversarial loss: 0.887530\n","epoch 3; iter: 0; batch classifier loss: 0.628283; batch adversarial loss: 0.845478\n","epoch 4; iter: 0; batch classifier loss: 0.591393; batch adversarial loss: 0.896099\n","epoch 5; iter: 0; batch classifier loss: 0.565236; batch adversarial loss: 0.912010\n","epoch 6; iter: 0; batch classifier loss: 0.584198; batch adversarial loss: 0.876160\n","epoch 7; iter: 0; batch classifier loss: 0.538693; batch adversarial loss: 0.906833\n","epoch 8; iter: 0; batch classifier loss: 0.545271; batch adversarial loss: 0.892694\n","epoch 9; iter: 0; batch classifier loss: 0.536436; batch adversarial loss: 0.858312\n","epoch 10; iter: 0; batch classifier loss: 0.529733; batch adversarial loss: 0.906842\n","epoch 11; iter: 0; batch classifier loss: 0.536563; batch adversarial loss: 0.913062\n","epoch 12; iter: 0; batch classifier loss: 0.510435; batch adversarial loss: 0.893214\n","epoch 13; iter: 0; batch classifier loss: 0.481412; batch adversarial loss: 0.898274\n","epoch 14; iter: 0; batch classifier loss: 0.563618; batch adversarial loss: 0.864108\n","epoch 15; iter: 0; batch classifier loss: 0.506426; batch adversarial loss: 0.889899\n","epoch 16; iter: 0; batch classifier loss: 0.488677; batch adversarial loss: 0.890363\n","epoch 17; iter: 0; batch classifier loss: 0.492729; batch adversarial loss: 0.896453\n","epoch 18; iter: 0; batch classifier loss: 0.458787; batch adversarial loss: 0.865937\n","epoch 19; iter: 0; batch classifier loss: 0.468541; batch adversarial loss: 0.895293\n","epoch 20; iter: 0; batch classifier loss: 0.488267; batch adversarial loss: 0.905798\n","epoch 21; iter: 0; batch classifier loss: 0.449219; batch adversarial loss: 0.871854\n","epoch 22; iter: 0; batch classifier loss: 0.542676; batch adversarial loss: 0.810579\n","epoch 23; iter: 0; batch classifier loss: 0.495973; batch adversarial loss: 0.858727\n","epoch 24; iter: 0; batch classifier loss: 0.475239; batch adversarial loss: 0.868634\n","epoch 25; iter: 0; batch classifier loss: 0.475307; batch adversarial loss: 0.868517\n","epoch 26; iter: 0; batch classifier loss: 0.498909; batch adversarial loss: 0.845651\n","epoch 27; iter: 0; batch classifier loss: 0.497000; batch adversarial loss: 0.800287\n","epoch 28; iter: 0; batch classifier loss: 0.456979; batch adversarial loss: 0.810262\n","epoch 29; iter: 0; batch classifier loss: 0.511973; batch adversarial loss: 0.789529\n","epoch 30; iter: 0; batch classifier loss: 0.458353; batch adversarial loss: 0.795758\n","epoch 31; iter: 0; batch classifier loss: 0.496055; batch adversarial loss: 0.793977\n","epoch 32; iter: 0; batch classifier loss: 0.502125; batch adversarial loss: 0.818829\n","epoch 33; iter: 0; batch classifier loss: 0.427524; batch adversarial loss: 0.851380\n","epoch 34; iter: 0; batch classifier loss: 0.500404; batch adversarial loss: 0.816465\n","epoch 35; iter: 0; batch classifier loss: 0.484989; batch adversarial loss: 0.790611\n","epoch 36; iter: 0; batch classifier loss: 0.517079; batch adversarial loss: 0.800208\n","epoch 37; iter: 0; batch classifier loss: 0.414017; batch adversarial loss: 0.818165\n","epoch 38; iter: 0; batch classifier loss: 0.492252; batch adversarial loss: 0.830312\n","epoch 39; iter: 0; batch classifier loss: 0.489123; batch adversarial loss: 0.775023\n","epoch 40; iter: 0; batch classifier loss: 0.498521; batch adversarial loss: 0.772795\n","epoch 41; iter: 0; batch classifier loss: 0.491587; batch adversarial loss: 0.768819\n","epoch 42; iter: 0; batch classifier loss: 0.454582; batch adversarial loss: 0.769733\n","epoch 43; iter: 0; batch classifier loss: 0.453427; batch adversarial loss: 0.760833\n","epoch 44; iter: 0; batch classifier loss: 0.513571; batch adversarial loss: 0.780875\n","epoch 45; iter: 0; batch classifier loss: 0.470231; batch adversarial loss: 0.785263\n","epoch 46; iter: 0; batch classifier loss: 0.481793; batch adversarial loss: 0.746966\n","epoch 47; iter: 0; batch classifier loss: 0.473546; batch adversarial loss: 0.761221\n","epoch 48; iter: 0; batch classifier loss: 0.496799; batch adversarial loss: 0.768400\n","epoch 49; iter: 0; batch classifier loss: 0.446422; batch adversarial loss: 0.750204\n","Accuracy 0.7318840579710145\n","epoch 0; iter: 0; batch classifier loss: 0.728465; batch adversarial loss: 0.571475\n","epoch 1; iter: 0; batch classifier loss: 0.716999; batch adversarial loss: 0.584665\n","epoch 2; iter: 0; batch classifier loss: 0.691573; batch adversarial loss: 0.590438\n","epoch 3; iter: 0; batch classifier loss: 0.679243; batch adversarial loss: 0.570297\n","epoch 4; iter: 0; batch classifier loss: 0.651440; batch adversarial loss: 0.595325\n","epoch 5; iter: 0; batch classifier loss: 0.658994; batch adversarial loss: 0.546655\n","epoch 6; iter: 0; batch classifier loss: 0.648448; batch adversarial loss: 0.590515\n","epoch 7; iter: 0; batch classifier loss: 0.645809; batch adversarial loss: 0.583529\n","epoch 8; iter: 0; batch classifier loss: 0.657939; batch adversarial loss: 0.600083\n","epoch 9; iter: 0; batch classifier loss: 0.593235; batch adversarial loss: 0.600854\n","epoch 10; iter: 0; batch classifier loss: 0.644099; batch adversarial loss: 0.562334\n","epoch 11; iter: 0; batch classifier loss: 0.607134; batch adversarial loss: 0.636552\n","epoch 12; iter: 0; batch classifier loss: 0.639083; batch adversarial loss: 0.608100\n","epoch 13; iter: 0; batch classifier loss: 0.612664; batch adversarial loss: 0.657969\n","epoch 14; iter: 0; batch classifier loss: 0.677451; batch adversarial loss: 0.631140\n","epoch 15; iter: 0; batch classifier loss: 0.615780; batch adversarial loss: 0.618906\n","epoch 16; iter: 0; batch classifier loss: 0.645844; batch adversarial loss: 0.617690\n","epoch 17; iter: 0; batch classifier loss: 0.587271; batch adversarial loss: 0.610434\n","epoch 18; iter: 0; batch classifier loss: 0.622512; batch adversarial loss: 0.663152\n","epoch 19; iter: 0; batch classifier loss: 0.607761; batch adversarial loss: 0.625004\n","epoch 20; iter: 0; batch classifier loss: 0.644727; batch adversarial loss: 0.654000\n","epoch 21; iter: 0; batch classifier loss: 0.631960; batch adversarial loss: 0.609142\n","epoch 22; iter: 0; batch classifier loss: 0.629411; batch adversarial loss: 0.697670\n","epoch 23; iter: 0; batch classifier loss: 0.654531; batch adversarial loss: 0.666520\n","epoch 24; iter: 0; batch classifier loss: 0.711980; batch adversarial loss: 0.653657\n","epoch 25; iter: 0; batch classifier loss: 0.694284; batch adversarial loss: 0.590740\n","epoch 26; iter: 0; batch classifier loss: 0.649060; batch adversarial loss: 0.683964\n","epoch 27; iter: 0; batch classifier loss: 0.668640; batch adversarial loss: 0.666181\n","epoch 28; iter: 0; batch classifier loss: 0.711257; batch adversarial loss: 0.685952\n","epoch 29; iter: 0; batch classifier loss: 0.640744; batch adversarial loss: 0.710680\n","epoch 30; iter: 0; batch classifier loss: 0.686591; batch adversarial loss: 0.679020\n","epoch 31; iter: 0; batch classifier loss: 0.665997; batch adversarial loss: 0.708929\n","epoch 32; iter: 0; batch classifier loss: 0.646102; batch adversarial loss: 0.686639\n","epoch 33; iter: 0; batch classifier loss: 0.667956; batch adversarial loss: 0.665008\n","epoch 34; iter: 0; batch classifier loss: 0.665087; batch adversarial loss: 0.603378\n","epoch 35; iter: 0; batch classifier loss: 0.748105; batch adversarial loss: 0.706068\n","epoch 36; iter: 0; batch classifier loss: 0.756985; batch adversarial loss: 0.666252\n","epoch 37; iter: 0; batch classifier loss: 0.755706; batch adversarial loss: 0.619708\n","epoch 38; iter: 0; batch classifier loss: 0.730870; batch adversarial loss: 0.666124\n","epoch 39; iter: 0; batch classifier loss: 0.691980; batch adversarial loss: 0.654719\n","epoch 40; iter: 0; batch classifier loss: 0.815777; batch adversarial loss: 0.738008\n","epoch 41; iter: 0; batch classifier loss: 0.673424; batch adversarial loss: 0.644395\n","epoch 42; iter: 0; batch classifier loss: 0.777087; batch adversarial loss: 0.638766\n","epoch 43; iter: 0; batch classifier loss: 0.798553; batch adversarial loss: 0.682872\n","epoch 44; iter: 0; batch classifier loss: 0.850687; batch adversarial loss: 0.686927\n","epoch 45; iter: 0; batch classifier loss: 0.748149; batch adversarial loss: 0.737679\n","epoch 46; iter: 0; batch classifier loss: 0.814856; batch adversarial loss: 0.671066\n","epoch 47; iter: 0; batch classifier loss: 0.840524; batch adversarial loss: 0.631836\n","epoch 48; iter: 0; batch classifier loss: 0.844595; batch adversarial loss: 0.743111\n","epoch 49; iter: 0; batch classifier loss: 0.929505; batch adversarial loss: 0.685449\n","Accuracy 0.45652173913043476\n","epoch 0; iter: 0; batch classifier loss: 0.659085; batch adversarial loss: 0.721187\n","epoch 1; iter: 0; batch classifier loss: 0.690730; batch adversarial loss: 0.692235\n","epoch 2; iter: 0; batch classifier loss: 0.620737; batch adversarial loss: 0.715765\n","epoch 3; iter: 0; batch classifier loss: 0.652435; batch adversarial loss: 0.713819\n","epoch 4; iter: 0; batch classifier loss: 0.617154; batch adversarial loss: 0.739134\n","epoch 5; iter: 0; batch classifier loss: 0.626970; batch adversarial loss: 0.715845\n","epoch 6; iter: 0; batch classifier loss: 0.623212; batch adversarial loss: 0.700556\n","epoch 7; iter: 0; batch classifier loss: 0.607454; batch adversarial loss: 0.703880\n","epoch 8; iter: 0; batch classifier loss: 0.570580; batch adversarial loss: 0.726875\n","epoch 9; iter: 0; batch classifier loss: 0.554075; batch adversarial loss: 0.709728\n","epoch 10; iter: 0; batch classifier loss: 0.586910; batch adversarial loss: 0.690045\n","epoch 11; iter: 0; batch classifier loss: 0.550537; batch adversarial loss: 0.702668\n","epoch 12; iter: 0; batch classifier loss: 0.538412; batch adversarial loss: 0.720157\n","epoch 13; iter: 0; batch classifier loss: 0.553517; batch adversarial loss: 0.668881\n","epoch 14; iter: 0; batch classifier loss: 0.575657; batch adversarial loss: 0.706111\n","epoch 15; iter: 0; batch classifier loss: 0.491651; batch adversarial loss: 0.690223\n","epoch 16; iter: 0; batch classifier loss: 0.521852; batch adversarial loss: 0.696289\n","epoch 17; iter: 0; batch classifier loss: 0.483736; batch adversarial loss: 0.682510\n","epoch 18; iter: 0; batch classifier loss: 0.525991; batch adversarial loss: 0.666392\n","epoch 19; iter: 0; batch classifier loss: 0.516410; batch adversarial loss: 0.654454\n","epoch 20; iter: 0; batch classifier loss: 0.506668; batch adversarial loss: 0.680207\n","epoch 21; iter: 0; batch classifier loss: 0.539939; batch adversarial loss: 0.683066\n","epoch 22; iter: 0; batch classifier loss: 0.538451; batch adversarial loss: 0.656852\n","epoch 23; iter: 0; batch classifier loss: 0.492285; batch adversarial loss: 0.644714\n","epoch 24; iter: 0; batch classifier loss: 0.502263; batch adversarial loss: 0.654770\n","epoch 25; iter: 0; batch classifier loss: 0.509057; batch adversarial loss: 0.652613\n","epoch 26; iter: 0; batch classifier loss: 0.514365; batch adversarial loss: 0.644719\n","epoch 27; iter: 0; batch classifier loss: 0.537529; batch adversarial loss: 0.630147\n","epoch 28; iter: 0; batch classifier loss: 0.546494; batch adversarial loss: 0.655689\n","epoch 29; iter: 0; batch classifier loss: 0.517886; batch adversarial loss: 0.617295\n","epoch 30; iter: 0; batch classifier loss: 0.478463; batch adversarial loss: 0.636669\n","epoch 31; iter: 0; batch classifier loss: 0.451121; batch adversarial loss: 0.662922\n","epoch 32; iter: 0; batch classifier loss: 0.548482; batch adversarial loss: 0.626089\n","epoch 33; iter: 0; batch classifier loss: 0.520294; batch adversarial loss: 0.652670\n","epoch 34; iter: 0; batch classifier loss: 0.516287; batch adversarial loss: 0.644022\n","epoch 35; iter: 0; batch classifier loss: 0.491487; batch adversarial loss: 0.614616\n","epoch 36; iter: 0; batch classifier loss: 0.488947; batch adversarial loss: 0.663958\n","epoch 37; iter: 0; batch classifier loss: 0.480464; batch adversarial loss: 0.651589\n","epoch 38; iter: 0; batch classifier loss: 0.508041; batch adversarial loss: 0.615451\n","epoch 39; iter: 0; batch classifier loss: 0.567928; batch adversarial loss: 0.606482\n","epoch 40; iter: 0; batch classifier loss: 0.427938; batch adversarial loss: 0.644851\n","epoch 41; iter: 0; batch classifier loss: 0.524144; batch adversarial loss: 0.608717\n","epoch 42; iter: 0; batch classifier loss: 0.509219; batch adversarial loss: 0.600357\n","epoch 43; iter: 0; batch classifier loss: 0.507879; batch adversarial loss: 0.615999\n","epoch 44; iter: 0; batch classifier loss: 0.452189; batch adversarial loss: 0.606308\n","epoch 45; iter: 0; batch classifier loss: 0.484295; batch adversarial loss: 0.625595\n","epoch 46; iter: 0; batch classifier loss: 0.415111; batch adversarial loss: 0.605606\n","epoch 47; iter: 0; batch classifier loss: 0.485851; batch adversarial loss: 0.617959\n","epoch 48; iter: 0; batch classifier loss: 0.414702; batch adversarial loss: 0.637868\n","epoch 49; iter: 0; batch classifier loss: 0.443126; batch adversarial loss: 0.602900\n","Accuracy 0.7697841726618705\n","epoch 0; iter: 0; batch classifier loss: 0.673449; batch adversarial loss: 0.832605\n","epoch 1; iter: 0; batch classifier loss: 0.688603; batch adversarial loss: 0.787051\n","epoch 2; iter: 0; batch classifier loss: 0.637863; batch adversarial loss: 0.808355\n","epoch 3; iter: 0; batch classifier loss: 0.643705; batch adversarial loss: 0.783922\n","epoch 4; iter: 0; batch classifier loss: 0.615258; batch adversarial loss: 0.801503\n","epoch 5; iter: 0; batch classifier loss: 0.620577; batch adversarial loss: 0.788635\n","epoch 6; iter: 0; batch classifier loss: 0.596705; batch adversarial loss: 0.778172\n","epoch 7; iter: 0; batch classifier loss: 0.540857; batch adversarial loss: 0.819456\n","epoch 8; iter: 0; batch classifier loss: 0.571325; batch adversarial loss: 0.795004\n","epoch 9; iter: 0; batch classifier loss: 0.566850; batch adversarial loss: 0.755890\n","epoch 10; iter: 0; batch classifier loss: 0.567651; batch adversarial loss: 0.751007\n","epoch 11; iter: 0; batch classifier loss: 0.540188; batch adversarial loss: 0.766724\n","epoch 12; iter: 0; batch classifier loss: 0.540826; batch adversarial loss: 0.776589\n","epoch 13; iter: 0; batch classifier loss: 0.543756; batch adversarial loss: 0.783299\n","epoch 14; iter: 0; batch classifier loss: 0.550314; batch adversarial loss: 0.779526\n","epoch 15; iter: 0; batch classifier loss: 0.519563; batch adversarial loss: 0.772380\n","epoch 16; iter: 0; batch classifier loss: 0.497060; batch adversarial loss: 0.775033\n","epoch 17; iter: 0; batch classifier loss: 0.497138; batch adversarial loss: 0.776949\n","epoch 18; iter: 0; batch classifier loss: 0.508220; batch adversarial loss: 0.750160\n","epoch 19; iter: 0; batch classifier loss: 0.503272; batch adversarial loss: 0.767067\n","epoch 20; iter: 0; batch classifier loss: 0.470173; batch adversarial loss: 0.770769\n","epoch 21; iter: 0; batch classifier loss: 0.456862; batch adversarial loss: 0.742439\n","epoch 22; iter: 0; batch classifier loss: 0.506987; batch adversarial loss: 0.751247\n","epoch 23; iter: 0; batch classifier loss: 0.487180; batch adversarial loss: 0.747255\n","epoch 24; iter: 0; batch classifier loss: 0.476937; batch adversarial loss: 0.748066\n","epoch 25; iter: 0; batch classifier loss: 0.480399; batch adversarial loss: 0.753238\n","epoch 26; iter: 0; batch classifier loss: 0.462746; batch adversarial loss: 0.745953\n","epoch 27; iter: 0; batch classifier loss: 0.507497; batch adversarial loss: 0.723749\n","epoch 28; iter: 0; batch classifier loss: 0.498706; batch adversarial loss: 0.723911\n","epoch 29; iter: 0; batch classifier loss: 0.465745; batch adversarial loss: 0.719427\n","epoch 30; iter: 0; batch classifier loss: 0.449585; batch adversarial loss: 0.743721\n","epoch 31; iter: 0; batch classifier loss: 0.521026; batch adversarial loss: 0.711830\n","epoch 32; iter: 0; batch classifier loss: 0.474294; batch adversarial loss: 0.727663\n","epoch 33; iter: 0; batch classifier loss: 0.430288; batch adversarial loss: 0.743531\n","epoch 34; iter: 0; batch classifier loss: 0.484839; batch adversarial loss: 0.695844\n","epoch 35; iter: 0; batch classifier loss: 0.509099; batch adversarial loss: 0.724476\n","epoch 36; iter: 0; batch classifier loss: 0.439816; batch adversarial loss: 0.726192\n","epoch 37; iter: 0; batch classifier loss: 0.490966; batch adversarial loss: 0.701813\n","epoch 38; iter: 0; batch classifier loss: 0.497592; batch adversarial loss: 0.695198\n","epoch 39; iter: 0; batch classifier loss: 0.484202; batch adversarial loss: 0.698915\n","epoch 40; iter: 0; batch classifier loss: 0.473799; batch adversarial loss: 0.716416\n","epoch 41; iter: 0; batch classifier loss: 0.524194; batch adversarial loss: 0.681590\n","epoch 42; iter: 0; batch classifier loss: 0.489741; batch adversarial loss: 0.706798\n","epoch 43; iter: 0; batch classifier loss: 0.441470; batch adversarial loss: 0.699164\n","epoch 44; iter: 0; batch classifier loss: 0.476431; batch adversarial loss: 0.688763\n","epoch 45; iter: 0; batch classifier loss: 0.483253; batch adversarial loss: 0.692785\n","epoch 46; iter: 0; batch classifier loss: 0.481399; batch adversarial loss: 0.679821\n","epoch 47; iter: 0; batch classifier loss: 0.451815; batch adversarial loss: 0.682638\n","epoch 48; iter: 0; batch classifier loss: 0.528132; batch adversarial loss: 0.668253\n","epoch 49; iter: 0; batch classifier loss: 0.504847; batch adversarial loss: 0.679204\n","Accuracy 0.7482014388489209\n","epoch 0; iter: 0; batch classifier loss: 0.690330; batch adversarial loss: 0.671265\n","epoch 1; iter: 0; batch classifier loss: 0.635254; batch adversarial loss: 0.680594\n","epoch 2; iter: 0; batch classifier loss: 0.637354; batch adversarial loss: 0.669992\n","epoch 3; iter: 0; batch classifier loss: 0.593769; batch adversarial loss: 0.679324\n","epoch 4; iter: 0; batch classifier loss: 0.612981; batch adversarial loss: 0.640453\n","epoch 5; iter: 0; batch classifier loss: 0.606185; batch adversarial loss: 0.678617\n","epoch 6; iter: 0; batch classifier loss: 0.601632; batch adversarial loss: 0.676810\n","epoch 7; iter: 0; batch classifier loss: 0.568462; batch adversarial loss: 0.669329\n","epoch 8; iter: 0; batch classifier loss: 0.555618; batch adversarial loss: 0.650523\n","epoch 9; iter: 0; batch classifier loss: 0.528407; batch adversarial loss: 0.657655\n","epoch 10; iter: 0; batch classifier loss: 0.584414; batch adversarial loss: 0.661375\n","epoch 11; iter: 0; batch classifier loss: 0.524902; batch adversarial loss: 0.683503\n","epoch 12; iter: 0; batch classifier loss: 0.536408; batch adversarial loss: 0.674660\n","epoch 13; iter: 0; batch classifier loss: 0.536223; batch adversarial loss: 0.647884\n","epoch 14; iter: 0; batch classifier loss: 0.517736; batch adversarial loss: 0.647930\n","epoch 15; iter: 0; batch classifier loss: 0.536001; batch adversarial loss: 0.648552\n","epoch 16; iter: 0; batch classifier loss: 0.510491; batch adversarial loss: 0.633760\n","epoch 17; iter: 0; batch classifier loss: 0.526765; batch adversarial loss: 0.640460\n","epoch 18; iter: 0; batch classifier loss: 0.533052; batch adversarial loss: 0.624530\n","epoch 19; iter: 0; batch classifier loss: 0.539670; batch adversarial loss: 0.626955\n","epoch 20; iter: 0; batch classifier loss: 0.530000; batch adversarial loss: 0.617211\n","epoch 21; iter: 0; batch classifier loss: 0.484192; batch adversarial loss: 0.649599\n","epoch 22; iter: 0; batch classifier loss: 0.524403; batch adversarial loss: 0.650645\n","epoch 23; iter: 0; batch classifier loss: 0.483915; batch adversarial loss: 0.600957\n","epoch 24; iter: 0; batch classifier loss: 0.490033; batch adversarial loss: 0.605100\n","epoch 25; iter: 0; batch classifier loss: 0.521950; batch adversarial loss: 0.643227\n","epoch 26; iter: 0; batch classifier loss: 0.469715; batch adversarial loss: 0.616630\n","epoch 27; iter: 0; batch classifier loss: 0.489936; batch adversarial loss: 0.608765\n","epoch 28; iter: 0; batch classifier loss: 0.487348; batch adversarial loss: 0.655915\n","epoch 29; iter: 0; batch classifier loss: 0.487972; batch adversarial loss: 0.609832\n","epoch 30; iter: 0; batch classifier loss: 0.498858; batch adversarial loss: 0.636338\n","epoch 31; iter: 0; batch classifier loss: 0.437305; batch adversarial loss: 0.588436\n","epoch 32; iter: 0; batch classifier loss: 0.468081; batch adversarial loss: 0.606061\n","epoch 33; iter: 0; batch classifier loss: 0.488620; batch adversarial loss: 0.592795\n","epoch 34; iter: 0; batch classifier loss: 0.453262; batch adversarial loss: 0.605803\n","epoch 35; iter: 0; batch classifier loss: 0.468072; batch adversarial loss: 0.569796\n","epoch 36; iter: 0; batch classifier loss: 0.460346; batch adversarial loss: 0.586967\n","epoch 37; iter: 0; batch classifier loss: 0.484933; batch adversarial loss: 0.586129\n","epoch 38; iter: 0; batch classifier loss: 0.519980; batch adversarial loss: 0.607370\n","epoch 39; iter: 0; batch classifier loss: 0.478438; batch adversarial loss: 0.611359\n","epoch 40; iter: 0; batch classifier loss: 0.540073; batch adversarial loss: 0.613223\n","epoch 41; iter: 0; batch classifier loss: 0.501101; batch adversarial loss: 0.571537\n","epoch 42; iter: 0; batch classifier loss: 0.489986; batch adversarial loss: 0.607548\n","epoch 43; iter: 0; batch classifier loss: 0.456966; batch adversarial loss: 0.631670\n","epoch 44; iter: 0; batch classifier loss: 0.460349; batch adversarial loss: 0.593528\n","epoch 45; iter: 0; batch classifier loss: 0.477596; batch adversarial loss: 0.574517\n","epoch 46; iter: 0; batch classifier loss: 0.429913; batch adversarial loss: 0.611365\n","epoch 47; iter: 0; batch classifier loss: 0.476957; batch adversarial loss: 0.581879\n","epoch 48; iter: 0; batch classifier loss: 0.459915; batch adversarial loss: 0.594937\n","epoch 49; iter: 0; batch classifier loss: 0.519695; batch adversarial loss: 0.593668\n","Accuracy 0.7608695652173914\n","epoch 0; iter: 0; batch classifier loss: 0.722065; batch adversarial loss: 0.587175\n","epoch 1; iter: 0; batch classifier loss: 0.716646; batch adversarial loss: 0.559501\n","epoch 2; iter: 0; batch classifier loss: 0.702345; batch adversarial loss: 0.551421\n","epoch 3; iter: 0; batch classifier loss: 0.679445; batch adversarial loss: 0.563684\n","epoch 4; iter: 0; batch classifier loss: 0.651333; batch adversarial loss: 0.593267\n","epoch 5; iter: 0; batch classifier loss: 0.651636; batch adversarial loss: 0.611543\n","epoch 6; iter: 0; batch classifier loss: 0.634934; batch adversarial loss: 0.585009\n","epoch 7; iter: 0; batch classifier loss: 0.612098; batch adversarial loss: 0.598167\n","epoch 8; iter: 0; batch classifier loss: 0.617417; batch adversarial loss: 0.571357\n","epoch 9; iter: 0; batch classifier loss: 0.599145; batch adversarial loss: 0.609013\n","epoch 10; iter: 0; batch classifier loss: 0.615894; batch adversarial loss: 0.583021\n","epoch 11; iter: 0; batch classifier loss: 0.646891; batch adversarial loss: 0.670720\n","epoch 12; iter: 0; batch classifier loss: 0.598280; batch adversarial loss: 0.548765\n","epoch 13; iter: 0; batch classifier loss: 0.547804; batch adversarial loss: 0.676689\n","epoch 14; iter: 0; batch classifier loss: 0.564142; batch adversarial loss: 0.640480\n","epoch 15; iter: 0; batch classifier loss: 0.541391; batch adversarial loss: 0.598713\n","epoch 16; iter: 0; batch classifier loss: 0.548683; batch adversarial loss: 0.613683\n","epoch 17; iter: 0; batch classifier loss: 0.532010; batch adversarial loss: 0.641991\n","epoch 18; iter: 0; batch classifier loss: 0.568240; batch adversarial loss: 0.565161\n","epoch 19; iter: 0; batch classifier loss: 0.529109; batch adversarial loss: 0.650280\n","epoch 20; iter: 0; batch classifier loss: 0.557931; batch adversarial loss: 0.594463\n","epoch 21; iter: 0; batch classifier loss: 0.550855; batch adversarial loss: 0.639786\n","epoch 22; iter: 0; batch classifier loss: 0.549993; batch adversarial loss: 0.520115\n","epoch 23; iter: 0; batch classifier loss: 0.536332; batch adversarial loss: 0.619784\n","epoch 24; iter: 0; batch classifier loss: 0.569561; batch adversarial loss: 0.612030\n","epoch 25; iter: 0; batch classifier loss: 0.541456; batch adversarial loss: 0.598405\n","epoch 26; iter: 0; batch classifier loss: 0.525433; batch adversarial loss: 0.522896\n","epoch 27; iter: 0; batch classifier loss: 0.512719; batch adversarial loss: 0.578448\n","epoch 28; iter: 0; batch classifier loss: 0.538083; batch adversarial loss: 0.633668\n","epoch 29; iter: 0; batch classifier loss: 0.512716; batch adversarial loss: 0.602725\n","epoch 30; iter: 0; batch classifier loss: 0.585459; batch adversarial loss: 0.589390\n","epoch 31; iter: 0; batch classifier loss: 0.571348; batch adversarial loss: 0.623260\n","epoch 32; iter: 0; batch classifier loss: 0.505768; batch adversarial loss: 0.531791\n","epoch 33; iter: 0; batch classifier loss: 0.491829; batch adversarial loss: 0.519167\n","epoch 34; iter: 0; batch classifier loss: 0.442460; batch adversarial loss: 0.483031\n","epoch 35; iter: 0; batch classifier loss: 0.525224; batch adversarial loss: 0.533834\n","epoch 36; iter: 0; batch classifier loss: 0.547558; batch adversarial loss: 0.505359\n","epoch 37; iter: 0; batch classifier loss: 0.550755; batch adversarial loss: 0.613328\n","epoch 38; iter: 0; batch classifier loss: 0.531678; batch adversarial loss: 0.571760\n","epoch 39; iter: 0; batch classifier loss: 0.521527; batch adversarial loss: 0.598749\n","epoch 40; iter: 0; batch classifier loss: 0.523063; batch adversarial loss: 0.545728\n","epoch 41; iter: 0; batch classifier loss: 0.484219; batch adversarial loss: 0.544148\n","epoch 42; iter: 0; batch classifier loss: 0.536834; batch adversarial loss: 0.587022\n","epoch 43; iter: 0; batch classifier loss: 0.543364; batch adversarial loss: 0.547555\n","epoch 44; iter: 0; batch classifier loss: 0.532579; batch adversarial loss: 0.564098\n","epoch 45; iter: 0; batch classifier loss: 0.453620; batch adversarial loss: 0.591632\n","epoch 46; iter: 0; batch classifier loss: 0.516803; batch adversarial loss: 0.661390\n","epoch 47; iter: 0; batch classifier loss: 0.578980; batch adversarial loss: 0.556384\n","epoch 48; iter: 0; batch classifier loss: 0.491975; batch adversarial loss: 0.649223\n","epoch 49; iter: 0; batch classifier loss: 0.485475; batch adversarial loss: 0.552107\n","Accuracy 0.7391304347826086\n","epoch 0; iter: 0; batch classifier loss: 0.676562; batch adversarial loss: 1.064583\n","epoch 1; iter: 0; batch classifier loss: 0.681848; batch adversarial loss: 1.095259\n","epoch 2; iter: 0; batch classifier loss: 0.627816; batch adversarial loss: 1.146223\n","epoch 3; iter: 0; batch classifier loss: 0.604687; batch adversarial loss: 1.133766\n","epoch 4; iter: 0; batch classifier loss: 0.589445; batch adversarial loss: 1.217201\n","epoch 5; iter: 0; batch classifier loss: 0.594434; batch adversarial loss: 1.231534\n","epoch 6; iter: 0; batch classifier loss: 0.620902; batch adversarial loss: 1.240309\n","epoch 7; iter: 0; batch classifier loss: 0.594834; batch adversarial loss: 1.325335\n","epoch 8; iter: 0; batch classifier loss: 0.575021; batch adversarial loss: 1.354841\n","epoch 9; iter: 0; batch classifier loss: 0.542286; batch adversarial loss: 1.243073\n","epoch 10; iter: 0; batch classifier loss: 0.587023; batch adversarial loss: 1.318610\n","epoch 11; iter: 0; batch classifier loss: 0.573725; batch adversarial loss: 1.371354\n","epoch 12; iter: 0; batch classifier loss: 0.616231; batch adversarial loss: 1.251635\n","epoch 13; iter: 0; batch classifier loss: 0.662826; batch adversarial loss: 1.304577\n","epoch 14; iter: 0; batch classifier loss: 0.574376; batch adversarial loss: 1.347051\n","epoch 15; iter: 0; batch classifier loss: 0.596241; batch adversarial loss: 1.278383\n","epoch 16; iter: 0; batch classifier loss: 0.557702; batch adversarial loss: 1.269978\n","epoch 17; iter: 0; batch classifier loss: 0.637867; batch adversarial loss: 1.332505\n","epoch 18; iter: 0; batch classifier loss: 0.540922; batch adversarial loss: 1.326655\n","epoch 19; iter: 0; batch classifier loss: 0.520962; batch adversarial loss: 1.255492\n","epoch 20; iter: 0; batch classifier loss: 0.631409; batch adversarial loss: 1.325816\n","epoch 21; iter: 0; batch classifier loss: 0.566786; batch adversarial loss: 1.315804\n","epoch 22; iter: 0; batch classifier loss: 0.604734; batch adversarial loss: 1.230311\n","epoch 23; iter: 0; batch classifier loss: 0.660765; batch adversarial loss: 1.224328\n","epoch 24; iter: 0; batch classifier loss: 0.615346; batch adversarial loss: 1.310298\n","epoch 25; iter: 0; batch classifier loss: 0.599083; batch adversarial loss: 1.288576\n","epoch 26; iter: 0; batch classifier loss: 0.650509; batch adversarial loss: 1.240686\n","epoch 27; iter: 0; batch classifier loss: 0.614858; batch adversarial loss: 1.357698\n","epoch 28; iter: 0; batch classifier loss: 0.635269; batch adversarial loss: 1.300341\n","epoch 29; iter: 0; batch classifier loss: 0.593294; batch adversarial loss: 1.270189\n","epoch 30; iter: 0; batch classifier loss: 0.660501; batch adversarial loss: 1.292149\n","epoch 31; iter: 0; batch classifier loss: 0.650147; batch adversarial loss: 1.278542\n","epoch 32; iter: 0; batch classifier loss: 0.593791; batch adversarial loss: 1.273317\n","epoch 33; iter: 0; batch classifier loss: 0.571388; batch adversarial loss: 1.243385\n","epoch 34; iter: 0; batch classifier loss: 0.701034; batch adversarial loss: 1.247468\n","epoch 35; iter: 0; batch classifier loss: 0.724806; batch adversarial loss: 1.283563\n","epoch 36; iter: 0; batch classifier loss: 0.637440; batch adversarial loss: 1.255488\n","epoch 37; iter: 0; batch classifier loss: 0.738140; batch adversarial loss: 1.254670\n","epoch 38; iter: 0; batch classifier loss: 0.673273; batch adversarial loss: 1.222950\n","epoch 39; iter: 0; batch classifier loss: 0.669748; batch adversarial loss: 1.235317\n","epoch 40; iter: 0; batch classifier loss: 0.665612; batch adversarial loss: 1.200656\n","epoch 41; iter: 0; batch classifier loss: 0.747227; batch adversarial loss: 1.243996\n","epoch 42; iter: 0; batch classifier loss: 0.694643; batch adversarial loss: 1.171349\n","epoch 43; iter: 0; batch classifier loss: 0.759578; batch adversarial loss: 1.221416\n","epoch 44; iter: 0; batch classifier loss: 0.756969; batch adversarial loss: 1.218678\n","epoch 45; iter: 0; batch classifier loss: 0.814824; batch adversarial loss: 1.198232\n","epoch 46; iter: 0; batch classifier loss: 0.845751; batch adversarial loss: 1.239261\n","epoch 47; iter: 0; batch classifier loss: 0.823225; batch adversarial loss: 1.243222\n","epoch 48; iter: 0; batch classifier loss: 0.639688; batch adversarial loss: 1.209875\n","epoch 49; iter: 0; batch classifier loss: 0.755904; batch adversarial loss: 1.180336\n","Accuracy 0.6594202898550725\n","epoch 0; iter: 0; batch classifier loss: 0.706996; batch adversarial loss: 0.896615\n","epoch 1; iter: 0; batch classifier loss: 0.670671; batch adversarial loss: 0.893918\n","epoch 2; iter: 0; batch classifier loss: 0.649222; batch adversarial loss: 0.910363\n","epoch 3; iter: 0; batch classifier loss: 0.608158; batch adversarial loss: 0.954153\n","epoch 4; iter: 0; batch classifier loss: 0.617496; batch adversarial loss: 0.956332\n","epoch 5; iter: 0; batch classifier loss: 0.613896; batch adversarial loss: 0.982880\n","epoch 6; iter: 0; batch classifier loss: 0.571253; batch adversarial loss: 0.980509\n","epoch 7; iter: 0; batch classifier loss: 0.583543; batch adversarial loss: 0.961845\n","epoch 8; iter: 0; batch classifier loss: 0.548324; batch adversarial loss: 0.993603\n","epoch 9; iter: 0; batch classifier loss: 0.555803; batch adversarial loss: 0.962504\n","epoch 10; iter: 0; batch classifier loss: 0.548538; batch adversarial loss: 1.024742\n","epoch 11; iter: 0; batch classifier loss: 0.517392; batch adversarial loss: 1.006802\n","epoch 12; iter: 0; batch classifier loss: 0.485875; batch adversarial loss: 0.995887\n","epoch 13; iter: 0; batch classifier loss: 0.544894; batch adversarial loss: 0.974945\n","epoch 14; iter: 0; batch classifier loss: 0.543458; batch adversarial loss: 0.953735\n","epoch 15; iter: 0; batch classifier loss: 0.467904; batch adversarial loss: 0.977683\n","epoch 16; iter: 0; batch classifier loss: 0.541319; batch adversarial loss: 0.968706\n","epoch 17; iter: 0; batch classifier loss: 0.441899; batch adversarial loss: 1.037968\n","epoch 18; iter: 0; batch classifier loss: 0.515383; batch adversarial loss: 1.003705\n","epoch 19; iter: 0; batch classifier loss: 0.498405; batch adversarial loss: 0.993118\n","epoch 20; iter: 0; batch classifier loss: 0.497015; batch adversarial loss: 0.987997\n","epoch 21; iter: 0; batch classifier loss: 0.540366; batch adversarial loss: 0.990591\n","epoch 22; iter: 0; batch classifier loss: 0.478950; batch adversarial loss: 0.977693\n","epoch 23; iter: 0; batch classifier loss: 0.623910; batch adversarial loss: 0.920970\n","epoch 24; iter: 0; batch classifier loss: 0.514099; batch adversarial loss: 0.954034\n","epoch 25; iter: 0; batch classifier loss: 0.567429; batch adversarial loss: 0.953651\n","epoch 26; iter: 0; batch classifier loss: 0.541136; batch adversarial loss: 0.931536\n","epoch 27; iter: 0; batch classifier loss: 0.555183; batch adversarial loss: 0.932467\n","epoch 28; iter: 0; batch classifier loss: 0.515391; batch adversarial loss: 0.952651\n","epoch 29; iter: 0; batch classifier loss: 0.492644; batch adversarial loss: 0.936361\n","epoch 30; iter: 0; batch classifier loss: 0.505311; batch adversarial loss: 0.943429\n","epoch 31; iter: 0; batch classifier loss: 0.519432; batch adversarial loss: 0.902149\n","epoch 32; iter: 0; batch classifier loss: 0.507890; batch adversarial loss: 0.951504\n","epoch 33; iter: 0; batch classifier loss: 0.521302; batch adversarial loss: 0.925081\n","epoch 34; iter: 0; batch classifier loss: 0.579797; batch adversarial loss: 0.903680\n","epoch 35; iter: 0; batch classifier loss: 0.534018; batch adversarial loss: 0.909028\n","epoch 36; iter: 0; batch classifier loss: 0.435601; batch adversarial loss: 0.950836\n","epoch 37; iter: 0; batch classifier loss: 0.436034; batch adversarial loss: 0.916568\n","epoch 38; iter: 0; batch classifier loss: 0.546016; batch adversarial loss: 0.874934\n","epoch 39; iter: 0; batch classifier loss: 0.504665; batch adversarial loss: 0.875334\n","epoch 40; iter: 0; batch classifier loss: 0.432909; batch adversarial loss: 0.921174\n","epoch 41; iter: 0; batch classifier loss: 0.573481; batch adversarial loss: 0.843816\n","epoch 42; iter: 0; batch classifier loss: 0.484483; batch adversarial loss: 0.909481\n","epoch 43; iter: 0; batch classifier loss: 0.474701; batch adversarial loss: 0.861606\n","epoch 44; iter: 0; batch classifier loss: 0.521617; batch adversarial loss: 0.875603\n","epoch 45; iter: 0; batch classifier loss: 0.426484; batch adversarial loss: 0.886529\n","epoch 46; iter: 0; batch classifier loss: 0.466770; batch adversarial loss: 0.850852\n","epoch 47; iter: 0; batch classifier loss: 0.506083; batch adversarial loss: 0.880937\n","epoch 48; iter: 0; batch classifier loss: 0.478194; batch adversarial loss: 0.852909\n","epoch 49; iter: 0; batch classifier loss: 0.463331; batch adversarial loss: 0.859666\n","Accuracy 0.7050359712230215\n","epoch 0; iter: 0; batch classifier loss: 0.723003; batch adversarial loss: 0.632475\n","epoch 1; iter: 0; batch classifier loss: 0.756022; batch adversarial loss: 0.653022\n","epoch 2; iter: 0; batch classifier loss: 0.700119; batch adversarial loss: 0.625799\n","epoch 3; iter: 0; batch classifier loss: 0.696136; batch adversarial loss: 0.631395\n","epoch 4; iter: 0; batch classifier loss: 0.670048; batch adversarial loss: 0.662922\n","epoch 5; iter: 0; batch classifier loss: 0.666929; batch adversarial loss: 0.625270\n","epoch 6; iter: 0; batch classifier loss: 0.656963; batch adversarial loss: 0.624511\n","epoch 7; iter: 0; batch classifier loss: 0.650601; batch adversarial loss: 0.637683\n","epoch 8; iter: 0; batch classifier loss: 0.634019; batch adversarial loss: 0.635057\n","epoch 9; iter: 0; batch classifier loss: 0.618603; batch adversarial loss: 0.647723\n","epoch 10; iter: 0; batch classifier loss: 0.639189; batch adversarial loss: 0.629212\n","epoch 11; iter: 0; batch classifier loss: 0.629804; batch adversarial loss: 0.642118\n","epoch 12; iter: 0; batch classifier loss: 0.638358; batch adversarial loss: 0.627954\n","epoch 13; iter: 0; batch classifier loss: 0.616720; batch adversarial loss: 0.658343\n","epoch 14; iter: 0; batch classifier loss: 0.670388; batch adversarial loss: 0.663666\n","epoch 15; iter: 0; batch classifier loss: 0.671682; batch adversarial loss: 0.614089\n","epoch 16; iter: 0; batch classifier loss: 0.617700; batch adversarial loss: 0.651781\n","epoch 17; iter: 0; batch classifier loss: 0.576080; batch adversarial loss: 0.642438\n","epoch 18; iter: 0; batch classifier loss: 0.617499; batch adversarial loss: 0.672887\n","epoch 19; iter: 0; batch classifier loss: 0.667047; batch adversarial loss: 0.662491\n","epoch 20; iter: 0; batch classifier loss: 0.662817; batch adversarial loss: 0.663161\n","epoch 21; iter: 0; batch classifier loss: 0.641703; batch adversarial loss: 0.664670\n","epoch 22; iter: 0; batch classifier loss: 0.642542; batch adversarial loss: 0.630152\n","epoch 23; iter: 0; batch classifier loss: 0.679653; batch adversarial loss: 0.672105\n","epoch 24; iter: 0; batch classifier loss: 0.646089; batch adversarial loss: 0.626844\n","epoch 25; iter: 0; batch classifier loss: 0.673124; batch adversarial loss: 0.641648\n","epoch 26; iter: 0; batch classifier loss: 0.733578; batch adversarial loss: 0.627397\n","epoch 27; iter: 0; batch classifier loss: 0.609566; batch adversarial loss: 0.650163\n","epoch 28; iter: 0; batch classifier loss: 0.604584; batch adversarial loss: 0.640738\n","epoch 29; iter: 0; batch classifier loss: 0.642569; batch adversarial loss: 0.661268\n","epoch 30; iter: 0; batch classifier loss: 0.678603; batch adversarial loss: 0.668078\n","epoch 31; iter: 0; batch classifier loss: 0.725374; batch adversarial loss: 0.644514\n","epoch 32; iter: 0; batch classifier loss: 0.772279; batch adversarial loss: 0.650916\n","epoch 33; iter: 0; batch classifier loss: 0.674715; batch adversarial loss: 0.672488\n","epoch 34; iter: 0; batch classifier loss: 0.635778; batch adversarial loss: 0.692131\n","epoch 35; iter: 0; batch classifier loss: 0.755516; batch adversarial loss: 0.668896\n","epoch 36; iter: 0; batch classifier loss: 0.790399; batch adversarial loss: 0.658243\n","epoch 37; iter: 0; batch classifier loss: 0.779227; batch adversarial loss: 0.687635\n","epoch 38; iter: 0; batch classifier loss: 0.710085; batch adversarial loss: 0.667078\n","epoch 39; iter: 0; batch classifier loss: 0.690569; batch adversarial loss: 0.652133\n","epoch 40; iter: 0; batch classifier loss: 0.736844; batch adversarial loss: 0.661562\n","epoch 41; iter: 0; batch classifier loss: 0.703317; batch adversarial loss: 0.662346\n","epoch 42; iter: 0; batch classifier loss: 0.849186; batch adversarial loss: 0.655861\n","epoch 43; iter: 0; batch classifier loss: 0.828080; batch adversarial loss: 0.656916\n","epoch 44; iter: 0; batch classifier loss: 0.712237; batch adversarial loss: 0.689758\n","epoch 45; iter: 0; batch classifier loss: 0.750127; batch adversarial loss: 0.664908\n","epoch 46; iter: 0; batch classifier loss: 0.897201; batch adversarial loss: 0.643694\n","epoch 47; iter: 0; batch classifier loss: 0.833950; batch adversarial loss: 0.666884\n","epoch 48; iter: 0; batch classifier loss: 0.797121; batch adversarial loss: 0.654899\n","epoch 49; iter: 0; batch classifier loss: 0.745726; batch adversarial loss: 0.645068\n","Accuracy 0.4892086330935252\n","epoch 0; iter: 0; batch classifier loss: 0.695072; batch adversarial loss: 0.746467\n","epoch 1; iter: 0; batch classifier loss: 0.678824; batch adversarial loss: 0.740274\n","epoch 2; iter: 0; batch classifier loss: 0.656698; batch adversarial loss: 0.739380\n","epoch 3; iter: 0; batch classifier loss: 0.639318; batch adversarial loss: 0.748816\n","epoch 4; iter: 0; batch classifier loss: 0.639557; batch adversarial loss: 0.738455\n","epoch 5; iter: 0; batch classifier loss: 0.587176; batch adversarial loss: 0.734128\n","epoch 6; iter: 0; batch classifier loss: 0.584907; batch adversarial loss: 0.733087\n","epoch 7; iter: 0; batch classifier loss: 0.547384; batch adversarial loss: 0.743495\n","epoch 8; iter: 0; batch classifier loss: 0.581129; batch adversarial loss: 0.726610\n","epoch 9; iter: 0; batch classifier loss: 0.544687; batch adversarial loss: 0.726481\n","epoch 10; iter: 0; batch classifier loss: 0.514590; batch adversarial loss: 0.724039\n","epoch 11; iter: 0; batch classifier loss: 0.537515; batch adversarial loss: 0.728566\n","epoch 12; iter: 0; batch classifier loss: 0.544861; batch adversarial loss: 0.718149\n","epoch 13; iter: 0; batch classifier loss: 0.534970; batch adversarial loss: 0.716172\n","epoch 14; iter: 0; batch classifier loss: 0.527395; batch adversarial loss: 0.716360\n","epoch 15; iter: 0; batch classifier loss: 0.537915; batch adversarial loss: 0.716756\n","epoch 16; iter: 0; batch classifier loss: 0.475418; batch adversarial loss: 0.713197\n","epoch 17; iter: 0; batch classifier loss: 0.529033; batch adversarial loss: 0.709323\n","epoch 18; iter: 0; batch classifier loss: 0.479775; batch adversarial loss: 0.707784\n","epoch 19; iter: 0; batch classifier loss: 0.482248; batch adversarial loss: 0.706115\n","epoch 20; iter: 0; batch classifier loss: 0.480409; batch adversarial loss: 0.702477\n","epoch 21; iter: 0; batch classifier loss: 0.500275; batch adversarial loss: 0.698474\n","epoch 22; iter: 0; batch classifier loss: 0.461263; batch adversarial loss: 0.698374\n","epoch 23; iter: 0; batch classifier loss: 0.509112; batch adversarial loss: 0.697207\n","epoch 24; iter: 0; batch classifier loss: 0.521014; batch adversarial loss: 0.690591\n","epoch 25; iter: 0; batch classifier loss: 0.457445; batch adversarial loss: 0.691532\n","epoch 26; iter: 0; batch classifier loss: 0.498247; batch adversarial loss: 0.685141\n","epoch 27; iter: 0; batch classifier loss: 0.524970; batch adversarial loss: 0.683252\n","epoch 28; iter: 0; batch classifier loss: 0.476042; batch adversarial loss: 0.678212\n","epoch 29; iter: 0; batch classifier loss: 0.461624; batch adversarial loss: 0.679129\n","epoch 30; iter: 0; batch classifier loss: 0.483719; batch adversarial loss: 0.671461\n","epoch 31; iter: 0; batch classifier loss: 0.492743; batch adversarial loss: 0.674540\n","epoch 32; iter: 0; batch classifier loss: 0.492777; batch adversarial loss: 0.669917\n","epoch 33; iter: 0; batch classifier loss: 0.505233; batch adversarial loss: 0.672327\n","epoch 34; iter: 0; batch classifier loss: 0.497294; batch adversarial loss: 0.665479\n","epoch 35; iter: 0; batch classifier loss: 0.453521; batch adversarial loss: 0.660912\n","epoch 36; iter: 0; batch classifier loss: 0.511449; batch adversarial loss: 0.670144\n","epoch 37; iter: 0; batch classifier loss: 0.470954; batch adversarial loss: 0.650646\n","epoch 38; iter: 0; batch classifier loss: 0.472506; batch adversarial loss: 0.656901\n","epoch 39; iter: 0; batch classifier loss: 0.464401; batch adversarial loss: 0.646093\n","epoch 40; iter: 0; batch classifier loss: 0.420317; batch adversarial loss: 0.659294\n","epoch 41; iter: 0; batch classifier loss: 0.515996; batch adversarial loss: 0.647722\n","epoch 42; iter: 0; batch classifier loss: 0.465243; batch adversarial loss: 0.642514\n","epoch 43; iter: 0; batch classifier loss: 0.487551; batch adversarial loss: 0.649374\n","epoch 44; iter: 0; batch classifier loss: 0.482652; batch adversarial loss: 0.640177\n","epoch 45; iter: 0; batch classifier loss: 0.494040; batch adversarial loss: 0.643587\n","epoch 46; iter: 0; batch classifier loss: 0.475948; batch adversarial loss: 0.632470\n","epoch 47; iter: 0; batch classifier loss: 0.481012; batch adversarial loss: 0.633004\n","epoch 48; iter: 0; batch classifier loss: 0.457876; batch adversarial loss: 0.635856\n","epoch 49; iter: 0; batch classifier loss: 0.482536; batch adversarial loss: 0.633683\n","Accuracy 0.7463768115942029\n","epoch 0; iter: 0; batch classifier loss: 0.654811; batch adversarial loss: 0.740947\n","epoch 1; iter: 0; batch classifier loss: 0.602462; batch adversarial loss: 0.725969\n","epoch 2; iter: 0; batch classifier loss: 0.624393; batch adversarial loss: 0.741988\n","epoch 3; iter: 0; batch classifier loss: 0.644358; batch adversarial loss: 0.744159\n","epoch 4; iter: 0; batch classifier loss: 0.582930; batch adversarial loss: 0.718647\n","epoch 5; iter: 0; batch classifier loss: 0.637504; batch adversarial loss: 0.774666\n","epoch 6; iter: 0; batch classifier loss: 0.536348; batch adversarial loss: 0.716062\n","epoch 7; iter: 0; batch classifier loss: 0.526217; batch adversarial loss: 0.707699\n","epoch 8; iter: 0; batch classifier loss: 0.536583; batch adversarial loss: 0.734503\n","epoch 9; iter: 0; batch classifier loss: 0.530657; batch adversarial loss: 0.714084\n","epoch 10; iter: 0; batch classifier loss: 0.578884; batch adversarial loss: 0.751259\n","epoch 11; iter: 0; batch classifier loss: 0.527079; batch adversarial loss: 0.725315\n","epoch 12; iter: 0; batch classifier loss: 0.570833; batch adversarial loss: 0.727529\n","epoch 13; iter: 0; batch classifier loss: 0.590236; batch adversarial loss: 0.728683\n","epoch 14; iter: 0; batch classifier loss: 0.515481; batch adversarial loss: 0.697802\n","epoch 15; iter: 0; batch classifier loss: 0.506489; batch adversarial loss: 0.713981\n","epoch 16; iter: 0; batch classifier loss: 0.486063; batch adversarial loss: 0.669311\n","epoch 17; iter: 0; batch classifier loss: 0.506722; batch adversarial loss: 0.703824\n","epoch 18; iter: 0; batch classifier loss: 0.529542; batch adversarial loss: 0.711434\n","epoch 19; iter: 0; batch classifier loss: 0.550748; batch adversarial loss: 0.694014\n","epoch 20; iter: 0; batch classifier loss: 0.491616; batch adversarial loss: 0.690023\n","epoch 21; iter: 0; batch classifier loss: 0.578378; batch adversarial loss: 0.715475\n","epoch 22; iter: 0; batch classifier loss: 0.548091; batch adversarial loss: 0.701477\n","epoch 23; iter: 0; batch classifier loss: 0.537201; batch adversarial loss: 0.684299\n","epoch 24; iter: 0; batch classifier loss: 0.492451; batch adversarial loss: 0.671221\n","epoch 25; iter: 0; batch classifier loss: 0.544177; batch adversarial loss: 0.691997\n","epoch 26; iter: 0; batch classifier loss: 0.544494; batch adversarial loss: 0.685046\n","epoch 27; iter: 0; batch classifier loss: 0.565728; batch adversarial loss: 0.683960\n","epoch 28; iter: 0; batch classifier loss: 0.472264; batch adversarial loss: 0.649441\n","epoch 29; iter: 0; batch classifier loss: 0.562346; batch adversarial loss: 0.670744\n","epoch 30; iter: 0; batch classifier loss: 0.525512; batch adversarial loss: 0.685326\n","epoch 31; iter: 0; batch classifier loss: 0.518536; batch adversarial loss: 0.669649\n","epoch 32; iter: 0; batch classifier loss: 0.507248; batch adversarial loss: 0.663839\n","epoch 33; iter: 0; batch classifier loss: 0.550294; batch adversarial loss: 0.674489\n","epoch 34; iter: 0; batch classifier loss: 0.614512; batch adversarial loss: 0.674500\n","epoch 35; iter: 0; batch classifier loss: 0.542345; batch adversarial loss: 0.658258\n","epoch 36; iter: 0; batch classifier loss: 0.534028; batch adversarial loss: 0.652332\n","epoch 37; iter: 0; batch classifier loss: 0.551526; batch adversarial loss: 0.669176\n","epoch 38; iter: 0; batch classifier loss: 0.572040; batch adversarial loss: 0.661933\n","epoch 39; iter: 0; batch classifier loss: 0.497133; batch adversarial loss: 0.652959\n","epoch 40; iter: 0; batch classifier loss: 0.539942; batch adversarial loss: 0.639155\n","epoch 41; iter: 0; batch classifier loss: 0.471015; batch adversarial loss: 0.620144\n","epoch 42; iter: 0; batch classifier loss: 0.530939; batch adversarial loss: 0.634044\n","epoch 43; iter: 0; batch classifier loss: 0.509907; batch adversarial loss: 0.615873\n","epoch 44; iter: 0; batch classifier loss: 0.472309; batch adversarial loss: 0.619572\n","epoch 45; iter: 0; batch classifier loss: 0.532690; batch adversarial loss: 0.639433\n","epoch 46; iter: 0; batch classifier loss: 0.541421; batch adversarial loss: 0.636903\n","epoch 47; iter: 0; batch classifier loss: 0.529989; batch adversarial loss: 0.617951\n","epoch 48; iter: 0; batch classifier loss: 0.477592; batch adversarial loss: 0.598155\n","epoch 49; iter: 0; batch classifier loss: 0.461048; batch adversarial loss: 0.606309\n","Accuracy 0.6376811594202898\n","epoch 0; iter: 0; batch classifier loss: 0.748382; batch adversarial loss: 0.706505\n","epoch 1; iter: 0; batch classifier loss: 0.719006; batch adversarial loss: 0.693546\n","epoch 2; iter: 0; batch classifier loss: 0.677432; batch adversarial loss: 0.702889\n","epoch 3; iter: 0; batch classifier loss: 0.680546; batch adversarial loss: 0.691052\n","epoch 4; iter: 0; batch classifier loss: 0.639128; batch adversarial loss: 0.704829\n","epoch 5; iter: 0; batch classifier loss: 0.592777; batch adversarial loss: 0.709442\n","epoch 6; iter: 0; batch classifier loss: 0.585060; batch adversarial loss: 0.697846\n","epoch 7; iter: 0; batch classifier loss: 0.571788; batch adversarial loss: 0.710537\n","epoch 8; iter: 0; batch classifier loss: 0.593856; batch adversarial loss: 0.748345\n","epoch 9; iter: 0; batch classifier loss: 0.562661; batch adversarial loss: 0.706964\n","epoch 10; iter: 0; batch classifier loss: 0.567100; batch adversarial loss: 0.702700\n","epoch 11; iter: 0; batch classifier loss: 0.572885; batch adversarial loss: 0.708718\n","epoch 12; iter: 0; batch classifier loss: 0.515955; batch adversarial loss: 0.686521\n","epoch 13; iter: 0; batch classifier loss: 0.479357; batch adversarial loss: 0.690774\n","epoch 14; iter: 0; batch classifier loss: 0.538953; batch adversarial loss: 0.719178\n","epoch 15; iter: 0; batch classifier loss: 0.580233; batch adversarial loss: 0.750299\n","epoch 16; iter: 0; batch classifier loss: 0.544720; batch adversarial loss: 0.733154\n","epoch 17; iter: 0; batch classifier loss: 0.556409; batch adversarial loss: 0.724524\n","epoch 18; iter: 0; batch classifier loss: 0.603081; batch adversarial loss: 0.763093\n","epoch 19; iter: 0; batch classifier loss: 0.537161; batch adversarial loss: 0.712884\n","epoch 20; iter: 0; batch classifier loss: 0.541700; batch adversarial loss: 0.729758\n","epoch 21; iter: 0; batch classifier loss: 0.577825; batch adversarial loss: 0.735342\n","epoch 22; iter: 0; batch classifier loss: 0.618175; batch adversarial loss: 0.781615\n","epoch 23; iter: 0; batch classifier loss: 0.632259; batch adversarial loss: 0.754989\n","epoch 24; iter: 0; batch classifier loss: 0.579429; batch adversarial loss: 0.746220\n","epoch 25; iter: 0; batch classifier loss: 0.563486; batch adversarial loss: 0.701787\n","epoch 26; iter: 0; batch classifier loss: 0.555848; batch adversarial loss: 0.730662\n","epoch 27; iter: 0; batch classifier loss: 0.588213; batch adversarial loss: 0.707551\n","epoch 28; iter: 0; batch classifier loss: 0.477667; batch adversarial loss: 0.656321\n","epoch 29; iter: 0; batch classifier loss: 0.612441; batch adversarial loss: 0.733223\n","epoch 30; iter: 0; batch classifier loss: 0.599132; batch adversarial loss: 0.733711\n","epoch 31; iter: 0; batch classifier loss: 0.524240; batch adversarial loss: 0.711298\n","epoch 32; iter: 0; batch classifier loss: 0.556016; batch adversarial loss: 0.668882\n","epoch 33; iter: 0; batch classifier loss: 0.561009; batch adversarial loss: 0.686298\n","epoch 34; iter: 0; batch classifier loss: 0.577121; batch adversarial loss: 0.705061\n","epoch 35; iter: 0; batch classifier loss: 0.522844; batch adversarial loss: 0.652142\n","epoch 36; iter: 0; batch classifier loss: 0.616562; batch adversarial loss: 0.722630\n","epoch 37; iter: 0; batch classifier loss: 0.475921; batch adversarial loss: 0.633614\n","epoch 38; iter: 0; batch classifier loss: 0.543987; batch adversarial loss: 0.659267\n","epoch 39; iter: 0; batch classifier loss: 0.546169; batch adversarial loss: 0.663321\n","epoch 40; iter: 0; batch classifier loss: 0.629007; batch adversarial loss: 0.721753\n","epoch 41; iter: 0; batch classifier loss: 0.582659; batch adversarial loss: 0.671525\n","epoch 42; iter: 0; batch classifier loss: 0.522871; batch adversarial loss: 0.645999\n","epoch 43; iter: 0; batch classifier loss: 0.594862; batch adversarial loss: 0.652423\n","epoch 44; iter: 0; batch classifier loss: 0.524726; batch adversarial loss: 0.612864\n","epoch 45; iter: 0; batch classifier loss: 0.580098; batch adversarial loss: 0.662363\n","epoch 46; iter: 0; batch classifier loss: 0.558226; batch adversarial loss: 0.637743\n","epoch 47; iter: 0; batch classifier loss: 0.560417; batch adversarial loss: 0.651704\n","epoch 48; iter: 0; batch classifier loss: 0.501437; batch adversarial loss: 0.636209\n","epoch 49; iter: 0; batch classifier loss: 0.598546; batch adversarial loss: 0.680987\n","Accuracy 0.6666666666666666\n","epoch 0; iter: 0; batch classifier loss: 0.805527; batch adversarial loss: 0.786945\n","epoch 1; iter: 0; batch classifier loss: 0.750970; batch adversarial loss: 0.825729\n","epoch 2; iter: 0; batch classifier loss: 0.697929; batch adversarial loss: 0.813730\n","epoch 3; iter: 0; batch classifier loss: 0.679241; batch adversarial loss: 0.838149\n","epoch 4; iter: 0; batch classifier loss: 0.686246; batch adversarial loss: 0.874326\n","epoch 5; iter: 0; batch classifier loss: 0.659293; batch adversarial loss: 0.917536\n","epoch 6; iter: 0; batch classifier loss: 0.635873; batch adversarial loss: 0.922425\n","epoch 7; iter: 0; batch classifier loss: 0.600179; batch adversarial loss: 0.952751\n","epoch 8; iter: 0; batch classifier loss: 0.633598; batch adversarial loss: 1.032735\n","epoch 9; iter: 0; batch classifier loss: 0.655550; batch adversarial loss: 1.110704\n","epoch 10; iter: 0; batch classifier loss: 0.618849; batch adversarial loss: 1.166522\n","epoch 11; iter: 0; batch classifier loss: 0.577597; batch adversarial loss: 1.154845\n","epoch 12; iter: 0; batch classifier loss: 0.616330; batch adversarial loss: 1.117655\n","epoch 13; iter: 0; batch classifier loss: 0.649683; batch adversarial loss: 1.217646\n","epoch 14; iter: 0; batch classifier loss: 0.646156; batch adversarial loss: 1.141502\n","epoch 15; iter: 0; batch classifier loss: 0.641004; batch adversarial loss: 1.163824\n","epoch 16; iter: 0; batch classifier loss: 0.664599; batch adversarial loss: 1.188031\n","epoch 17; iter: 0; batch classifier loss: 0.671455; batch adversarial loss: 1.211203\n","epoch 18; iter: 0; batch classifier loss: 0.639219; batch adversarial loss: 1.153589\n","epoch 19; iter: 0; batch classifier loss: 0.546399; batch adversarial loss: 1.194284\n","epoch 20; iter: 0; batch classifier loss: 0.564589; batch adversarial loss: 1.092275\n","epoch 21; iter: 0; batch classifier loss: 0.600659; batch adversarial loss: 1.104688\n","epoch 22; iter: 0; batch classifier loss: 0.609608; batch adversarial loss: 1.169684\n","epoch 23; iter: 0; batch classifier loss: 0.607004; batch adversarial loss: 1.117442\n","epoch 24; iter: 0; batch classifier loss: 0.649870; batch adversarial loss: 1.195659\n","epoch 25; iter: 0; batch classifier loss: 0.630404; batch adversarial loss: 1.127358\n","epoch 26; iter: 0; batch classifier loss: 0.528982; batch adversarial loss: 1.080950\n","epoch 27; iter: 0; batch classifier loss: 0.648956; batch adversarial loss: 1.165390\n","epoch 28; iter: 0; batch classifier loss: 0.657289; batch adversarial loss: 1.178653\n","epoch 29; iter: 0; batch classifier loss: 0.584907; batch adversarial loss: 1.140430\n","epoch 30; iter: 0; batch classifier loss: 0.622130; batch adversarial loss: 1.123462\n","epoch 31; iter: 0; batch classifier loss: 0.552816; batch adversarial loss: 1.111444\n","epoch 32; iter: 0; batch classifier loss: 0.636035; batch adversarial loss: 1.145013\n","epoch 33; iter: 0; batch classifier loss: 0.657861; batch adversarial loss: 1.087171\n","epoch 34; iter: 0; batch classifier loss: 0.597331; batch adversarial loss: 1.111026\n","epoch 35; iter: 0; batch classifier loss: 0.695257; batch adversarial loss: 1.110814\n","epoch 36; iter: 0; batch classifier loss: 0.778172; batch adversarial loss: 1.135712\n","epoch 37; iter: 0; batch classifier loss: 0.615215; batch adversarial loss: 1.089931\n","epoch 38; iter: 0; batch classifier loss: 0.673326; batch adversarial loss: 1.100261\n","epoch 39; iter: 0; batch classifier loss: 0.675589; batch adversarial loss: 1.094419\n","epoch 40; iter: 0; batch classifier loss: 0.687085; batch adversarial loss: 1.074134\n","epoch 41; iter: 0; batch classifier loss: 0.724093; batch adversarial loss: 1.108867\n","epoch 42; iter: 0; batch classifier loss: 0.727470; batch adversarial loss: 1.079328\n","epoch 43; iter: 0; batch classifier loss: 0.564625; batch adversarial loss: 1.050526\n","epoch 44; iter: 0; batch classifier loss: 0.768470; batch adversarial loss: 1.090599\n","epoch 45; iter: 0; batch classifier loss: 0.681076; batch adversarial loss: 1.056812\n","epoch 46; iter: 0; batch classifier loss: 0.722577; batch adversarial loss: 1.048574\n","epoch 47; iter: 0; batch classifier loss: 0.668450; batch adversarial loss: 1.059995\n","epoch 48; iter: 0; batch classifier loss: 0.851221; batch adversarial loss: 1.102159\n","epoch 49; iter: 0; batch classifier loss: 0.680893; batch adversarial loss: 1.036935\n","Accuracy 0.6834532374100719\n","epoch 0; iter: 0; batch classifier loss: 0.663281; batch adversarial loss: 0.526693\n","epoch 1; iter: 0; batch classifier loss: 0.668968; batch adversarial loss: 0.525532\n","epoch 2; iter: 0; batch classifier loss: 0.652358; batch adversarial loss: 0.579190\n","epoch 3; iter: 0; batch classifier loss: 0.643777; batch adversarial loss: 0.539031\n","epoch 4; iter: 0; batch classifier loss: 0.603849; batch adversarial loss: 0.558708\n","epoch 5; iter: 0; batch classifier loss: 0.615166; batch adversarial loss: 0.526638\n","epoch 6; iter: 0; batch classifier loss: 0.566807; batch adversarial loss: 0.520576\n","epoch 7; iter: 0; batch classifier loss: 0.626270; batch adversarial loss: 0.574301\n","epoch 8; iter: 0; batch classifier loss: 0.604105; batch adversarial loss: 0.537882\n","epoch 9; iter: 0; batch classifier loss: 0.567054; batch adversarial loss: 0.581413\n","epoch 10; iter: 0; batch classifier loss: 0.581147; batch adversarial loss: 0.575854\n","epoch 11; iter: 0; batch classifier loss: 0.603146; batch adversarial loss: 0.560472\n","epoch 12; iter: 0; batch classifier loss: 0.572725; batch adversarial loss: 0.548388\n","epoch 13; iter: 0; batch classifier loss: 0.536289; batch adversarial loss: 0.582882\n","epoch 14; iter: 0; batch classifier loss: 0.593823; batch adversarial loss: 0.568522\n","epoch 15; iter: 0; batch classifier loss: 0.578600; batch adversarial loss: 0.622016\n","epoch 16; iter: 0; batch classifier loss: 0.589944; batch adversarial loss: 0.626250\n","epoch 17; iter: 0; batch classifier loss: 0.571135; batch adversarial loss: 0.653876\n","epoch 18; iter: 0; batch classifier loss: 0.505734; batch adversarial loss: 0.565099\n","epoch 19; iter: 0; batch classifier loss: 0.578062; batch adversarial loss: 0.595237\n","epoch 20; iter: 0; batch classifier loss: 0.578231; batch adversarial loss: 0.576060\n","epoch 21; iter: 0; batch classifier loss: 0.545008; batch adversarial loss: 0.640638\n","epoch 22; iter: 0; batch classifier loss: 0.500059; batch adversarial loss: 0.615403\n","epoch 23; iter: 0; batch classifier loss: 0.526542; batch adversarial loss: 0.648031\n","epoch 24; iter: 0; batch classifier loss: 0.539355; batch adversarial loss: 0.637554\n","epoch 25; iter: 0; batch classifier loss: 0.605629; batch adversarial loss: 0.677977\n","epoch 26; iter: 0; batch classifier loss: 0.573167; batch adversarial loss: 0.633247\n","epoch 27; iter: 0; batch classifier loss: 0.615977; batch adversarial loss: 0.660925\n","epoch 28; iter: 0; batch classifier loss: 0.537879; batch adversarial loss: 0.619443\n","epoch 29; iter: 0; batch classifier loss: 0.545544; batch adversarial loss: 0.602156\n","epoch 30; iter: 0; batch classifier loss: 0.554933; batch adversarial loss: 0.649120\n","epoch 31; iter: 0; batch classifier loss: 0.622976; batch adversarial loss: 0.639240\n","epoch 32; iter: 0; batch classifier loss: 0.608423; batch adversarial loss: 0.653563\n","epoch 33; iter: 0; batch classifier loss: 0.579632; batch adversarial loss: 0.656575\n","epoch 34; iter: 0; batch classifier loss: 0.547772; batch adversarial loss: 0.647435\n","epoch 35; iter: 0; batch classifier loss: 0.567466; batch adversarial loss: 0.668538\n","epoch 36; iter: 0; batch classifier loss: 0.631119; batch adversarial loss: 0.659137\n","epoch 37; iter: 0; batch classifier loss: 0.565373; batch adversarial loss: 0.662807\n","epoch 38; iter: 0; batch classifier loss: 0.638513; batch adversarial loss: 0.629392\n","epoch 39; iter: 0; batch classifier loss: 0.611576; batch adversarial loss: 0.677053\n","epoch 40; iter: 0; batch classifier loss: 0.629720; batch adversarial loss: 0.692825\n","epoch 41; iter: 0; batch classifier loss: 0.581699; batch adversarial loss: 0.632419\n","epoch 42; iter: 0; batch classifier loss: 0.628795; batch adversarial loss: 0.608319\n","epoch 43; iter: 0; batch classifier loss: 0.608155; batch adversarial loss: 0.613799\n","epoch 44; iter: 0; batch classifier loss: 0.692621; batch adversarial loss: 0.705296\n","epoch 45; iter: 0; batch classifier loss: 0.658756; batch adversarial loss: 0.673563\n","epoch 46; iter: 0; batch classifier loss: 0.689811; batch adversarial loss: 0.676952\n","epoch 47; iter: 0; batch classifier loss: 0.612631; batch adversarial loss: 0.669575\n","epoch 48; iter: 0; batch classifier loss: 0.677522; batch adversarial loss: 0.683520\n","epoch 49; iter: 0; batch classifier loss: 0.633665; batch adversarial loss: 0.667354\n","Accuracy 0.6187050359712231\n","epoch 0; iter: 0; batch classifier loss: 0.666289; batch adversarial loss: 0.724715\n","epoch 1; iter: 0; batch classifier loss: 0.651014; batch adversarial loss: 0.739360\n","epoch 2; iter: 0; batch classifier loss: 0.645056; batch adversarial loss: 0.739096\n","epoch 3; iter: 0; batch classifier loss: 0.611043; batch adversarial loss: 0.737058\n","epoch 4; iter: 0; batch classifier loss: 0.570271; batch adversarial loss: 0.773225\n","epoch 5; iter: 0; batch classifier loss: 0.581285; batch adversarial loss: 0.734595\n","epoch 6; iter: 0; batch classifier loss: 0.596015; batch adversarial loss: 0.718357\n","epoch 7; iter: 0; batch classifier loss: 0.557716; batch adversarial loss: 0.721443\n","epoch 8; iter: 0; batch classifier loss: 0.580750; batch adversarial loss: 0.723922\n","epoch 9; iter: 0; batch classifier loss: 0.562730; batch adversarial loss: 0.722482\n","epoch 10; iter: 0; batch classifier loss: 0.546361; batch adversarial loss: 0.740378\n","epoch 11; iter: 0; batch classifier loss: 0.569285; batch adversarial loss: 0.686190\n","epoch 12; iter: 0; batch classifier loss: 0.494405; batch adversarial loss: 0.716048\n","epoch 13; iter: 0; batch classifier loss: 0.540392; batch adversarial loss: 0.697563\n","epoch 14; iter: 0; batch classifier loss: 0.492092; batch adversarial loss: 0.719118\n","epoch 15; iter: 0; batch classifier loss: 0.518169; batch adversarial loss: 0.701396\n","epoch 16; iter: 0; batch classifier loss: 0.506184; batch adversarial loss: 0.707237\n","epoch 17; iter: 0; batch classifier loss: 0.494955; batch adversarial loss: 0.695642\n","epoch 18; iter: 0; batch classifier loss: 0.440977; batch adversarial loss: 0.720243\n","epoch 19; iter: 0; batch classifier loss: 0.459521; batch adversarial loss: 0.682748\n","epoch 20; iter: 0; batch classifier loss: 0.503118; batch adversarial loss: 0.678382\n","epoch 21; iter: 0; batch classifier loss: 0.512017; batch adversarial loss: 0.689504\n","epoch 22; iter: 0; batch classifier loss: 0.471786; batch adversarial loss: 0.666825\n","epoch 23; iter: 0; batch classifier loss: 0.470640; batch adversarial loss: 0.695963\n","epoch 24; iter: 0; batch classifier loss: 0.486406; batch adversarial loss: 0.678727\n","epoch 25; iter: 0; batch classifier loss: 0.548441; batch adversarial loss: 0.703488\n","epoch 26; iter: 0; batch classifier loss: 0.518569; batch adversarial loss: 0.644982\n","epoch 27; iter: 0; batch classifier loss: 0.497110; batch adversarial loss: 0.668511\n","epoch 28; iter: 0; batch classifier loss: 0.467836; batch adversarial loss: 0.680933\n","epoch 29; iter: 0; batch classifier loss: 0.492117; batch adversarial loss: 0.644792\n","epoch 30; iter: 0; batch classifier loss: 0.466777; batch adversarial loss: 0.669865\n","epoch 31; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.658526\n","epoch 32; iter: 0; batch classifier loss: 0.479426; batch adversarial loss: 0.660990\n","epoch 33; iter: 0; batch classifier loss: 0.419140; batch adversarial loss: 0.674786\n","epoch 34; iter: 0; batch classifier loss: 0.510939; batch adversarial loss: 0.630967\n","epoch 35; iter: 0; batch classifier loss: 0.478178; batch adversarial loss: 0.637443\n","epoch 36; iter: 0; batch classifier loss: 0.390625; batch adversarial loss: 0.688559\n","epoch 37; iter: 0; batch classifier loss: 0.485016; batch adversarial loss: 0.627610\n","epoch 38; iter: 0; batch classifier loss: 0.447887; batch adversarial loss: 0.685578\n","epoch 39; iter: 0; batch classifier loss: 0.448656; batch adversarial loss: 0.630423\n","epoch 40; iter: 0; batch classifier loss: 0.470463; batch adversarial loss: 0.619995\n","epoch 41; iter: 0; batch classifier loss: 0.390183; batch adversarial loss: 0.644129\n","epoch 42; iter: 0; batch classifier loss: 0.381700; batch adversarial loss: 0.629318\n","epoch 43; iter: 0; batch classifier loss: 0.474071; batch adversarial loss: 0.637276\n","epoch 44; iter: 0; batch classifier loss: 0.441993; batch adversarial loss: 0.643158\n","epoch 45; iter: 0; batch classifier loss: 0.440694; batch adversarial loss: 0.643723\n","epoch 46; iter: 0; batch classifier loss: 0.422578; batch adversarial loss: 0.627199\n","epoch 47; iter: 0; batch classifier loss: 0.449718; batch adversarial loss: 0.612383\n","epoch 48; iter: 0; batch classifier loss: 0.407120; batch adversarial loss: 0.629865\n","epoch 49; iter: 0; batch classifier loss: 0.446278; batch adversarial loss: 0.632452\n","Accuracy 0.6521739130434783\n","epoch 0; iter: 0; batch classifier loss: 0.772480; batch adversarial loss: 0.696460\n","epoch 1; iter: 0; batch classifier loss: 0.723047; batch adversarial loss: 0.693300\n","epoch 2; iter: 0; batch classifier loss: 0.676374; batch adversarial loss: 0.681044\n","epoch 3; iter: 0; batch classifier loss: 0.660494; batch adversarial loss: 0.678209\n","epoch 4; iter: 0; batch classifier loss: 0.650425; batch adversarial loss: 0.689843\n","epoch 5; iter: 0; batch classifier loss: 0.632448; batch adversarial loss: 0.685531\n","epoch 6; iter: 0; batch classifier loss: 0.617999; batch adversarial loss: 0.652316\n","epoch 7; iter: 0; batch classifier loss: 0.635577; batch adversarial loss: 0.630406\n","epoch 8; iter: 0; batch classifier loss: 0.606342; batch adversarial loss: 0.654432\n","epoch 9; iter: 0; batch classifier loss: 0.601027; batch adversarial loss: 0.667306\n","epoch 10; iter: 0; batch classifier loss: 0.608705; batch adversarial loss: 0.669958\n","epoch 11; iter: 0; batch classifier loss: 0.583440; batch adversarial loss: 0.636969\n","epoch 12; iter: 0; batch classifier loss: 0.609212; batch adversarial loss: 0.660312\n","epoch 13; iter: 0; batch classifier loss: 0.587217; batch adversarial loss: 0.647235\n","epoch 14; iter: 0; batch classifier loss: 0.558785; batch adversarial loss: 0.634126\n","epoch 15; iter: 0; batch classifier loss: 0.618797; batch adversarial loss: 0.676364\n","epoch 16; iter: 0; batch classifier loss: 0.568798; batch adversarial loss: 0.639405\n","epoch 17; iter: 0; batch classifier loss: 0.520432; batch adversarial loss: 0.631973\n","epoch 18; iter: 0; batch classifier loss: 0.540537; batch adversarial loss: 0.626545\n","epoch 19; iter: 0; batch classifier loss: 0.578733; batch adversarial loss: 0.640280\n","epoch 20; iter: 0; batch classifier loss: 0.533325; batch adversarial loss: 0.640614\n","epoch 21; iter: 0; batch classifier loss: 0.517152; batch adversarial loss: 0.613659\n","epoch 22; iter: 0; batch classifier loss: 0.485795; batch adversarial loss: 0.607515\n","epoch 23; iter: 0; batch classifier loss: 0.515308; batch adversarial loss: 0.601451\n","epoch 24; iter: 0; batch classifier loss: 0.510885; batch adversarial loss: 0.637019\n","epoch 25; iter: 0; batch classifier loss: 0.522998; batch adversarial loss: 0.628048\n","epoch 26; iter: 0; batch classifier loss: 0.490031; batch adversarial loss: 0.651685\n","epoch 27; iter: 0; batch classifier loss: 0.499240; batch adversarial loss: 0.614903\n","epoch 28; iter: 0; batch classifier loss: 0.503425; batch adversarial loss: 0.616850\n","epoch 29; iter: 0; batch classifier loss: 0.547293; batch adversarial loss: 0.614348\n","epoch 30; iter: 0; batch classifier loss: 0.544590; batch adversarial loss: 0.630932\n","epoch 31; iter: 0; batch classifier loss: 0.518597; batch adversarial loss: 0.609740\n","epoch 32; iter: 0; batch classifier loss: 0.535193; batch adversarial loss: 0.652731\n","epoch 33; iter: 0; batch classifier loss: 0.454503; batch adversarial loss: 0.590478\n","epoch 34; iter: 0; batch classifier loss: 0.494305; batch adversarial loss: 0.592799\n","epoch 35; iter: 0; batch classifier loss: 0.513255; batch adversarial loss: 0.601779\n","epoch 36; iter: 0; batch classifier loss: 0.514752; batch adversarial loss: 0.627994\n","epoch 37; iter: 0; batch classifier loss: 0.549229; batch adversarial loss: 0.609326\n","epoch 38; iter: 0; batch classifier loss: 0.437452; batch adversarial loss: 0.614298\n","epoch 39; iter: 0; batch classifier loss: 0.478781; batch adversarial loss: 0.600420\n","epoch 40; iter: 0; batch classifier loss: 0.491852; batch adversarial loss: 0.615503\n","epoch 41; iter: 0; batch classifier loss: 0.498153; batch adversarial loss: 0.595504\n","epoch 42; iter: 0; batch classifier loss: 0.504082; batch adversarial loss: 0.596740\n","epoch 43; iter: 0; batch classifier loss: 0.501761; batch adversarial loss: 0.579635\n","epoch 44; iter: 0; batch classifier loss: 0.486986; batch adversarial loss: 0.602734\n","epoch 45; iter: 0; batch classifier loss: 0.512596; batch adversarial loss: 0.610234\n","epoch 46; iter: 0; batch classifier loss: 0.548364; batch adversarial loss: 0.563472\n","epoch 47; iter: 0; batch classifier loss: 0.522888; batch adversarial loss: 0.612039\n","epoch 48; iter: 0; batch classifier loss: 0.547701; batch adversarial loss: 0.569679\n","epoch 49; iter: 0; batch classifier loss: 0.501731; batch adversarial loss: 0.594987\n","Accuracy 0.7246376811594203\n","epoch 0; iter: 0; batch classifier loss: 0.741082; batch adversarial loss: 0.696112\n","epoch 1; iter: 0; batch classifier loss: 0.683376; batch adversarial loss: 0.698600\n","epoch 2; iter: 0; batch classifier loss: 0.675751; batch adversarial loss: 0.692622\n","epoch 3; iter: 0; batch classifier loss: 0.641475; batch adversarial loss: 0.689043\n","epoch 4; iter: 0; batch classifier loss: 0.604789; batch adversarial loss: 0.687774\n","epoch 5; iter: 0; batch classifier loss: 0.611591; batch adversarial loss: 0.683289\n","epoch 6; iter: 0; batch classifier loss: 0.607480; batch adversarial loss: 0.679730\n","epoch 7; iter: 0; batch classifier loss: 0.601825; batch adversarial loss: 0.679323\n","epoch 8; iter: 0; batch classifier loss: 0.606036; batch adversarial loss: 0.681627\n","epoch 9; iter: 0; batch classifier loss: 0.591611; batch adversarial loss: 0.673782\n","epoch 10; iter: 0; batch classifier loss: 0.541538; batch adversarial loss: 0.671701\n","epoch 11; iter: 0; batch classifier loss: 0.537390; batch adversarial loss: 0.670013\n","epoch 12; iter: 0; batch classifier loss: 0.562850; batch adversarial loss: 0.671874\n","epoch 13; iter: 0; batch classifier loss: 0.604804; batch adversarial loss: 0.670540\n","epoch 14; iter: 0; batch classifier loss: 0.546636; batch adversarial loss: 0.672663\n","epoch 15; iter: 0; batch classifier loss: 0.541915; batch adversarial loss: 0.659463\n","epoch 16; iter: 0; batch classifier loss: 0.592159; batch adversarial loss: 0.666574\n","epoch 17; iter: 0; batch classifier loss: 0.552428; batch adversarial loss: 0.658451\n","epoch 18; iter: 0; batch classifier loss: 0.516640; batch adversarial loss: 0.647358\n","epoch 19; iter: 0; batch classifier loss: 0.534882; batch adversarial loss: 0.651829\n","epoch 20; iter: 0; batch classifier loss: 0.539486; batch adversarial loss: 0.654387\n","epoch 21; iter: 0; batch classifier loss: 0.520118; batch adversarial loss: 0.651801\n","epoch 22; iter: 0; batch classifier loss: 0.525527; batch adversarial loss: 0.660409\n","epoch 23; iter: 0; batch classifier loss: 0.489083; batch adversarial loss: 0.641331\n","epoch 24; iter: 0; batch classifier loss: 0.543146; batch adversarial loss: 0.645803\n","epoch 25; iter: 0; batch classifier loss: 0.551800; batch adversarial loss: 0.650220\n","epoch 26; iter: 0; batch classifier loss: 0.530525; batch adversarial loss: 0.635958\n","epoch 27; iter: 0; batch classifier loss: 0.517514; batch adversarial loss: 0.640109\n","epoch 28; iter: 0; batch classifier loss: 0.505350; batch adversarial loss: 0.635429\n","epoch 29; iter: 0; batch classifier loss: 0.582075; batch adversarial loss: 0.650885\n","epoch 30; iter: 0; batch classifier loss: 0.470809; batch adversarial loss: 0.636777\n","epoch 31; iter: 0; batch classifier loss: 0.550435; batch adversarial loss: 0.640969\n","epoch 32; iter: 0; batch classifier loss: 0.586377; batch adversarial loss: 0.634302\n","epoch 33; iter: 0; batch classifier loss: 0.512161; batch adversarial loss: 0.639474\n","epoch 34; iter: 0; batch classifier loss: 0.492459; batch adversarial loss: 0.629136\n","epoch 35; iter: 0; batch classifier loss: 0.534101; batch adversarial loss: 0.613917\n","epoch 36; iter: 0; batch classifier loss: 0.568820; batch adversarial loss: 0.624615\n","epoch 37; iter: 0; batch classifier loss: 0.496142; batch adversarial loss: 0.616503\n","epoch 38; iter: 0; batch classifier loss: 0.509683; batch adversarial loss: 0.630537\n","epoch 39; iter: 0; batch classifier loss: 0.461381; batch adversarial loss: 0.634902\n","epoch 40; iter: 0; batch classifier loss: 0.479633; batch adversarial loss: 0.634062\n","epoch 41; iter: 0; batch classifier loss: 0.561687; batch adversarial loss: 0.626319\n","epoch 42; iter: 0; batch classifier loss: 0.530031; batch adversarial loss: 0.615301\n","epoch 43; iter: 0; batch classifier loss: 0.536532; batch adversarial loss: 0.630193\n","epoch 44; iter: 0; batch classifier loss: 0.491666; batch adversarial loss: 0.605191\n","epoch 45; iter: 0; batch classifier loss: 0.529867; batch adversarial loss: 0.615019\n","epoch 46; iter: 0; batch classifier loss: 0.518487; batch adversarial loss: 0.609085\n","epoch 47; iter: 0; batch classifier loss: 0.447804; batch adversarial loss: 0.607354\n","epoch 48; iter: 0; batch classifier loss: 0.493510; batch adversarial loss: 0.614322\n","epoch 49; iter: 0; batch classifier loss: 0.564517; batch adversarial loss: 0.619250\n","Accuracy 0.6811594202898551\n","epoch 0; iter: 0; batch classifier loss: 0.704679; batch adversarial loss: 0.698334\n","epoch 1; iter: 0; batch classifier loss: 0.681391; batch adversarial loss: 0.701045\n","epoch 2; iter: 0; batch classifier loss: 0.666429; batch adversarial loss: 0.692642\n","epoch 3; iter: 0; batch classifier loss: 0.635844; batch adversarial loss: 0.671526\n","epoch 4; iter: 0; batch classifier loss: 0.632801; batch adversarial loss: 0.686295\n","epoch 5; iter: 0; batch classifier loss: 0.627607; batch adversarial loss: 0.680110\n","epoch 6; iter: 0; batch classifier loss: 0.647407; batch adversarial loss: 0.684808\n","epoch 7; iter: 0; batch classifier loss: 0.605693; batch adversarial loss: 0.678457\n","epoch 8; iter: 0; batch classifier loss: 0.611086; batch adversarial loss: 0.677544\n","epoch 9; iter: 0; batch classifier loss: 0.565671; batch adversarial loss: 0.661345\n","epoch 10; iter: 0; batch classifier loss: 0.577140; batch adversarial loss: 0.657762\n","epoch 11; iter: 0; batch classifier loss: 0.525747; batch adversarial loss: 0.656003\n","epoch 12; iter: 0; batch classifier loss: 0.561667; batch adversarial loss: 0.660545\n","epoch 13; iter: 0; batch classifier loss: 0.543256; batch adversarial loss: 0.653541\n","epoch 14; iter: 0; batch classifier loss: 0.525334; batch adversarial loss: 0.650470\n","epoch 15; iter: 0; batch classifier loss: 0.546310; batch adversarial loss: 0.648447\n","epoch 16; iter: 0; batch classifier loss: 0.550924; batch adversarial loss: 0.650944\n","epoch 17; iter: 0; batch classifier loss: 0.563292; batch adversarial loss: 0.660697\n","epoch 18; iter: 0; batch classifier loss: 0.545148; batch adversarial loss: 0.645424\n","epoch 19; iter: 0; batch classifier loss: 0.523976; batch adversarial loss: 0.641838\n","epoch 20; iter: 0; batch classifier loss: 0.491772; batch adversarial loss: 0.633248\n","epoch 21; iter: 0; batch classifier loss: 0.549149; batch adversarial loss: 0.640595\n","epoch 22; iter: 0; batch classifier loss: 0.479095; batch adversarial loss: 0.642773\n","epoch 23; iter: 0; batch classifier loss: 0.481882; batch adversarial loss: 0.642719\n","epoch 24; iter: 0; batch classifier loss: 0.540942; batch adversarial loss: 0.636894\n","epoch 25; iter: 0; batch classifier loss: 0.513431; batch adversarial loss: 0.620392\n","epoch 26; iter: 0; batch classifier loss: 0.499530; batch adversarial loss: 0.637285\n","epoch 27; iter: 0; batch classifier loss: 0.487156; batch adversarial loss: 0.633628\n","epoch 28; iter: 0; batch classifier loss: 0.449893; batch adversarial loss: 0.610662\n","epoch 29; iter: 0; batch classifier loss: 0.498574; batch adversarial loss: 0.638475\n","epoch 30; iter: 0; batch classifier loss: 0.480759; batch adversarial loss: 0.608889\n","epoch 31; iter: 0; batch classifier loss: 0.492571; batch adversarial loss: 0.620707\n","epoch 32; iter: 0; batch classifier loss: 0.468201; batch adversarial loss: 0.615484\n","epoch 33; iter: 0; batch classifier loss: 0.484059; batch adversarial loss: 0.616367\n","epoch 34; iter: 0; batch classifier loss: 0.439675; batch adversarial loss: 0.614980\n","epoch 35; iter: 0; batch classifier loss: 0.438109; batch adversarial loss: 0.622196\n","epoch 36; iter: 0; batch classifier loss: 0.485377; batch adversarial loss: 0.602478\n","epoch 37; iter: 0; batch classifier loss: 0.438462; batch adversarial loss: 0.628431\n","epoch 38; iter: 0; batch classifier loss: 0.469003; batch adversarial loss: 0.600158\n","epoch 39; iter: 0; batch classifier loss: 0.452409; batch adversarial loss: 0.618003\n","epoch 40; iter: 0; batch classifier loss: 0.443383; batch adversarial loss: 0.617701\n","epoch 41; iter: 0; batch classifier loss: 0.518155; batch adversarial loss: 0.625671\n","epoch 42; iter: 0; batch classifier loss: 0.513872; batch adversarial loss: 0.603871\n","epoch 43; iter: 0; batch classifier loss: 0.436492; batch adversarial loss: 0.616080\n","epoch 44; iter: 0; batch classifier loss: 0.443103; batch adversarial loss: 0.618295\n","epoch 45; iter: 0; batch classifier loss: 0.508967; batch adversarial loss: 0.620620\n","epoch 46; iter: 0; batch classifier loss: 0.467267; batch adversarial loss: 0.588297\n","epoch 47; iter: 0; batch classifier loss: 0.467189; batch adversarial loss: 0.596337\n","epoch 48; iter: 0; batch classifier loss: 0.519348; batch adversarial loss: 0.585849\n","epoch 49; iter: 0; batch classifier loss: 0.462954; batch adversarial loss: 0.587314\n","Accuracy 0.7050359712230215\n","epoch 0; iter: 0; batch classifier loss: 0.698173; batch adversarial loss: 0.947072\n","epoch 1; iter: 0; batch classifier loss: 0.668939; batch adversarial loss: 0.967644\n","epoch 2; iter: 0; batch classifier loss: 0.656200; batch adversarial loss: 1.017723\n","epoch 3; iter: 0; batch classifier loss: 0.621496; batch adversarial loss: 1.080313\n","epoch 4; iter: 0; batch classifier loss: 0.630627; batch adversarial loss: 1.009361\n","epoch 5; iter: 0; batch classifier loss: 0.572022; batch adversarial loss: 1.128036\n","epoch 6; iter: 0; batch classifier loss: 0.626276; batch adversarial loss: 1.072282\n","epoch 7; iter: 0; batch classifier loss: 0.606354; batch adversarial loss: 1.042662\n","epoch 8; iter: 0; batch classifier loss: 0.568071; batch adversarial loss: 1.092136\n","epoch 9; iter: 0; batch classifier loss: 0.527429; batch adversarial loss: 1.163465\n","epoch 10; iter: 0; batch classifier loss: 0.582050; batch adversarial loss: 1.093681\n","epoch 11; iter: 0; batch classifier loss: 0.534408; batch adversarial loss: 1.156024\n","epoch 12; iter: 0; batch classifier loss: 0.504741; batch adversarial loss: 1.157272\n","epoch 13; iter: 0; batch classifier loss: 0.577161; batch adversarial loss: 1.049065\n","epoch 14; iter: 0; batch classifier loss: 0.558589; batch adversarial loss: 1.114144\n","epoch 15; iter: 0; batch classifier loss: 0.603628; batch adversarial loss: 1.099103\n","epoch 16; iter: 0; batch classifier loss: 0.522305; batch adversarial loss: 1.135152\n","epoch 17; iter: 0; batch classifier loss: 0.553998; batch adversarial loss: 1.103262\n","epoch 18; iter: 0; batch classifier loss: 0.604722; batch adversarial loss: 1.063650\n","epoch 19; iter: 0; batch classifier loss: 0.521341; batch adversarial loss: 1.127309\n","epoch 20; iter: 0; batch classifier loss: 0.556912; batch adversarial loss: 1.096724\n","epoch 21; iter: 0; batch classifier loss: 0.523544; batch adversarial loss: 1.088687\n","epoch 22; iter: 0; batch classifier loss: 0.538714; batch adversarial loss: 1.059058\n","epoch 23; iter: 0; batch classifier loss: 0.532638; batch adversarial loss: 1.049790\n","epoch 24; iter: 0; batch classifier loss: 0.518368; batch adversarial loss: 1.042592\n","epoch 25; iter: 0; batch classifier loss: 0.500122; batch adversarial loss: 1.060168\n","epoch 26; iter: 0; batch classifier loss: 0.582788; batch adversarial loss: 1.043589\n","epoch 27; iter: 0; batch classifier loss: 0.517501; batch adversarial loss: 1.017071\n","epoch 28; iter: 0; batch classifier loss: 0.529128; batch adversarial loss: 1.042294\n","epoch 29; iter: 0; batch classifier loss: 0.498411; batch adversarial loss: 1.036823\n","epoch 30; iter: 0; batch classifier loss: 0.575288; batch adversarial loss: 0.988631\n","epoch 31; iter: 0; batch classifier loss: 0.541718; batch adversarial loss: 1.005796\n","epoch 32; iter: 0; batch classifier loss: 0.556684; batch adversarial loss: 1.012531\n","epoch 33; iter: 0; batch classifier loss: 0.472522; batch adversarial loss: 1.050430\n","epoch 34; iter: 0; batch classifier loss: 0.462609; batch adversarial loss: 1.043579\n","epoch 35; iter: 0; batch classifier loss: 0.415002; batch adversarial loss: 1.097757\n","epoch 36; iter: 0; batch classifier loss: 0.591798; batch adversarial loss: 0.974706\n","epoch 37; iter: 0; batch classifier loss: 0.548850; batch adversarial loss: 0.948246\n","epoch 38; iter: 0; batch classifier loss: 0.530291; batch adversarial loss: 0.912382\n","epoch 39; iter: 0; batch classifier loss: 0.464521; batch adversarial loss: 0.989499\n","epoch 40; iter: 0; batch classifier loss: 0.491161; batch adversarial loss: 0.972604\n","epoch 41; iter: 0; batch classifier loss: 0.474762; batch adversarial loss: 1.025705\n","epoch 42; iter: 0; batch classifier loss: 0.541611; batch adversarial loss: 0.961718\n","epoch 43; iter: 0; batch classifier loss: 0.485177; batch adversarial loss: 1.056907\n","epoch 44; iter: 0; batch classifier loss: 0.545883; batch adversarial loss: 0.940225\n","epoch 45; iter: 0; batch classifier loss: 0.483635; batch adversarial loss: 0.920343\n","epoch 46; iter: 0; batch classifier loss: 0.493825; batch adversarial loss: 0.933881\n","epoch 47; iter: 0; batch classifier loss: 0.479342; batch adversarial loss: 0.974764\n","epoch 48; iter: 0; batch classifier loss: 0.506528; batch adversarial loss: 0.971653\n","epoch 49; iter: 0; batch classifier loss: 0.384845; batch adversarial loss: 0.999829\n","Accuracy 0.7410071942446043\n","epoch 0; iter: 0; batch classifier loss: 0.696228; batch adversarial loss: 0.834272\n","epoch 1; iter: 0; batch classifier loss: 0.666292; batch adversarial loss: 0.841390\n","epoch 2; iter: 0; batch classifier loss: 0.648479; batch adversarial loss: 0.827774\n","epoch 3; iter: 0; batch classifier loss: 0.644965; batch adversarial loss: 0.856741\n","epoch 4; iter: 0; batch classifier loss: 0.606141; batch adversarial loss: 0.848459\n","epoch 5; iter: 0; batch classifier loss: 0.624653; batch adversarial loss: 0.855156\n","epoch 6; iter: 0; batch classifier loss: 0.577906; batch adversarial loss: 0.889830\n","epoch 7; iter: 0; batch classifier loss: 0.542672; batch adversarial loss: 0.894937\n","epoch 8; iter: 0; batch classifier loss: 0.550660; batch adversarial loss: 0.865694\n","epoch 9; iter: 0; batch classifier loss: 0.544592; batch adversarial loss: 0.915995\n","epoch 10; iter: 0; batch classifier loss: 0.539901; batch adversarial loss: 0.869350\n","epoch 11; iter: 0; batch classifier loss: 0.546356; batch adversarial loss: 0.882485\n","epoch 12; iter: 0; batch classifier loss: 0.533611; batch adversarial loss: 0.868301\n","epoch 13; iter: 0; batch classifier loss: 0.541837; batch adversarial loss: 0.835926\n","epoch 14; iter: 0; batch classifier loss: 0.517384; batch adversarial loss: 0.882758\n","epoch 15; iter: 0; batch classifier loss: 0.496895; batch adversarial loss: 0.859974\n","epoch 16; iter: 0; batch classifier loss: 0.558038; batch adversarial loss: 0.848411\n","epoch 17; iter: 0; batch classifier loss: 0.516021; batch adversarial loss: 0.847417\n","epoch 18; iter: 0; batch classifier loss: 0.589708; batch adversarial loss: 0.839958\n","epoch 19; iter: 0; batch classifier loss: 0.503808; batch adversarial loss: 0.860404\n","epoch 20; iter: 0; batch classifier loss: 0.534835; batch adversarial loss: 0.834876\n","epoch 21; iter: 0; batch classifier loss: 0.515314; batch adversarial loss: 0.834448\n","epoch 22; iter: 0; batch classifier loss: 0.467950; batch adversarial loss: 0.854301\n","epoch 23; iter: 0; batch classifier loss: 0.494839; batch adversarial loss: 0.838092\n","epoch 24; iter: 0; batch classifier loss: 0.465417; batch adversarial loss: 0.835000\n","epoch 25; iter: 0; batch classifier loss: 0.559496; batch adversarial loss: 0.806829\n","epoch 26; iter: 0; batch classifier loss: 0.451194; batch adversarial loss: 0.855700\n","epoch 27; iter: 0; batch classifier loss: 0.527626; batch adversarial loss: 0.818063\n","epoch 28; iter: 0; batch classifier loss: 0.525155; batch adversarial loss: 0.807182\n","epoch 29; iter: 0; batch classifier loss: 0.537621; batch adversarial loss: 0.807314\n","epoch 30; iter: 0; batch classifier loss: 0.503106; batch adversarial loss: 0.813614\n","epoch 31; iter: 0; batch classifier loss: 0.509448; batch adversarial loss: 0.815989\n","epoch 32; iter: 0; batch classifier loss: 0.505563; batch adversarial loss: 0.798075\n","epoch 33; iter: 0; batch classifier loss: 0.542136; batch adversarial loss: 0.775658\n","epoch 34; iter: 0; batch classifier loss: 0.488812; batch adversarial loss: 0.785646\n","epoch 35; iter: 0; batch classifier loss: 0.459831; batch adversarial loss: 0.805580\n","epoch 36; iter: 0; batch classifier loss: 0.517388; batch adversarial loss: 0.774121\n","epoch 37; iter: 0; batch classifier loss: 0.485101; batch adversarial loss: 0.777756\n","epoch 38; iter: 0; batch classifier loss: 0.522110; batch adversarial loss: 0.775302\n","epoch 39; iter: 0; batch classifier loss: 0.570534; batch adversarial loss: 0.765332\n","epoch 40; iter: 0; batch classifier loss: 0.466163; batch adversarial loss: 0.758427\n","epoch 41; iter: 0; batch classifier loss: 0.495000; batch adversarial loss: 0.766565\n","epoch 42; iter: 0; batch classifier loss: 0.470749; batch adversarial loss: 0.773594\n","epoch 43; iter: 0; batch classifier loss: 0.520895; batch adversarial loss: 0.742529\n","epoch 44; iter: 0; batch classifier loss: 0.483737; batch adversarial loss: 0.770874\n","epoch 45; iter: 0; batch classifier loss: 0.520971; batch adversarial loss: 0.740581\n","epoch 46; iter: 0; batch classifier loss: 0.488238; batch adversarial loss: 0.740298\n","epoch 47; iter: 0; batch classifier loss: 0.448709; batch adversarial loss: 0.758618\n","epoch 48; iter: 0; batch classifier loss: 0.444869; batch adversarial loss: 0.750918\n","epoch 49; iter: 0; batch classifier loss: 0.469097; batch adversarial loss: 0.746194\n","Accuracy 0.7246376811594203\n","epoch 0; iter: 0; batch classifier loss: 0.719547; batch adversarial loss: 0.552487\n","epoch 1; iter: 0; batch classifier loss: 0.712243; batch adversarial loss: 0.557333\n","epoch 2; iter: 0; batch classifier loss: 0.702977; batch adversarial loss: 0.547866\n","epoch 3; iter: 0; batch classifier loss: 0.742055; batch adversarial loss: 0.573859\n","epoch 4; iter: 0; batch classifier loss: 0.686510; batch adversarial loss: 0.626657\n","epoch 5; iter: 0; batch classifier loss: 0.698260; batch adversarial loss: 0.604537\n","epoch 6; iter: 0; batch classifier loss: 0.660653; batch adversarial loss: 0.634089\n","epoch 7; iter: 0; batch classifier loss: 0.684843; batch adversarial loss: 0.552193\n","epoch 8; iter: 0; batch classifier loss: 0.673472; batch adversarial loss: 0.613438\n","epoch 9; iter: 0; batch classifier loss: 0.633545; batch adversarial loss: 0.629688\n","epoch 10; iter: 0; batch classifier loss: 0.640022; batch adversarial loss: 0.639498\n","epoch 11; iter: 0; batch classifier loss: 0.633299; batch adversarial loss: 0.646072\n","epoch 12; iter: 0; batch classifier loss: 0.593735; batch adversarial loss: 0.615715\n","epoch 13; iter: 0; batch classifier loss: 0.703835; batch adversarial loss: 0.591580\n","epoch 14; iter: 0; batch classifier loss: 0.679050; batch adversarial loss: 0.620675\n","epoch 15; iter: 0; batch classifier loss: 0.655389; batch adversarial loss: 0.650172\n","epoch 16; iter: 0; batch classifier loss: 0.660303; batch adversarial loss: 0.653661\n","epoch 17; iter: 0; batch classifier loss: 0.649832; batch adversarial loss: 0.633518\n","epoch 18; iter: 0; batch classifier loss: 0.682974; batch adversarial loss: 0.548705\n","epoch 19; iter: 0; batch classifier loss: 0.644354; batch adversarial loss: 0.670087\n","epoch 20; iter: 0; batch classifier loss: 0.617366; batch adversarial loss: 0.638900\n","epoch 21; iter: 0; batch classifier loss: 0.594044; batch adversarial loss: 0.683311\n","epoch 22; iter: 0; batch classifier loss: 0.646161; batch adversarial loss: 0.713792\n","epoch 23; iter: 0; batch classifier loss: 0.654392; batch adversarial loss: 0.608966\n","epoch 24; iter: 0; batch classifier loss: 0.693478; batch adversarial loss: 0.664074\n","epoch 25; iter: 0; batch classifier loss: 0.703382; batch adversarial loss: 0.674364\n","epoch 26; iter: 0; batch classifier loss: 0.713234; batch adversarial loss: 0.681519\n","epoch 27; iter: 0; batch classifier loss: 0.798195; batch adversarial loss: 0.627871\n","epoch 28; iter: 0; batch classifier loss: 0.826266; batch adversarial loss: 0.685912\n","epoch 29; iter: 0; batch classifier loss: 0.719167; batch adversarial loss: 0.653995\n","epoch 30; iter: 0; batch classifier loss: 0.818427; batch adversarial loss: 0.636815\n","epoch 31; iter: 0; batch classifier loss: 0.818827; batch adversarial loss: 0.721638\n","epoch 32; iter: 0; batch classifier loss: 0.809413; batch adversarial loss: 0.745708\n","epoch 33; iter: 0; batch classifier loss: 0.778754; batch adversarial loss: 0.692780\n","epoch 34; iter: 0; batch classifier loss: 0.843770; batch adversarial loss: 0.706666\n","epoch 35; iter: 0; batch classifier loss: 0.849595; batch adversarial loss: 0.660667\n","epoch 36; iter: 0; batch classifier loss: 0.862394; batch adversarial loss: 0.687199\n","epoch 37; iter: 0; batch classifier loss: 0.899076; batch adversarial loss: 0.731570\n","epoch 38; iter: 0; batch classifier loss: 0.951291; batch adversarial loss: 0.644981\n","epoch 39; iter: 0; batch classifier loss: 0.888905; batch adversarial loss: 0.700675\n","epoch 40; iter: 0; batch classifier loss: 0.910401; batch adversarial loss: 0.717946\n","epoch 41; iter: 0; batch classifier loss: 1.004446; batch adversarial loss: 0.685187\n","epoch 42; iter: 0; batch classifier loss: 0.970076; batch adversarial loss: 0.714971\n","epoch 43; iter: 0; batch classifier loss: 0.947898; batch adversarial loss: 0.677725\n","epoch 44; iter: 0; batch classifier loss: 0.959048; batch adversarial loss: 0.736891\n","epoch 45; iter: 0; batch classifier loss: 0.978110; batch adversarial loss: 0.678151\n","epoch 46; iter: 0; batch classifier loss: 1.011205; batch adversarial loss: 0.737197\n","epoch 47; iter: 0; batch classifier loss: 1.046561; batch adversarial loss: 0.704770\n","epoch 48; iter: 0; batch classifier loss: 0.995237; batch adversarial loss: 0.767933\n","epoch 49; iter: 0; batch classifier loss: 1.058930; batch adversarial loss: 0.679981\n"],"name":"stdout"},{"output_type":"stream","text":["divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.41304347826086957\n","epoch 0; iter: 0; batch classifier loss: 0.696900; batch adversarial loss: 0.632290\n","epoch 1; iter: 0; batch classifier loss: 0.654230; batch adversarial loss: 0.662017\n","epoch 2; iter: 0; batch classifier loss: 0.639635; batch adversarial loss: 0.636059\n","epoch 3; iter: 0; batch classifier loss: 0.637697; batch adversarial loss: 0.614834\n","epoch 4; iter: 0; batch classifier loss: 0.607531; batch adversarial loss: 0.584257\n","epoch 5; iter: 0; batch classifier loss: 0.603212; batch adversarial loss: 0.653445\n","epoch 6; iter: 0; batch classifier loss: 0.576767; batch adversarial loss: 0.631808\n","epoch 7; iter: 0; batch classifier loss: 0.601778; batch adversarial loss: 0.623119\n","epoch 8; iter: 0; batch classifier loss: 0.612407; batch adversarial loss: 0.637058\n","epoch 9; iter: 0; batch classifier loss: 0.574916; batch adversarial loss: 0.633776\n","epoch 10; iter: 0; batch classifier loss: 0.569207; batch adversarial loss: 0.665343\n","epoch 11; iter: 0; batch classifier loss: 0.571010; batch adversarial loss: 0.677141\n","epoch 12; iter: 0; batch classifier loss: 0.563068; batch adversarial loss: 0.627230\n","epoch 13; iter: 0; batch classifier loss: 0.567428; batch adversarial loss: 0.664695\n","epoch 14; iter: 0; batch classifier loss: 0.545413; batch adversarial loss: 0.643129\n","epoch 15; iter: 0; batch classifier loss: 0.514975; batch adversarial loss: 0.662381\n","epoch 16; iter: 0; batch classifier loss: 0.563681; batch adversarial loss: 0.652986\n","epoch 17; iter: 0; batch classifier loss: 0.537747; batch adversarial loss: 0.640798\n","epoch 18; iter: 0; batch classifier loss: 0.526996; batch adversarial loss: 0.584599\n","epoch 19; iter: 0; batch classifier loss: 0.520710; batch adversarial loss: 0.609288\n","epoch 20; iter: 0; batch classifier loss: 0.558059; batch adversarial loss: 0.671160\n","epoch 21; iter: 0; batch classifier loss: 0.527188; batch adversarial loss: 0.605778\n","epoch 22; iter: 0; batch classifier loss: 0.467918; batch adversarial loss: 0.597385\n","epoch 23; iter: 0; batch classifier loss: 0.516132; batch adversarial loss: 0.621051\n","epoch 24; iter: 0; batch classifier loss: 0.467455; batch adversarial loss: 0.584327\n","epoch 25; iter: 0; batch classifier loss: 0.496702; batch adversarial loss: 0.649139\n","epoch 26; iter: 0; batch classifier loss: 0.462484; batch adversarial loss: 0.631721\n","epoch 27; iter: 0; batch classifier loss: 0.485604; batch adversarial loss: 0.623576\n","epoch 28; iter: 0; batch classifier loss: 0.461972; batch adversarial loss: 0.600268\n","epoch 29; iter: 0; batch classifier loss: 0.460849; batch adversarial loss: 0.601956\n","epoch 30; iter: 0; batch classifier loss: 0.496364; batch adversarial loss: 0.633770\n","epoch 31; iter: 0; batch classifier loss: 0.497279; batch adversarial loss: 0.591309\n","epoch 32; iter: 0; batch classifier loss: 0.528129; batch adversarial loss: 0.595184\n","epoch 33; iter: 0; batch classifier loss: 0.446738; batch adversarial loss: 0.634345\n","epoch 34; iter: 0; batch classifier loss: 0.487431; batch adversarial loss: 0.624024\n","epoch 35; iter: 0; batch classifier loss: 0.490251; batch adversarial loss: 0.623565\n","epoch 36; iter: 0; batch classifier loss: 0.484903; batch adversarial loss: 0.605760\n","epoch 37; iter: 0; batch classifier loss: 0.464242; batch adversarial loss: 0.606620\n","epoch 38; iter: 0; batch classifier loss: 0.483013; batch adversarial loss: 0.626740\n","epoch 39; iter: 0; batch classifier loss: 0.545917; batch adversarial loss: 0.604712\n","epoch 40; iter: 0; batch classifier loss: 0.494953; batch adversarial loss: 0.646797\n","epoch 41; iter: 0; batch classifier loss: 0.496307; batch adversarial loss: 0.552650\n","epoch 42; iter: 0; batch classifier loss: 0.461111; batch adversarial loss: 0.592802\n","epoch 43; iter: 0; batch classifier loss: 0.520133; batch adversarial loss: 0.607440\n","epoch 44; iter: 0; batch classifier loss: 0.483906; batch adversarial loss: 0.585278\n","epoch 45; iter: 0; batch classifier loss: 0.535076; batch adversarial loss: 0.574260\n","epoch 46; iter: 0; batch classifier loss: 0.543748; batch adversarial loss: 0.694287\n","epoch 47; iter: 0; batch classifier loss: 0.507379; batch adversarial loss: 0.610888\n","epoch 48; iter: 0; batch classifier loss: 0.513188; batch adversarial loss: 0.603020\n","epoch 49; iter: 0; batch classifier loss: 0.480143; batch adversarial loss: 0.595589\n","Accuracy 0.7681159420289855\n","epoch 0; iter: 0; batch classifier loss: 0.686322; batch adversarial loss: 0.569122\n","epoch 1; iter: 0; batch classifier loss: 0.669800; batch adversarial loss: 0.595388\n","epoch 2; iter: 0; batch classifier loss: 0.660514; batch adversarial loss: 0.585967\n","epoch 3; iter: 0; batch classifier loss: 0.643373; batch adversarial loss: 0.620219\n","epoch 4; iter: 0; batch classifier loss: 0.643384; batch adversarial loss: 0.599206\n","epoch 5; iter: 0; batch classifier loss: 0.638804; batch adversarial loss: 0.613794\n","epoch 6; iter: 0; batch classifier loss: 0.622320; batch adversarial loss: 0.591163\n","epoch 7; iter: 0; batch classifier loss: 0.602951; batch adversarial loss: 0.628745\n","epoch 8; iter: 0; batch classifier loss: 0.564933; batch adversarial loss: 0.636389\n","epoch 9; iter: 0; batch classifier loss: 0.609454; batch adversarial loss: 0.618000\n","epoch 10; iter: 0; batch classifier loss: 0.609388; batch adversarial loss: 0.635678\n","epoch 11; iter: 0; batch classifier loss: 0.602782; batch adversarial loss: 0.631415\n","epoch 12; iter: 0; batch classifier loss: 0.618397; batch adversarial loss: 0.624650\n","epoch 13; iter: 0; batch classifier loss: 0.573903; batch adversarial loss: 0.589281\n","epoch 14; iter: 0; batch classifier loss: 0.596979; batch adversarial loss: 0.612318\n","epoch 15; iter: 0; batch classifier loss: 0.601939; batch adversarial loss: 0.647134\n","epoch 16; iter: 0; batch classifier loss: 0.608966; batch adversarial loss: 0.597185\n","epoch 17; iter: 0; batch classifier loss: 0.609726; batch adversarial loss: 0.642723\n","epoch 18; iter: 0; batch classifier loss: 0.566320; batch adversarial loss: 0.618768\n","epoch 19; iter: 0; batch classifier loss: 0.537654; batch adversarial loss: 0.650049\n","epoch 20; iter: 0; batch classifier loss: 0.597629; batch adversarial loss: 0.648843\n","epoch 21; iter: 0; batch classifier loss: 0.606301; batch adversarial loss: 0.636603\n","epoch 22; iter: 0; batch classifier loss: 0.608092; batch adversarial loss: 0.669418\n","epoch 23; iter: 0; batch classifier loss: 0.610441; batch adversarial loss: 0.618952\n","epoch 24; iter: 0; batch classifier loss: 0.594426; batch adversarial loss: 0.632134\n","epoch 25; iter: 0; batch classifier loss: 0.575819; batch adversarial loss: 0.635229\n","epoch 26; iter: 0; batch classifier loss: 0.551214; batch adversarial loss: 0.683034\n","epoch 27; iter: 0; batch classifier loss: 0.649138; batch adversarial loss: 0.688876\n","epoch 28; iter: 0; batch classifier loss: 0.591208; batch adversarial loss: 0.684411\n","epoch 29; iter: 0; batch classifier loss: 0.552832; batch adversarial loss: 0.636380\n","epoch 30; iter: 0; batch classifier loss: 0.676843; batch adversarial loss: 0.652928\n","epoch 31; iter: 0; batch classifier loss: 0.570251; batch adversarial loss: 0.652068\n","epoch 32; iter: 0; batch classifier loss: 0.612661; batch adversarial loss: 0.644871\n","epoch 33; iter: 0; batch classifier loss: 0.581204; batch adversarial loss: 0.675010\n","epoch 34; iter: 0; batch classifier loss: 0.655054; batch adversarial loss: 0.682695\n","epoch 35; iter: 0; batch classifier loss: 0.681639; batch adversarial loss: 0.705846\n","epoch 36; iter: 0; batch classifier loss: 0.497689; batch adversarial loss: 0.668590\n","epoch 37; iter: 0; batch classifier loss: 0.545754; batch adversarial loss: 0.663780\n","epoch 38; iter: 0; batch classifier loss: 0.610426; batch adversarial loss: 0.628451\n","epoch 39; iter: 0; batch classifier loss: 0.673704; batch adversarial loss: 0.655953\n","epoch 40; iter: 0; batch classifier loss: 0.680995; batch adversarial loss: 0.664671\n","epoch 41; iter: 0; batch classifier loss: 0.612952; batch adversarial loss: 0.654948\n","epoch 42; iter: 0; batch classifier loss: 0.563368; batch adversarial loss: 0.641800\n","epoch 43; iter: 0; batch classifier loss: 0.577958; batch adversarial loss: 0.646827\n","epoch 44; iter: 0; batch classifier loss: 0.623433; batch adversarial loss: 0.658213\n","epoch 45; iter: 0; batch classifier loss: 0.569721; batch adversarial loss: 0.659733\n","epoch 46; iter: 0; batch classifier loss: 0.617318; batch adversarial loss: 0.639607\n","epoch 47; iter: 0; batch classifier loss: 0.746180; batch adversarial loss: 0.699515\n","epoch 48; iter: 0; batch classifier loss: 0.547797; batch adversarial loss: 0.662713\n","epoch 49; iter: 0; batch classifier loss: 0.692013; batch adversarial loss: 0.624015\n","Accuracy 0.5611510791366906\n","epoch 0; iter: 0; batch classifier loss: 0.743372; batch adversarial loss: 0.683546\n","epoch 1; iter: 0; batch classifier loss: 0.714664; batch adversarial loss: 0.669834\n","epoch 2; iter: 0; batch classifier loss: 0.672689; batch adversarial loss: 0.647263\n","epoch 3; iter: 0; batch classifier loss: 0.657830; batch adversarial loss: 0.667234\n","epoch 4; iter: 0; batch classifier loss: 0.699976; batch adversarial loss: 0.703025\n","epoch 5; iter: 0; batch classifier loss: 0.670058; batch adversarial loss: 0.659640\n","epoch 6; iter: 0; batch classifier loss: 0.609430; batch adversarial loss: 0.622689\n","epoch 7; iter: 0; batch classifier loss: 0.688909; batch adversarial loss: 0.673998\n","epoch 8; iter: 0; batch classifier loss: 0.626649; batch adversarial loss: 0.656548\n","epoch 9; iter: 0; batch classifier loss: 0.673275; batch adversarial loss: 0.654179\n","epoch 10; iter: 0; batch classifier loss: 0.615273; batch adversarial loss: 0.634902\n","epoch 11; iter: 0; batch classifier loss: 0.586724; batch adversarial loss: 0.612844\n","epoch 12; iter: 0; batch classifier loss: 0.636974; batch adversarial loss: 0.687499\n","epoch 13; iter: 0; batch classifier loss: 0.629585; batch adversarial loss: 0.686892\n","epoch 14; iter: 0; batch classifier loss: 0.588925; batch adversarial loss: 0.638177\n","epoch 15; iter: 0; batch classifier loss: 0.604717; batch adversarial loss: 0.667820\n","epoch 16; iter: 0; batch classifier loss: 0.601576; batch adversarial loss: 0.617142\n","epoch 17; iter: 0; batch classifier loss: 0.564731; batch adversarial loss: 0.642257\n","epoch 18; iter: 0; batch classifier loss: 0.578522; batch adversarial loss: 0.618390\n","epoch 19; iter: 0; batch classifier loss: 0.569901; batch adversarial loss: 0.636919\n","epoch 20; iter: 0; batch classifier loss: 0.540576; batch adversarial loss: 0.595675\n","epoch 21; iter: 0; batch classifier loss: 0.526205; batch adversarial loss: 0.599051\n","epoch 22; iter: 0; batch classifier loss: 0.550615; batch adversarial loss: 0.635428\n","epoch 23; iter: 0; batch classifier loss: 0.520994; batch adversarial loss: 0.585744\n","epoch 24; iter: 0; batch classifier loss: 0.545866; batch adversarial loss: 0.601444\n","epoch 25; iter: 0; batch classifier loss: 0.536335; batch adversarial loss: 0.590725\n","epoch 26; iter: 0; batch classifier loss: 0.527254; batch adversarial loss: 0.589954\n","epoch 27; iter: 0; batch classifier loss: 0.476506; batch adversarial loss: 0.569690\n","epoch 28; iter: 0; batch classifier loss: 0.507138; batch adversarial loss: 0.584108\n","epoch 29; iter: 0; batch classifier loss: 0.516454; batch adversarial loss: 0.598649\n","epoch 30; iter: 0; batch classifier loss: 0.442112; batch adversarial loss: 0.555743\n","epoch 31; iter: 0; batch classifier loss: 0.440789; batch adversarial loss: 0.571623\n","epoch 32; iter: 0; batch classifier loss: 0.495303; batch adversarial loss: 0.572153\n","epoch 33; iter: 0; batch classifier loss: 0.498370; batch adversarial loss: 0.591791\n","epoch 34; iter: 0; batch classifier loss: 0.496891; batch adversarial loss: 0.567568\n","epoch 35; iter: 0; batch classifier loss: 0.434110; batch adversarial loss: 0.553979\n","epoch 36; iter: 0; batch classifier loss: 0.466131; batch adversarial loss: 0.566286\n","epoch 37; iter: 0; batch classifier loss: 0.539887; batch adversarial loss: 0.624911\n","epoch 38; iter: 0; batch classifier loss: 0.456889; batch adversarial loss: 0.611748\n","epoch 39; iter: 0; batch classifier loss: 0.439035; batch adversarial loss: 0.595664\n","epoch 40; iter: 0; batch classifier loss: 0.480601; batch adversarial loss: 0.558083\n","epoch 41; iter: 0; batch classifier loss: 0.491578; batch adversarial loss: 0.583341\n","epoch 42; iter: 0; batch classifier loss: 0.518339; batch adversarial loss: 0.619754\n","epoch 43; iter: 0; batch classifier loss: 0.468921; batch adversarial loss: 0.610075\n","epoch 44; iter: 0; batch classifier loss: 0.457301; batch adversarial loss: 0.592365\n","epoch 45; iter: 0; batch classifier loss: 0.473398; batch adversarial loss: 0.547442\n","epoch 46; iter: 0; batch classifier loss: 0.503665; batch adversarial loss: 0.594634\n","epoch 47; iter: 0; batch classifier loss: 0.436215; batch adversarial loss: 0.561741\n","epoch 48; iter: 0; batch classifier loss: 0.395561; batch adversarial loss: 0.582243\n","epoch 49; iter: 0; batch classifier loss: 0.453878; batch adversarial loss: 0.546117\n","Accuracy 0.6906474820143885\n","epoch 0; iter: 0; batch classifier loss: 0.704555; batch adversarial loss: 0.581466\n","epoch 1; iter: 0; batch classifier loss: 0.691257; batch adversarial loss: 0.556254\n","epoch 2; iter: 0; batch classifier loss: 0.672351; batch adversarial loss: 0.554922\n","epoch 3; iter: 0; batch classifier loss: 0.682695; batch adversarial loss: 0.564403\n","epoch 4; iter: 0; batch classifier loss: 0.680469; batch adversarial loss: 0.593593\n","epoch 5; iter: 0; batch classifier loss: 0.633834; batch adversarial loss: 0.562340\n","epoch 6; iter: 0; batch classifier loss: 0.655404; batch adversarial loss: 0.578590\n","epoch 7; iter: 0; batch classifier loss: 0.590517; batch adversarial loss: 0.542064\n","epoch 8; iter: 0; batch classifier loss: 0.629662; batch adversarial loss: 0.571635\n","epoch 9; iter: 0; batch classifier loss: 0.617698; batch adversarial loss: 0.639876\n","epoch 10; iter: 0; batch classifier loss: 0.659991; batch adversarial loss: 0.620171\n","epoch 11; iter: 0; batch classifier loss: 0.608467; batch adversarial loss: 0.649344\n","epoch 12; iter: 0; batch classifier loss: 0.592283; batch adversarial loss: 0.635459\n","epoch 13; iter: 0; batch classifier loss: 0.617934; batch adversarial loss: 0.573259\n","epoch 14; iter: 0; batch classifier loss: 0.638813; batch adversarial loss: 0.626316\n","epoch 15; iter: 0; batch classifier loss: 0.653091; batch adversarial loss: 0.607178\n","epoch 16; iter: 0; batch classifier loss: 0.609927; batch adversarial loss: 0.639739\n","epoch 17; iter: 0; batch classifier loss: 0.590468; batch adversarial loss: 0.593143\n","epoch 18; iter: 0; batch classifier loss: 0.617277; batch adversarial loss: 0.715469\n","epoch 19; iter: 0; batch classifier loss: 0.672118; batch adversarial loss: 0.630171\n","epoch 20; iter: 0; batch classifier loss: 0.625862; batch adversarial loss: 0.620582\n","epoch 21; iter: 0; batch classifier loss: 0.626221; batch adversarial loss: 0.623969\n","epoch 22; iter: 0; batch classifier loss: 0.697336; batch adversarial loss: 0.705978\n","epoch 23; iter: 0; batch classifier loss: 0.645833; batch adversarial loss: 0.645855\n","epoch 24; iter: 0; batch classifier loss: 0.655203; batch adversarial loss: 0.602070\n","epoch 25; iter: 0; batch classifier loss: 0.532186; batch adversarial loss: 0.639522\n","epoch 26; iter: 0; batch classifier loss: 0.666343; batch adversarial loss: 0.611220\n","epoch 27; iter: 0; batch classifier loss: 0.694710; batch adversarial loss: 0.619693\n","epoch 28; iter: 0; batch classifier loss: 0.651733; batch adversarial loss: 0.659305\n","epoch 29; iter: 0; batch classifier loss: 0.658367; batch adversarial loss: 0.636301\n","epoch 30; iter: 0; batch classifier loss: 0.612230; batch adversarial loss: 0.629643\n","epoch 31; iter: 0; batch classifier loss: 0.701938; batch adversarial loss: 0.708791\n","epoch 32; iter: 0; batch classifier loss: 0.698487; batch adversarial loss: 0.661243\n","epoch 33; iter: 0; batch classifier loss: 0.674984; batch adversarial loss: 0.658504\n","epoch 34; iter: 0; batch classifier loss: 0.728009; batch adversarial loss: 0.633658\n","epoch 35; iter: 0; batch classifier loss: 0.764741; batch adversarial loss: 0.691058\n","epoch 36; iter: 0; batch classifier loss: 0.791326; batch adversarial loss: 0.677509\n","epoch 37; iter: 0; batch classifier loss: 0.794816; batch adversarial loss: 0.670779\n","epoch 38; iter: 0; batch classifier loss: 0.784604; batch adversarial loss: 0.645392\n","epoch 39; iter: 0; batch classifier loss: 0.714691; batch adversarial loss: 0.691455\n","epoch 40; iter: 0; batch classifier loss: 0.768997; batch adversarial loss: 0.670956\n","epoch 41; iter: 0; batch classifier loss: 0.789465; batch adversarial loss: 0.689422\n","epoch 42; iter: 0; batch classifier loss: 0.799758; batch adversarial loss: 0.665430\n","epoch 43; iter: 0; batch classifier loss: 0.732921; batch adversarial loss: 0.703082\n","epoch 44; iter: 0; batch classifier loss: 0.757318; batch adversarial loss: 0.733040\n","epoch 45; iter: 0; batch classifier loss: 0.842889; batch adversarial loss: 0.698442\n","epoch 46; iter: 0; batch classifier loss: 0.906697; batch adversarial loss: 0.725387\n","epoch 47; iter: 0; batch classifier loss: 0.905609; batch adversarial loss: 0.676609\n","epoch 48; iter: 0; batch classifier loss: 0.805850; batch adversarial loss: 0.714676\n","epoch 49; iter: 0; batch classifier loss: 0.896677; batch adversarial loss: 0.739953\n","Accuracy 0.4057971014492754\n","epoch 0; iter: 0; batch classifier loss: 0.714777; batch adversarial loss: 0.708553\n","epoch 1; iter: 0; batch classifier loss: 0.690624; batch adversarial loss: 0.711606\n","epoch 2; iter: 0; batch classifier loss: 0.666240; batch adversarial loss: 0.697407\n","epoch 3; iter: 0; batch classifier loss: 0.646075; batch adversarial loss: 0.697285\n","epoch 4; iter: 0; batch classifier loss: 0.625404; batch adversarial loss: 0.704564\n","epoch 5; iter: 0; batch classifier loss: 0.592623; batch adversarial loss: 0.697713\n","epoch 6; iter: 0; batch classifier loss: 0.608317; batch adversarial loss: 0.697509\n","epoch 7; iter: 0; batch classifier loss: 0.628212; batch adversarial loss: 0.695297\n","epoch 8; iter: 0; batch classifier loss: 0.567915; batch adversarial loss: 0.682388\n","epoch 9; iter: 0; batch classifier loss: 0.598760; batch adversarial loss: 0.701120\n","epoch 10; iter: 0; batch classifier loss: 0.548964; batch adversarial loss: 0.678360\n","epoch 11; iter: 0; batch classifier loss: 0.555754; batch adversarial loss: 0.689108\n","epoch 12; iter: 0; batch classifier loss: 0.539666; batch adversarial loss: 0.680310\n","epoch 13; iter: 0; batch classifier loss: 0.585372; batch adversarial loss: 0.694997\n","epoch 14; iter: 0; batch classifier loss: 0.521947; batch adversarial loss: 0.676920\n","epoch 15; iter: 0; batch classifier loss: 0.527681; batch adversarial loss: 0.667727\n","epoch 16; iter: 0; batch classifier loss: 0.498133; batch adversarial loss: 0.670930\n","epoch 17; iter: 0; batch classifier loss: 0.527775; batch adversarial loss: 0.668060\n","epoch 18; iter: 0; batch classifier loss: 0.566492; batch adversarial loss: 0.673377\n","epoch 19; iter: 0; batch classifier loss: 0.575374; batch adversarial loss: 0.667572\n","epoch 20; iter: 0; batch classifier loss: 0.463662; batch adversarial loss: 0.662732\n","epoch 21; iter: 0; batch classifier loss: 0.462268; batch adversarial loss: 0.642432\n","epoch 22; iter: 0; batch classifier loss: 0.518188; batch adversarial loss: 0.658279\n","epoch 23; iter: 0; batch classifier loss: 0.512742; batch adversarial loss: 0.656479\n","epoch 24; iter: 0; batch classifier loss: 0.529173; batch adversarial loss: 0.658772\n","epoch 25; iter: 0; batch classifier loss: 0.512981; batch adversarial loss: 0.643654\n","epoch 26; iter: 0; batch classifier loss: 0.506973; batch adversarial loss: 0.650757\n","epoch 27; iter: 0; batch classifier loss: 0.511708; batch adversarial loss: 0.646653\n","epoch 28; iter: 0; batch classifier loss: 0.502719; batch adversarial loss: 0.645627\n","epoch 29; iter: 0; batch classifier loss: 0.529414; batch adversarial loss: 0.659247\n","epoch 30; iter: 0; batch classifier loss: 0.466201; batch adversarial loss: 0.643251\n","epoch 31; iter: 0; batch classifier loss: 0.493961; batch adversarial loss: 0.629279\n","epoch 32; iter: 0; batch classifier loss: 0.507186; batch adversarial loss: 0.634089\n","epoch 33; iter: 0; batch classifier loss: 0.511004; batch adversarial loss: 0.637195\n","epoch 34; iter: 0; batch classifier loss: 0.440162; batch adversarial loss: 0.648555\n","epoch 35; iter: 0; batch classifier loss: 0.466459; batch adversarial loss: 0.612713\n","epoch 36; iter: 0; batch classifier loss: 0.500704; batch adversarial loss: 0.621093\n","epoch 37; iter: 0; batch classifier loss: 0.476276; batch adversarial loss: 0.626344\n","epoch 38; iter: 0; batch classifier loss: 0.527035; batch adversarial loss: 0.620486\n","epoch 39; iter: 0; batch classifier loss: 0.455362; batch adversarial loss: 0.622461\n","epoch 40; iter: 0; batch classifier loss: 0.544793; batch adversarial loss: 0.606791\n","epoch 41; iter: 0; batch classifier loss: 0.466847; batch adversarial loss: 0.620869\n","epoch 42; iter: 0; batch classifier loss: 0.492072; batch adversarial loss: 0.606070\n","epoch 43; iter: 0; batch classifier loss: 0.531923; batch adversarial loss: 0.628780\n","epoch 44; iter: 0; batch classifier loss: 0.546300; batch adversarial loss: 0.619080\n","epoch 45; iter: 0; batch classifier loss: 0.440708; batch adversarial loss: 0.607182\n","epoch 46; iter: 0; batch classifier loss: 0.485870; batch adversarial loss: 0.604156\n","epoch 47; iter: 0; batch classifier loss: 0.471121; batch adversarial loss: 0.615751\n","epoch 48; iter: 0; batch classifier loss: 0.445363; batch adversarial loss: 0.597083\n","epoch 49; iter: 0; batch classifier loss: 0.482650; batch adversarial loss: 0.612711\n","Accuracy 0.7463768115942029\n","epoch 0; iter: 0; batch classifier loss: 0.679352; batch adversarial loss: 0.664276\n","epoch 1; iter: 0; batch classifier loss: 0.677835; batch adversarial loss: 0.662385\n","epoch 2; iter: 0; batch classifier loss: 0.659568; batch adversarial loss: 0.666337\n","epoch 3; iter: 0; batch classifier loss: 0.642319; batch adversarial loss: 0.666353\n","epoch 4; iter: 0; batch classifier loss: 0.651651; batch adversarial loss: 0.665920\n","epoch 5; iter: 0; batch classifier loss: 0.622956; batch adversarial loss: 0.657911\n","epoch 6; iter: 0; batch classifier loss: 0.609943; batch adversarial loss: 0.658778\n","epoch 7; iter: 0; batch classifier loss: 0.583137; batch adversarial loss: 0.653745\n","epoch 8; iter: 0; batch classifier loss: 0.597443; batch adversarial loss: 0.659575\n","epoch 9; iter: 0; batch classifier loss: 0.621166; batch adversarial loss: 0.639076\n","epoch 10; iter: 0; batch classifier loss: 0.622605; batch adversarial loss: 0.647112\n","epoch 11; iter: 0; batch classifier loss: 0.572800; batch adversarial loss: 0.649800\n","epoch 12; iter: 0; batch classifier loss: 0.603120; batch adversarial loss: 0.654122\n","epoch 13; iter: 0; batch classifier loss: 0.555620; batch adversarial loss: 0.635539\n","epoch 14; iter: 0; batch classifier loss: 0.577748; batch adversarial loss: 0.641074\n","epoch 15; iter: 0; batch classifier loss: 0.592438; batch adversarial loss: 0.647779\n","epoch 16; iter: 0; batch classifier loss: 0.538424; batch adversarial loss: 0.635239\n","epoch 17; iter: 0; batch classifier loss: 0.551093; batch adversarial loss: 0.649451\n","epoch 18; iter: 0; batch classifier loss: 0.596491; batch adversarial loss: 0.642056\n","epoch 19; iter: 0; batch classifier loss: 0.607932; batch adversarial loss: 0.639812\n","epoch 20; iter: 0; batch classifier loss: 0.537766; batch adversarial loss: 0.640253\n","epoch 21; iter: 0; batch classifier loss: 0.521469; batch adversarial loss: 0.627369\n","epoch 22; iter: 0; batch classifier loss: 0.549052; batch adversarial loss: 0.632371\n","epoch 23; iter: 0; batch classifier loss: 0.571219; batch adversarial loss: 0.635111\n","epoch 24; iter: 0; batch classifier loss: 0.559918; batch adversarial loss: 0.622144\n","epoch 25; iter: 0; batch classifier loss: 0.581984; batch adversarial loss: 0.625018\n","epoch 26; iter: 0; batch classifier loss: 0.544787; batch adversarial loss: 0.637499\n","epoch 27; iter: 0; batch classifier loss: 0.553173; batch adversarial loss: 0.642392\n","epoch 28; iter: 0; batch classifier loss: 0.611289; batch adversarial loss: 0.622407\n","epoch 29; iter: 0; batch classifier loss: 0.563161; batch adversarial loss: 0.627419\n","epoch 30; iter: 0; batch classifier loss: 0.613090; batch adversarial loss: 0.628397\n","epoch 31; iter: 0; batch classifier loss: 0.593019; batch adversarial loss: 0.615601\n","epoch 32; iter: 0; batch classifier loss: 0.535561; batch adversarial loss: 0.622283\n","epoch 33; iter: 0; batch classifier loss: 0.609477; batch adversarial loss: 0.629173\n","epoch 34; iter: 0; batch classifier loss: 0.548803; batch adversarial loss: 0.611215\n","epoch 35; iter: 0; batch classifier loss: 0.570189; batch adversarial loss: 0.626375\n","epoch 36; iter: 0; batch classifier loss: 0.596565; batch adversarial loss: 0.656034\n","epoch 37; iter: 0; batch classifier loss: 0.554727; batch adversarial loss: 0.606489\n","epoch 38; iter: 0; batch classifier loss: 0.573359; batch adversarial loss: 0.585744\n","epoch 39; iter: 0; batch classifier loss: 0.543404; batch adversarial loss: 0.635087\n","epoch 40; iter: 0; batch classifier loss: 0.614905; batch adversarial loss: 0.631217\n","epoch 41; iter: 0; batch classifier loss: 0.648438; batch adversarial loss: 0.610497\n","epoch 42; iter: 0; batch classifier loss: 0.630336; batch adversarial loss: 0.616394\n","epoch 43; iter: 0; batch classifier loss: 0.560144; batch adversarial loss: 0.616957\n","epoch 44; iter: 0; batch classifier loss: 0.484467; batch adversarial loss: 0.622741\n","epoch 45; iter: 0; batch classifier loss: 0.508952; batch adversarial loss: 0.610880\n","epoch 46; iter: 0; batch classifier loss: 0.593641; batch adversarial loss: 0.619292\n","epoch 47; iter: 0; batch classifier loss: 0.587972; batch adversarial loss: 0.630831\n","epoch 48; iter: 0; batch classifier loss: 0.561589; batch adversarial loss: 0.618095\n","epoch 49; iter: 0; batch classifier loss: 0.639112; batch adversarial loss: 0.631619\n","Accuracy 0.6739130434782609\n","epoch 0; iter: 0; batch classifier loss: 0.700787; batch adversarial loss: 0.658138\n","epoch 1; iter: 0; batch classifier loss: 0.681726; batch adversarial loss: 0.657825\n","epoch 2; iter: 0; batch classifier loss: 0.671224; batch adversarial loss: 0.660996\n","epoch 3; iter: 0; batch classifier loss: 0.650782; batch adversarial loss: 0.645352\n","epoch 4; iter: 0; batch classifier loss: 0.651825; batch adversarial loss: 0.652068\n","epoch 5; iter: 0; batch classifier loss: 0.628556; batch adversarial loss: 0.645480\n","epoch 6; iter: 0; batch classifier loss: 0.639153; batch adversarial loss: 0.641490\n","epoch 7; iter: 0; batch classifier loss: 0.639347; batch adversarial loss: 0.663241\n","epoch 8; iter: 0; batch classifier loss: 0.648698; batch adversarial loss: 0.666265\n","epoch 9; iter: 0; batch classifier loss: 0.619292; batch adversarial loss: 0.633996\n","epoch 10; iter: 0; batch classifier loss: 0.608177; batch adversarial loss: 0.636571\n","epoch 11; iter: 0; batch classifier loss: 0.581100; batch adversarial loss: 0.627401\n","epoch 12; iter: 0; batch classifier loss: 0.608331; batch adversarial loss: 0.650738\n","epoch 13; iter: 0; batch classifier loss: 0.584866; batch adversarial loss: 0.628547\n","epoch 14; iter: 0; batch classifier loss: 0.629426; batch adversarial loss: 0.639856\n","epoch 15; iter: 0; batch classifier loss: 0.576772; batch adversarial loss: 0.635781\n","epoch 16; iter: 0; batch classifier loss: 0.593870; batch adversarial loss: 0.637770\n","epoch 17; iter: 0; batch classifier loss: 0.547257; batch adversarial loss: 0.629301\n","epoch 18; iter: 0; batch classifier loss: 0.554889; batch adversarial loss: 0.645391\n","epoch 19; iter: 0; batch classifier loss: 0.590992; batch adversarial loss: 0.620516\n","epoch 20; iter: 0; batch classifier loss: 0.584130; batch adversarial loss: 0.633176\n","epoch 21; iter: 0; batch classifier loss: 0.610087; batch adversarial loss: 0.641649\n","epoch 22; iter: 0; batch classifier loss: 0.612447; batch adversarial loss: 0.629397\n","epoch 23; iter: 0; batch classifier loss: 0.547813; batch adversarial loss: 0.607908\n","epoch 24; iter: 0; batch classifier loss: 0.610195; batch adversarial loss: 0.606164\n","epoch 25; iter: 0; batch classifier loss: 0.526449; batch adversarial loss: 0.617557\n","epoch 26; iter: 0; batch classifier loss: 0.557996; batch adversarial loss: 0.609469\n","epoch 27; iter: 0; batch classifier loss: 0.582625; batch adversarial loss: 0.647617\n","epoch 28; iter: 0; batch classifier loss: 0.613161; batch adversarial loss: 0.618736\n","epoch 29; iter: 0; batch classifier loss: 0.527419; batch adversarial loss: 0.622655\n","epoch 30; iter: 0; batch classifier loss: 0.555344; batch adversarial loss: 0.600712\n","epoch 31; iter: 0; batch classifier loss: 0.532395; batch adversarial loss: 0.622985\n","epoch 32; iter: 0; batch classifier loss: 0.527324; batch adversarial loss: 0.632323\n","epoch 33; iter: 0; batch classifier loss: 0.547557; batch adversarial loss: 0.579109\n","epoch 34; iter: 0; batch classifier loss: 0.527615; batch adversarial loss: 0.626721\n","epoch 35; iter: 0; batch classifier loss: 0.561492; batch adversarial loss: 0.608846\n","epoch 36; iter: 0; batch classifier loss: 0.556575; batch adversarial loss: 0.614684\n","epoch 37; iter: 0; batch classifier loss: 0.573428; batch adversarial loss: 0.589166\n","epoch 38; iter: 0; batch classifier loss: 0.499734; batch adversarial loss: 0.596267\n","epoch 39; iter: 0; batch classifier loss: 0.527897; batch adversarial loss: 0.633808\n","epoch 40; iter: 0; batch classifier loss: 0.562699; batch adversarial loss: 0.611401\n","epoch 41; iter: 0; batch classifier loss: 0.541970; batch adversarial loss: 0.613237\n","epoch 42; iter: 0; batch classifier loss: 0.533577; batch adversarial loss: 0.633327\n","epoch 43; iter: 0; batch classifier loss: 0.560842; batch adversarial loss: 0.621823\n","epoch 44; iter: 0; batch classifier loss: 0.583852; batch adversarial loss: 0.601409\n","epoch 45; iter: 0; batch classifier loss: 0.536718; batch adversarial loss: 0.610625\n","epoch 46; iter: 0; batch classifier loss: 0.647561; batch adversarial loss: 0.594505\n","epoch 47; iter: 0; batch classifier loss: 0.465652; batch adversarial loss: 0.626882\n","epoch 48; iter: 0; batch classifier loss: 0.535506; batch adversarial loss: 0.623946\n","epoch 49; iter: 0; batch classifier loss: 0.563638; batch adversarial loss: 0.577712\n","Accuracy 0.697841726618705\n","epoch 0; iter: 0; batch classifier loss: 0.803994; batch adversarial loss: 0.676410\n","epoch 1; iter: 0; batch classifier loss: 0.739181; batch adversarial loss: 0.675120\n","epoch 2; iter: 0; batch classifier loss: 0.715437; batch adversarial loss: 0.671275\n","epoch 3; iter: 0; batch classifier loss: 0.677797; batch adversarial loss: 0.643337\n","epoch 4; iter: 0; batch classifier loss: 0.695390; batch adversarial loss: 0.660767\n","epoch 5; iter: 0; batch classifier loss: 0.705583; batch adversarial loss: 0.674838\n","epoch 6; iter: 0; batch classifier loss: 0.685036; batch adversarial loss: 0.664525\n","epoch 7; iter: 0; batch classifier loss: 0.669355; batch adversarial loss: 0.659045\n","epoch 8; iter: 0; batch classifier loss: 0.666460; batch adversarial loss: 0.652685\n","epoch 9; iter: 0; batch classifier loss: 0.664556; batch adversarial loss: 0.622481\n","epoch 10; iter: 0; batch classifier loss: 0.644425; batch adversarial loss: 0.647354\n","epoch 11; iter: 0; batch classifier loss: 0.659230; batch adversarial loss: 0.638521\n","epoch 12; iter: 0; batch classifier loss: 0.650899; batch adversarial loss: 0.639151\n","epoch 13; iter: 0; batch classifier loss: 0.631095; batch adversarial loss: 0.620220\n","epoch 14; iter: 0; batch classifier loss: 0.653724; batch adversarial loss: 0.643778\n","epoch 15; iter: 0; batch classifier loss: 0.633689; batch adversarial loss: 0.617004\n","epoch 16; iter: 0; batch classifier loss: 0.577160; batch adversarial loss: 0.620076\n","epoch 17; iter: 0; batch classifier loss: 0.591184; batch adversarial loss: 0.638387\n","epoch 18; iter: 0; batch classifier loss: 0.611902; batch adversarial loss: 0.634857\n","epoch 19; iter: 0; batch classifier loss: 0.591412; batch adversarial loss: 0.629434\n","epoch 20; iter: 0; batch classifier loss: 0.575947; batch adversarial loss: 0.636102\n","epoch 21; iter: 0; batch classifier loss: 0.589777; batch adversarial loss: 0.614776\n","epoch 22; iter: 0; batch classifier loss: 0.549692; batch adversarial loss: 0.620420\n","epoch 23; iter: 0; batch classifier loss: 0.585448; batch adversarial loss: 0.626540\n","epoch 24; iter: 0; batch classifier loss: 0.573395; batch adversarial loss: 0.609506\n","epoch 25; iter: 0; batch classifier loss: 0.563264; batch adversarial loss: 0.601332\n","epoch 26; iter: 0; batch classifier loss: 0.526083; batch adversarial loss: 0.597960\n","epoch 27; iter: 0; batch classifier loss: 0.532395; batch adversarial loss: 0.585829\n","epoch 28; iter: 0; batch classifier loss: 0.502224; batch adversarial loss: 0.593652\n","epoch 29; iter: 0; batch classifier loss: 0.554057; batch adversarial loss: 0.619154\n","epoch 30; iter: 0; batch classifier loss: 0.515095; batch adversarial loss: 0.579085\n","epoch 31; iter: 0; batch classifier loss: 0.515659; batch adversarial loss: 0.650788\n","epoch 32; iter: 0; batch classifier loss: 0.538231; batch adversarial loss: 0.608924\n","epoch 33; iter: 0; batch classifier loss: 0.533832; batch adversarial loss: 0.616308\n","epoch 34; iter: 0; batch classifier loss: 0.573841; batch adversarial loss: 0.599666\n","epoch 35; iter: 0; batch classifier loss: 0.537307; batch adversarial loss: 0.638722\n","epoch 36; iter: 0; batch classifier loss: 0.523036; batch adversarial loss: 0.577138\n","epoch 37; iter: 0; batch classifier loss: 0.506811; batch adversarial loss: 0.615863\n","epoch 38; iter: 0; batch classifier loss: 0.507571; batch adversarial loss: 0.618688\n","epoch 39; iter: 0; batch classifier loss: 0.496285; batch adversarial loss: 0.593241\n","epoch 40; iter: 0; batch classifier loss: 0.523595; batch adversarial loss: 0.572933\n","epoch 41; iter: 0; batch classifier loss: 0.535916; batch adversarial loss: 0.594827\n","epoch 42; iter: 0; batch classifier loss: 0.511822; batch adversarial loss: 0.580578\n","epoch 43; iter: 0; batch classifier loss: 0.507441; batch adversarial loss: 0.567299\n","epoch 44; iter: 0; batch classifier loss: 0.512896; batch adversarial loss: 0.586992\n","epoch 45; iter: 0; batch classifier loss: 0.459933; batch adversarial loss: 0.616502\n","epoch 46; iter: 0; batch classifier loss: 0.518487; batch adversarial loss: 0.607034\n","epoch 47; iter: 0; batch classifier loss: 0.399559; batch adversarial loss: 0.550887\n","epoch 48; iter: 0; batch classifier loss: 0.492868; batch adversarial loss: 0.597509\n","epoch 49; iter: 0; batch classifier loss: 0.494512; batch adversarial loss: 0.599758\n","Accuracy 0.7697841726618705\n","epoch 0; iter: 0; batch classifier loss: 0.690557; batch adversarial loss: 0.670531\n","epoch 1; iter: 0; batch classifier loss: 0.678193; batch adversarial loss: 0.698434\n","epoch 2; iter: 0; batch classifier loss: 0.622650; batch adversarial loss: 0.633275\n","epoch 3; iter: 0; batch classifier loss: 0.625994; batch adversarial loss: 0.629775\n","epoch 4; iter: 0; batch classifier loss: 0.585382; batch adversarial loss: 0.631351\n","epoch 5; iter: 0; batch classifier loss: 0.570296; batch adversarial loss: 0.596967\n","epoch 6; iter: 0; batch classifier loss: 0.603775; batch adversarial loss: 0.655131\n","epoch 7; iter: 0; batch classifier loss: 0.596198; batch adversarial loss: 0.630293\n","epoch 8; iter: 0; batch classifier loss: 0.587597; batch adversarial loss: 0.639553\n","epoch 9; iter: 0; batch classifier loss: 0.554206; batch adversarial loss: 0.674918\n","epoch 10; iter: 0; batch classifier loss: 0.562644; batch adversarial loss: 0.628811\n","epoch 11; iter: 0; batch classifier loss: 0.583927; batch adversarial loss: 0.677231\n","epoch 12; iter: 0; batch classifier loss: 0.541679; batch adversarial loss: 0.621747\n","epoch 13; iter: 0; batch classifier loss: 0.513106; batch adversarial loss: 0.606311\n","epoch 14; iter: 0; batch classifier loss: 0.530871; batch adversarial loss: 0.585095\n","epoch 15; iter: 0; batch classifier loss: 0.540694; batch adversarial loss: 0.608489\n","epoch 16; iter: 0; batch classifier loss: 0.551621; batch adversarial loss: 0.628128\n","epoch 17; iter: 0; batch classifier loss: 0.521524; batch adversarial loss: 0.613002\n","epoch 18; iter: 0; batch classifier loss: 0.506635; batch adversarial loss: 0.565079\n","epoch 19; iter: 0; batch classifier loss: 0.506348; batch adversarial loss: 0.607553\n","epoch 20; iter: 0; batch classifier loss: 0.516276; batch adversarial loss: 0.616525\n","epoch 21; iter: 0; batch classifier loss: 0.469039; batch adversarial loss: 0.597654\n","epoch 22; iter: 0; batch classifier loss: 0.484335; batch adversarial loss: 0.591863\n","epoch 23; iter: 0; batch classifier loss: 0.578317; batch adversarial loss: 0.631864\n","epoch 24; iter: 0; batch classifier loss: 0.470009; batch adversarial loss: 0.570449\n","epoch 25; iter: 0; batch classifier loss: 0.480983; batch adversarial loss: 0.590890\n","epoch 26; iter: 0; batch classifier loss: 0.581684; batch adversarial loss: 0.672804\n","epoch 27; iter: 0; batch classifier loss: 0.506239; batch adversarial loss: 0.637467\n","epoch 28; iter: 0; batch classifier loss: 0.466828; batch adversarial loss: 0.580845\n","epoch 29; iter: 0; batch classifier loss: 0.462021; batch adversarial loss: 0.554320\n","epoch 30; iter: 0; batch classifier loss: 0.552840; batch adversarial loss: 0.610808\n","epoch 31; iter: 0; batch classifier loss: 0.540866; batch adversarial loss: 0.611201\n","epoch 32; iter: 0; batch classifier loss: 0.478096; batch adversarial loss: 0.579374\n","epoch 33; iter: 0; batch classifier loss: 0.543534; batch adversarial loss: 0.580710\n","epoch 34; iter: 0; batch classifier loss: 0.519461; batch adversarial loss: 0.610284\n","epoch 35; iter: 0; batch classifier loss: 0.524573; batch adversarial loss: 0.564889\n","epoch 36; iter: 0; batch classifier loss: 0.456442; batch adversarial loss: 0.521121\n","epoch 37; iter: 0; batch classifier loss: 0.452653; batch adversarial loss: 0.578447\n","epoch 38; iter: 0; batch classifier loss: 0.445058; batch adversarial loss: 0.569894\n","epoch 39; iter: 0; batch classifier loss: 0.457848; batch adversarial loss: 0.559121\n","epoch 40; iter: 0; batch classifier loss: 0.444958; batch adversarial loss: 0.595752\n","epoch 41; iter: 0; batch classifier loss: 0.434767; batch adversarial loss: 0.555672\n","epoch 42; iter: 0; batch classifier loss: 0.524199; batch adversarial loss: 0.617726\n","epoch 43; iter: 0; batch classifier loss: 0.510917; batch adversarial loss: 0.575750\n","epoch 44; iter: 0; batch classifier loss: 0.501354; batch adversarial loss: 0.611636\n","epoch 45; iter: 0; batch classifier loss: 0.493345; batch adversarial loss: 0.562040\n","epoch 46; iter: 0; batch classifier loss: 0.505917; batch adversarial loss: 0.607038\n","epoch 47; iter: 0; batch classifier loss: 0.468062; batch adversarial loss: 0.621103\n","epoch 48; iter: 0; batch classifier loss: 0.460895; batch adversarial loss: 0.545543\n","epoch 49; iter: 0; batch classifier loss: 0.431663; batch adversarial loss: 0.520820\n","Accuracy 0.7101449275362319\n","epoch 0; iter: 0; batch classifier loss: 0.706415; batch adversarial loss: 0.762736\n","epoch 1; iter: 0; batch classifier loss: 0.682092; batch adversarial loss: 0.781670\n","epoch 2; iter: 0; batch classifier loss: 0.652690; batch adversarial loss: 0.777744\n","epoch 3; iter: 0; batch classifier loss: 0.623815; batch adversarial loss: 0.770678\n","epoch 4; iter: 0; batch classifier loss: 0.594723; batch adversarial loss: 0.779065\n","epoch 5; iter: 0; batch classifier loss: 0.616687; batch adversarial loss: 0.739889\n","epoch 6; iter: 0; batch classifier loss: 0.610121; batch adversarial loss: 0.812127\n","epoch 7; iter: 0; batch classifier loss: 0.630733; batch adversarial loss: 0.898532\n","epoch 8; iter: 0; batch classifier loss: 0.584363; batch adversarial loss: 0.769313\n","epoch 9; iter: 0; batch classifier loss: 0.563093; batch adversarial loss: 0.863880\n","epoch 10; iter: 0; batch classifier loss: 0.515364; batch adversarial loss: 0.763116\n","epoch 11; iter: 0; batch classifier loss: 0.612827; batch adversarial loss: 0.839052\n","epoch 12; iter: 0; batch classifier loss: 0.597311; batch adversarial loss: 0.837199\n","epoch 13; iter: 0; batch classifier loss: 0.604145; batch adversarial loss: 0.830826\n","epoch 14; iter: 0; batch classifier loss: 0.543052; batch adversarial loss: 0.845643\n","epoch 15; iter: 0; batch classifier loss: 0.686279; batch adversarial loss: 0.942269\n","epoch 16; iter: 0; batch classifier loss: 0.616706; batch adversarial loss: 0.883967\n","epoch 17; iter: 0; batch classifier loss: 0.574696; batch adversarial loss: 0.813590\n","epoch 18; iter: 0; batch classifier loss: 0.582077; batch adversarial loss: 0.859846\n","epoch 19; iter: 0; batch classifier loss: 0.583508; batch adversarial loss: 0.851687\n","epoch 20; iter: 0; batch classifier loss: 0.585548; batch adversarial loss: 0.879037\n","epoch 21; iter: 0; batch classifier loss: 0.520741; batch adversarial loss: 0.800442\n","epoch 22; iter: 0; batch classifier loss: 0.587560; batch adversarial loss: 0.849667\n","epoch 23; iter: 0; batch classifier loss: 0.566113; batch adversarial loss: 0.764094\n","epoch 24; iter: 0; batch classifier loss: 0.499932; batch adversarial loss: 0.746479\n","epoch 25; iter: 0; batch classifier loss: 0.625518; batch adversarial loss: 0.864818\n","epoch 26; iter: 0; batch classifier loss: 0.605649; batch adversarial loss: 0.841353\n","epoch 27; iter: 0; batch classifier loss: 0.665867; batch adversarial loss: 0.896413\n","epoch 28; iter: 0; batch classifier loss: 0.527268; batch adversarial loss: 0.768508\n","epoch 29; iter: 0; batch classifier loss: 0.560477; batch adversarial loss: 0.787927\n","epoch 30; iter: 0; batch classifier loss: 0.591781; batch adversarial loss: 0.799115\n","epoch 31; iter: 0; batch classifier loss: 0.553373; batch adversarial loss: 0.770637\n","epoch 32; iter: 0; batch classifier loss: 0.611049; batch adversarial loss: 0.846575\n","epoch 33; iter: 0; batch classifier loss: 0.618582; batch adversarial loss: 0.811584\n","epoch 34; iter: 0; batch classifier loss: 0.564800; batch adversarial loss: 0.807415\n","epoch 35; iter: 0; batch classifier loss: 0.683474; batch adversarial loss: 0.856618\n","epoch 36; iter: 0; batch classifier loss: 0.649219; batch adversarial loss: 0.839378\n","epoch 37; iter: 0; batch classifier loss: 0.620360; batch adversarial loss: 0.830857\n","epoch 38; iter: 0; batch classifier loss: 0.690649; batch adversarial loss: 0.837045\n","epoch 39; iter: 0; batch classifier loss: 0.597156; batch adversarial loss: 0.787495\n","epoch 40; iter: 0; batch classifier loss: 0.457685; batch adversarial loss: 0.695786\n","epoch 41; iter: 0; batch classifier loss: 0.655395; batch adversarial loss: 0.833672\n","epoch 42; iter: 0; batch classifier loss: 0.519010; batch adversarial loss: 0.712937\n","epoch 43; iter: 0; batch classifier loss: 0.700575; batch adversarial loss: 0.859820\n","epoch 44; iter: 0; batch classifier loss: 0.653766; batch adversarial loss: 0.816747\n","epoch 45; iter: 0; batch classifier loss: 0.572260; batch adversarial loss: 0.771874\n","epoch 46; iter: 0; batch classifier loss: 0.622551; batch adversarial loss: 0.808902\n","epoch 47; iter: 0; batch classifier loss: 0.550467; batch adversarial loss: 0.730493\n","epoch 48; iter: 0; batch classifier loss: 0.552251; batch adversarial loss: 0.738672\n","epoch 49; iter: 0; batch classifier loss: 0.482967; batch adversarial loss: 0.684380\n","Accuracy 0.6739130434782609\n","epoch 0; iter: 0; batch classifier loss: 0.673146; batch adversarial loss: 0.816050\n","epoch 1; iter: 0; batch classifier loss: 0.656673; batch adversarial loss: 0.817224\n","epoch 2; iter: 0; batch classifier loss: 0.638122; batch adversarial loss: 0.851260\n","epoch 3; iter: 0; batch classifier loss: 0.603585; batch adversarial loss: 0.910339\n","epoch 4; iter: 0; batch classifier loss: 0.610228; batch adversarial loss: 0.827050\n","epoch 5; iter: 0; batch classifier loss: 0.607001; batch adversarial loss: 0.868893\n","epoch 6; iter: 0; batch classifier loss: 0.569291; batch adversarial loss: 0.924079\n","epoch 7; iter: 0; batch classifier loss: 0.552114; batch adversarial loss: 0.889916\n","epoch 8; iter: 0; batch classifier loss: 0.592922; batch adversarial loss: 0.848397\n","epoch 9; iter: 0; batch classifier loss: 0.575886; batch adversarial loss: 0.851581\n","epoch 10; iter: 0; batch classifier loss: 0.548814; batch adversarial loss: 0.905021\n","epoch 11; iter: 0; batch classifier loss: 0.542179; batch adversarial loss: 0.878722\n","epoch 12; iter: 0; batch classifier loss: 0.502535; batch adversarial loss: 0.896466\n","epoch 13; iter: 0; batch classifier loss: 0.535858; batch adversarial loss: 0.869017\n","epoch 14; iter: 0; batch classifier loss: 0.517495; batch adversarial loss: 0.904167\n","epoch 15; iter: 0; batch classifier loss: 0.529933; batch adversarial loss: 0.830388\n","epoch 16; iter: 0; batch classifier loss: 0.542936; batch adversarial loss: 0.872177\n","epoch 17; iter: 0; batch classifier loss: 0.508723; batch adversarial loss: 0.859183\n","epoch 18; iter: 0; batch classifier loss: 0.512640; batch adversarial loss: 0.838989\n","epoch 19; iter: 0; batch classifier loss: 0.507685; batch adversarial loss: 0.827966\n","epoch 20; iter: 0; batch classifier loss: 0.489550; batch adversarial loss: 0.865688\n","epoch 21; iter: 0; batch classifier loss: 0.549650; batch adversarial loss: 0.818744\n","epoch 22; iter: 0; batch classifier loss: 0.473785; batch adversarial loss: 0.875814\n","epoch 23; iter: 0; batch classifier loss: 0.503709; batch adversarial loss: 0.836890\n","epoch 24; iter: 0; batch classifier loss: 0.507117; batch adversarial loss: 0.792677\n","epoch 25; iter: 0; batch classifier loss: 0.569905; batch adversarial loss: 0.758886\n","epoch 26; iter: 0; batch classifier loss: 0.483092; batch adversarial loss: 0.837600\n","epoch 27; iter: 0; batch classifier loss: 0.458261; batch adversarial loss: 0.810001\n","epoch 28; iter: 0; batch classifier loss: 0.445842; batch adversarial loss: 0.835484\n","epoch 29; iter: 0; batch classifier loss: 0.443201; batch adversarial loss: 0.841574\n","epoch 30; iter: 0; batch classifier loss: 0.421921; batch adversarial loss: 0.808402\n","epoch 31; iter: 0; batch classifier loss: 0.497240; batch adversarial loss: 0.806359\n","epoch 32; iter: 0; batch classifier loss: 0.455504; batch adversarial loss: 0.811107\n","epoch 33; iter: 0; batch classifier loss: 0.485039; batch adversarial loss: 0.780015\n","epoch 34; iter: 0; batch classifier loss: 0.469489; batch adversarial loss: 0.803443\n","epoch 35; iter: 0; batch classifier loss: 0.492453; batch adversarial loss: 0.797869\n","epoch 36; iter: 0; batch classifier loss: 0.508454; batch adversarial loss: 0.797118\n","epoch 37; iter: 0; batch classifier loss: 0.471915; batch adversarial loss: 0.790102\n","epoch 38; iter: 0; batch classifier loss: 0.450103; batch adversarial loss: 0.760104\n","epoch 39; iter: 0; batch classifier loss: 0.488695; batch adversarial loss: 0.755107\n","epoch 40; iter: 0; batch classifier loss: 0.529094; batch adversarial loss: 0.769647\n","epoch 41; iter: 0; batch classifier loss: 0.430779; batch adversarial loss: 0.797065\n","epoch 42; iter: 0; batch classifier loss: 0.452311; batch adversarial loss: 0.753875\n","epoch 43; iter: 0; batch classifier loss: 0.523429; batch adversarial loss: 0.755554\n","epoch 44; iter: 0; batch classifier loss: 0.539977; batch adversarial loss: 0.726729\n","epoch 45; iter: 0; batch classifier loss: 0.496935; batch adversarial loss: 0.755464\n","epoch 46; iter: 0; batch classifier loss: 0.512422; batch adversarial loss: 0.772558\n","epoch 47; iter: 0; batch classifier loss: 0.524286; batch adversarial loss: 0.733219\n","epoch 48; iter: 0; batch classifier loss: 0.524069; batch adversarial loss: 0.762381\n","epoch 49; iter: 0; batch classifier loss: 0.462940; batch adversarial loss: 0.759049\n","Accuracy 0.7463768115942029\n","epoch 0; iter: 0; batch classifier loss: 0.747774; batch adversarial loss: 0.673258\n","epoch 1; iter: 0; batch classifier loss: 0.695729; batch adversarial loss: 0.675506\n","epoch 2; iter: 0; batch classifier loss: 0.682410; batch adversarial loss: 0.677514\n","epoch 3; iter: 0; batch classifier loss: 0.631409; batch adversarial loss: 0.650173\n","epoch 4; iter: 0; batch classifier loss: 0.642756; batch adversarial loss: 0.652781\n","epoch 5; iter: 0; batch classifier loss: 0.616783; batch adversarial loss: 0.638520\n","epoch 6; iter: 0; batch classifier loss: 0.640297; batch adversarial loss: 0.662772\n","epoch 7; iter: 0; batch classifier loss: 0.615230; batch adversarial loss: 0.672444\n","epoch 8; iter: 0; batch classifier loss: 0.567787; batch adversarial loss: 0.656598\n","epoch 9; iter: 0; batch classifier loss: 0.580866; batch adversarial loss: 0.659610\n","epoch 10; iter: 0; batch classifier loss: 0.597916; batch adversarial loss: 0.644138\n","epoch 11; iter: 0; batch classifier loss: 0.537130; batch adversarial loss: 0.646698\n","epoch 12; iter: 0; batch classifier loss: 0.546355; batch adversarial loss: 0.657567\n","epoch 13; iter: 0; batch classifier loss: 0.539653; batch adversarial loss: 0.654568\n","epoch 14; iter: 0; batch classifier loss: 0.517298; batch adversarial loss: 0.628389\n","epoch 15; iter: 0; batch classifier loss: 0.528140; batch adversarial loss: 0.664621\n","epoch 16; iter: 0; batch classifier loss: 0.512941; batch adversarial loss: 0.626016\n","epoch 17; iter: 0; batch classifier loss: 0.556299; batch adversarial loss: 0.621501\n","epoch 18; iter: 0; batch classifier loss: 0.524537; batch adversarial loss: 0.620127\n","epoch 19; iter: 0; batch classifier loss: 0.488215; batch adversarial loss: 0.650902\n","epoch 20; iter: 0; batch classifier loss: 0.485278; batch adversarial loss: 0.648469\n","epoch 21; iter: 0; batch classifier loss: 0.543308; batch adversarial loss: 0.653723\n","epoch 22; iter: 0; batch classifier loss: 0.534666; batch adversarial loss: 0.623219\n","epoch 23; iter: 0; batch classifier loss: 0.561002; batch adversarial loss: 0.619905\n","epoch 24; iter: 0; batch classifier loss: 0.461350; batch adversarial loss: 0.611474\n","epoch 25; iter: 0; batch classifier loss: 0.495643; batch adversarial loss: 0.630304\n","epoch 26; iter: 0; batch classifier loss: 0.503980; batch adversarial loss: 0.619832\n","epoch 27; iter: 0; batch classifier loss: 0.479964; batch adversarial loss: 0.641100\n","epoch 28; iter: 0; batch classifier loss: 0.499422; batch adversarial loss: 0.604647\n","epoch 29; iter: 0; batch classifier loss: 0.486545; batch adversarial loss: 0.637014\n","epoch 30; iter: 0; batch classifier loss: 0.430532; batch adversarial loss: 0.627471\n","epoch 31; iter: 0; batch classifier loss: 0.517745; batch adversarial loss: 0.655480\n","epoch 32; iter: 0; batch classifier loss: 0.488541; batch adversarial loss: 0.626843\n","epoch 33; iter: 0; batch classifier loss: 0.459593; batch adversarial loss: 0.619344\n","epoch 34; iter: 0; batch classifier loss: 0.529648; batch adversarial loss: 0.609468\n","epoch 35; iter: 0; batch classifier loss: 0.446344; batch adversarial loss: 0.612145\n","epoch 36; iter: 0; batch classifier loss: 0.458647; batch adversarial loss: 0.627132\n","epoch 37; iter: 0; batch classifier loss: 0.479993; batch adversarial loss: 0.546153\n","epoch 38; iter: 0; batch classifier loss: 0.482939; batch adversarial loss: 0.603264\n","epoch 39; iter: 0; batch classifier loss: 0.448870; batch adversarial loss: 0.614731\n","epoch 40; iter: 0; batch classifier loss: 0.517528; batch adversarial loss: 0.623999\n","epoch 41; iter: 0; batch classifier loss: 0.451891; batch adversarial loss: 0.581898\n","epoch 42; iter: 0; batch classifier loss: 0.493346; batch adversarial loss: 0.596114\n","epoch 43; iter: 0; batch classifier loss: 0.439198; batch adversarial loss: 0.596184\n","epoch 44; iter: 0; batch classifier loss: 0.474584; batch adversarial loss: 0.608715\n","epoch 45; iter: 0; batch classifier loss: 0.402796; batch adversarial loss: 0.588596\n","epoch 46; iter: 0; batch classifier loss: 0.479495; batch adversarial loss: 0.580048\n","epoch 47; iter: 0; batch classifier loss: 0.415588; batch adversarial loss: 0.589269\n","epoch 48; iter: 0; batch classifier loss: 0.480787; batch adversarial loss: 0.613881\n","epoch 49; iter: 0; batch classifier loss: 0.405738; batch adversarial loss: 0.588381\n","Accuracy 0.7266187050359713\n","epoch 0; iter: 0; batch classifier loss: 0.689895; batch adversarial loss: 0.800384\n","epoch 1; iter: 0; batch classifier loss: 0.667196; batch adversarial loss: 0.829957\n","epoch 2; iter: 0; batch classifier loss: 0.641543; batch adversarial loss: 0.821039\n","epoch 3; iter: 0; batch classifier loss: 0.623638; batch adversarial loss: 0.833519\n","epoch 4; iter: 0; batch classifier loss: 0.614537; batch adversarial loss: 0.837172\n","epoch 5; iter: 0; batch classifier loss: 0.592745; batch adversarial loss: 0.856287\n","epoch 6; iter: 0; batch classifier loss: 0.593998; batch adversarial loss: 0.830702\n","epoch 7; iter: 0; batch classifier loss: 0.570238; batch adversarial loss: 0.855219\n","epoch 8; iter: 0; batch classifier loss: 0.568097; batch adversarial loss: 0.829209\n","epoch 9; iter: 0; batch classifier loss: 0.551380; batch adversarial loss: 0.841538\n","epoch 10; iter: 0; batch classifier loss: 0.547340; batch adversarial loss: 0.842716\n","epoch 11; iter: 0; batch classifier loss: 0.562653; batch adversarial loss: 0.838026\n","epoch 12; iter: 0; batch classifier loss: 0.544558; batch adversarial loss: 0.853776\n","epoch 13; iter: 0; batch classifier loss: 0.564729; batch adversarial loss: 0.858863\n","epoch 14; iter: 0; batch classifier loss: 0.504156; batch adversarial loss: 0.842528\n","epoch 15; iter: 0; batch classifier loss: 0.581111; batch adversarial loss: 0.859442\n","epoch 16; iter: 0; batch classifier loss: 0.602947; batch adversarial loss: 0.852188\n","epoch 17; iter: 0; batch classifier loss: 0.517392; batch adversarial loss: 0.826897\n","epoch 18; iter: 0; batch classifier loss: 0.535453; batch adversarial loss: 0.826449\n","epoch 19; iter: 0; batch classifier loss: 0.603214; batch adversarial loss: 0.824908\n","epoch 20; iter: 0; batch classifier loss: 0.588881; batch adversarial loss: 0.824775\n","epoch 21; iter: 0; batch classifier loss: 0.536405; batch adversarial loss: 0.816458\n","epoch 22; iter: 0; batch classifier loss: 0.546121; batch adversarial loss: 0.816499\n","epoch 23; iter: 0; batch classifier loss: 0.550576; batch adversarial loss: 0.809407\n","epoch 24; iter: 0; batch classifier loss: 0.485815; batch adversarial loss: 0.808199\n","epoch 25; iter: 0; batch classifier loss: 0.495293; batch adversarial loss: 0.806783\n","epoch 26; iter: 0; batch classifier loss: 0.534586; batch adversarial loss: 0.802589\n","epoch 27; iter: 0; batch classifier loss: 0.604954; batch adversarial loss: 0.807957\n","epoch 28; iter: 0; batch classifier loss: 0.572526; batch adversarial loss: 0.811306\n","epoch 29; iter: 0; batch classifier loss: 0.530671; batch adversarial loss: 0.800408\n","epoch 30; iter: 0; batch classifier loss: 0.679054; batch adversarial loss: 0.791115\n","epoch 31; iter: 0; batch classifier loss: 0.500792; batch adversarial loss: 0.791703\n","epoch 32; iter: 0; batch classifier loss: 0.557440; batch adversarial loss: 0.786922\n","epoch 33; iter: 0; batch classifier loss: 0.572661; batch adversarial loss: 0.788917\n","epoch 34; iter: 0; batch classifier loss: 0.532911; batch adversarial loss: 0.785237\n","epoch 35; iter: 0; batch classifier loss: 0.676727; batch adversarial loss: 0.782302\n","epoch 36; iter: 0; batch classifier loss: 0.565437; batch adversarial loss: 0.773777\n","epoch 37; iter: 0; batch classifier loss: 0.592569; batch adversarial loss: 0.773379\n","epoch 38; iter: 0; batch classifier loss: 0.565567; batch adversarial loss: 0.767255\n","epoch 39; iter: 0; batch classifier loss: 0.570128; batch adversarial loss: 0.756692\n","epoch 40; iter: 0; batch classifier loss: 0.587771; batch adversarial loss: 0.753093\n","epoch 41; iter: 0; batch classifier loss: 0.545093; batch adversarial loss: 0.752800\n","epoch 42; iter: 0; batch classifier loss: 0.493575; batch adversarial loss: 0.748599\n","epoch 43; iter: 0; batch classifier loss: 0.604438; batch adversarial loss: 0.745121\n","epoch 44; iter: 0; batch classifier loss: 0.603447; batch adversarial loss: 0.742294\n","epoch 45; iter: 0; batch classifier loss: 0.601631; batch adversarial loss: 0.737817\n","epoch 46; iter: 0; batch classifier loss: 0.480035; batch adversarial loss: 0.731466\n","epoch 47; iter: 0; batch classifier loss: 0.561239; batch adversarial loss: 0.734819\n","epoch 48; iter: 0; batch classifier loss: 0.536905; batch adversarial loss: 0.725455\n","epoch 49; iter: 0; batch classifier loss: 0.648314; batch adversarial loss: 0.722810\n","Accuracy 0.6834532374100719\n","epoch 0; iter: 0; batch classifier loss: 0.707028; batch adversarial loss: 0.730882\n","epoch 1; iter: 0; batch classifier loss: 0.691035; batch adversarial loss: 0.756964\n","epoch 2; iter: 0; batch classifier loss: 0.678625; batch adversarial loss: 0.747718\n","epoch 3; iter: 0; batch classifier loss: 0.657403; batch adversarial loss: 0.748036\n","epoch 4; iter: 0; batch classifier loss: 0.639231; batch adversarial loss: 0.759784\n","epoch 5; iter: 0; batch classifier loss: 0.627178; batch adversarial loss: 0.741370\n","epoch 6; iter: 0; batch classifier loss: 0.611774; batch adversarial loss: 0.739793\n","epoch 7; iter: 0; batch classifier loss: 0.596236; batch adversarial loss: 0.756099\n","epoch 8; iter: 0; batch classifier loss: 0.598913; batch adversarial loss: 0.745350\n","epoch 9; iter: 0; batch classifier loss: 0.594755; batch adversarial loss: 0.758734\n","epoch 10; iter: 0; batch classifier loss: 0.572595; batch adversarial loss: 0.743394\n","epoch 11; iter: 0; batch classifier loss: 0.570015; batch adversarial loss: 0.746887\n","epoch 12; iter: 0; batch classifier loss: 0.561706; batch adversarial loss: 0.740686\n","epoch 13; iter: 0; batch classifier loss: 0.569285; batch adversarial loss: 0.733505\n","epoch 14; iter: 0; batch classifier loss: 0.522809; batch adversarial loss: 0.761213\n","epoch 15; iter: 0; batch classifier loss: 0.552527; batch adversarial loss: 0.751767\n","epoch 16; iter: 0; batch classifier loss: 0.507012; batch adversarial loss: 0.734744\n","epoch 17; iter: 0; batch classifier loss: 0.527228; batch adversarial loss: 0.743871\n","epoch 18; iter: 0; batch classifier loss: 0.560630; batch adversarial loss: 0.710483\n","epoch 19; iter: 0; batch classifier loss: 0.524943; batch adversarial loss: 0.744271\n","epoch 20; iter: 0; batch classifier loss: 0.505778; batch adversarial loss: 0.747951\n","epoch 21; iter: 0; batch classifier loss: 0.513815; batch adversarial loss: 0.709523\n","epoch 22; iter: 0; batch classifier loss: 0.513100; batch adversarial loss: 0.717218\n","epoch 23; iter: 0; batch classifier loss: 0.491384; batch adversarial loss: 0.731165\n","epoch 24; iter: 0; batch classifier loss: 0.466440; batch adversarial loss: 0.743371\n","epoch 25; iter: 0; batch classifier loss: 0.507462; batch adversarial loss: 0.727825\n","epoch 26; iter: 0; batch classifier loss: 0.490317; batch adversarial loss: 0.713978\n","epoch 27; iter: 0; batch classifier loss: 0.533211; batch adversarial loss: 0.690345\n","epoch 28; iter: 0; batch classifier loss: 0.455251; batch adversarial loss: 0.707132\n","epoch 29; iter: 0; batch classifier loss: 0.583917; batch adversarial loss: 0.676850\n","epoch 30; iter: 0; batch classifier loss: 0.457257; batch adversarial loss: 0.703475\n","epoch 31; iter: 0; batch classifier loss: 0.480756; batch adversarial loss: 0.712141\n","epoch 32; iter: 0; batch classifier loss: 0.424151; batch adversarial loss: 0.711243\n","epoch 33; iter: 0; batch classifier loss: 0.545972; batch adversarial loss: 0.689237\n","epoch 34; iter: 0; batch classifier loss: 0.498873; batch adversarial loss: 0.690167\n","epoch 35; iter: 0; batch classifier loss: 0.503033; batch adversarial loss: 0.697576\n","epoch 36; iter: 0; batch classifier loss: 0.460931; batch adversarial loss: 0.693197\n","epoch 37; iter: 0; batch classifier loss: 0.506529; batch adversarial loss: 0.680490\n","epoch 38; iter: 0; batch classifier loss: 0.525432; batch adversarial loss: 0.644579\n","epoch 39; iter: 0; batch classifier loss: 0.470675; batch adversarial loss: 0.701861\n","epoch 40; iter: 0; batch classifier loss: 0.451819; batch adversarial loss: 0.690937\n","epoch 41; iter: 0; batch classifier loss: 0.480649; batch adversarial loss: 0.677516\n","epoch 42; iter: 0; batch classifier loss: 0.491780; batch adversarial loss: 0.701109\n","epoch 43; iter: 0; batch classifier loss: 0.488112; batch adversarial loss: 0.674960\n","epoch 44; iter: 0; batch classifier loss: 0.453875; batch adversarial loss: 0.669098\n","epoch 45; iter: 0; batch classifier loss: 0.413965; batch adversarial loss: 0.694569\n","epoch 46; iter: 0; batch classifier loss: 0.431555; batch adversarial loss: 0.676185\n","epoch 47; iter: 0; batch classifier loss: 0.464934; batch adversarial loss: 0.678684\n","epoch 48; iter: 0; batch classifier loss: 0.495225; batch adversarial loss: 0.655302\n","epoch 49; iter: 0; batch classifier loss: 0.482186; batch adversarial loss: 0.682965\n","Accuracy 0.7318840579710145\n","epoch 0; iter: 0; batch classifier loss: 0.676369; batch adversarial loss: 0.940034\n","epoch 1; iter: 0; batch classifier loss: 0.654218; batch adversarial loss: 0.937813\n","epoch 2; iter: 0; batch classifier loss: 0.642434; batch adversarial loss: 0.981946\n","epoch 3; iter: 0; batch classifier loss: 0.629896; batch adversarial loss: 1.003492\n","epoch 4; iter: 0; batch classifier loss: 0.612134; batch adversarial loss: 1.104464\n","epoch 5; iter: 0; batch classifier loss: 0.602365; batch adversarial loss: 1.024993\n","epoch 6; iter: 0; batch classifier loss: 0.586519; batch adversarial loss: 1.079221\n","epoch 7; iter: 0; batch classifier loss: 0.596569; batch adversarial loss: 1.143189\n","epoch 8; iter: 0; batch classifier loss: 0.554441; batch adversarial loss: 1.116873\n","epoch 9; iter: 0; batch classifier loss: 0.581066; batch adversarial loss: 1.129827\n","epoch 10; iter: 0; batch classifier loss: 0.554260; batch adversarial loss: 1.136608\n","epoch 11; iter: 0; batch classifier loss: 0.547515; batch adversarial loss: 1.108508\n","epoch 12; iter: 0; batch classifier loss: 0.642856; batch adversarial loss: 1.147764\n","epoch 13; iter: 0; batch classifier loss: 0.622880; batch adversarial loss: 1.143132\n","epoch 14; iter: 0; batch classifier loss: 0.581596; batch adversarial loss: 1.118332\n","epoch 15; iter: 0; batch classifier loss: 0.504652; batch adversarial loss: 1.063820\n","epoch 16; iter: 0; batch classifier loss: 0.526160; batch adversarial loss: 1.123738\n","epoch 17; iter: 0; batch classifier loss: 0.638750; batch adversarial loss: 1.134321\n","epoch 18; iter: 0; batch classifier loss: 0.509936; batch adversarial loss: 1.122947\n","epoch 19; iter: 0; batch classifier loss: 0.527853; batch adversarial loss: 1.133650\n","epoch 20; iter: 0; batch classifier loss: 0.593992; batch adversarial loss: 1.105114\n","epoch 21; iter: 0; batch classifier loss: 0.511820; batch adversarial loss: 1.144617\n","epoch 22; iter: 0; batch classifier loss: 0.605816; batch adversarial loss: 1.100234\n","epoch 23; iter: 0; batch classifier loss: 0.558076; batch adversarial loss: 1.126970\n","epoch 24; iter: 0; batch classifier loss: 0.578223; batch adversarial loss: 1.113985\n","epoch 25; iter: 0; batch classifier loss: 0.545269; batch adversarial loss: 1.091750\n","epoch 26; iter: 0; batch classifier loss: 0.646274; batch adversarial loss: 1.079718\n","epoch 27; iter: 0; batch classifier loss: 0.725279; batch adversarial loss: 1.130942\n","epoch 28; iter: 0; batch classifier loss: 0.602653; batch adversarial loss: 1.112292\n","epoch 29; iter: 0; batch classifier loss: 0.681104; batch adversarial loss: 1.103633\n","epoch 30; iter: 0; batch classifier loss: 0.599167; batch adversarial loss: 1.035846\n","epoch 31; iter: 0; batch classifier loss: 0.638293; batch adversarial loss: 1.084835\n","epoch 32; iter: 0; batch classifier loss: 0.690064; batch adversarial loss: 1.081435\n","epoch 33; iter: 0; batch classifier loss: 0.684368; batch adversarial loss: 1.078394\n","epoch 34; iter: 0; batch classifier loss: 0.660535; batch adversarial loss: 1.056831\n","epoch 35; iter: 0; batch classifier loss: 0.574103; batch adversarial loss: 1.058134\n","epoch 36; iter: 0; batch classifier loss: 0.756375; batch adversarial loss: 1.057802\n","epoch 37; iter: 0; batch classifier loss: 0.601778; batch adversarial loss: 1.059367\n","epoch 38; iter: 0; batch classifier loss: 0.620950; batch adversarial loss: 1.046868\n","epoch 39; iter: 0; batch classifier loss: 0.733428; batch adversarial loss: 1.061399\n","epoch 40; iter: 0; batch classifier loss: 0.712322; batch adversarial loss: 1.053056\n","epoch 41; iter: 0; batch classifier loss: 0.725315; batch adversarial loss: 1.048723\n","epoch 42; iter: 0; batch classifier loss: 0.638058; batch adversarial loss: 1.058988\n","epoch 43; iter: 0; batch classifier loss: 0.637254; batch adversarial loss: 1.044588\n","epoch 44; iter: 0; batch classifier loss: 0.697492; batch adversarial loss: 1.040530\n","epoch 45; iter: 0; batch classifier loss: 0.608848; batch adversarial loss: 1.030314\n","epoch 46; iter: 0; batch classifier loss: 0.607352; batch adversarial loss: 1.022328\n","epoch 47; iter: 0; batch classifier loss: 0.642746; batch adversarial loss: 1.016472\n","epoch 48; iter: 0; batch classifier loss: 0.780976; batch adversarial loss: 1.013240\n","epoch 49; iter: 0; batch classifier loss: 0.697004; batch adversarial loss: 0.997795\n","Accuracy 0.6014492753623188\n","epoch 0; iter: 0; batch classifier loss: 0.707832; batch adversarial loss: 0.679947\n","epoch 1; iter: 0; batch classifier loss: 0.687738; batch adversarial loss: 0.680613\n","epoch 2; iter: 0; batch classifier loss: 0.672720; batch adversarial loss: 0.680488\n","epoch 3; iter: 0; batch classifier loss: 0.653298; batch adversarial loss: 0.670196\n","epoch 4; iter: 0; batch classifier loss: 0.634931; batch adversarial loss: 0.655374\n","epoch 5; iter: 0; batch classifier loss: 0.644657; batch adversarial loss: 0.660570\n","epoch 6; iter: 0; batch classifier loss: 0.596657; batch adversarial loss: 0.671083\n","epoch 7; iter: 0; batch classifier loss: 0.558831; batch adversarial loss: 0.664891\n","epoch 8; iter: 0; batch classifier loss: 0.570283; batch adversarial loss: 0.671099\n","epoch 9; iter: 0; batch classifier loss: 0.575546; batch adversarial loss: 0.635503\n","epoch 10; iter: 0; batch classifier loss: 0.549229; batch adversarial loss: 0.668774\n","epoch 11; iter: 0; batch classifier loss: 0.537246; batch adversarial loss: 0.636712\n","epoch 12; iter: 0; batch classifier loss: 0.566982; batch adversarial loss: 0.644361\n","epoch 13; iter: 0; batch classifier loss: 0.519534; batch adversarial loss: 0.635271\n","epoch 14; iter: 0; batch classifier loss: 0.499600; batch adversarial loss: 0.670115\n","epoch 15; iter: 0; batch classifier loss: 0.515422; batch adversarial loss: 0.633763\n","epoch 16; iter: 0; batch classifier loss: 0.493686; batch adversarial loss: 0.634092\n","epoch 17; iter: 0; batch classifier loss: 0.486961; batch adversarial loss: 0.649412\n","epoch 18; iter: 0; batch classifier loss: 0.515504; batch adversarial loss: 0.651875\n","epoch 19; iter: 0; batch classifier loss: 0.502154; batch adversarial loss: 0.628807\n","epoch 20; iter: 0; batch classifier loss: 0.486495; batch adversarial loss: 0.631960\n","epoch 21; iter: 0; batch classifier loss: 0.466337; batch adversarial loss: 0.644979\n","epoch 22; iter: 0; batch classifier loss: 0.489303; batch adversarial loss: 0.622782\n","epoch 23; iter: 0; batch classifier loss: 0.445803; batch adversarial loss: 0.633270\n","epoch 24; iter: 0; batch classifier loss: 0.547982; batch adversarial loss: 0.641967\n","epoch 25; iter: 0; batch classifier loss: 0.494944; batch adversarial loss: 0.615655\n","epoch 26; iter: 0; batch classifier loss: 0.505466; batch adversarial loss: 0.628096\n","epoch 27; iter: 0; batch classifier loss: 0.532087; batch adversarial loss: 0.633355\n","epoch 28; iter: 0; batch classifier loss: 0.507369; batch adversarial loss: 0.617354\n","epoch 29; iter: 0; batch classifier loss: 0.509837; batch adversarial loss: 0.628622\n","epoch 30; iter: 0; batch classifier loss: 0.499334; batch adversarial loss: 0.641476\n","epoch 31; iter: 0; batch classifier loss: 0.530260; batch adversarial loss: 0.645380\n","epoch 32; iter: 0; batch classifier loss: 0.485094; batch adversarial loss: 0.620377\n","epoch 33; iter: 0; batch classifier loss: 0.488417; batch adversarial loss: 0.619732\n","epoch 34; iter: 0; batch classifier loss: 0.556355; batch adversarial loss: 0.637453\n","epoch 35; iter: 0; batch classifier loss: 0.501701; batch adversarial loss: 0.630265\n","epoch 36; iter: 0; batch classifier loss: 0.460925; batch adversarial loss: 0.614268\n","epoch 37; iter: 0; batch classifier loss: 0.446574; batch adversarial loss: 0.588822\n","epoch 38; iter: 0; batch classifier loss: 0.434241; batch adversarial loss: 0.591041\n","epoch 39; iter: 0; batch classifier loss: 0.397924; batch adversarial loss: 0.598768\n","epoch 40; iter: 0; batch classifier loss: 0.441142; batch adversarial loss: 0.602729\n","epoch 41; iter: 0; batch classifier loss: 0.509779; batch adversarial loss: 0.618455\n","epoch 42; iter: 0; batch classifier loss: 0.449194; batch adversarial loss: 0.603748\n","epoch 43; iter: 0; batch classifier loss: 0.472432; batch adversarial loss: 0.599638\n","epoch 44; iter: 0; batch classifier loss: 0.492137; batch adversarial loss: 0.601662\n","epoch 45; iter: 0; batch classifier loss: 0.476649; batch adversarial loss: 0.599285\n","epoch 46; iter: 0; batch classifier loss: 0.452602; batch adversarial loss: 0.604919\n","epoch 47; iter: 0; batch classifier loss: 0.525847; batch adversarial loss: 0.625159\n","epoch 48; iter: 0; batch classifier loss: 0.497080; batch adversarial loss: 0.602939\n","epoch 49; iter: 0; batch classifier loss: 0.493935; batch adversarial loss: 0.594748\n","Accuracy 0.7391304347826086\n","epoch 0; iter: 0; batch classifier loss: 0.674584; batch adversarial loss: 0.602534\n","epoch 1; iter: 0; batch classifier loss: 0.656759; batch adversarial loss: 0.580703\n","epoch 2; iter: 0; batch classifier loss: 0.653437; batch adversarial loss: 0.632682\n","epoch 3; iter: 0; batch classifier loss: 0.643948; batch adversarial loss: 0.595901\n","epoch 4; iter: 0; batch classifier loss: 0.635332; batch adversarial loss: 0.595848\n","epoch 5; iter: 0; batch classifier loss: 0.629151; batch adversarial loss: 0.548139\n","epoch 6; iter: 0; batch classifier loss: 0.592914; batch adversarial loss: 0.593312\n","epoch 7; iter: 0; batch classifier loss: 0.581658; batch adversarial loss: 0.590900\n","epoch 8; iter: 0; batch classifier loss: 0.574524; batch adversarial loss: 0.668556\n","epoch 9; iter: 0; batch classifier loss: 0.565306; batch adversarial loss: 0.585614\n","epoch 10; iter: 0; batch classifier loss: 0.573595; batch adversarial loss: 0.601436\n","epoch 11; iter: 0; batch classifier loss: 0.616539; batch adversarial loss: 0.623360\n","epoch 12; iter: 0; batch classifier loss: 0.567602; batch adversarial loss: 0.555963\n","epoch 13; iter: 0; batch classifier loss: 0.574008; batch adversarial loss: 0.644458\n","epoch 14; iter: 0; batch classifier loss: 0.561159; batch adversarial loss: 0.601388\n","epoch 15; iter: 0; batch classifier loss: 0.579238; batch adversarial loss: 0.620527\n","epoch 16; iter: 0; batch classifier loss: 0.563909; batch adversarial loss: 0.646412\n","epoch 17; iter: 0; batch classifier loss: 0.547300; batch adversarial loss: 0.651661\n","epoch 18; iter: 0; batch classifier loss: 0.523879; batch adversarial loss: 0.603144\n","epoch 19; iter: 0; batch classifier loss: 0.574302; batch adversarial loss: 0.630062\n","epoch 20; iter: 0; batch classifier loss: 0.562664; batch adversarial loss: 0.635517\n","epoch 21; iter: 0; batch classifier loss: 0.577597; batch adversarial loss: 0.607927\n","epoch 22; iter: 0; batch classifier loss: 0.529830; batch adversarial loss: 0.609755\n","epoch 23; iter: 0; batch classifier loss: 0.593879; batch adversarial loss: 0.663428\n","epoch 24; iter: 0; batch classifier loss: 0.554850; batch adversarial loss: 0.613715\n","epoch 25; iter: 0; batch classifier loss: 0.520651; batch adversarial loss: 0.633198\n","epoch 26; iter: 0; batch classifier loss: 0.523288; batch adversarial loss: 0.696343\n","epoch 27; iter: 0; batch classifier loss: 0.552316; batch adversarial loss: 0.646486\n","epoch 28; iter: 0; batch classifier loss: 0.534603; batch adversarial loss: 0.634650\n","epoch 29; iter: 0; batch classifier loss: 0.515095; batch adversarial loss: 0.621799\n","epoch 30; iter: 0; batch classifier loss: 0.563806; batch adversarial loss: 0.621173\n","epoch 31; iter: 0; batch classifier loss: 0.526503; batch adversarial loss: 0.658186\n","epoch 32; iter: 0; batch classifier loss: 0.528039; batch adversarial loss: 0.606344\n","epoch 33; iter: 0; batch classifier loss: 0.484603; batch adversarial loss: 0.643561\n","epoch 34; iter: 0; batch classifier loss: 0.511447; batch adversarial loss: 0.640752\n","epoch 35; iter: 0; batch classifier loss: 0.593322; batch adversarial loss: 0.678633\n","epoch 36; iter: 0; batch classifier loss: 0.526619; batch adversarial loss: 0.674754\n","epoch 37; iter: 0; batch classifier loss: 0.540595; batch adversarial loss: 0.657370\n","epoch 38; iter: 0; batch classifier loss: 0.483666; batch adversarial loss: 0.663509\n","epoch 39; iter: 0; batch classifier loss: 0.552917; batch adversarial loss: 0.716002\n","epoch 40; iter: 0; batch classifier loss: 0.518766; batch adversarial loss: 0.643729\n","epoch 41; iter: 0; batch classifier loss: 0.555751; batch adversarial loss: 0.691712\n","epoch 42; iter: 0; batch classifier loss: 0.565190; batch adversarial loss: 0.655927\n","epoch 43; iter: 0; batch classifier loss: 0.572612; batch adversarial loss: 0.549463\n","epoch 44; iter: 0; batch classifier loss: 0.565313; batch adversarial loss: 0.681435\n","epoch 45; iter: 0; batch classifier loss: 0.521871; batch adversarial loss: 0.615140\n","epoch 46; iter: 0; batch classifier loss: 0.549553; batch adversarial loss: 0.692492\n","epoch 47; iter: 0; batch classifier loss: 0.496350; batch adversarial loss: 0.634243\n","epoch 48; iter: 0; batch classifier loss: 0.561563; batch adversarial loss: 0.662363\n","epoch 49; iter: 0; batch classifier loss: 0.678404; batch adversarial loss: 0.663056\n","Accuracy 0.6762589928057554\n","epoch 0; iter: 0; batch classifier loss: 0.721578; batch adversarial loss: 0.687482\n","epoch 1; iter: 0; batch classifier loss: 0.660571; batch adversarial loss: 0.683144\n","epoch 2; iter: 0; batch classifier loss: 0.682447; batch adversarial loss: 0.664149\n","epoch 3; iter: 0; batch classifier loss: 0.655136; batch adversarial loss: 0.657561\n","epoch 4; iter: 0; batch classifier loss: 0.644814; batch adversarial loss: 0.663450\n","epoch 5; iter: 0; batch classifier loss: 0.640110; batch adversarial loss: 0.662989\n","epoch 6; iter: 0; batch classifier loss: 0.604279; batch adversarial loss: 0.651910\n","epoch 7; iter: 0; batch classifier loss: 0.641471; batch adversarial loss: 0.659555\n","epoch 8; iter: 0; batch classifier loss: 0.616071; batch adversarial loss: 0.663104\n","epoch 9; iter: 0; batch classifier loss: 0.610410; batch adversarial loss: 0.657945\n","epoch 10; iter: 0; batch classifier loss: 0.605465; batch adversarial loss: 0.657555\n","epoch 11; iter: 0; batch classifier loss: 0.593427; batch adversarial loss: 0.649875\n","epoch 12; iter: 0; batch classifier loss: 0.594187; batch adversarial loss: 0.630383\n","epoch 13; iter: 0; batch classifier loss: 0.535485; batch adversarial loss: 0.637801\n","epoch 14; iter: 0; batch classifier loss: 0.572971; batch adversarial loss: 0.629214\n","epoch 15; iter: 0; batch classifier loss: 0.596529; batch adversarial loss: 0.634253\n","epoch 16; iter: 0; batch classifier loss: 0.555541; batch adversarial loss: 0.625247\n","epoch 17; iter: 0; batch classifier loss: 0.565354; batch adversarial loss: 0.627033\n","epoch 18; iter: 0; batch classifier loss: 0.535704; batch adversarial loss: 0.622792\n","epoch 19; iter: 0; batch classifier loss: 0.550066; batch adversarial loss: 0.667878\n","epoch 20; iter: 0; batch classifier loss: 0.535761; batch adversarial loss: 0.638596\n","epoch 21; iter: 0; batch classifier loss: 0.514727; batch adversarial loss: 0.638194\n","epoch 22; iter: 0; batch classifier loss: 0.517295; batch adversarial loss: 0.624385\n","epoch 23; iter: 0; batch classifier loss: 0.487288; batch adversarial loss: 0.632549\n","epoch 24; iter: 0; batch classifier loss: 0.510431; batch adversarial loss: 0.634943\n","epoch 25; iter: 0; batch classifier loss: 0.511897; batch adversarial loss: 0.628508\n","epoch 26; iter: 0; batch classifier loss: 0.536922; batch adversarial loss: 0.625427\n","epoch 27; iter: 0; batch classifier loss: 0.505674; batch adversarial loss: 0.596837\n","epoch 28; iter: 0; batch classifier loss: 0.502580; batch adversarial loss: 0.615005\n","epoch 29; iter: 0; batch classifier loss: 0.561395; batch adversarial loss: 0.601927\n","epoch 30; iter: 0; batch classifier loss: 0.491549; batch adversarial loss: 0.619573\n","epoch 31; iter: 0; batch classifier loss: 0.533341; batch adversarial loss: 0.619508\n","epoch 32; iter: 0; batch classifier loss: 0.484257; batch adversarial loss: 0.614276\n","epoch 33; iter: 0; batch classifier loss: 0.450703; batch adversarial loss: 0.591766\n","epoch 34; iter: 0; batch classifier loss: 0.576075; batch adversarial loss: 0.617026\n","epoch 35; iter: 0; batch classifier loss: 0.493309; batch adversarial loss: 0.605527\n","epoch 36; iter: 0; batch classifier loss: 0.488900; batch adversarial loss: 0.603164\n","epoch 37; iter: 0; batch classifier loss: 0.488554; batch adversarial loss: 0.576723\n","epoch 38; iter: 0; batch classifier loss: 0.485219; batch adversarial loss: 0.617232\n","epoch 39; iter: 0; batch classifier loss: 0.527790; batch adversarial loss: 0.593603\n","epoch 40; iter: 0; batch classifier loss: 0.438149; batch adversarial loss: 0.569317\n","epoch 41; iter: 0; batch classifier loss: 0.462180; batch adversarial loss: 0.596788\n","epoch 42; iter: 0; batch classifier loss: 0.494857; batch adversarial loss: 0.585738\n","epoch 43; iter: 0; batch classifier loss: 0.508808; batch adversarial loss: 0.601447\n","epoch 44; iter: 0; batch classifier loss: 0.549038; batch adversarial loss: 0.595094\n","epoch 45; iter: 0; batch classifier loss: 0.484749; batch adversarial loss: 0.626120\n","epoch 46; iter: 0; batch classifier loss: 0.530242; batch adversarial loss: 0.605085\n","epoch 47; iter: 0; batch classifier loss: 0.479229; batch adversarial loss: 0.589332\n","epoch 48; iter: 0; batch classifier loss: 0.515545; batch adversarial loss: 0.613105\n","epoch 49; iter: 0; batch classifier loss: 0.491752; batch adversarial loss: 0.588852\n","Accuracy 0.6690647482014388\n","epoch 0; iter: 0; batch classifier loss: 0.722397; batch adversarial loss: 0.521885\n","epoch 1; iter: 0; batch classifier loss: 0.712314; batch adversarial loss: 0.555441\n","epoch 2; iter: 0; batch classifier loss: 0.697715; batch adversarial loss: 0.550852\n","epoch 3; iter: 0; batch classifier loss: 0.702426; batch adversarial loss: 0.541875\n","epoch 4; iter: 0; batch classifier loss: 0.675702; batch adversarial loss: 0.597483\n","epoch 5; iter: 0; batch classifier loss: 0.664551; batch adversarial loss: 0.578701\n","epoch 6; iter: 0; batch classifier loss: 0.626944; batch adversarial loss: 0.572496\n","epoch 7; iter: 0; batch classifier loss: 0.655361; batch adversarial loss: 0.581417\n","epoch 8; iter: 0; batch classifier loss: 0.630494; batch adversarial loss: 0.622368\n","epoch 9; iter: 0; batch classifier loss: 0.625137; batch adversarial loss: 0.615526\n","epoch 10; iter: 0; batch classifier loss: 0.625462; batch adversarial loss: 0.663624\n","epoch 11; iter: 0; batch classifier loss: 0.609104; batch adversarial loss: 0.621087\n","epoch 12; iter: 0; batch classifier loss: 0.649498; batch adversarial loss: 0.591312\n","epoch 13; iter: 0; batch classifier loss: 0.647187; batch adversarial loss: 0.650555\n","epoch 14; iter: 0; batch classifier loss: 0.630993; batch adversarial loss: 0.668965\n","epoch 15; iter: 0; batch classifier loss: 0.637775; batch adversarial loss: 0.653022\n","epoch 16; iter: 0; batch classifier loss: 0.628072; batch adversarial loss: 0.661625\n","epoch 17; iter: 0; batch classifier loss: 0.589836; batch adversarial loss: 0.634577\n","epoch 18; iter: 0; batch classifier loss: 0.577999; batch adversarial loss: 0.674043\n","epoch 19; iter: 0; batch classifier loss: 0.669281; batch adversarial loss: 0.725425\n","epoch 20; iter: 0; batch classifier loss: 0.602586; batch adversarial loss: 0.638579\n","epoch 21; iter: 0; batch classifier loss: 0.654335; batch adversarial loss: 0.676738\n","epoch 22; iter: 0; batch classifier loss: 0.676681; batch adversarial loss: 0.645212\n","epoch 23; iter: 0; batch classifier loss: 0.661725; batch adversarial loss: 0.631045\n","epoch 24; iter: 0; batch classifier loss: 0.635769; batch adversarial loss: 0.692244\n","epoch 25; iter: 0; batch classifier loss: 0.751690; batch adversarial loss: 0.601390\n","epoch 26; iter: 0; batch classifier loss: 0.628531; batch adversarial loss: 0.684564\n","epoch 27; iter: 0; batch classifier loss: 0.644584; batch adversarial loss: 0.707579\n","epoch 28; iter: 0; batch classifier loss: 0.676437; batch adversarial loss: 0.685515\n","epoch 29; iter: 0; batch classifier loss: 0.634481; batch adversarial loss: 0.704849\n","epoch 30; iter: 0; batch classifier loss: 0.666721; batch adversarial loss: 0.703245\n","epoch 31; iter: 0; batch classifier loss: 0.660000; batch adversarial loss: 0.757722\n","epoch 32; iter: 0; batch classifier loss: 0.761136; batch adversarial loss: 0.748075\n","epoch 33; iter: 0; batch classifier loss: 0.679593; batch adversarial loss: 0.769095\n","epoch 34; iter: 0; batch classifier loss: 0.765181; batch adversarial loss: 0.722837\n","epoch 35; iter: 0; batch classifier loss: 0.751887; batch adversarial loss: 0.747639\n","epoch 36; iter: 0; batch classifier loss: 0.772489; batch adversarial loss: 0.670451\n","epoch 37; iter: 0; batch classifier loss: 0.861483; batch adversarial loss: 0.715900\n","epoch 38; iter: 0; batch classifier loss: 0.697283; batch adversarial loss: 0.692945\n","epoch 39; iter: 0; batch classifier loss: 0.805100; batch adversarial loss: 0.727857\n","epoch 40; iter: 0; batch classifier loss: 0.861701; batch adversarial loss: 0.729208\n","epoch 41; iter: 0; batch classifier loss: 0.821057; batch adversarial loss: 0.731995\n","epoch 42; iter: 0; batch classifier loss: 0.851344; batch adversarial loss: 0.715895\n","epoch 43; iter: 0; batch classifier loss: 0.853575; batch adversarial loss: 0.702854\n","epoch 44; iter: 0; batch classifier loss: 0.907466; batch adversarial loss: 0.684963\n","epoch 45; iter: 0; batch classifier loss: 0.898844; batch adversarial loss: 0.775867\n","epoch 46; iter: 0; batch classifier loss: 0.804141; batch adversarial loss: 0.686476\n","epoch 47; iter: 0; batch classifier loss: 0.952366; batch adversarial loss: 0.735148\n","epoch 48; iter: 0; batch classifier loss: 0.885495; batch adversarial loss: 0.675492\n","epoch 49; iter: 0; batch classifier loss: 0.936337; batch adversarial loss: 0.681716\n","Accuracy 0.4782608695652174\n","epoch 0; iter: 0; batch classifier loss: 0.717812; batch adversarial loss: 0.578974\n","epoch 1; iter: 0; batch classifier loss: 0.718951; batch adversarial loss: 0.549490\n","epoch 2; iter: 0; batch classifier loss: 0.691150; batch adversarial loss: 0.594628\n","epoch 3; iter: 0; batch classifier loss: 0.693067; batch adversarial loss: 0.588932\n","epoch 4; iter: 0; batch classifier loss: 0.695675; batch adversarial loss: 0.622413\n","epoch 5; iter: 0; batch classifier loss: 0.688872; batch adversarial loss: 0.620758\n","epoch 6; iter: 0; batch classifier loss: 0.665830; batch adversarial loss: 0.620742\n","epoch 7; iter: 0; batch classifier loss: 0.663869; batch adversarial loss: 0.621048\n","epoch 8; iter: 0; batch classifier loss: 0.667177; batch adversarial loss: 0.620732\n","epoch 9; iter: 0; batch classifier loss: 0.674592; batch adversarial loss: 0.639507\n","epoch 10; iter: 0; batch classifier loss: 0.681940; batch adversarial loss: 0.649308\n","epoch 11; iter: 0; batch classifier loss: 0.670241; batch adversarial loss: 0.607980\n","epoch 12; iter: 0; batch classifier loss: 0.691422; batch adversarial loss: 0.607471\n","epoch 13; iter: 0; batch classifier loss: 0.640473; batch adversarial loss: 0.654759\n","epoch 14; iter: 0; batch classifier loss: 0.684780; batch adversarial loss: 0.609355\n","epoch 15; iter: 0; batch classifier loss: 0.681962; batch adversarial loss: 0.647808\n","epoch 16; iter: 0; batch classifier loss: 0.676735; batch adversarial loss: 0.684100\n","epoch 17; iter: 0; batch classifier loss: 0.662118; batch adversarial loss: 0.640343\n","epoch 18; iter: 0; batch classifier loss: 0.637687; batch adversarial loss: 0.649251\n","epoch 19; iter: 0; batch classifier loss: 0.698882; batch adversarial loss: 0.638545\n","epoch 20; iter: 0; batch classifier loss: 0.701213; batch adversarial loss: 0.650601\n","epoch 21; iter: 0; batch classifier loss: 0.641856; batch adversarial loss: 0.629118\n","epoch 22; iter: 0; batch classifier loss: 0.725680; batch adversarial loss: 0.638898\n","epoch 23; iter: 0; batch classifier loss: 0.716083; batch adversarial loss: 0.620789\n","epoch 24; iter: 0; batch classifier loss: 0.712740; batch adversarial loss: 0.641041\n","epoch 25; iter: 0; batch classifier loss: 0.795000; batch adversarial loss: 0.581826\n","epoch 26; iter: 0; batch classifier loss: 0.672920; batch adversarial loss: 0.663052\n","epoch 27; iter: 0; batch classifier loss: 0.669065; batch adversarial loss: 0.669859\n","epoch 28; iter: 0; batch classifier loss: 0.785058; batch adversarial loss: 0.681777\n","epoch 29; iter: 0; batch classifier loss: 0.752980; batch adversarial loss: 0.688229\n","epoch 30; iter: 0; batch classifier loss: 0.825668; batch adversarial loss: 0.678188\n","epoch 31; iter: 0; batch classifier loss: 0.782952; batch adversarial loss: 0.639826\n","epoch 32; iter: 0; batch classifier loss: 0.827364; batch adversarial loss: 0.661013\n","epoch 33; iter: 0; batch classifier loss: 0.858015; batch adversarial loss: 0.635900\n","epoch 34; iter: 0; batch classifier loss: 0.800822; batch adversarial loss: 0.666701\n","epoch 35; iter: 0; batch classifier loss: 0.817404; batch adversarial loss: 0.636487\n","epoch 36; iter: 0; batch classifier loss: 0.863607; batch adversarial loss: 0.684960\n","epoch 37; iter: 0; batch classifier loss: 0.761063; batch adversarial loss: 0.667382\n","epoch 38; iter: 0; batch classifier loss: 0.841256; batch adversarial loss: 0.672358\n","epoch 39; iter: 0; batch classifier loss: 0.794846; batch adversarial loss: 0.687353\n","epoch 40; iter: 0; batch classifier loss: 0.880400; batch adversarial loss: 0.644584\n","epoch 41; iter: 0; batch classifier loss: 0.888737; batch adversarial loss: 0.675509\n","epoch 42; iter: 0; batch classifier loss: 0.929093; batch adversarial loss: 0.695583\n","epoch 43; iter: 0; batch classifier loss: 0.885099; batch adversarial loss: 0.731490\n","epoch 44; iter: 0; batch classifier loss: 0.841393; batch adversarial loss: 0.709908\n","epoch 45; iter: 0; batch classifier loss: 0.865623; batch adversarial loss: 0.690305\n","epoch 46; iter: 0; batch classifier loss: 0.890324; batch adversarial loss: 0.678291\n","epoch 47; iter: 0; batch classifier loss: 0.961426; batch adversarial loss: 0.697971\n","epoch 48; iter: 0; batch classifier loss: 0.888179; batch adversarial loss: 0.698674\n","epoch 49; iter: 0; batch classifier loss: 0.895146; batch adversarial loss: 0.676867\n","Accuracy 0.41304347826086957\n","epoch 0; iter: 0; batch classifier loss: 0.706691; batch adversarial loss: 0.575476\n","epoch 1; iter: 0; batch classifier loss: 0.693860; batch adversarial loss: 0.595544\n","epoch 2; iter: 0; batch classifier loss: 0.681876; batch adversarial loss: 0.586490\n","epoch 3; iter: 0; batch classifier loss: 0.680852; batch adversarial loss: 0.612756\n","epoch 4; iter: 0; batch classifier loss: 0.661646; batch adversarial loss: 0.599283\n","epoch 5; iter: 0; batch classifier loss: 0.637773; batch adversarial loss: 0.587636\n","epoch 6; iter: 0; batch classifier loss: 0.637605; batch adversarial loss: 0.602366\n","epoch 7; iter: 0; batch classifier loss: 0.659668; batch adversarial loss: 0.608763\n","epoch 8; iter: 0; batch classifier loss: 0.641438; batch adversarial loss: 0.640793\n","epoch 9; iter: 0; batch classifier loss: 0.600577; batch adversarial loss: 0.655603\n","epoch 10; iter: 0; batch classifier loss: 0.625062; batch adversarial loss: 0.631156\n","epoch 11; iter: 0; batch classifier loss: 0.603635; batch adversarial loss: 0.651534\n","epoch 12; iter: 0; batch classifier loss: 0.637211; batch adversarial loss: 0.642082\n","epoch 13; iter: 0; batch classifier loss: 0.657080; batch adversarial loss: 0.628477\n","epoch 14; iter: 0; batch classifier loss: 0.592577; batch adversarial loss: 0.630665\n","epoch 15; iter: 0; batch classifier loss: 0.638926; batch adversarial loss: 0.550265\n","epoch 16; iter: 0; batch classifier loss: 0.575806; batch adversarial loss: 0.620563\n","epoch 17; iter: 0; batch classifier loss: 0.591139; batch adversarial loss: 0.609863\n","epoch 18; iter: 0; batch classifier loss: 0.610191; batch adversarial loss: 0.627273\n","epoch 19; iter: 0; batch classifier loss: 0.575541; batch adversarial loss: 0.643798\n","epoch 20; iter: 0; batch classifier loss: 0.586030; batch adversarial loss: 0.616996\n","epoch 21; iter: 0; batch classifier loss: 0.562825; batch adversarial loss: 0.603125\n","epoch 22; iter: 0; batch classifier loss: 0.657682; batch adversarial loss: 0.620934\n","epoch 23; iter: 0; batch classifier loss: 0.631097; batch adversarial loss: 0.660276\n","epoch 24; iter: 0; batch classifier loss: 0.596161; batch adversarial loss: 0.665486\n","epoch 25; iter: 0; batch classifier loss: 0.643773; batch adversarial loss: 0.652864\n","epoch 26; iter: 0; batch classifier loss: 0.721207; batch adversarial loss: 0.638213\n","epoch 27; iter: 0; batch classifier loss: 0.618699; batch adversarial loss: 0.607112\n","epoch 28; iter: 0; batch classifier loss: 0.687699; batch adversarial loss: 0.572943\n","epoch 29; iter: 0; batch classifier loss: 0.614318; batch adversarial loss: 0.673842\n","epoch 30; iter: 0; batch classifier loss: 0.625018; batch adversarial loss: 0.712757\n","epoch 31; iter: 0; batch classifier loss: 0.745854; batch adversarial loss: 0.605666\n","epoch 32; iter: 0; batch classifier loss: 0.596310; batch adversarial loss: 0.646581\n","epoch 33; iter: 0; batch classifier loss: 0.581753; batch adversarial loss: 0.621077\n","epoch 34; iter: 0; batch classifier loss: 0.631598; batch adversarial loss: 0.656320\n","epoch 35; iter: 0; batch classifier loss: 0.673298; batch adversarial loss: 0.663027\n","epoch 36; iter: 0; batch classifier loss: 0.640567; batch adversarial loss: 0.645237\n","epoch 37; iter: 0; batch classifier loss: 0.643566; batch adversarial loss: 0.647356\n","epoch 38; iter: 0; batch classifier loss: 0.715331; batch adversarial loss: 0.598761\n","epoch 39; iter: 0; batch classifier loss: 0.645653; batch adversarial loss: 0.633168\n","epoch 40; iter: 0; batch classifier loss: 0.666358; batch adversarial loss: 0.603301\n","epoch 41; iter: 0; batch classifier loss: 0.571208; batch adversarial loss: 0.615712\n","epoch 42; iter: 0; batch classifier loss: 0.685623; batch adversarial loss: 0.617405\n","epoch 43; iter: 0; batch classifier loss: 0.680848; batch adversarial loss: 0.695065\n","epoch 44; iter: 0; batch classifier loss: 0.655212; batch adversarial loss: 0.610960\n","epoch 45; iter: 0; batch classifier loss: 0.647938; batch adversarial loss: 0.667986\n","epoch 46; iter: 0; batch classifier loss: 0.708891; batch adversarial loss: 0.623937\n","epoch 47; iter: 0; batch classifier loss: 0.681595; batch adversarial loss: 0.631427\n","epoch 48; iter: 0; batch classifier loss: 0.675840; batch adversarial loss: 0.691794\n","epoch 49; iter: 0; batch classifier loss: 0.740010; batch adversarial loss: 0.638452\n","Accuracy 0.5434782608695652\n","epoch 0; iter: 0; batch classifier loss: 0.695642; batch adversarial loss: 0.559998\n","epoch 1; iter: 0; batch classifier loss: 0.688420; batch adversarial loss: 0.550800\n","epoch 2; iter: 0; batch classifier loss: 0.684912; batch adversarial loss: 0.572423\n","epoch 3; iter: 0; batch classifier loss: 0.691835; batch adversarial loss: 0.549778\n","epoch 4; iter: 0; batch classifier loss: 0.685093; batch adversarial loss: 0.577016\n","epoch 5; iter: 0; batch classifier loss: 0.667225; batch adversarial loss: 0.547427\n","epoch 6; iter: 0; batch classifier loss: 0.659872; batch adversarial loss: 0.584013\n","epoch 7; iter: 0; batch classifier loss: 0.641640; batch adversarial loss: 0.579994\n","epoch 8; iter: 0; batch classifier loss: 0.605545; batch adversarial loss: 0.565514\n","epoch 9; iter: 0; batch classifier loss: 0.636680; batch adversarial loss: 0.574681\n","epoch 10; iter: 0; batch classifier loss: 0.635870; batch adversarial loss: 0.592543\n","epoch 11; iter: 0; batch classifier loss: 0.636138; batch adversarial loss: 0.600502\n","epoch 12; iter: 0; batch classifier loss: 0.609004; batch adversarial loss: 0.589573\n","epoch 13; iter: 0; batch classifier loss: 0.593048; batch adversarial loss: 0.610884\n","epoch 14; iter: 0; batch classifier loss: 0.595018; batch adversarial loss: 0.664723\n","epoch 15; iter: 0; batch classifier loss: 0.604035; batch adversarial loss: 0.604707\n","epoch 16; iter: 0; batch classifier loss: 0.583727; batch adversarial loss: 0.575100\n","epoch 17; iter: 0; batch classifier loss: 0.576538; batch adversarial loss: 0.581972\n","epoch 18; iter: 0; batch classifier loss: 0.556222; batch adversarial loss: 0.639219\n","epoch 19; iter: 0; batch classifier loss: 0.637913; batch adversarial loss: 0.617816\n","epoch 20; iter: 0; batch classifier loss: 0.700247; batch adversarial loss: 0.543925\n","epoch 21; iter: 0; batch classifier loss: 0.614909; batch adversarial loss: 0.642060\n","epoch 22; iter: 0; batch classifier loss: 0.671607; batch adversarial loss: 0.579969\n","epoch 23; iter: 0; batch classifier loss: 0.628570; batch adversarial loss: 0.673679\n","epoch 24; iter: 0; batch classifier loss: 0.624928; batch adversarial loss: 0.604995\n","epoch 25; iter: 0; batch classifier loss: 0.663944; batch adversarial loss: 0.692654\n","epoch 26; iter: 0; batch classifier loss: 0.604620; batch adversarial loss: 0.687270\n","epoch 27; iter: 0; batch classifier loss: 0.600592; batch adversarial loss: 0.680917\n","epoch 28; iter: 0; batch classifier loss: 0.658568; batch adversarial loss: 0.614626\n","epoch 29; iter: 0; batch classifier loss: 0.646326; batch adversarial loss: 0.595349\n","epoch 30; iter: 0; batch classifier loss: 0.682925; batch adversarial loss: 0.614222\n","epoch 31; iter: 0; batch classifier loss: 0.696612; batch adversarial loss: 0.638978\n","epoch 32; iter: 0; batch classifier loss: 0.695281; batch adversarial loss: 0.665180\n","epoch 33; iter: 0; batch classifier loss: 0.636904; batch adversarial loss: 0.655176\n","epoch 34; iter: 0; batch classifier loss: 0.670136; batch adversarial loss: 0.663250\n","epoch 35; iter: 0; batch classifier loss: 0.663988; batch adversarial loss: 0.622133\n","epoch 36; iter: 0; batch classifier loss: 0.726611; batch adversarial loss: 0.673353\n","epoch 37; iter: 0; batch classifier loss: 0.753263; batch adversarial loss: 0.695148\n","epoch 38; iter: 0; batch classifier loss: 0.736083; batch adversarial loss: 0.615651\n","epoch 39; iter: 0; batch classifier loss: 0.703956; batch adversarial loss: 0.644482\n","epoch 40; iter: 0; batch classifier loss: 0.760843; batch adversarial loss: 0.657218\n","epoch 41; iter: 0; batch classifier loss: 0.721238; batch adversarial loss: 0.670870\n","epoch 42; iter: 0; batch classifier loss: 0.832051; batch adversarial loss: 0.637725\n","epoch 43; iter: 0; batch classifier loss: 0.784659; batch adversarial loss: 0.631890\n","epoch 44; iter: 0; batch classifier loss: 0.841168; batch adversarial loss: 0.630884\n","epoch 45; iter: 0; batch classifier loss: 0.736739; batch adversarial loss: 0.683079\n","epoch 46; iter: 0; batch classifier loss: 0.884774; batch adversarial loss: 0.628267\n","epoch 47; iter: 0; batch classifier loss: 0.764127; batch adversarial loss: 0.635083\n","epoch 48; iter: 0; batch classifier loss: 0.774979; batch adversarial loss: 0.656084\n","epoch 49; iter: 0; batch classifier loss: 0.872326; batch adversarial loss: 0.694874\n","Accuracy 0.5251798561151079\n","epoch 0; iter: 0; batch classifier loss: 0.709882; batch adversarial loss: 0.560755\n","epoch 1; iter: 0; batch classifier loss: 0.680773; batch adversarial loss: 0.607861\n","epoch 2; iter: 0; batch classifier loss: 0.671255; batch adversarial loss: 0.606297\n","epoch 3; iter: 0; batch classifier loss: 0.664232; batch adversarial loss: 0.630040\n","epoch 4; iter: 0; batch classifier loss: 0.647491; batch adversarial loss: 0.621956\n","epoch 5; iter: 0; batch classifier loss: 0.664670; batch adversarial loss: 0.609447\n","epoch 6; iter: 0; batch classifier loss: 0.625332; batch adversarial loss: 0.597461\n","epoch 7; iter: 0; batch classifier loss: 0.614354; batch adversarial loss: 0.616596\n","epoch 8; iter: 0; batch classifier loss: 0.638836; batch adversarial loss: 0.584113\n","epoch 9; iter: 0; batch classifier loss: 0.631612; batch adversarial loss: 0.607247\n","epoch 10; iter: 0; batch classifier loss: 0.653358; batch adversarial loss: 0.627590\n","epoch 11; iter: 0; batch classifier loss: 0.597679; batch adversarial loss: 0.683251\n","epoch 12; iter: 0; batch classifier loss: 0.607163; batch adversarial loss: 0.616613\n","epoch 13; iter: 0; batch classifier loss: 0.604568; batch adversarial loss: 0.619624\n","epoch 14; iter: 0; batch classifier loss: 0.574962; batch adversarial loss: 0.622412\n","epoch 15; iter: 0; batch classifier loss: 0.606082; batch adversarial loss: 0.635290\n","epoch 16; iter: 0; batch classifier loss: 0.602941; batch adversarial loss: 0.636452\n","epoch 17; iter: 0; batch classifier loss: 0.662369; batch adversarial loss: 0.652164\n","epoch 18; iter: 0; batch classifier loss: 0.575314; batch adversarial loss: 0.666630\n","epoch 19; iter: 0; batch classifier loss: 0.557444; batch adversarial loss: 0.650126\n","epoch 20; iter: 0; batch classifier loss: 0.591669; batch adversarial loss: 0.661474\n","epoch 21; iter: 0; batch classifier loss: 0.550840; batch adversarial loss: 0.629154\n","epoch 22; iter: 0; batch classifier loss: 0.554901; batch adversarial loss: 0.675552\n","epoch 23; iter: 0; batch classifier loss: 0.574054; batch adversarial loss: 0.647581\n","epoch 24; iter: 0; batch classifier loss: 0.633874; batch adversarial loss: 0.664929\n","epoch 25; iter: 0; batch classifier loss: 0.571634; batch adversarial loss: 0.677820\n","epoch 26; iter: 0; batch classifier loss: 0.560131; batch adversarial loss: 0.644044\n","epoch 27; iter: 0; batch classifier loss: 0.643310; batch adversarial loss: 0.704214\n","epoch 28; iter: 0; batch classifier loss: 0.583957; batch adversarial loss: 0.679855\n","epoch 29; iter: 0; batch classifier loss: 0.654136; batch adversarial loss: 0.678794\n","epoch 30; iter: 0; batch classifier loss: 0.636841; batch adversarial loss: 0.684002\n","epoch 31; iter: 0; batch classifier loss: 0.600028; batch adversarial loss: 0.664235\n","epoch 32; iter: 0; batch classifier loss: 0.641633; batch adversarial loss: 0.711566\n","epoch 33; iter: 0; batch classifier loss: 0.635320; batch adversarial loss: 0.691576\n","epoch 34; iter: 0; batch classifier loss: 0.667200; batch adversarial loss: 0.651596\n","epoch 35; iter: 0; batch classifier loss: 0.696038; batch adversarial loss: 0.642718\n","epoch 36; iter: 0; batch classifier loss: 0.650702; batch adversarial loss: 0.711308\n","epoch 37; iter: 0; batch classifier loss: 0.589861; batch adversarial loss: 0.657164\n","epoch 38; iter: 0; batch classifier loss: 0.691408; batch adversarial loss: 0.675545\n","epoch 39; iter: 0; batch classifier loss: 0.698741; batch adversarial loss: 0.691104\n","epoch 40; iter: 0; batch classifier loss: 0.604060; batch adversarial loss: 0.651089\n","epoch 41; iter: 0; batch classifier loss: 0.708751; batch adversarial loss: 0.665226\n","epoch 42; iter: 0; batch classifier loss: 0.675570; batch adversarial loss: 0.660767\n","epoch 43; iter: 0; batch classifier loss: 0.665429; batch adversarial loss: 0.658319\n","epoch 44; iter: 0; batch classifier loss: 0.602903; batch adversarial loss: 0.617217\n","epoch 45; iter: 0; batch classifier loss: 0.697299; batch adversarial loss: 0.662557\n","epoch 46; iter: 0; batch classifier loss: 0.647182; batch adversarial loss: 0.625472\n","epoch 47; iter: 0; batch classifier loss: 0.724488; batch adversarial loss: 0.676598\n","epoch 48; iter: 0; batch classifier loss: 0.700317; batch adversarial loss: 0.675605\n","epoch 49; iter: 0; batch classifier loss: 0.753786; batch adversarial loss: 0.658096\n","Accuracy 0.6330935251798561\n","epoch 0; iter: 0; batch classifier loss: 0.719086; batch adversarial loss: 0.657149\n","epoch 1; iter: 0; batch classifier loss: 0.674671; batch adversarial loss: 0.646448\n","epoch 2; iter: 0; batch classifier loss: 0.647402; batch adversarial loss: 0.641146\n","epoch 3; iter: 0; batch classifier loss: 0.647742; batch adversarial loss: 0.652204\n","epoch 4; iter: 0; batch classifier loss: 0.647433; batch adversarial loss: 0.625287\n","epoch 5; iter: 0; batch classifier loss: 0.639323; batch adversarial loss: 0.641626\n","epoch 6; iter: 0; batch classifier loss: 0.613987; batch adversarial loss: 0.652182\n","epoch 7; iter: 0; batch classifier loss: 0.618685; batch adversarial loss: 0.634035\n","epoch 8; iter: 0; batch classifier loss: 0.613652; batch adversarial loss: 0.638309\n","epoch 9; iter: 0; batch classifier loss: 0.621119; batch adversarial loss: 0.644715\n","epoch 10; iter: 0; batch classifier loss: 0.648801; batch adversarial loss: 0.617008\n","epoch 11; iter: 0; batch classifier loss: 0.588875; batch adversarial loss: 0.629112\n","epoch 12; iter: 0; batch classifier loss: 0.613121; batch adversarial loss: 0.625747\n","epoch 13; iter: 0; batch classifier loss: 0.565888; batch adversarial loss: 0.634731\n","epoch 14; iter: 0; batch classifier loss: 0.595693; batch adversarial loss: 0.634802\n","epoch 15; iter: 0; batch classifier loss: 0.573826; batch adversarial loss: 0.637289\n","epoch 16; iter: 0; batch classifier loss: 0.589457; batch adversarial loss: 0.657091\n","epoch 17; iter: 0; batch classifier loss: 0.577839; batch adversarial loss: 0.641436\n","epoch 18; iter: 0; batch classifier loss: 0.544583; batch adversarial loss: 0.627341\n","epoch 19; iter: 0; batch classifier loss: 0.574210; batch adversarial loss: 0.620388\n","epoch 20; iter: 0; batch classifier loss: 0.599166; batch adversarial loss: 0.634584\n","epoch 21; iter: 0; batch classifier loss: 0.558925; batch adversarial loss: 0.636720\n","epoch 22; iter: 0; batch classifier loss: 0.593740; batch adversarial loss: 0.626757\n","epoch 23; iter: 0; batch classifier loss: 0.579211; batch adversarial loss: 0.607507\n","epoch 24; iter: 0; batch classifier loss: 0.624586; batch adversarial loss: 0.592518\n","epoch 25; iter: 0; batch classifier loss: 0.560769; batch adversarial loss: 0.635234\n","epoch 26; iter: 0; batch classifier loss: 0.607949; batch adversarial loss: 0.642491\n","epoch 27; iter: 0; batch classifier loss: 0.568480; batch adversarial loss: 0.599729\n","epoch 28; iter: 0; batch classifier loss: 0.616940; batch adversarial loss: 0.637328\n","epoch 29; iter: 0; batch classifier loss: 0.569671; batch adversarial loss: 0.628479\n","epoch 30; iter: 0; batch classifier loss: 0.547088; batch adversarial loss: 0.624047\n","epoch 31; iter: 0; batch classifier loss: 0.577088; batch adversarial loss: 0.630033\n","epoch 32; iter: 0; batch classifier loss: 0.576129; batch adversarial loss: 0.627220\n","epoch 33; iter: 0; batch classifier loss: 0.593393; batch adversarial loss: 0.642556\n","epoch 34; iter: 0; batch classifier loss: 0.583118; batch adversarial loss: 0.597862\n","epoch 35; iter: 0; batch classifier loss: 0.622708; batch adversarial loss: 0.613876\n","epoch 36; iter: 0; batch classifier loss: 0.585123; batch adversarial loss: 0.637451\n","epoch 37; iter: 0; batch classifier loss: 0.579435; batch adversarial loss: 0.635516\n","epoch 38; iter: 0; batch classifier loss: 0.636018; batch adversarial loss: 0.642065\n","epoch 39; iter: 0; batch classifier loss: 0.511516; batch adversarial loss: 0.619945\n","epoch 40; iter: 0; batch classifier loss: 0.526118; batch adversarial loss: 0.610042\n","epoch 41; iter: 0; batch classifier loss: 0.600352; batch adversarial loss: 0.612295\n","epoch 42; iter: 0; batch classifier loss: 0.596732; batch adversarial loss: 0.606917\n","epoch 43; iter: 0; batch classifier loss: 0.650669; batch adversarial loss: 0.643916\n","epoch 44; iter: 0; batch classifier loss: 0.578387; batch adversarial loss: 0.631912\n","epoch 45; iter: 0; batch classifier loss: 0.579774; batch adversarial loss: 0.604155\n","epoch 46; iter: 0; batch classifier loss: 0.554482; batch adversarial loss: 0.614185\n","epoch 47; iter: 0; batch classifier loss: 0.599891; batch adversarial loss: 0.624780\n","epoch 48; iter: 0; batch classifier loss: 0.594970; batch adversarial loss: 0.604976\n","epoch 49; iter: 0; batch classifier loss: 0.553256; batch adversarial loss: 0.615799\n","Accuracy 0.5434782608695652\n","epoch 0; iter: 0; batch classifier loss: 0.698065; batch adversarial loss: 0.642562\n","epoch 1; iter: 0; batch classifier loss: 0.691547; batch adversarial loss: 0.645874\n","epoch 2; iter: 0; batch classifier loss: 0.678922; batch adversarial loss: 0.633481\n","epoch 3; iter: 0; batch classifier loss: 0.669904; batch adversarial loss: 0.645378\n","epoch 4; iter: 0; batch classifier loss: 0.690249; batch adversarial loss: 0.625749\n","epoch 5; iter: 0; batch classifier loss: 0.662709; batch adversarial loss: 0.645404\n","epoch 6; iter: 0; batch classifier loss: 0.643221; batch adversarial loss: 0.636496\n","epoch 7; iter: 0; batch classifier loss: 0.633021; batch adversarial loss: 0.624068\n","epoch 8; iter: 0; batch classifier loss: 0.625622; batch adversarial loss: 0.655689\n","epoch 9; iter: 0; batch classifier loss: 0.618833; batch adversarial loss: 0.620666\n","epoch 10; iter: 0; batch classifier loss: 0.678360; batch adversarial loss: 0.608515\n","epoch 11; iter: 0; batch classifier loss: 0.628517; batch adversarial loss: 0.643950\n","epoch 12; iter: 0; batch classifier loss: 0.593766; batch adversarial loss: 0.659088\n","epoch 13; iter: 0; batch classifier loss: 0.617437; batch adversarial loss: 0.612463\n","epoch 14; iter: 0; batch classifier loss: 0.658199; batch adversarial loss: 0.641567\n","epoch 15; iter: 0; batch classifier loss: 0.629255; batch adversarial loss: 0.654150\n","epoch 16; iter: 0; batch classifier loss: 0.594640; batch adversarial loss: 0.668051\n","epoch 17; iter: 0; batch classifier loss: 0.607425; batch adversarial loss: 0.644682\n","epoch 18; iter: 0; batch classifier loss: 0.567789; batch adversarial loss: 0.644920\n","epoch 19; iter: 0; batch classifier loss: 0.616714; batch adversarial loss: 0.645052\n","epoch 20; iter: 0; batch classifier loss: 0.650977; batch adversarial loss: 0.623354\n","epoch 21; iter: 0; batch classifier loss: 0.601579; batch adversarial loss: 0.637799\n","epoch 22; iter: 0; batch classifier loss: 0.598790; batch adversarial loss: 0.659662\n","epoch 23; iter: 0; batch classifier loss: 0.636762; batch adversarial loss: 0.622360\n","epoch 24; iter: 0; batch classifier loss: 0.674066; batch adversarial loss: 0.642830\n","epoch 25; iter: 0; batch classifier loss: 0.676290; batch adversarial loss: 0.631472\n","epoch 26; iter: 0; batch classifier loss: 0.602861; batch adversarial loss: 0.624272\n","epoch 27; iter: 0; batch classifier loss: 0.642473; batch adversarial loss: 0.632633\n","epoch 28; iter: 0; batch classifier loss: 0.631542; batch adversarial loss: 0.644284\n","epoch 29; iter: 0; batch classifier loss: 0.643928; batch adversarial loss: 0.641109\n","epoch 30; iter: 0; batch classifier loss: 0.678116; batch adversarial loss: 0.648743\n","epoch 31; iter: 0; batch classifier loss: 0.659267; batch adversarial loss: 0.630934\n","epoch 32; iter: 0; batch classifier loss: 0.660290; batch adversarial loss: 0.679539\n","epoch 33; iter: 0; batch classifier loss: 0.649025; batch adversarial loss: 0.615302\n","epoch 34; iter: 0; batch classifier loss: 0.705328; batch adversarial loss: 0.675600\n","epoch 35; iter: 0; batch classifier loss: 0.669417; batch adversarial loss: 0.646759\n","epoch 36; iter: 0; batch classifier loss: 0.655407; batch adversarial loss: 0.646310\n","epoch 37; iter: 0; batch classifier loss: 0.681029; batch adversarial loss: 0.664999\n","epoch 38; iter: 0; batch classifier loss: 0.650571; batch adversarial loss: 0.643422\n","epoch 39; iter: 0; batch classifier loss: 0.665388; batch adversarial loss: 0.652788\n","epoch 40; iter: 0; batch classifier loss: 0.750022; batch adversarial loss: 0.607067\n","epoch 41; iter: 0; batch classifier loss: 0.705269; batch adversarial loss: 0.613775\n","epoch 42; iter: 0; batch classifier loss: 0.686547; batch adversarial loss: 0.635516\n","epoch 43; iter: 0; batch classifier loss: 0.667099; batch adversarial loss: 0.628198\n","epoch 44; iter: 0; batch classifier loss: 0.624149; batch adversarial loss: 0.619063\n","epoch 45; iter: 0; batch classifier loss: 0.680342; batch adversarial loss: 0.667934\n","epoch 46; iter: 0; batch classifier loss: 0.682176; batch adversarial loss: 0.622812\n","epoch 47; iter: 0; batch classifier loss: 0.736376; batch adversarial loss: 0.587996\n","epoch 48; iter: 0; batch classifier loss: 0.694782; batch adversarial loss: 0.616387\n","epoch 49; iter: 0; batch classifier loss: 0.610751; batch adversarial loss: 0.642251\n","Accuracy 0.4927536231884058\n","epoch 0; iter: 0; batch classifier loss: 0.722182; batch adversarial loss: 0.608456\n","epoch 1; iter: 0; batch classifier loss: 0.685552; batch adversarial loss: 0.636508\n","epoch 2; iter: 0; batch classifier loss: 0.702870; batch adversarial loss: 0.594413\n","epoch 3; iter: 0; batch classifier loss: 0.675862; batch adversarial loss: 0.652049\n","epoch 4; iter: 0; batch classifier loss: 0.675222; batch adversarial loss: 0.603317\n","epoch 5; iter: 0; batch classifier loss: 0.665035; batch adversarial loss: 0.610972\n","epoch 6; iter: 0; batch classifier loss: 0.674745; batch adversarial loss: 0.629848\n","epoch 7; iter: 0; batch classifier loss: 0.662228; batch adversarial loss: 0.642761\n","epoch 8; iter: 0; batch classifier loss: 0.659555; batch adversarial loss: 0.655699\n","epoch 9; iter: 0; batch classifier loss: 0.617800; batch adversarial loss: 0.602326\n","epoch 10; iter: 0; batch classifier loss: 0.633123; batch adversarial loss: 0.608423\n","epoch 11; iter: 0; batch classifier loss: 0.652850; batch adversarial loss: 0.595238\n","epoch 12; iter: 0; batch classifier loss: 0.648553; batch adversarial loss: 0.679232\n","epoch 13; iter: 0; batch classifier loss: 0.677846; batch adversarial loss: 0.661237\n","epoch 14; iter: 0; batch classifier loss: 0.640924; batch adversarial loss: 0.640827\n","epoch 15; iter: 0; batch classifier loss: 0.666122; batch adversarial loss: 0.654744\n","epoch 16; iter: 0; batch classifier loss: 0.668334; batch adversarial loss: 0.673661\n","epoch 17; iter: 0; batch classifier loss: 0.709454; batch adversarial loss: 0.702878\n","epoch 18; iter: 0; batch classifier loss: 0.655756; batch adversarial loss: 0.631026\n","epoch 19; iter: 0; batch classifier loss: 0.636512; batch adversarial loss: 0.695396\n","epoch 20; iter: 0; batch classifier loss: 0.735503; batch adversarial loss: 0.686532\n","epoch 21; iter: 0; batch classifier loss: 0.636626; batch adversarial loss: 0.630405\n","epoch 22; iter: 0; batch classifier loss: 0.623590; batch adversarial loss: 0.644837\n","epoch 23; iter: 0; batch classifier loss: 0.631649; batch adversarial loss: 0.626673\n","epoch 24; iter: 0; batch classifier loss: 0.647869; batch adversarial loss: 0.623280\n","epoch 25; iter: 0; batch classifier loss: 0.720823; batch adversarial loss: 0.682962\n","epoch 26; iter: 0; batch classifier loss: 0.776120; batch adversarial loss: 0.638393\n","epoch 27; iter: 0; batch classifier loss: 0.753250; batch adversarial loss: 0.696728\n","epoch 28; iter: 0; batch classifier loss: 0.675350; batch adversarial loss: 0.673975\n","epoch 29; iter: 0; batch classifier loss: 0.699947; batch adversarial loss: 0.616827\n","epoch 30; iter: 0; batch classifier loss: 0.697159; batch adversarial loss: 0.613951\n","epoch 31; iter: 0; batch classifier loss: 0.787057; batch adversarial loss: 0.689875\n","epoch 32; iter: 0; batch classifier loss: 0.731967; batch adversarial loss: 0.659000\n","epoch 33; iter: 0; batch classifier loss: 0.696596; batch adversarial loss: 0.616156\n","epoch 34; iter: 0; batch classifier loss: 0.743219; batch adversarial loss: 0.726467\n","epoch 35; iter: 0; batch classifier loss: 0.786520; batch adversarial loss: 0.695139\n","epoch 36; iter: 0; batch classifier loss: 0.764877; batch adversarial loss: 0.654436\n","epoch 37; iter: 0; batch classifier loss: 0.718223; batch adversarial loss: 0.647410\n","epoch 38; iter: 0; batch classifier loss: 0.790720; batch adversarial loss: 0.657075\n","epoch 39; iter: 0; batch classifier loss: 0.743035; batch adversarial loss: 0.647989\n","epoch 40; iter: 0; batch classifier loss: 0.726876; batch adversarial loss: 0.732900\n","epoch 41; iter: 0; batch classifier loss: 0.853347; batch adversarial loss: 0.688339\n","epoch 42; iter: 0; batch classifier loss: 0.848720; batch adversarial loss: 0.670848\n","epoch 43; iter: 0; batch classifier loss: 0.781768; batch adversarial loss: 0.681172\n","epoch 44; iter: 0; batch classifier loss: 0.765103; batch adversarial loss: 0.640379\n","epoch 45; iter: 0; batch classifier loss: 0.818741; batch adversarial loss: 0.668027\n","epoch 46; iter: 0; batch classifier loss: 0.802823; batch adversarial loss: 0.627725\n","epoch 47; iter: 0; batch classifier loss: 0.848868; batch adversarial loss: 0.639442\n","epoch 48; iter: 0; batch classifier loss: 0.814132; batch adversarial loss: 0.671062\n","epoch 49; iter: 0; batch classifier loss: 0.744082; batch adversarial loss: 0.669774\n","Accuracy 0.45652173913043476\n"],"name":"stdout"}]}]}