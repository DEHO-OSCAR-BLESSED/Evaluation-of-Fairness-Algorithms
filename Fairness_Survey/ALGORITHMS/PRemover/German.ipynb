{"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13896,"status":"ok","timestamp":1629699077246,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"q5qYRG8zufHw","outputId":"462ddd99-0137-4479-97fe-65e6de6db48d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting aif360\n","  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 30.9 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n","Requirement already satisfied: numpy\u003e=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n","Requirement already satisfied: pandas\u003e=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n","Requirement already satisfied: scikit-learn\u003e=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n","Collecting tempeh\n","  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n","Requirement already satisfied: scipy\u003c1.6.0,\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.24.0-\u003eaif360) (2018.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.24.0-\u003eaif360) (2.8.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas\u003e=0.24.0-\u003eaif360) (1.15.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.1-\u003eaif360) (1.0.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eaif360) (0.10.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eaif360) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eaif360) (2.4.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh-\u003eaif360) (2.23.0)\n","Collecting memory-profiler\n","  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 40.7 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh-\u003eaif360) (3.6.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler-\u003etempeh-\u003eaif360) (5.4.8)\n","Requirement already satisfied: more-itertools\u003e=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (8.8.0)\n","Requirement already satisfied: atomicwrites\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (1.4.0)\n","Requirement already satisfied: pluggy\u003c0.8,\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (0.7.1)\n","Requirement already satisfied: attrs\u003e=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (21.2.0)\n","Requirement already satisfied: py\u003e=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (1.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (57.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (2021.5.30)\n","Requirement already satisfied: tqdm\u003e4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap-\u003etempeh-\u003eaif360) (4.62.0)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap-\u003etempeh-\u003eaif360) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap-\u003etempeh-\u003eaif360) (1.3.0)\n","Requirement already satisfied: llvmlite\u003c0.35,\u003e=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba-\u003eshap-\u003etempeh-\u003eaif360) (0.34.0)\n","Building wheels for collected packages: memory-profiler, shap\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=713d09d7f6e005cc2a27d18a6156abe66c2c08917001f4357ced97e3578c80bb\n","  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491646 sha256=5555d2bca2d412785dd965829ba0a8dbb704afd881af5da890afb6fbd88aca78\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built memory-profiler shap\n","Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n","Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n","Collecting fairlearn\n","  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 31.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n","Requirement already satisfied: scikit-learn\u003e=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n","Requirement already satisfied: pandas\u003e=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.25.1-\u003efairlearn) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.25.1-\u003efairlearn) (2018.9)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas\u003e=0.25.1-\u003efairlearn) (1.15.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.1-\u003efairlearn) (1.0.1)\n","Installing collected packages: fairlearn\n","Successfully installed fairlearn-0.7.0\n"]}],"source":["!pip install aif360\n","!pip install fairlearn"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3214,"status":"ok","timestamp":1629699080373,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"_NQn2JJ0uw6u","outputId":"01cbf43c-3b12-4cf7-a696-58e77cdcbc7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n","\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 40 kB 36.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71 kB 36.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 81 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 92 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 112 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 122 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 133 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 143 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 148 kB 34.4 MB/s \n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.0.1\n"]}],"source":["!pip install xlsxwriter"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5055,"status":"ok","timestamp":1629699085391,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"a0YklbHpAxd8","outputId":"e0b48396-8971-4062-d3c2-c2683619bfc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting BlackBoxAuditing\n","  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 23.1 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler\u003e=0.10-\u003ematplotlib-\u003eBlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eBlackBoxAuditing) (2018.9)\n","Building wheels for collected packages: BlackBoxAuditing\n","  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394771 sha256=42de109249d150506f616c28763ec659e75fb1906443e41a7540fc8ff155f7fc\n","  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n","Successfully built BlackBoxAuditing\n","Installing collected packages: BlackBoxAuditing\n","Successfully installed BlackBoxAuditing-0.1.54\n"]}],"source":["!pip install BlackBoxAuditing"]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10217,"status":"ok","timestamp":1629699095565,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"rf1aISz6vGfR","outputId":"35ccda5e-1c93-4433-b5fe-cb9d74f93804"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39816,"status":"ok","timestamp":1629699135277,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"FEGPULDrvk3g","outputId":"086176d7-ba5c-4a73-c9a0-5367e1722308"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# PR REMOVER 1\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280883,"status":"ok","timestamp":1629699416105,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"uN9VfZBAvxCj","outputId":"6d75b32b-d8b2-4e81-ecd3-b29b79ae9f94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.78\n","Accuracy 0.68\n","Accuracy 0.755\n","Accuracy 0.7\n","Accuracy 0.725\n","Accuracy 0.77\n","Accuracy 0.75\n","Accuracy 0.755\n","Accuracy 0.725\n","Accuracy 0.7\n","Accuracy 0.735\n","Accuracy 0.74\n","Accuracy 0.73\n","Accuracy 0.745\n","Accuracy 0.755\n","Accuracy 0.755\n","Accuracy 0.73\n","Accuracy 0.74\n","Accuracy 0.7\n","Accuracy 0.73\n","Accuracy 0.69\n","Accuracy 0.75\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.715\n","Accuracy 0.735\n","Accuracy 0.72\n","Accuracy 0.745\n","Accuracy 0.785\n","Accuracy 0.73\n","Accuracy 0.735\n","Accuracy 0.735\n","Accuracy 0.7\n","Accuracy 0.755\n","Accuracy 0.71\n","Accuracy 0.755\n","Accuracy 0.745\n","Accuracy 0.75\n","Accuracy 0.675\n","Accuracy 0.775\n","Accuracy 0.755\n","Accuracy 0.69\n","Accuracy 0.665\n","Accuracy 0.765\n","Accuracy 0.705\n","Accuracy 0.725\n","Accuracy 0.73\n","Accuracy 0.74\n","Accuracy 0.755\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('default')\n","  train.insert(0, 'default', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('default')\n","  test.insert(0, 'default', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 1, sensitive_attr= 'age')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['default']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover1.xlsx')\n","  German= excelBook['German']\n","  data= German.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover1.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='German', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"4H3vvxWBboi5"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"reSfNpjhFH8r"},"source":["# PR REMOVER 25\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253150,"status":"ok","timestamp":1629699669249,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"dtplOkDrFH8r","outputId":"149b80ef-25bc-482d-ca36-3a52a6239374"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.77\n","Accuracy 0.68\n","Accuracy 0.76\n","Accuracy 0.7\n","Accuracy 0.725\n","Accuracy 0.755\n","Accuracy 0.75\n","Accuracy 0.755\n","Accuracy 0.725\n","Accuracy 0.7\n","Accuracy 0.735\n","Accuracy 0.745\n","Accuracy 0.725\n","Accuracy 0.745\n","Accuracy 0.755\n","Accuracy 0.755\n","Accuracy 0.72\n","Accuracy 0.74\n","Accuracy 0.7\n","Accuracy 0.73\n","Accuracy 0.69\n","Accuracy 0.755\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.715\n","Accuracy 0.735\n","Accuracy 0.72\n","Accuracy 0.745\n","Accuracy 0.785\n","Accuracy 0.73\n","Accuracy 0.735\n","Accuracy 0.755\n","Accuracy 0.715\n","Accuracy 0.755\n","Accuracy 0.71\n","Accuracy 0.755\n","Accuracy 0.745\n","Accuracy 0.75\n","Accuracy 0.685\n","Accuracy 0.775\n","Accuracy 0.755\n","Accuracy 0.685\n","Accuracy 0.665\n","Accuracy 0.765\n","Accuracy 0.705\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.74\n","Accuracy 0.755\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('default')\n","  train.insert(0, 'default', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('default')\n","  test.insert(0, 'default', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 25, sensitive_attr= 'age')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['default']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover25.xlsx')\n","  German= excelBook['German']\n","  data= German.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover25.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='German', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"2zGRNHEQFIPE"},"source":["# PR REMOVER 50\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KOUNqFT4FIPG"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.77\n","Accuracy 0.68\n","Accuracy 0.76\n","Accuracy 0.7\n","Accuracy 0.725\n","Accuracy 0.755\n","Accuracy 0.75\n","Accuracy 0.755\n","Accuracy 0.725\n","Accuracy 0.7\n","Accuracy 0.735\n","Accuracy 0.745\n","Accuracy 0.725\n","Accuracy 0.745\n","Accuracy 0.755\n","Accuracy 0.755\n","Accuracy 0.73\n","Accuracy 0.74\n","Accuracy 0.7\n","Accuracy 0.73\n","Accuracy 0.69\n","Accuracy 0.755\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.715\n","Accuracy 0.735\n","Accuracy 0.72\n","Accuracy 0.745\n","Accuracy 0.785\n","Accuracy 0.73\n","Accuracy 0.735\n","Accuracy 0.755\n","Accuracy 0.715\n","Accuracy 0.755\n","Accuracy 0.71\n","Accuracy 0.755\n","Accuracy 0.74\n","Accuracy 0.75\n","Accuracy 0.675\n","Accuracy 0.775\n","Accuracy 0.755\n","Accuracy 0.69\n","Accuracy 0.665\n","Accuracy 0.765\n","Accuracy 0.705\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.74\n","Accuracy 0.755\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('default')\n","  train.insert(0, 'default', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('default')\n","  test.insert(0, 'default', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 50, sensitive_attr= 'age')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['default']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover50.xlsx')\n","  German= excelBook['German']\n","  data= German.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover50.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='German', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"SglOigoJKEiy"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vP-IlZfPKFU6"},"source":["# PR REMOVER 75\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N4pHADeEKFU7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.77\n","Accuracy 0.68\n","Accuracy 0.76\n","Accuracy 0.7\n","Accuracy 0.725\n","Accuracy 0.775\n","Accuracy 0.75\n","Accuracy 0.755\n","Accuracy 0.725\n","Accuracy 0.7\n","Accuracy 0.735\n","Accuracy 0.745\n","Accuracy 0.725\n","Accuracy 0.745\n","Accuracy 0.755\n","Accuracy 0.755\n","Accuracy 0.72\n","Accuracy 0.74\n","Accuracy 0.7\n","Accuracy 0.73\n","Accuracy 0.69\n","Accuracy 0.755\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.715\n","Accuracy 0.735\n","Accuracy 0.72\n","Accuracy 0.745\n","Accuracy 0.775\n","Accuracy 0.73\n","Accuracy 0.735\n","Accuracy 0.75\n","Accuracy 0.715\n","Accuracy 0.755\n","Accuracy 0.71\n","Accuracy 0.755\n","Accuracy 0.74\n","Accuracy 0.75\n","Accuracy 0.675\n","Accuracy 0.775\n","Accuracy 0.755\n","Accuracy 0.69\n","Accuracy 0.665\n","Accuracy 0.765\n","Accuracy 0.705\n","Accuracy 0.73\n","Accuracy 0.73\n","Accuracy 0.74\n","Accuracy 0.755\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('default')\n","  train.insert(0, 'default', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('default')\n","  test.insert(0, 'default', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 75, sensitive_attr= 'age')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['default']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover75.xlsx')\n","  German= excelBook['German']\n","  data= German.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover75.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='German', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"NDxf1UeRVgOp"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"eNlkgkHyKHkO"},"source":["# PR REMOVER 100\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25xsmsZAKHkS"},"outputs":[],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('default')\n","  train.insert(0, 'default', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/German/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('default')\n","  test.insert(0, 'default', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 100, sensitive_attr= 'age')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['default']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'age':1}]\n","  disadvantagedGroup= [{'age':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'default',\n","                  favorable_classes= [1],protected_attribute_names=['age'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['age'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover100.xlsx')\n","  German= excelBook['German']\n","  data= German.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover100.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='German', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNv9Tyl6d0KY1WKWj6xpMGO","name":"German.ipynb","provenance":[{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}