{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dropout.ipynb","provenance":[{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"authorship_tag":"ABX9TyOQbb+EOX1R57zB1Xp0BVyt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5qYRG8zufHw","executionInfo":{"status":"ok","timestamp":1629641353743,"user_tz":-570,"elapsed":6204,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"17033607-92ab-4e64-a7ac-9e1d16b7fda4"},"source":["!pip install aif360\n","!pip install fairlearn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: aif360 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n","Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n","Requirement already satisfied: tempeh in /usr/local/lib/python3.7/dist-packages (from aif360) (0.1.12)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.3.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (2.23.0)\n","Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (0.39.0)\n","Requirement already satisfied: memory-profiler in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (0.58.0)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360) (3.6.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360) (5.4.8)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (57.4.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (21.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (8.8.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360) (1.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360) (2.10)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (4.62.0)\n","Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.0.7)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (1.3.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360) (0.51.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360) (0.34.0)\n","Requirement already satisfied: fairlearn in /usr/local/lib/python3.7/dist-packages (0.7.0)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n","Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TltW3iPkux0Q","executionInfo":{"status":"ok","timestamp":1629641353746,"user_tz":-570,"elapsed":33,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"cdde70d8-c5e9-4f00-dab5-d84c8301b87d"},"source":["!apt-get install -jre\n","!java -version"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: Command line option 'j' [from -jre] is not understood in combination with the other options.\n","openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KssrNl8GvDYU","executionInfo":{"status":"ok","timestamp":1629641356869,"user_tz":-570,"elapsed":3133,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"5e36d402-c747-4627-aaf2-2ab717e99b19"},"source":["!pip install h2o"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h2o in /usr/local/lib/python3.7/dist-packages (3.32.1.6)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n","Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.7/dist-packages (from h2o) (0.4.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NQn2JJ0uw6u","executionInfo":{"status":"ok","timestamp":1629641359918,"user_tz":-570,"elapsed":3057,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"0264a223-87fd-48cf-b4da-b111af21582c"},"source":["!pip install xlsxwriter"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0YklbHpAxd8","executionInfo":{"status":"ok","timestamp":1629641362889,"user_tz":-570,"elapsed":3005,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"856fbbae-8005-4b5c-e8e5-c7b1629293b7"},"source":["!pip install BlackBoxAuditing"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: BlackBoxAuditing in /usr/local/lib/python3.7/dist-packages (0.1.54)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->BlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rf1aISz6vGfR","executionInfo":{"status":"ok","timestamp":1629641367002,"user_tz":-570,"elapsed":4141,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"96de1542-2f61-4511-a8a5-3c8a4cb603e1"},"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","import h2o\n","from h2o.automl import H2OAutoML\n","from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"RcxQeeX7vUXz","executionInfo":{"status":"ok","timestamp":1629641373876,"user_tz":-570,"elapsed":6893,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"26b9a779-c3eb-4cbb-e0e3-5efdf5d64b01"},"source":["h2o.init()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n","Attempting to start a local H2O server...\n","  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n","  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n","  Ice root: /tmp/tmp5plbzhsw\n","  JVM stdout: /tmp/tmp5plbzhsw/h2o_unknownUser_started_from_python.out\n","  JVM stderr: /tmp/tmp5plbzhsw/h2o_unknownUser_started_from_python.err\n","  Server is running at http://127.0.0.1:54321\n","Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n","<td>02 secs</td></tr>\n","<tr><td>H2O_cluster_timezone:</td>\n","<td>Etc/UTC</td></tr>\n","<tr><td>H2O_data_parsing_timezone:</td>\n","<td>UTC</td></tr>\n","<tr><td>H2O_cluster_version:</td>\n","<td>3.32.1.6</td></tr>\n","<tr><td>H2O_cluster_version_age:</td>\n","<td>2 days </td></tr>\n","<tr><td>H2O_cluster_name:</td>\n","<td>H2O_from_python_unknownUser_el47h8</td></tr>\n","<tr><td>H2O_cluster_total_nodes:</td>\n","<td>1</td></tr>\n","<tr><td>H2O_cluster_free_memory:</td>\n","<td>3.172 Gb</td></tr>\n","<tr><td>H2O_cluster_total_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_allowed_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_status:</td>\n","<td>accepting new members, healthy</td></tr>\n","<tr><td>H2O_connection_url:</td>\n","<td>http://127.0.0.1:54321</td></tr>\n","<tr><td>H2O_connection_proxy:</td>\n","<td>{\"http\": null, \"https\": null}</td></tr>\n","<tr><td>H2O_internal_security:</td>\n","<td>False</td></tr>\n","<tr><td>H2O_API_Extensions:</td>\n","<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n","<tr><td>Python_version:</td>\n","<td>3.7.11 final</td></tr></table></div>"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O_cluster_uptime:         02 secs\n","H2O_cluster_timezone:       Etc/UTC\n","H2O_data_parsing_timezone:  UTC\n","H2O_cluster_version:        3.32.1.6\n","H2O_cluster_version_age:    2 days\n","H2O_cluster_name:           H2O_from_python_unknownUser_el47h8\n","H2O_cluster_total_nodes:    1\n","H2O_cluster_free_memory:    3.172 Gb\n","H2O_cluster_total_cores:    2\n","H2O_cluster_allowed_cores:  2\n","H2O_cluster_status:         accepting new members, healthy\n","H2O_connection_url:         http://127.0.0.1:54321\n","H2O_connection_proxy:       {\"http\": null, \"https\": null}\n","H2O_internal_security:      False\n","H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python_version:             3.7.11 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEGPULDrvk3g","executionInfo":{"status":"ok","timestamp":1629644055210,"user_tz":-570,"elapsed":1406,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"8025ebaa-ee97-4ae4-ef59-323c9b2b9be4"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# PR REMOVER 1\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uN9VfZBAvxCj","executionInfo":{"status":"ok","timestamp":1629637795591,"user_tz":-570,"elapsed":224551,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"6316d035-7578-4c5a-bde3-5b86af3c3959"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 1, sensitive_attr= 'HOME_LANGUAGE')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover1.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover1.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Accuracy 0.7122302158273381\n","Accuracy 0.7338129496402878\n","Accuracy 0.6811594202898551\n","Accuracy 0.7536231884057971\n","Accuracy 0.7608695652173914\n","Accuracy 0.7194244604316546\n","Accuracy 0.7266187050359713\n","Accuracy 0.7391304347826086\n","Accuracy 0.782608695652174\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7246376811594203\n","Accuracy 0.6956521739130435\n","Accuracy 0.6811594202898551\n","Accuracy 0.7553956834532374\n","Accuracy 0.7338129496402878\n","Accuracy 0.6521739130434783\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n","Accuracy 0.7266187050359713\n","Accuracy 0.7122302158273381\n","Accuracy 0.7101449275362319\n","Accuracy 0.717391304347826\n","Accuracy 0.7608695652173914\n","Accuracy 0.7338129496402878\n","Accuracy 0.7194244604316546\n","Accuracy 0.7246376811594203\n","Accuracy 0.7101449275362319\n","Accuracy 0.717391304347826\n","Accuracy 0.6906474820143885\n","Accuracy 0.7697841726618705\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7318840579710145\n","Accuracy 0.717391304347826\n","Accuracy 0.6956521739130435\n","Accuracy 0.7050359712230215\n","Accuracy 0.6906474820143885\n","Accuracy 0.7463768115942029\n","Accuracy 0.7318840579710145\n","Accuracy 0.7681159420289855\n","Accuracy 0.7697841726618705\n","Accuracy 0.7410071942446043\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.7536231884057971\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4H3vvxWBboi5"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ft1FUcM7FHaZ"},"source":["# PR REMOVER 1\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yot4aDYyFHah","executionInfo":{"status":"ok","timestamp":1629637795591,"user_tz":-570,"elapsed":224551,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"6316d035-7578-4c5a-bde3-5b86af3c3959"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 25, sensitive_attr= 'HOME_LANGUAGE')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover1.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover1.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy 0.7122302158273381\n","Accuracy 0.7338129496402878\n","Accuracy 0.6811594202898551\n","Accuracy 0.7536231884057971\n","Accuracy 0.7608695652173914\n","Accuracy 0.7194244604316546\n","Accuracy 0.7266187050359713\n","Accuracy 0.7391304347826086\n","Accuracy 0.782608695652174\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7246376811594203\n","Accuracy 0.6956521739130435\n","Accuracy 0.6811594202898551\n","Accuracy 0.7553956834532374\n","Accuracy 0.7338129496402878\n","Accuracy 0.6521739130434783\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n","Accuracy 0.7266187050359713\n","Accuracy 0.7122302158273381\n","Accuracy 0.7101449275362319\n","Accuracy 0.717391304347826\n","Accuracy 0.7608695652173914\n","Accuracy 0.7338129496402878\n","Accuracy 0.7194244604316546\n","Accuracy 0.7246376811594203\n","Accuracy 0.7101449275362319\n","Accuracy 0.717391304347826\n","Accuracy 0.6906474820143885\n","Accuracy 0.7697841726618705\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7318840579710145\n","Accuracy 0.717391304347826\n","Accuracy 0.6956521739130435\n","Accuracy 0.7050359712230215\n","Accuracy 0.6906474820143885\n","Accuracy 0.7463768115942029\n","Accuracy 0.7318840579710145\n","Accuracy 0.7681159420289855\n","Accuracy 0.7697841726618705\n","Accuracy 0.7410071942446043\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.7536231884057971\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"reSfNpjhFH8r"},"source":["# PR REMOVER 25\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtplOkDrFH8r","executionInfo":{"status":"ok","timestamp":1629641616614,"user_tz":-570,"elapsed":216391,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"28767d71-68ae-430e-bfe0-4552b8a6d054"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 25, sensitive_attr= 'HOME_LANGUAGE')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover25.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover25.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Accuracy 0.7122302158273381\n","Accuracy 0.7338129496402878\n","Accuracy 0.6811594202898551\n","Accuracy 0.7536231884057971\n","Accuracy 0.7608695652173914\n","Accuracy 0.7194244604316546\n","Accuracy 0.7266187050359713\n","Accuracy 0.7391304347826086\n","Accuracy 0.7608695652173914\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7246376811594203\n","Accuracy 0.6956521739130435\n","Accuracy 0.6811594202898551\n","Accuracy 0.7553956834532374\n","Accuracy 0.7338129496402878\n","Accuracy 0.6521739130434783\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n","Accuracy 0.7194244604316546\n","Accuracy 0.7122302158273381\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.7608695652173914\n","Accuracy 0.7338129496402878\n","Accuracy 0.7194244604316546\n","Accuracy 0.7246376811594203\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.6906474820143885\n","Accuracy 0.7697841726618705\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7101449275362319\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n","Accuracy 0.7050359712230215\n","Accuracy 0.6906474820143885\n","Accuracy 0.7463768115942029\n","Accuracy 0.7318840579710145\n","Accuracy 0.7681159420289855\n","Accuracy 0.7697841726618705\n","Accuracy 0.7410071942446043\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2zGRNHEQFIPE"},"source":["# PR REMOVER 50\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOUNqFT4FIPG","executionInfo":{"status":"ok","timestamp":1629643199754,"user_tz":-570,"elapsed":87701,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"2874d2f9-a5f9-4e41-8d00-2a1e30e37675"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 50, sensitive_attr= 'HOME_LANGUAGE')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover50.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover50.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Accuracy 0.7122302158273381\n","Accuracy 0.7338129496402878\n","Accuracy 0.6811594202898551\n","Accuracy 0.7536231884057971\n","Accuracy 0.7608695652173914\n","Accuracy 0.7194244604316546\n","Accuracy 0.7266187050359713\n","Accuracy 0.7391304347826086\n","Accuracy 0.7536231884057971\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7246376811594203\n","Accuracy 0.6956521739130435\n","Accuracy 0.6811594202898551\n","Accuracy 0.7553956834532374\n","Accuracy 0.7338129496402878\n","Accuracy 0.6521739130434783\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n","Accuracy 0.7194244604316546\n","Accuracy 0.7122302158273381\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.7608695652173914\n","Accuracy 0.6906474820143885\n","Accuracy 0.7194244604316546\n","Accuracy 0.7246376811594203\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.6906474820143885\n","Accuracy 0.7697841726618705\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7318840579710145\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n","Accuracy 0.7050359712230215\n","Accuracy 0.6906474820143885\n","Accuracy 0.7463768115942029\n","Accuracy 0.7318840579710145\n","Accuracy 0.7681159420289855\n","Accuracy 0.7697841726618705\n","Accuracy 0.7410071942446043\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SglOigoJKEiy"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vP-IlZfPKFU6"},"source":["# PR REMOVER 75\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4pHADeEKFU7","executionInfo":{"status":"ok","timestamp":1629643933458,"user_tz":-570,"elapsed":100622,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"24351418-ec7e-4037-b87b-85a0d6c6973a"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 75, sensitive_attr= 'HOME_LANGUAGE')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover75.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover75.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Accuracy 0.7122302158273381\n","Accuracy 0.7338129496402878\n","Accuracy 0.6811594202898551\n","Accuracy 0.7536231884057971\n","Accuracy 0.7608695652173914\n","Accuracy 0.7194244604316546\n","Accuracy 0.7266187050359713\n","Accuracy 0.7391304347826086\n","Accuracy 0.7536231884057971\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7246376811594203\n","Accuracy 0.6956521739130435\n","Accuracy 0.6811594202898551\n","Accuracy 0.7553956834532374\n","Accuracy 0.7338129496402878\n","Accuracy 0.6521739130434783\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n","Accuracy 0.7194244604316546\n","Accuracy 0.7122302158273381\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.7608695652173914\n","Accuracy 0.6618705035971223\n","Accuracy 0.7194244604316546\n","Accuracy 0.7246376811594203\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.6906474820143885\n","Accuracy 0.7697841726618705\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7318840579710145\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n","Accuracy 0.7050359712230215\n","Accuracy 0.6906474820143885\n","Accuracy 0.7463768115942029\n","Accuracy 0.7318840579710145\n","Accuracy 0.7681159420289855\n","Accuracy 0.7697841726618705\n","Accuracy 0.7410071942446043\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NDxf1UeRVgOp"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"eNlkgkHyKHkO"},"source":["# PR REMOVER 100\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25xsmsZAKHkS","executionInfo":{"status":"ok","timestamp":1629644280858,"user_tz":-570,"elapsed":216866,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"8559439b-cd58-4ffc-d495-6749a2d5d208"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = train.pop('PROGRAM_ENROLMENT_STATUS')\n","  train.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Dropout/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['STUDENT_KEY','CAREER_TERM_YEAR'],axis=1)\n","  first_column = test.pop('PROGRAM_ENROLMENT_STATUS')\n","  test.insert(0, 'PROGRAM_ENROLMENT_STATUS', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** prejudice remover regularizer*****************************\n","  Classifier = PrejudiceRemover(eta= 100, sensitive_attr= 'HOME_LANGUAGE')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['PROGRAM_ENROLMENT_STATUS']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'HOME_LANGUAGE':1}]\n","  disadvantagedGroup= [{'HOME_LANGUAGE':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'PROGRAM_ENROLMENT_STATUS',\n","                  favorable_classes= [1],protected_attribute_names=['HOME_LANGUAGE'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['HOME_LANGUAGE'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover100.xlsx')\n","  Dropout= excelBook['Dropout']\n","  data= Dropout.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/PRemover/PRemover100.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Dropout', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Accuracy 0.7122302158273381\n","Accuracy 0.7338129496402878\n","Accuracy 0.6811594202898551\n","Accuracy 0.7536231884057971\n","Accuracy 0.7608695652173914\n","Accuracy 0.7194244604316546\n","Accuracy 0.7266187050359713\n","Accuracy 0.7391304347826086\n","Accuracy 0.7463768115942029\n","Accuracy 0.717391304347826\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7246376811594203\n","Accuracy 0.6956521739130435\n","Accuracy 0.6811594202898551\n","Accuracy 0.7553956834532374\n","Accuracy 0.7338129496402878\n","Accuracy 0.6521739130434783\n","Accuracy 0.717391304347826\n","Accuracy 0.7318840579710145\n","Accuracy 0.7194244604316546\n","Accuracy 0.7122302158273381\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.7608695652173914\n","Accuracy 0.6762589928057554\n","Accuracy 0.7194244604316546\n","Accuracy 0.7246376811594203\n","Accuracy 0.7101449275362319\n","Accuracy 0.7246376811594203\n","Accuracy 0.6906474820143885\n","Accuracy 0.7697841726618705\n","Accuracy 0.7246376811594203\n","Accuracy 0.7246376811594203\n","Accuracy 0.7028985507246377\n","Accuracy 0.762589928057554\n","Accuracy 0.7769784172661871\n","Accuracy 0.7318840579710145\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n","Accuracy 0.7050359712230215\n","Accuracy 0.6906474820143885\n","Accuracy 0.7463768115942029\n","Accuracy 0.7318840579710145\n","Accuracy 0.7681159420289855\n","Accuracy 0.7697841726618705\n","Accuracy 0.7410071942446043\n","Accuracy 0.7246376811594203\n","Accuracy 0.717391304347826\n","Accuracy 0.7028985507246377\n"],"name":"stdout"}]}]}