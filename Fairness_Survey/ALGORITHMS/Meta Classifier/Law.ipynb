{"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13432,"status":"ok","timestamp":1629949372462,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"q5qYRG8zufHw","outputId":"0d3f7b84-f695-4747-e85b-48f9c84c16b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting aif360\n","  Downloading aif360-0.4.0-py3-none-any.whl (175 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 32.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas\u003e=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.1.5)\n","Requirement already satisfied: numpy\u003e=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.19.5)\n","Requirement already satisfied: scikit-learn\u003e=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360) (0.22.2.post1)\n","Requirement already satisfied: scipy\u003c1.6.0,\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.2.2)\n","Collecting tempeh\n","  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.24.0-\u003eaif360) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.24.0-\u003eaif360) (2018.9)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas\u003e=0.24.0-\u003eaif360) (1.15.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.1-\u003eaif360) (1.0.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eaif360) (1.3.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eaif360) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eaif360) (2.4.7)\n","Collecting shap\n","  Downloading shap-0.39.0.tar.gz (356 kB)\n","\u001b[K     |████████████████████████████████| 356 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh-\u003eaif360) (3.6.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh-\u003eaif360) (2.23.0)\n","Collecting memory-profiler\n","  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler-\u003etempeh-\u003eaif360) (5.4.8)\n","Requirement already satisfied: py\u003e=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (1.10.0)\n","Requirement already satisfied: attrs\u003e=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (21.2.0)\n","Requirement already satisfied: atomicwrites\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (1.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (57.4.0)\n","Requirement already satisfied: pluggy\u003c0.8,\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (0.7.1)\n","Requirement already satisfied: more-itertools\u003e=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest-\u003etempeh-\u003eaif360) (8.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (2021.5.30)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etempeh-\u003eaif360) (3.0.4)\n","Requirement already satisfied: tqdm\u003e4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap-\u003etempeh-\u003eaif360) (4.62.0)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap-\u003etempeh-\u003eaif360) (0.51.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap-\u003etempeh-\u003eaif360) (1.3.0)\n","Requirement already satisfied: llvmlite\u003c0.35,\u003e=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba-\u003eshap-\u003etempeh-\u003eaif360) (0.34.0)\n","Building wheels for collected packages: memory-profiler, shap\n","  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=0fe25b0fc42d713dca53c7868cc3bb33cb3211ed11f0e87cab216eb16f09682e\n","  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n","  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491650 sha256=ac2b66a6883f9c1645b7a1d2b00e21edf91c974117cc032b4b7a909b911a7191\n","  Stored in directory: /root/.cache/pip/wheels/ca/25/8f/6ae5df62c32651cd719e972e738a8aaa4a87414c4d2b14c9c0\n","Successfully built memory-profiler shap\n","Installing collected packages: slicer, shap, memory-profiler, tempeh, aif360\n","Successfully installed aif360-0.4.0 memory-profiler-0.58.0 shap-0.39.0 slicer-0.0.7 tempeh-0.1.12\n","Collecting fairlearn\n","  Downloading fairlearn-0.7.0-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 38.7 MB/s \n","\u001b[?25hRequirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n","Requirement already satisfied: scikit-learn\u003e=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (0.22.2.post1)\n","Requirement already satisfied: pandas\u003e=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.1.5)\n","Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.19.5)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.25.1-\u003efairlearn) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas\u003e=0.25.1-\u003efairlearn) (2018.9)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas\u003e=0.25.1-\u003efairlearn) (1.15.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn\u003e=0.22.1-\u003efairlearn) (1.0.1)\n","Installing collected packages: fairlearn\n","Successfully installed fairlearn-0.7.0\n"]}],"source":["!pip install aif360\n","!pip install fairlearn"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1278,"status":"ok","timestamp":1629949373712,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"TltW3iPkux0Q","outputId":"92c531f8-cb03-4eed-babc-6d277f685a86"},"outputs":[{"name":"stdout","output_type":"stream","text":["E: Command line option 'j' [from -jre] is not understood in combination with the other options.\n","openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"]}],"source":["!apt-get install -jre\n","!java -version"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29867,"status":"ok","timestamp":1629949403577,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"KssrNl8GvDYU","outputId":"fabf590a-1a48-40ec-9d30-a9a3ef4ccd32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting h2o\n","  Downloading h2o-3.32.1.6.tar.gz (168.4 MB)\n","\u001b[K     |████████████████████████████████| 168.4 MB 70 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n","Collecting colorama\u003e=0.3.8\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eh2o) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eh2o) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eh2o) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eh2o) (2021.5.30)\n","Building wheels for collected packages: h2o\n","  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for h2o: filename=h2o-3.32.1.6-py2.py3-none-any.whl size=168439194 sha256=ba59a673d4b03d1799c44ac772a90185b229d26eff3570fc71f61600aca58ef8\n","  Stored in directory: /root/.cache/pip/wheels/ee/0f/51/849ba221c4c1b11a04efb4a3427dc9cb1c4dcde218c6c98b13\n","Successfully built h2o\n","Installing collected packages: colorama, h2o\n","Successfully installed colorama-0.4.4 h2o-3.32.1.6\n"]}],"source":["!pip install h2o"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3105,"status":"ok","timestamp":1629949406667,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"_NQn2JJ0uw6u","outputId":"cdca069e-a462-43b8-cadc-119e2c69c0af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n","\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 40 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 81 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 92 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 112 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 122 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 133 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 143 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 148 kB 33.0 MB/s \n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.0.1\n"]}],"source":["!pip install xlsxwriter"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5204,"status":"ok","timestamp":1629949411835,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"a0YklbHpAxd8","outputId":"84a29564-3fc6-45d8-d665-0efe5ebeca96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting BlackBoxAuditing\n","  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 32.4 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003eBlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler\u003e=0.10-\u003ematplotlib-\u003eBlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eBlackBoxAuditing) (2018.9)\n","Building wheels for collected packages: BlackBoxAuditing\n","  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394771 sha256=46d583857f3fb09b9506a6acf2fd93807889e288c20b6e0990167895635b536a\n","  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n","Successfully built BlackBoxAuditing\n","Installing collected packages: BlackBoxAuditing\n","Successfully installed BlackBoxAuditing-0.1.54\n"]}],"source":["!pip install BlackBoxAuditing"]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":375,"status":"ok","timestamp":1629949970942,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"rf1aISz6vGfR"},"outputs":[],"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover, MetaFairClassifier, AdversarialDebiasing\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","import h2o\n","from h2o.automl import H2OAutoML\n","from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"executionInfo":{"elapsed":7298,"status":"ok","timestamp":1629949429279,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"RcxQeeX7vUXz","outputId":"2bd0f757-55e6-4a7f-bdf3-98c2f5eb7087"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n","Attempting to start a local H2O server...\n","  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n","  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n","  Ice root: /tmp/tmp728k_1f6\n","  JVM stdout: /tmp/tmp728k_1f6/h2o_unknownUser_started_from_python.out\n","  JVM stderr: /tmp/tmp728k_1f6/h2o_unknownUser_started_from_python.err\n","  Server is running at http://127.0.0.1:54321\n","Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"]},{"data":{"text/html":["\u003cdiv style=\"overflow:auto\"\u003e\u003ctable style=\"width:50%\"\u003e\u003ctr\u003e\u003ctd\u003eH2O_cluster_uptime:\u003c/td\u003e\n","\u003ctd\u003e03 secs\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_timezone:\u003c/td\u003e\n","\u003ctd\u003eEtc/UTC\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_data_parsing_timezone:\u003c/td\u003e\n","\u003ctd\u003eUTC\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_version:\u003c/td\u003e\n","\u003ctd\u003e3.32.1.6\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_version_age:\u003c/td\u003e\n","\u003ctd\u003e6 days \u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_name:\u003c/td\u003e\n","\u003ctd\u003eH2O_from_python_unknownUser_p2umze\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_total_nodes:\u003c/td\u003e\n","\u003ctd\u003e1\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_free_memory:\u003c/td\u003e\n","\u003ctd\u003e3.172 Gb\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_total_cores:\u003c/td\u003e\n","\u003ctd\u003e2\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_allowed_cores:\u003c/td\u003e\n","\u003ctd\u003e2\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_cluster_status:\u003c/td\u003e\n","\u003ctd\u003eaccepting new members, healthy\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_connection_url:\u003c/td\u003e\n","\u003ctd\u003ehttp://127.0.0.1:54321\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_connection_proxy:\u003c/td\u003e\n","\u003ctd\u003e{\"http\": null, \"https\": null}\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_internal_security:\u003c/td\u003e\n","\u003ctd\u003eFalse\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003eH2O_API_Extensions:\u003c/td\u003e\n","\u003ctd\u003eAmazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\u003c/td\u003e\u003c/tr\u003e\n","\u003ctr\u003e\u003ctd\u003ePython_version:\u003c/td\u003e\n","\u003ctd\u003e3.7.11 final\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003c/div\u003e"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O_cluster_uptime:         03 secs\n","H2O_cluster_timezone:       Etc/UTC\n","H2O_data_parsing_timezone:  UTC\n","H2O_cluster_version:        3.32.1.6\n","H2O_cluster_version_age:    6 days\n","H2O_cluster_name:           H2O_from_python_unknownUser_p2umze\n","H2O_cluster_total_nodes:    1\n","H2O_cluster_free_memory:    3.172 Gb\n","H2O_cluster_total_cores:    2\n","H2O_cluster_allowed_cores:  2\n","H2O_cluster_status:         accepting new members, healthy\n","H2O_connection_url:         http://127.0.0.1:54321\n","H2O_connection_proxy:       {\"http\": null, \"https\": null}\n","H2O_internal_security:      False\n","H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python_version:             3.7.11 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{},"output_type":"display_data"}],"source":["h2o.init()"]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39981,"status":"ok","timestamp":1629949772038,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"FEGPULDrvk3g","outputId":"f9c2a439-158f-4ac2-f4dd-2faa62a305c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# Meta\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69027,"status":"ok","timestamp":1629950610398,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"uN9VfZBAvxCj","outputId":"94f2dd2e-487e-4d6a-a236-d56d1d801d78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.8884809545663148\n","Accuracy 0.893299678751721\n","Accuracy 0.8859568609453878\n","Accuracy 0.890546122074346\n","Accuracy 0.8857536132140399\n","Accuracy 0.8944469940339606\n","Accuracy 0.890546122074346\n","Accuracy 0.8903166590178981\n","Accuracy 0.8896282698485544\n","Accuracy 0.8921771048405598\n","Accuracy 0.8873336392840753\n","Accuracy 0.8978889398806792\n","Accuracy 0.887792565396971\n","Accuracy 0.8861863240018357\n","Accuracy 0.888735948612067\n","Accuracy 0.8845800826067003\n","Accuracy 0.8891693437356586\n","Accuracy 0.8916934373565856\n","Accuracy 0.8960532354290959\n","Accuracy 0.8969947235604496\n","Accuracy 0.8811381367599816\n","Accuracy 0.8942175309775127\n","Accuracy 0.8834327673244607\n","Accuracy 0.8942175309775127\n","Accuracy 0.8926359256710255\n","Accuracy 0.8868747131711794\n","Accuracy 0.8937586048646168\n","Accuracy 0.8866452501147315\n","Accuracy 0.8910050481872418\n","Accuracy 0.8846065611378756\n","Accuracy 0.8912345112436898\n","Accuracy 0.893299678751721\n","Accuracy 0.8843506195502524\n","Accuracy 0.8969710876548875\n","Accuracy 0.8910300527643955\n","Accuracy 0.8972005507113354\n","Accuracy 0.8864157870582836\n","Accuracy 0.8857273978889398\n","Accuracy 0.8900871959614503\n","Accuracy 0.8912594631796283\n","Accuracy 0.8852684717760441\n","Accuracy 0.893070215695273\n","Accuracy 0.8916934373565856\n","Accuracy 0.8893988067921065\n","Accuracy 0.8896535902729984\n","Accuracy 0.8891693437356586\n","Accuracy 0.8919229004130335\n","Accuracy 0.8850390087195962\n","Accuracy 0.8949059201468563\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta0.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta0.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"reSfNpjhFH8r"},"source":["# Meta 0.2\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68095,"status":"ok","timestamp":1629950765827,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"dtplOkDrFH8r","outputId":"a713c3f4-a659-4b91-c097-5ea45393b32d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.8930947465014911\n","Accuracy 0.888022028453419\n","Accuracy 0.893070215695273\n","Accuracy 0.8852684717760441\n","Accuracy 0.8900871959614503\n","Accuracy 0.8850653819683414\n","Accuracy 0.8937586048646168\n","Accuracy 0.890546122074346\n","Accuracy 0.8891693437356586\n","Accuracy 0.8882514915098669\n","Accuracy 0.891947694425327\n","Accuracy 0.8868747131711794\n","Accuracy 0.8967416245984396\n","Accuracy 0.8871041762276274\n","Accuracy 0.8852684717760441\n","Accuracy 0.8882771277816013\n","Accuracy 0.8832033042680129\n","Accuracy 0.8889398806792106\n","Accuracy 0.8914639743001377\n","Accuracy 0.8960532354290959\n","Accuracy 0.8958476714842853\n","Accuracy 0.8799908214777421\n","Accuracy 0.8944469940339606\n","Accuracy 0.882744378155117\n","Accuracy 0.8937586048646168\n","Accuracy 0.891947694425327\n","Accuracy 0.8868747131711794\n","Accuracy 0.8935291418081689\n","Accuracy 0.8852684717760441\n","Accuracy 0.8903166590178981\n","Accuracy 0.8846065611378756\n","Accuracy 0.8907755851307939\n","Accuracy 0.8937586048646168\n","Accuracy 0.8832033042680129\n","Accuracy 0.8965121615419918\n","Accuracy 0.8894241798577656\n","Accuracy 0.8969710876548875\n","Accuracy 0.8864157870582836\n","Accuracy 0.885497934832492\n","Accuracy 0.8891693437356586\n","Accuracy 0.8910300527643955\n","Accuracy 0.8852684717760441\n","Accuracy 0.893070215695273\n","Accuracy 0.8910050481872418\n","Accuracy 0.8889398806792106\n","Accuracy 0.8891947694425327\n","Accuracy 0.8884809545663148\n","Accuracy 0.8914639743001377\n","Accuracy 0.8843506195502524\n","Accuracy 0.8946764570904084\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.2, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta2.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta2.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"2zGRNHEQFIPE"},"source":["# Meta 0.4\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102605,"status":"ok","timestamp":1629950869549,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"KOUNqFT4FIPG","outputId":"04c005a6-fc47-415a-b0de-c0e88afb1900"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.8882514915098669\n","Accuracy 0.8937586048646168\n","Accuracy 0.885497934832492\n","Accuracy 0.8900871959614503\n","Accuracy 0.8857536132140399\n","Accuracy 0.8946764570904084\n","Accuracy 0.890546122074346\n","Accuracy 0.890546122074346\n","Accuracy 0.8893988067921065\n","Accuracy 0.8921771048405598\n","Accuracy 0.8873336392840753\n","Accuracy 0.8967416245984396\n","Accuracy 0.8873336392840753\n","Accuracy 0.8861863240018357\n","Accuracy 0.888735948612067\n","Accuracy 0.8836622303809086\n","Accuracy 0.8891693437356586\n","Accuracy 0.8921523634694815\n","Accuracy 0.8960532354290959\n","Accuracy 0.8972241339756825\n","Accuracy 0.8815970628728774\n","Accuracy 0.8944469940339606\n","Accuracy 0.8834327673244607\n","Accuracy 0.8939880679210647\n","Accuracy 0.8924065152557926\n","Accuracy 0.8868747131711794\n","Accuracy 0.8937586048646168\n","Accuracy 0.8861863240018357\n","Accuracy 0.8903166590178981\n","Accuracy 0.8848359715531086\n","Accuracy 0.8912345112436898\n","Accuracy 0.8937586048646168\n","Accuracy 0.8838916934373566\n","Accuracy 0.8969710876548875\n","Accuracy 0.8910300527643955\n","Accuracy 0.8981184029371271\n","Accuracy 0.8866452501147315\n","Accuracy 0.8866452501147315\n","Accuracy 0.8896282698485544\n","Accuracy 0.8912594631796283\n","Accuracy 0.8852684717760441\n","Accuracy 0.8928407526388251\n","Accuracy 0.8921523634694815\n","Accuracy 0.8893988067921065\n","Accuracy 0.8896535902729984\n","Accuracy 0.8893988067921065\n","Accuracy 0.8916934373565856\n","Accuracy 0.8852684717760441\n","Accuracy 0.895823772372648\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.4, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta4.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta4.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"SglOigoJKEiy"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vP-IlZfPKFU6"},"source":["# Meta 0.6\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":138459,"status":"ok","timestamp":1629951009051,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"},"user_tz":-570},"id":"N4pHADeEKFU7","outputId":"c5ab0a98-14f1-4280-b345-de7efd0e5cd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.8884809545663148\n","Accuracy 0.17508031206975677\n","Accuracy 0.17989903625516293\n","Accuracy 0.890546122074346\n","Accuracy 0.8857536132140399\n","Accuracy 0.8944469940339606\n","Accuracy 0.890546122074346\n","Accuracy 0.3061037173015145\n","Accuracy 0.8896282698485544\n","Accuracy 0.8921771048405598\n","Accuracy 0.8873336392840753\n","Accuracy 0.8978889398806792\n","Accuracy 0.26548875631023405\n","Accuracy 0.2911886186324002\n","Accuracy 0.27506308786418904\n","Accuracy 0.23680587425424507\n","Accuracy 0.2452960073428178\n","Accuracy 0.8916934373565856\n","Accuracy 0.3095456631482331\n","Accuracy 0.8969947235604496\n","Accuracy 0.24483708122992198\n","Accuracy 0.8942175309775127\n","Accuracy 0.8834327673244607\n","Accuracy 0.2358880220284534\n","Accuracy 0.8926359256710255\n","Accuracy 0.27742083524552547\n","Accuracy 0.8937586048646168\n","Accuracy 0.26411197797154656\n","Accuracy 0.8910050481872418\n","Accuracy 0.3269098417068135\n","Accuracy 0.8912345112436898\n","Accuracy 0.893299678751721\n","Accuracy 0.8843506195502524\n","Accuracy 0.21248279027076641\n","Accuracy 0.8910300527643955\n","Accuracy 0.14502065167508033\n","Accuracy 0.28728774667278567\n","Accuracy 0.2927948600275356\n","Accuracy 0.8900871959614503\n","Accuracy 0.34985088323009866\n","Accuracy 0.3102340523175769\n","Accuracy 0.2905002294630564\n","Accuracy 0.18357044515832951\n","Accuracy 0.2356585589720055\n","Accuracy 0.2482220692819454\n","Accuracy 0.8891693437356586\n","Accuracy 0.8919229004130335\n","Accuracy 0.2069756769160165\n","Accuracy 0.8949059201468563\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.6, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta6.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta6.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"NDxf1UeRVgOp"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"eNlkgkHyKHkO"},"source":["# Meta 0.8\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"25xsmsZAKHkS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.8926359256710255\n","Accuracy 0.8884809545663148\n","Accuracy 0.893299678751721\n","Accuracy 0.8859568609453878\n","Accuracy 0.890546122074346\n","Accuracy 0.1587520073411333\n","Accuracy 0.8944469940339606\n","Accuracy 0.890546122074346\n","Accuracy 0.25791647544745294\n","Accuracy 0.22303809086737036\n","Accuracy 0.8921771048405598\n","Accuracy 0.20215695273061038\n","Accuracy 0.29004130335016065\n","Accuracy 0.2182193666819642\n","Accuracy 0.7888939880679211\n","Accuracy 0.28355127322780455\n","Accuracy 0.19573198715006884\n","Accuracy 0.8891693437356586\n","Accuracy 0.8916934373565856\n","Accuracy 0.8960532354290959\n","Accuracy 0.8969947235604496\n","Accuracy 0.19435520881138138\n","Accuracy 0.8942175309775127\n","Accuracy 0.19022487379531897\n","Accuracy 0.8942175309775127\n","Accuracy 0.8926359256710255\n","Accuracy 0.1642955484167049\n","Accuracy 0.768012849931161\n","Accuracy 0.8143643873336393\n","Accuracy 0.2319871500688389\n","Accuracy 0.24615737554484973\n","Accuracy 0.2122533272143185\n","Accuracy 0.893299678751721\n","Accuracy 0.8843506195502524\n","Accuracy 0.8969710876548875\n","Accuracy 0.8910300527643955\n","Accuracy 0.8972005507113354\n","Accuracy 0.8864157870582836\n","Accuracy 0.8857273978889398\n","Accuracy 0.1854061496099128\n","Accuracy 0.2507455838495068\n","Accuracy 0.8852684717760441\n","Accuracy 0.893070215695273\n","Accuracy 0.8916934373565856\n","Accuracy 0.8893988067921065\n","Accuracy 0.5615966964900206\n","Accuracy 0.8891693437356586\n","Accuracy 0.8919229004130335\n","Accuracy 0.747590637907297\n","Accuracy 0.2714547957778798\n"]}],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.8, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta8.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta8.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]},{"cell_type":"markdown","metadata":{"id":"n7JaK7kHpWVa"},"source":["# Meta 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMTAhY3NpYUT"},"outputs":[],"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path).drop(['region_first'],axis=1)\n","  first_column = train.pop('first_pf')\n","  train.insert(0, 'first_pf', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Law/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path).drop(['region_first'],axis=1)\n","  first_column = test.pop('first_pf')\n","  test.insert(0, 'first_pf', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=1.0, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['first_pf']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'first_pf',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta10.xlsx')\n","  Law= excelBook['Law']\n","  data= Law.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta10.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Law', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMswMilgmxEkiO1BhBZFtxr","name":"Law.ipynb","provenance":[{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}