{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Violent.ipynb","provenance":[{"file_id":"1-ar5jhY8kGUSwnnZRMZsNOt02wwgn6dV","timestamp":1629951726822},{"file_id":"1RyrIFd1EbO7wTWXg1693zq8SahcbsU8L","timestamp":1628685738191},{"file_id":"1zUVqlZwnp2gUWV_U6552PNihQarJC9I9","timestamp":1628683226587},{"file_id":"1AJWD--4mn4SFR1x2nX38Hkscv0C2Ovqi","timestamp":1628499839227}],"authorship_tag":"ABX9TyOX4tClqSONl6BypxVG3H+H"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ff_Jv8Ptu4lP"},"source":["\n","# INSTALLATION"]},{"cell_type":"code","metadata":{"id":"q5qYRG8zufHw","executionInfo":{"status":"aborted","timestamp":1629967595094,"user_tz":-570,"elapsed":80,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["!pip install aif360\n","!pip install fairlearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TltW3iPkux0Q","executionInfo":{"status":"aborted","timestamp":1629967595094,"user_tz":-570,"elapsed":80,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["!apt-get install -jre\n","!java -version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KssrNl8GvDYU","executionInfo":{"status":"aborted","timestamp":1629967595095,"user_tz":-570,"elapsed":80,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["!pip install h2o"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NQn2JJ0uw6u","executionInfo":{"status":"aborted","timestamp":1629967595096,"user_tz":-570,"elapsed":81,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["!pip install xlsxwriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0YklbHpAxd8","executionInfo":{"status":"ok","timestamp":1629967505098,"user_tz":-570,"elapsed":5513,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"6de02052-4f26-489d-e702-b330e5ac7b09"},"source":["!pip install BlackBoxAuditing"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting BlackBoxAuditing\n","  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->BlackBoxAuditing) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n","Building wheels for collected packages: BlackBoxAuditing\n","  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394771 sha256=2f18382574c5918b9cf98dfd8e6aeffb5db68bf60dfdc25a857a69a67a95bcfb\n","  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n","Successfully built BlackBoxAuditing\n","Installing collected packages: BlackBoxAuditing\n","Successfully installed BlackBoxAuditing-0.1.54\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Y_uQ6vdvN4a"},"source":["#IMPORTS"]},{"cell_type":"code","metadata":{"id":"rf1aISz6vGfR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629967516336,"user_tz":-570,"elapsed":11263,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"40b44ae3-dae1-40dc-ed2b-d2b679ffbae5"},"source":["import numpy as np\n","from mlxtend.feature_selection import  ExhaustiveFeatureSelector\n","from xgboost import  XGBClassifier\n","# import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import openpyxl\n","import xlsxwriter\n","from openpyxl import  load_workbook\n","\n","import BlackBoxAuditing\n","import shap\n","#suppress setwith copy warning\n","pd.set_option('mode.chained_assignment',None)\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectKBest, SelectFwe, SelectPercentile,SelectFdr, SelectFpr, SelectFromModel\n","from sklearn.feature_selection import chi2, mutual_info_classif\n","# from skfeature.function.similarity_based import fisher_score\n","from aif360.algorithms.inprocessing import PrejudiceRemover, MetaFairClassifier, AdversarialDebiasing\n","import matplotlib.pyplot as plt\n","from aif360.metrics.classification_metric import ClassificationMetric\n","\n","from aif360.metrics import BinaryLabelDatasetMetric\n","from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing, LFR,OptimPreproc\n","from aif360.datasets import StandardDataset , BinaryLabelDataset\n","from sklearn.preprocessing import MinMaxScaler \n","MM= MinMaxScaler()\n","import h2o\n","from h2o.automl import H2OAutoML\n","from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n","\n","import sys\n","sys.path.append(\"../\")\n","import os\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"RcxQeeX7vUXz","executionInfo":{"status":"ok","timestamp":1629967523393,"user_tz":-570,"elapsed":7127,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"61507b8b-ff3c-441e-dd24-98b303a5ea7c"},"source":["h2o.init()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n","Attempting to start a local H2O server...\n","  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n","  Starting server from /usr/local/lib/python3.7/dist-packages/h2o/backend/bin/h2o.jar\n","  Ice root: /tmp/tmpwypdf6wc\n","  JVM stdout: /tmp/tmpwypdf6wc/h2o_unknownUser_started_from_python.out\n","  JVM stderr: /tmp/tmpwypdf6wc/h2o_unknownUser_started_from_python.err\n","  Server is running at http://127.0.0.1:54321\n","Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n","<td>03 secs</td></tr>\n","<tr><td>H2O_cluster_timezone:</td>\n","<td>Etc/UTC</td></tr>\n","<tr><td>H2O_data_parsing_timezone:</td>\n","<td>UTC</td></tr>\n","<tr><td>H2O_cluster_version:</td>\n","<td>3.32.1.6</td></tr>\n","<tr><td>H2O_cluster_version_age:</td>\n","<td>6 days </td></tr>\n","<tr><td>H2O_cluster_name:</td>\n","<td>H2O_from_python_unknownUser_ogr3vi</td></tr>\n","<tr><td>H2O_cluster_total_nodes:</td>\n","<td>1</td></tr>\n","<tr><td>H2O_cluster_free_memory:</td>\n","<td>3.172 Gb</td></tr>\n","<tr><td>H2O_cluster_total_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_allowed_cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O_cluster_status:</td>\n","<td>accepting new members, healthy</td></tr>\n","<tr><td>H2O_connection_url:</td>\n","<td>http://127.0.0.1:54321</td></tr>\n","<tr><td>H2O_connection_proxy:</td>\n","<td>{\"http\": null, \"https\": null}</td></tr>\n","<tr><td>H2O_internal_security:</td>\n","<td>False</td></tr>\n","<tr><td>H2O_API_Extensions:</td>\n","<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n","<tr><td>Python_version:</td>\n","<td>3.7.11 final</td></tr></table></div>"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O_cluster_uptime:         03 secs\n","H2O_cluster_timezone:       Etc/UTC\n","H2O_data_parsing_timezone:  UTC\n","H2O_cluster_version:        3.32.1.6\n","H2O_cluster_version_age:    6 days\n","H2O_cluster_name:           H2O_from_python_unknownUser_ogr3vi\n","H2O_cluster_total_nodes:    1\n","H2O_cluster_free_memory:    3.172 Gb\n","H2O_cluster_total_cores:    2\n","H2O_cluster_allowed_cores:  2\n","H2O_cluster_status:         accepting new members, healthy\n","H2O_connection_url:         http://127.0.0.1:54321\n","H2O_connection_proxy:       {\"http\": null, \"https\": null}\n","H2O_internal_security:      False\n","H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python_version:             3.7.11 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RQVI-ISXvrZm"},"source":["#**************************LOADING DATASET*******************************"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEGPULDrvk3g","executionInfo":{"status":"ok","timestamp":1629967587907,"user_tz":-570,"elapsed":64540,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"41700066-48f9-4d00-f29c-83fde5e9941b"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDh3f5HwHubq"},"source":["# Meta\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"id":"uN9VfZBAvxCj","executionInfo":{"status":"error","timestamp":1629967595101,"user_tz":-570,"elapsed":7294,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"b3c4a3a2-0a68-4212-c584-6bae360768ba"},"source":["for i in range(1,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('two_year_recid')\n","  train.insert(0, 'two_year_recid', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('two_year_recid')\n","  test.insert(0, 'two_year_recid', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['two_year_recid']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta0.xlsx')\n","  Violent= excelBook['Violent']\n","  data= Violent.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta0.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Violent', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-87aa39532b29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m   \u001b[0mexcelBook\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta0.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m   \u001b[0mViolent\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mexcelBook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Violent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mViolent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(filename, read_only, keep_vba, data_only, guess_types, keep_links)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mws_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkSheetParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mws_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openpyxl/reader/worksheet.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mtag_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mdispatcher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtag_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openpyxl/reader/worksheet.py\u001b[0m in \u001b[0;36mparse_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msafe_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCELL_TAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openpyxl/reader/worksheet.py\u001b[0m in \u001b[0;36mparse_cell\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"reSfNpjhFH8r"},"source":["# Meta 0.2\n","\n"]},{"cell_type":"code","metadata":{"id":"dtplOkDrFH8r","executionInfo":{"status":"aborted","timestamp":1629967595046,"user_tz":-570,"elapsed":485,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["for i in range(27,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('two_year_recid')\n","  train.insert(0, 'two_year_recid', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('two_year_recid')\n","  test.insert(0, 'two_year_recid', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.2, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['two_year_recid']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta2.xlsx')\n","  Violent= excelBook['Violent']\n","  data= Violent.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta2.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Violent', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zGRNHEQFIPE"},"source":["# Meta 0.4\n","\n"]},{"cell_type":"code","metadata":{"id":"KOUNqFT4FIPG","executionInfo":{"status":"aborted","timestamp":1629967595060,"user_tz":-570,"elapsed":490,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["for i in range(27,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('two_year_recid')\n","  train.insert(0, 'two_year_recid', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('two_year_recid')\n","  test.insert(0, 'two_year_recid', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.4, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['two_year_recid']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta4.xlsx')\n","  Violent= excelBook['Violent']\n","  data= Violent.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta4.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Violent', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftSjLfE8zEVE","executionInfo":{"status":"aborted","timestamp":1629967595075,"user_tz":-570,"elapsed":505,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["i"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SglOigoJKEiy"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vP-IlZfPKFU6"},"source":["# Meta 0.6\n","\n"]},{"cell_type":"code","metadata":{"id":"BJwzFJoM11mF","executionInfo":{"status":"aborted","timestamp":1629967595082,"user_tz":-570,"elapsed":70,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["i"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4pHADeEKFU7","executionInfo":{"status":"aborted","timestamp":1629967595086,"user_tz":-570,"elapsed":74,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}}},"source":["for i in range(27,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('two_year_recid')\n","  train.insert(0, 'two_year_recid', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('two_year_recid')\n","  test.insert(0, 'two_year_recid', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.6, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['two_year_recid']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta6.xlsx')\n","  Violent= excelBook['Violent']\n","  data= Violent.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta6.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Violent', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NDxf1UeRVgOp"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"eNlkgkHyKHkO"},"source":["# Meta 0.8\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1N39bUEHwXKb","executionInfo":{"status":"ok","timestamp":1629969556677,"user_tz":-570,"elapsed":569,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"93297489-3ef9-4e9e-d4dc-0ff899e35a1c"},"source":["i"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"25xsmsZAKHkS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629970081516,"user_tz":-570,"elapsed":524404,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"92637596-e7eb-4fad-9ad1-0b1cc4f66fd1"},"source":["for i in range(27,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('two_year_recid')\n","  train.insert(0, 'two_year_recid', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('two_year_recid')\n","  test.insert(0, 'two_year_recid', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=0.8, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['two_year_recid']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta8.xlsx')\n","  Violent= excelBook['Violent']\n","  data= Violent.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta8.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Violent', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7793017456359103\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7855361596009975\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.6521197007481296\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7593516209476309\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.729426433915212\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7406483790523691\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7556109725685786\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7443890274314214\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7618453865336658\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7693266832917706\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7680798004987531\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7680798004987531\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7668329177057357\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.8042394014962594\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7556109725685786\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.6820448877805486\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.756857855361596\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.770573566084788\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7007481296758105\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7805486284289277\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7680798004987531\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.6745635910224439\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7718204488778054\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.756857855361596\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvJQIcvSvtVm","executionInfo":{"status":"ok","timestamp":1629970082118,"user_tz":-570,"elapsed":640,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"183f638d-63fe-4150-efdf-22ca0025fc31"},"source":["i"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"n7JaK7kHpWVa"},"source":["# Meta 1.0"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSo8oNye093L","executionInfo":{"status":"ok","timestamp":1629970759458,"user_tz":-570,"elapsed":450,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"e88dac3c-b59a-417d-8591-1eef4f778261"},"source":["i"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"CMTAhY3NpYUT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629971356688,"user_tz":-570,"elapsed":596324,"user":{"displayName":"DEHO OSCAR BLESSED","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhE0cXJBikzHY7xUavBkbPRseKZ_N-obrw0xIoLhQ=s64","userId":"04127040763952829247"}},"outputId":"1c658ca9-0ab9-4aff-b46a-07b2bfd573f5"},"source":["for i in range(27,51,1):\n","\n","  train_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Train'\n","  train_path= os.path.join(train_url ,(\"Train\"+ str(i)+ \".csv\"))\n","  train= pd.read_csv(train_path)\n","  first_column = train.pop('two_year_recid')\n","  train.insert(0, 'two_year_recid', first_column)\n","\n","  test_url=r'/content/gdrive/MyDrive/Datasets/SurveyData/DATASET/Violent/Test'\n","  test_path= os.path.join(test_url ,(\"Test\"+ str(i)+ \".csv\"))\n","  test= pd.read_csv(test_path)\n","  first_column = test.pop('two_year_recid')\n","  test.insert(0, 'two_year_recid', first_column)\n","\n","\n","  # # normalization of train and test sets\n","  # Fitter= MM.fit(train)\n","  # transformed_train=Fitter.transform(train)\n","  # train=pd.DataFrame(transformed_train, columns= train.columns)\n","\n","  # #test normalization\n","  # transformed_test=Fitter.transform(test)\n","  # test=pd.DataFrame(transformed_test, columns= test.columns)\n","\n","\n","  ## ****************CONVERTING TO BLD FORMAT******************************\n","  #BLD Train set\n","  class Train(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Train, self).__init__(df=train  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","  # BLD Test\n","  BLD_Train = Train(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","\n","  class Test(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(Test, self).__init__(df=test  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_Test= Test(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","  \n","  #******************************** MetaFair Classifier regularizer*****************************\n","  Classifier = MetaFairClassifier(tau=1.0, sensitive_attr= 'race')\n","  Classifier.fit(BLD_Train)\n","  prediction= Classifier.predict(BLD_Test)\n","  #**********************REPLACE LABELS OF DUPLICATED TEST SET WITH PREDICTIONS****************************\n","  #predicted labels\n","  # gbm_Predictions= best_model.predict(Test)\n","  # gbm_Predictions= gbm_Predictions.as_data_frame()\n","  predicted_df= test.copy()\n","  predicted_df['two_year_recid']= prediction.labels\n","\n","  # ********************COMPUTE DISCRIMINATION*****************************\n","\n","  advantagedGroup= [{'race':1}]\n","  disadvantagedGroup= [{'race':0}]\n","\n","  class PredTest(StandardDataset):\n","      def __init__(self,label_name= 'two_year_recid',\n","                  favorable_classes= [1],protected_attribute_names=['race'],   privileged_classes=[[1]], ):\n","\n","\n","          super(PredTest, self).__init__(df=predicted_df  , label_name=label_name ,\n","              favorable_classes=favorable_classes , protected_attribute_names=protected_attribute_names ,\n","              privileged_classes=privileged_classes ,\n","            )\n","\n","  BLD_PredTest= PredTest(protected_attribute_names= ['race'],\n","                        privileged_classes= [[1]])\n","\n","\n","  excelBook= load_workbook('/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta10.xlsx')\n","  Violent= excelBook['Violent']\n","  data= Violent.values\n","\n","  # Get columns\n","  columns = next(data)[0:]\n","  10# Create a DataFrame based on the second and subsequent lines of data\n","  OldDF = pd.DataFrame(data, columns=columns)\n","\n","  ClassifierBias = ClassificationMetric( BLD_Test,BLD_PredTest    , unprivileged_groups= disadvantagedGroup, privileged_groups= advantagedGroup)\n","  Accuracy= ClassifierBias.accuracy()\n","  TPR= ClassifierBias.true_positive_rate()\n","  TNR= ClassifierBias.true_negative_rate()\n","  NPV= ClassifierBias.negative_predictive_value()\n","  PPV= ClassifierBias.positive_predictive_value()\n","  SP=ClassifierBias .statistical_parity_difference() \n","  IF=ClassifierBias.consistency()\n","  DI=ClassifierBias.disparate_impact()\n","  EOP=ClassifierBias.true_positive_rate_difference()\n","  EO=ClassifierBias.average_odds_difference()\n","  FDR= ClassifierBias.false_discovery_rate(privileged=False)- ClassifierBias.false_discovery_rate(privileged=True)\n","  NPV_diff=ClassifierBias.negative_predictive_value(privileged=False)-ClassifierBias.negative_predictive_value(privileged=True)\n","  FOR=ClassifierBias.false_omission_rate(privileged=False)-ClassifierBias.false_omission_rate(privileged=True)\n","  PPV_diff=ClassifierBias.positive_predictive_value(privileged=False) -ClassifierBias.positive_predictive_value(privileged=True)\n","  BGE = ClassifierBias.between_group_generalized_entropy_index()\n","  WGE = ClassifierBias.generalized_entropy_index()-ClassifierBias.between_group_generalized_entropy_index()\n","  BGTI = ClassifierBias.between_group_theil_index()\n","  WGTI = ClassifierBias.theil_index() -ClassifierBias.between_group_theil_index()\n","  EDF= ClassifierBias.differential_fairness_bias_amplification()\n","\n","  newdf= pd.DataFrame(index = [0], data= { 'ACCURACY': Accuracy,'TPR': TPR, 'PPV':PPV, 'TNR':TNR,'NPV':NPV,'SP':SP,'CONSISTENCY':IF,'DI':DI,'EOP':EOP,'EO':EO,'FDR':FDR,'NPV_diff':NPV_diff, \n","                                          'FOR':FOR,'PPV_diff':PPV_diff,'BGEI':BGE,'WGEI':WGE,'BGTI':BGTI,'WGTI':WGTI,'EDF':EDF})\n","  newdf=pd.concat([OldDF,newdf])\n","\n","  pathway= r\"/content/gdrive/MyDrive/Datasets/SurveyData/RESULTS/Meta/Meta10.xlsx\"\n","\n","  with pd.ExcelWriter(pathway, engine='openpyxl') as writer:\n","    #load workbook base as for writer\n","    writer.book= excelBook\n","    writer.sheets=dict((ws.title, ws) for ws in excelBook.worksheets)\n","    newdf.to_excel(writer, sheet_name='Violent', index=False)\n","    # newdf.to_excel(writer, sheet_name='Adult', index=False)\n","\n","  print('Accuracy', Accuracy)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.8354114713216958\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7668329177057357\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.6271820448877805\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7481296758104738\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.8478802992518704\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7556109725685786\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.6970074812967582\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.8192019950124688\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7780548628428927\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7418952618453866\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7693266832917706\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.830423940149626\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7531172069825436\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.770573566084788\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7605985037406484\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.6758104738154613\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7718204488778054\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.78428927680798\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.685785536159601\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.8478802992518704\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","overflow encountered in add\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7531172069825436\n"],"name":"stdout"},{"output_type":"stream","text":["invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.683291770573566\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7743142144638404\n"],"name":"stdout"},{"output_type":"stream","text":["overflow encountered in exp\n","overflow encountered in add\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","overflow encountered in add\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n","invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy 0.7817955112219451\n"],"name":"stdout"}]}]}